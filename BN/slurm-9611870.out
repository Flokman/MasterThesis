
The following have been reloaded with a version change:
  1) FFTW/3.3.7-gompic-2018a => FFTW/3.3.7-gompi-2018a
  2) OpenMPI/2.1.2-gcccuda-2018a => OpenMPI/2.1.2-GCC-6.4.0-2.28
  3) Python/3.6.4-fosscuda-2018a => Python/3.6.4-foss-2018a
  4) ScaLAPACK/2.0.2-gompic-2018a-OpenBLAS-0.2.20 => ScaLAPACK/2.0.2-gompi-2018a-OpenBLAS-0.2.20

2020-02-18 09:53:00.285458: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-18 09:53:00.285977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GRID V100D-32Q major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:02:00.0
totalMemory: 31.87GiB freeMemory: 29.56GiB
2020-02-18 09:53:00.286027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-02-18 09:53:01.263267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-18 09:53:01.263363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-02-18 09:53:01.263392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-02-18 09:53:01.263514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28669 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2020-02-18 09:53:01.265234: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Random seed for replication: 530
dataset_name = /Messidor2_PNG_AUG_256.hdf5, batch_size = 32, num_classes = 5, epochs = 1,
        MCBN_amount_of_predictions = 50, MCBN_batch_size = 250, test_img_idx = 609,
        train_test_split = 0.8, to_shuffle = True, augmentation = False, label_count = [1261, 1416, 1397, 1455, 1463],
        label_normalizer = True, save_augmentation_to_hdf5 = True, learn rate = 1e-05,
        add_mcbn_inside = True, train_all_layers = True, weights_to_use = None,
        mcbn = True, es_patience = 30, train_val_split = 0.9
x_train shape: (5593, 256, 256, 3)
5593 train samples
1399 test samples
block1_conv1
1
block1_conv2
3
block2_conv1
6
block2_conv2
8
block3_conv1
11
block3_conv2
13
block3_conv3
15
block4_conv1
18
block4_conv2
20
block4_conv3
22
block5_conv1
25
block5_conv2
27
block5_conv3
29
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 256, 256, 3)       0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      
_________________________________________________________________
MCBatchNorm_1 (MCBatchNorm)  (None, 256, 256, 64)      0         
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     
_________________________________________________________________
MCBatchNorm_2 (MCBatchNorm)  (None, 256, 256, 64)      0         
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     
_________________________________________________________________
MCBatchNorm_3 (MCBatchNorm)  (None, 128, 128, 128)     0         
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    
_________________________________________________________________
MCBatchNorm_4 (MCBatchNorm)  (None, 128, 128, 128)     0         
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    
_________________________________________________________________
MCBatchNorm_5 (MCBatchNorm)  (None, 64, 64, 256)       0         
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
MCBatchNorm_6 (MCBatchNorm)  (None, 64, 64, 256)       0         
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
MCBatchNorm_7 (MCBatchNorm)  (None, 64, 64, 256)       0         
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   
_________________________________________________________________
MCBatchNorm_8 (MCBatchNorm)  (None, 32, 32, 512)       0         
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
MCBatchNorm_9 (MCBatchNorm)  (None, 32, 32, 512)       0         
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
MCBatchNorm_10 (MCBatchNorm) (None, 32, 32, 512)       0         
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
MCBatchNorm_11 (MCBatchNorm) (None, 16, 16, 512)       0         
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
MCBatchNorm_12 (MCBatchNorm) (None, 16, 16, 512)       0         
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
MCBatchNorm_13 (MCBatchNorm) (None, 16, 16, 512)       0         
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         
_________________________________________________________________
flatten (Flatten)            (None, 32768)             0         
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              134221824 
_________________________________________________________________
MCBatchNorm_14 (MCBatchNorm) (None, 4096)              0         
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312  
_________________________________________________________________
MCBatchNorm_15 (MCBatchNorm) (None, 4096)              0         
_________________________________________________________________
predictions (Dense)          (None, 5)                 20485     
=================================================================
Total params: 165,738,309
Trainable params: 165,738,309
Non-trainable params: 0
_________________________________________________________________
Start fitting monte carlo mcbn model
Epoch 1/1
 - 93s - loss: 1.7922 - acc: 0.3703 - val_loss: 1.6094 - val_acc: 0.2196
/software/software/h5py/2.7.1-fosscuda-2018a-Python-3.6.4/lib/python3.6/site-packages/h5py-2.7.1-py3.6-linux-x86_64.egg/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Traceback (most recent call last):
  File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
RuntimeError: Can't decrement id ref count (file write failed: time = Tue Feb 18 09:54:58 2020
, filename = 'path_to_my_weights.h5', file descriptor = 46, errno = 122, error message = 'Disk quota exceeded', buf = 0x314a1f88, total write size = 1984, bytes this sub-write = 1984, bytes actually written = 18446744073709551615, offset = 11702272)
Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
Traceback (most recent call last):
  File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
RuntimeError: Can't decrement id ref count (file write failed: time = Tue Feb 18 09:54:58 2020
, filename = 'path_to_my_weights.h5', file descriptor = 46, errno = 122, error message = 'Disk quota exceeded', buf = 0x314a1f88, total write size = 1984, bytes this sub-write = 1984, bytes actually written = 18446744073709551615, offset = 11702272)
Traceback (most recent call last):
  File "/software/software/TensorFlow/1.12.0-fosscuda-2018a-Python-3.6.4/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py", line 1444, in save_weights
    saving.save_weights_to_hdf5_group(f, self.layers)
  File "/software/software/TensorFlow/1.12.0-fosscuda-2018a-Python-3.6.4/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py", line 743, in save_weights_to_hdf5_group
    param_dset[:] = val
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "/software/software/h5py/2.7.1-fosscuda-2018a-Python-3.6.4/lib/python3.6/site-packages/h5py-2.7.1-py3.6-linux-x86_64.egg/h5py/_hl/dataset.py", line 632, in __setitem__
    self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5d.pyx", line 221, in h5py.h5d.DatasetID.write
  File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
  File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
OSError: Can't prepare for writing data (file write failed: time = Tue Feb 18 09:54:58 2020
, filename = 'path_to_my_weights.h5', file descriptor = 46, errno = 122, error message = 'Disk quota exceeded', buf = 0x1071e000000, total write size = 9437184, bytes this sub-write = 9437184, bytes actually written = 18446744073709551615, offset = 11706304)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "mcbn_astro.py", line 456, in <module>
    main()
  File "mcbn_astro.py", line 399, in main
    mcbn_model.save_weights('path_to_my_weights.h5')
  File "/software/software/TensorFlow/1.12.0-fosscuda-2018a-Python-3.6.4/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py", line 1444, in save_weights
    saving.save_weights_to_hdf5_group(f, self.layers)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "/software/software/h5py/2.7.1-fosscuda-2018a-Python-3.6.4/lib/python3.6/site-packages/h5py-2.7.1-py3.6-linux-x86_64.egg/h5py/_hl/files.py", line 317, in __exit__
    self.close()
  File "/software/software/h5py/2.7.1-fosscuda-2018a-Python-3.6.4/lib/python3.6/site-packages/h5py-2.7.1-py3.6-linux-x86_64.egg/h5py/_hl/files.py", line 299, in close
    h5i.dec_ref(id_)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
RuntimeError: Problems closing file (file write failed: time = Tue Feb 18 09:54:58 2020
, filename = 'path_to_my_weights.h5', file descriptor = 46, errno = 122, error message = 'Disk quota exceeded', buf = 0x2fb31280, total write size = 4096, bytes this sub-write = 4096, bytes actually written = 18446744073709551615, offset = 4096)
[pg-gpu35:06084] *** Process received signal ***
[pg-gpu35:06084] Signal: Segmentation fault (11)
[pg-gpu35:06084] Signal code: Address not mapped (1)
[pg-gpu35:06084] Failing at address: 0x558
[pg-gpu35:06084] [ 0] /lib64/libpthread.so.0(+0xf5f0)[0x7fc2b64735f0]
[pg-gpu35:06084] [ 1] /software/software/HDF5/1.10.1-fosscuda-2018a/lib/libhdf5.so.101(H5F_close+0x25)[0x7fc2627f2595]
[pg-gpu35:06084] [ 2] /software/software/HDF5/1.10.1-fosscuda-2018a/lib/libhdf5.so.101(H5I_dec_ref+0x78)[0x7fc2628647b8]
[pg-gpu35:06084] [ 3] /software/software/HDF5/1.10.1-fosscuda-2018a/lib/libhdf5.so.101(H5I_dec_app_ref+0x24)[0x7fc262864884]
[pg-gpu35:06084] [ 4] /software/software/HDF5/1.10.1-fosscuda-2018a/lib/libhdf5.so.101(H5Idec_ref+0x34)[0x7fc262864964]
[pg-gpu35:06084] [ 5] /software/software/h5py/2.7.1-fosscuda-2018a-Python-3.6.4/lib/python3.6/site-packages/h5py-2.7.1-py3.6-linux-x86_64.egg/h5py/defs.cpython-36m-x86_64-linux-gnu.so(+0x1c12f)[0x7fc260cd012f]
[pg-gpu35:06084] [ 6] /software/software/h5py/2.7.1-fosscuda-2018a-Python-3.6.4/lib/python3.6/site-packages/h5py-2.7.1-py3.6-linux-x86_64.egg/h5py/_objects.cpython-36m-x86_64-linux-gnu.so(+0xcf4d)[0x7fc260cfff4d]
[pg-gpu35:06084] [ 7] /software/software/Python/3.6.4-foss-2018a/lib/libpython3.6m.so.1.0(+0xb0009)[0x7fc2b6c36009]
[pg-gpu35:06084] [ 8] /software/software/Python/3.6.4-foss-2018a/lib/libpython3.6m.so.1.0(+0x17d057)[0x7fc2b6d03057]
[pg-gpu35:06084] [ 9] /software/software/Python/3.6.4-foss-2018a/lib/libpython3.6m.so.1.0(+0x17d067)[0x7fc2b6d03067]
[pg-gpu35:06084] [10] /software/software/Python/3.6.4-foss-2018a/lib/libpython3.6m.so.1.0(+0x17d067)[0x7fc2b6d03067]
[pg-gpu35:06084] [11] /software/software/Python/3.6.4-foss-2018a/lib/libpython3.6m.so.1.0(+0x17d067)[0x7fc2b6d03067]
[pg-gpu35:06084] [12] /software/software/Python/3.6.4-foss-2018a/lib/libpython3.6m.so.1.0(+0x17d067)[0x7fc2b6d03067]
[pg-gpu35:06084] [13] /software/software/Python/3.6.4-foss-2018a/lib/libpython3.6m.so.1.0(+0x17d067)[0x7fc2b6d03067]
[pg-gpu35:06084] [14] /software/software/Python/3.6.4-foss-2018a/lib/libpython3.6m.so.1.0(+0x17d067)[0x7fc2b6d03067]
[pg-gpu35:06084] [15] /software/software/Python/3.6.4-foss-2018a/lib/libpython3.6m.so.1.0(+0xc3b97)[0x7fc2b6c49b97]
[pg-gpu35:06084] [16] /software/software/Python/3.6.4-foss-2018a/lib/libpython3.6m.so.1.0(PyDict_SetItemString+0x38)[0x7fc2b6c4e1e8]
[pg-gpu35:06084] [17] /software/software/Python/3.6.4-foss-2018a/lib/libpython3.6m.so.1.0(PyImport_Cleanup+0x8c)[0x7fc2b6cea6ac]
[pg-gpu35:06084] [18] /software/software/Python/3.6.4-foss-2018a/lib/libpython3.6m.so.1.0(Py_FinalizeEx+0x6b)[0x7fc2b6cf516b]
[pg-gpu35:06084] [19] /software/software/Python/3.6.4-foss-2018a/lib/libpython3.6m.so.1.0(Py_Main+0x6c9)[0x7fc2b6d0ff69]
[pg-gpu35:06084] [20] python(main+0x177)[0x400b87]
[pg-gpu35:06084] [21] /lib64/libc.so.6(__libc_start_main+0xf5)[0x7fc2b5eb5505]
[pg-gpu35:06084] [22] python[0x400c3f]
[pg-gpu35:06084] *** End of error message ***
/var/spool/slurmd/job9611870/slurm_script: line 14:  6084 Segmentation fault      python mcbn_astro.py


###############################################################################
Peregrine Cluster
Job 9611870 for user 's2934833'
Finished at: Tue Feb 18 09:55:00 CET 2020

Job details:
============

Name                : mcbn_astro
User                : s2934833
Partition           : gpu
Nodes               : pg-gpu35
Cores               : 12
State               : FAILED
Submit              : 2020-02-18T09:51:44
Start               : 2020-02-18T09:52:35
End                 : 2020-02-18T09:54:59
Reserved walltime   : 04:00:00
Used walltime       : 00:02:24
Used CPU time       : 00:01:55 (efficiency:  6.69%)
% User (Computation): 78.06%
% System (I/O)      : 21.94%
Mem reserved        : 62.50G/node
Max Mem used        : 9.57G (pg-gpu35)
Max Disk Write      : 184.32K (pg-gpu35)
Max Disk Read       : 5.47M (pg-gpu35)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/additional_information/scientific_output

################################################################################
