
The following have been reloaded with a version change:
  1) FFTW/3.3.8-gompic-2019b => FFTW/3.3.8-gompi-2019b
  2) OpenMPI/3.1.4-gcccuda-2019b => OpenMPI/3.1.4-GCC-8.3.0
  3) ScaLAPACK/2.0.2-gompic-2019b => ScaLAPACK/2.0.2-gompi-2019b
  4) SciPy-bundle/2019.10-fosscuda-2019b-Python-3.7.4 => SciPy-bundle/2019.10-foss-2019b-Python-3.7.4

2020-05-25 10:43:06.493221: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-25 10:43:19.528271: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-05-25 10:43:19.534857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-25 10:43:19.535300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-25 10:43:19.535348: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-25 10:43:19.540556: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-25 10:43:19.544100: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-25 10:43:19.545893: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-25 10:43:19.549283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-25 10:43:19.551235: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-25 10:43:19.556387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-25 10:43:19.556568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-25 10:43:19.557362: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-25 10:43:19.557731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-05-25 10:43:19.560230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-25 10:43:19.560623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-25 10:43:19.560669: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-25 10:43:19.560704: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-25 10:43:19.560726: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-25 10:43:19.560746: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-25 10:43:19.560767: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-25 10:43:19.560788: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-25 10:43:19.560808: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-25 10:43:19.560906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-25 10:43:19.561336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-25 10:43:19.561688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-05-25 10:43:19.561738: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-25 10:43:20.171504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-25 10:43:20.171583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-05-25 10:43:20.171598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-05-25 10:43:20.171856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-25 10:43:20.172437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-25 10:43:20.172959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-25 10:43:20.173367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28652 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2020-05-25 10:43:20.173952: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 10:43:35.888248: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-25 10:43:36.182753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-25 10:43:38.521570: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 10:43:38.521721: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1259] Profiler found 1 GPUs
2020-05-25 10:43:38.524714: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1
2020-05-25 10:43:38.625663: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-05-25 10:43:38.626392: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-05-25 10:43:38.685785: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 10:43:38.685953: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
dataset_name = CIFAR10, batch_size = 32, num_classes = 10, epochs = 500,
          test_img_idx = 5454, train_test_split = 0.7, to_shuffle = False,
          augmentation = False, label_normalizer = False,
          save_augmentation_to_hdf5 = True, learn rate = 1e-05, train_all_layers = True,
          weights_to_use = imagenet, es_patience = 20, train_val_split = 0.875,
          N_ENSEMBLE_MEMBERS = 3, MIN_DELTA = 0.005, Early_monitor = val_accuracy
x_train shape: (50000, 32, 32, 3)
x_train_re shape: (50000, 75, 75, 3)
50000 train samples
10000 test samples
Total labels in train set:  [5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]
Labels in validation set:  [139, 115, 122, 105, 118, 122, 127, 129, 131, 142]
Labels in test set:  [861, 885, 878, 895, 882, 878, 873, 871, 869, 858]
Xception
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 75, 75, 3)]  0                                            
__________________________________________________________________________________________________
block1_conv1 (Conv2D)           (None, 37, 37, 32)   864         input_1[0][0]                    
__________________________________________________________________________________________________
block1_conv1_bn (BatchNormaliza (None, 37, 37, 32)   128         block1_conv1[0][0]               
__________________________________________________________________________________________________
block1_conv1_act (Activation)   (None, 37, 37, 32)   0           block1_conv1_bn[0][0]            
__________________________________________________________________________________________________
block1_conv2 (Conv2D)           (None, 35, 35, 64)   18432       block1_conv1_act[0][0]           
__________________________________________________________________________________________________
block1_conv2_bn (BatchNormaliza (None, 35, 35, 64)   256         block1_conv2[0][0]               
__________________________________________________________________________________________________
block1_conv2_act (Activation)   (None, 35, 35, 64)   0           block1_conv2_bn[0][0]            
__________________________________________________________________________________________________
block2_sepconv1 (SeparableConv2 (None, 35, 35, 128)  8768        block1_conv2_act[0][0]           
__________________________________________________________________________________________________
block2_sepconv1_bn (BatchNormal (None, 35, 35, 128)  512         block2_sepconv1[0][0]            
__________________________________________________________________________________________________
block2_sepconv2_act (Activation (None, 35, 35, 128)  0           block2_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block2_sepconv2 (SeparableConv2 (None, 35, 35, 128)  17536       block2_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block2_sepconv2_bn (BatchNormal (None, 35, 35, 128)  512         block2_sepconv2[0][0]            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 18, 18, 128)  8192        block1_conv2_act[0][0]           
__________________________________________________________________________________________________
block2_pool (MaxPooling2D)      (None, 18, 18, 128)  0           block2_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 18, 18, 128)  512         conv2d[0][0]                     
__________________________________________________________________________________________________
add (Add)                       (None, 18, 18, 128)  0           block2_pool[0][0]                
                                                                 batch_normalization[0][0]        
__________________________________________________________________________________________________
block3_sepconv1_act (Activation (None, 18, 18, 128)  0           add[0][0]                        
__________________________________________________________________________________________________
block3_sepconv1 (SeparableConv2 (None, 18, 18, 256)  33920       block3_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block3_sepconv1_bn (BatchNormal (None, 18, 18, 256)  1024        block3_sepconv1[0][0]            
__________________________________________________________________________________________________
block3_sepconv2_act (Activation (None, 18, 18, 256)  0           block3_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block3_sepconv2 (SeparableConv2 (None, 18, 18, 256)  67840       block3_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block3_sepconv2_bn (BatchNormal (None, 18, 18, 256)  1024        block3_sepconv2[0][0]            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 9, 9, 256)    32768       add[0][0]                        
__________________________________________________________________________________________________
block3_pool (MaxPooling2D)      (None, 9, 9, 256)    0           block3_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 9, 9, 256)    1024        conv2d_1[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 9, 9, 256)    0           block3_pool[0][0]                
                                                                 batch_normalization_1[0][0]      
__________________________________________________________________________________________________
block4_sepconv1_act (Activation (None, 9, 9, 256)    0           add_1[0][0]                      
__________________________________________________________________________________________________
block4_sepconv1 (SeparableConv2 (None, 9, 9, 728)    188672      block4_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block4_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block4_sepconv1[0][0]            
__________________________________________________________________________________________________
block4_sepconv2_act (Activation (None, 9, 9, 728)    0           block4_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block4_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block4_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block4_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block4_sepconv2[0][0]            
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 5, 5, 728)    186368      add_1[0][0]                      
__________________________________________________________________________________________________
block4_pool (MaxPooling2D)      (None, 5, 5, 728)    0           block4_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 5, 5, 728)    2912        conv2d_2[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, 5, 5, 728)    0           block4_pool[0][0]                
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
block5_sepconv1_act (Activation (None, 5, 5, 728)    0           add_2[0][0]                      
__________________________________________________________________________________________________
block5_sepconv1 (SeparableConv2 (None, 5, 5, 728)    536536      block5_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block5_sepconv1_bn (BatchNormal (None, 5, 5, 728)    2912        block5_sepconv1[0][0]            
__________________________________________________________________________________________________
block5_sepconv2_act (Activation (None, 5, 5, 728)    0           block5_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block5_sepconv2 (SeparableConv2 (None, 5, 5, 728)    536536      block5_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block5_sepconv2_bn (BatchNormal (None, 5, 5, 728)    2912        block5_sepconv2[0][0]            
__________________________________________________________________________________________________
block5_sepconv3_act (Activation (None, 5, 5, 728)    0           block5_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block5_sepconv3 (SeparableConv2 (None, 5, 5, 728)    536536      block5_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block5_sepconv3_bn (BatchNormal (None, 5, 5, 728)    2912        block5_sepconv3[0][0]            
__________________________________________________________________________________________________
add_3 (Add)                     (None, 5, 5, 728)    0           block5_sepconv3_bn[0][0]         
                                                                 add_2[0][0]                      
__________________________________________________________________________________________________
block6_sepconv1_act (Activation (None, 5, 5, 728)    0           add_3[0][0]                      
__________________________________________________________________________________________________
block6_sepconv1 (SeparableConv2 (None, 5, 5, 728)    536536      block6_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block6_sepconv1_bn (BatchNormal (None, 5, 5, 728)    2912        block6_sepconv1[0][0]            
__________________________________________________________________________________________________
block6_sepconv2_act (Activation (None, 5, 5, 728)    0           block6_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block6_sepconv2 (SeparableConv2 (None, 5, 5, 728)    536536      block6_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block6_sepconv2_bn (BatchNormal (None, 5, 5, 728)    2912        block6_sepconv2[0][0]            
__________________________________________________________________________________________________
block6_sepconv3_act (Activation (None, 5, 5, 728)    0           block6_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block6_sepconv3 (SeparableConv2 (None, 5, 5, 728)    536536      block6_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block6_sepconv3_bn (BatchNormal (None, 5, 5, 728)    2912        block6_sepconv3[0][0]            
__________________________________________________________________________________________________
add_4 (Add)                     (None, 5, 5, 728)    0           block6_sepconv3_bn[0][0]         
                                                                 add_3[0][0]                      
__________________________________________________________________________________________________
block7_sepconv1_act (Activation (None, 5, 5, 728)    0           add_4[0][0]                      
__________________________________________________________________________________________________
block7_sepconv1 (SeparableConv2 (None, 5, 5, 728)    536536      block7_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block7_sepconv1_bn (BatchNormal (None, 5, 5, 728)    2912        block7_sepconv1[0][0]            
__________________________________________________________________________________________________
block7_sepconv2_act (Activation (None, 5, 5, 728)    0           block7_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block7_sepconv2 (SeparableConv2 (None, 5, 5, 728)    536536      block7_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block7_sepconv2_bn (BatchNormal (None, 5, 5, 728)    2912        block7_sepconv2[0][0]            
__________________________________________________________________________________________________
block7_sepconv3_act (Activation (None, 5, 5, 728)    0           block7_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block7_sepconv3 (SeparableConv2 (None, 5, 5, 728)    536536      block7_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block7_sepconv3_bn (BatchNormal (None, 5, 5, 728)    2912        block7_sepconv3[0][0]            
__________________________________________________________________________________________________
add_5 (Add)                     (None, 5, 5, 728)    0           block7_sepconv3_bn[0][0]         
                                                                 add_4[0][0]                      
__________________________________________________________________________________________________
block8_sepconv1_act (Activation (None, 5, 5, 728)    0           add_5[0][0]                      
__________________________________________________________________________________________________
block8_sepconv1 (SeparableConv2 (None, 5, 5, 728)    536536      block8_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block8_sepconv1_bn (BatchNormal (None, 5, 5, 728)    2912        block8_sepconv1[0][0]            
__________________________________________________________________________________________________
block8_sepconv2_act (Activation (None, 5, 5, 728)    0           block8_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block8_sepconv2 (SeparableConv2 (None, 5, 5, 728)    536536      block8_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block8_sepconv2_bn (BatchNormal (None, 5, 5, 728)    2912        block8_sepconv2[0][0]            
__________________________________________________________________________________________________
block8_sepconv3_act (Activation (None, 5, 5, 728)    0           block8_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block8_sepconv3 (SeparableConv2 (None, 5, 5, 728)    536536      block8_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block8_sepconv3_bn (BatchNormal (None, 5, 5, 728)    2912        block8_sepconv3[0][0]            
__________________________________________________________________________________________________
add_6 (Add)                     (None, 5, 5, 728)    0           block8_sepconv3_bn[0][0]         
                                                                 add_5[0][0]                      
__________________________________________________________________________________________________
block9_sepconv1_act (Activation (None, 5, 5, 728)    0           add_6[0][0]                      
__________________________________________________________________________________________________
block9_sepconv1 (SeparableConv2 (None, 5, 5, 728)    536536      block9_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block9_sepconv1_bn (BatchNormal (None, 5, 5, 728)    2912        block9_sepconv1[0][0]            
__________________________________________________________________________________________________
block9_sepconv2_act (Activation (None, 5, 5, 728)    0           block9_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block9_sepconv2 (SeparableConv2 (None, 5, 5, 728)    536536      block9_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block9_sepconv2_bn (BatchNormal (None, 5, 5, 728)    2912        block9_sepconv2[0][0]            
__________________________________________________________________________________________________
block9_sepconv3_act (Activation (None, 5, 5, 728)    0           block9_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block9_sepconv3 (SeparableConv2 (None, 5, 5, 728)    536536      block9_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block9_sepconv3_bn (BatchNormal (None, 5, 5, 728)    2912        block9_sepconv3[0][0]            
__________________________________________________________________________________________________
add_7 (Add)                     (None, 5, 5, 728)    0           block9_sepconv3_bn[0][0]         
                                                                 add_6[0][0]                      
__________________________________________________________________________________________________
block10_sepconv1_act (Activatio (None, 5, 5, 728)    0           add_7[0][0]                      
__________________________________________________________________________________________________
block10_sepconv1 (SeparableConv (None, 5, 5, 728)    536536      block10_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block10_sepconv1_bn (BatchNorma (None, 5, 5, 728)    2912        block10_sepconv1[0][0]           
__________________________________________________________________________________________________
block10_sepconv2_act (Activatio (None, 5, 5, 728)    0           block10_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block10_sepconv2 (SeparableConv (None, 5, 5, 728)    536536      block10_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block10_sepconv2_bn (BatchNorma (None, 5, 5, 728)    2912        block10_sepconv2[0][0]           
__________________________________________________________________________________________________
block10_sepconv3_act (Activatio (None, 5, 5, 728)    0           block10_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
block10_sepconv3 (SeparableConv (None, 5, 5, 728)    536536      block10_sepconv3_act[0][0]       
__________________________________________________________________________________________________
block10_sepconv3_bn (BatchNorma (None, 5, 5, 728)    2912        block10_sepconv3[0][0]           
__________________________________________________________________________________________________
add_8 (Add)                     (None, 5, 5, 728)    0           block10_sepconv3_bn[0][0]        
                                                                 add_7[0][0]                      
__________________________________________________________________________________________________
block11_sepconv1_act (Activatio (None, 5, 5, 728)    0           add_8[0][0]                      
__________________________________________________________________________________________________
block11_sepconv1 (SeparableConv (None, 5, 5, 728)    536536      block11_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block11_sepconv1_bn (BatchNorma (None, 5, 5, 728)    2912        block11_sepconv1[0][0]           
__________________________________________________________________________________________________
block11_sepconv2_act (Activatio (None, 5, 5, 728)    0           block11_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block11_sepconv2 (SeparableConv (None, 5, 5, 728)    536536      block11_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block11_sepconv2_bn (BatchNorma (None, 5, 5, 728)    2912        block11_sepconv2[0][0]           
__________________________________________________________________________________________________
block11_sepconv3_act (Activatio (None, 5, 5, 728)    0           block11_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
block11_sepconv3 (SeparableConv (None, 5, 5, 728)    536536      block11_sepconv3_act[0][0]       
__________________________________________________________________________________________________
block11_sepconv3_bn (BatchNorma (None, 5, 5, 728)    2912        block11_sepconv3[0][0]           
__________________________________________________________________________________________________
add_9 (Add)                     (None, 5, 5, 728)    0           block11_sepconv3_bn[0][0]        
                                                                 add_8[0][0]                      
__________________________________________________________________________________________________
block12_sepconv1_act (Activatio (None, 5, 5, 728)    0           add_9[0][0]                      
__________________________________________________________________________________________________
block12_sepconv1 (SeparableConv (None, 5, 5, 728)    536536      block12_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block12_sepconv1_bn (BatchNorma (None, 5, 5, 728)    2912        block12_sepconv1[0][0]           
__________________________________________________________________________________________________
block12_sepconv2_act (Activatio (None, 5, 5, 728)    0           block12_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block12_sepconv2 (SeparableConv (None, 5, 5, 728)    536536      block12_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block12_sepconv2_bn (BatchNorma (None, 5, 5, 728)    2912        block12_sepconv2[0][0]           
__________________________________________________________________________________________________
block12_sepconv3_act (Activatio (None, 5, 5, 728)    0           block12_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
block12_sepconv3 (SeparableConv (None, 5, 5, 728)    536536      block12_sepconv3_act[0][0]       
__________________________________________________________________________________________________
block12_sepconv3_bn (BatchNorma (None, 5, 5, 728)    2912        block12_sepconv3[0][0]           
__________________________________________________________________________________________________
add_10 (Add)                    (None, 5, 5, 728)    0           block12_sepconv3_bn[0][0]        
                                                                 add_9[0][0]                      
__________________________________________________________________________________________________
block13_sepconv1_act (Activatio (None, 5, 5, 728)    0           add_10[0][0]                     
__________________________________________________________________________________________________
block13_sepconv1 (SeparableConv (None, 5, 5, 728)    536536      block13_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block13_sepconv1_bn (BatchNorma (None, 5, 5, 728)    2912        block13_sepconv1[0][0]           
__________________________________________________________________________________________________
block13_sepconv2_act (Activatio (None, 5, 5, 728)    0           block13_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block13_sepconv2 (SeparableConv (None, 5, 5, 1024)   752024      block13_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block13_sepconv2_bn (BatchNorma (None, 5, 5, 1024)   4096        block13_sepconv2[0][0]           
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 3, 3, 1024)   745472      add_10[0][0]                     
__________________________________________________________________________________________________
block13_pool (MaxPooling2D)     (None, 3, 3, 1024)   0           block13_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 3, 3, 1024)   4096        conv2d_3[0][0]                   
__________________________________________________________________________________________________
add_11 (Add)                    (None, 3, 3, 1024)   0           block13_pool[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
block14_sepconv1 (SeparableConv (None, 3, 3, 1536)   1582080     add_11[0][0]                     
__________________________________________________________________________________________________
block14_sepconv1_bn (BatchNorma (None, 3, 3, 1536)   6144        block14_sepconv1[0][0]           
__________________________________________________________________________________________________
block14_sepconv1_act (Activatio (None, 3, 3, 1536)   0           block14_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block14_sepconv2 (SeparableConv (None, 3, 3, 2048)   3159552     block14_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block14_sepconv2_bn (BatchNorma (None, 3, 3, 2048)   8192        block14_sepconv2[0][0]           
__________________________________________________________________________________________________
block14_sepconv2_act (Activatio (None, 3, 3, 2048)   0           block14_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
flatten (Flatten)               (None, 18432)        0           block14_sepconv2_act[0][0]       
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         75501568    flatten[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
predictions (Dense)             (None, 10)           40970       fc2[0][0]                        
==================================================================================================
Total params: 113,185,330
Trainable params: 113,130,802
Non-trainable params: 54,528
__________________________________________________________________________________________________
Start fitting ensemble models
Length split part:  16667
Labels in this part of split:  [1667, 1656, 1712, 1682, 1675, 1579, 1703, 1687, 1681, 1625]
Train for 521 steps, validate for 40 steps
Epoch 1/500
521/521 - 44s - loss: 1.5204 - accuracy: 0.4756 - val_loss: 1.0972 - val_accuracy: 0.6040
Epoch 2/500
521/521 - 33s - loss: 0.8723 - accuracy: 0.6956 - val_loss: 1.0166 - val_accuracy: 0.6408
Epoch 3/500
521/521 - 27s - loss: 0.4943 - accuracy: 0.8351 - val_loss: 1.0565 - val_accuracy: 0.6624
Epoch 4/500
521/521 - 27s - loss: 0.2312 - accuracy: 0.9359 - val_loss: 1.2415 - val_accuracy: 0.6408
Epoch 5/500
521/521 - 27s - loss: 0.0815 - accuracy: 0.9867 - val_loss: 1.4398 - val_accuracy: 0.6440
Epoch 6/500
521/521 - 27s - loss: 0.0270 - accuracy: 0.9980 - val_loss: 1.6017 - val_accuracy: 0.6464
Epoch 7/500
521/521 - 27s - loss: 0.0110 - accuracy: 0.9990 - val_loss: 1.7518 - val_accuracy: 0.6504
Epoch 8/500
521/521 - 27s - loss: 0.0050 - accuracy: 0.9996 - val_loss: 1.8539 - val_accuracy: 0.6512
Epoch 9/500
521/521 - 27s - loss: 0.0249 - accuracy: 0.9925 - val_loss: 2.0236 - val_accuracy: 0.6400
Epoch 10/500
521/521 - 27s - loss: 0.0367 - accuracy: 0.9906 - val_loss: 2.0229 - val_accuracy: 0.6368
Epoch 11/500
521/521 - 27s - loss: 0.0068 - accuracy: 0.9990 - val_loss: 2.2431 - val_accuracy: 0.6536
Epoch 12/500
521/521 - 27s - loss: 0.0044 - accuracy: 0.9992 - val_loss: 2.1905 - val_accuracy: 0.6528
Epoch 13/500
521/521 - 27s - loss: 0.0217 - accuracy: 0.9949 - val_loss: 2.2873 - val_accuracy: 0.6448
Epoch 14/500
521/521 - 27s - loss: 0.0241 - accuracy: 0.9935 - val_loss: 2.2977 - val_accuracy: 0.6512
Epoch 15/500
521/521 - 27s - loss: 0.0168 - accuracy: 0.9956 - val_loss: 2.3929 - val_accuracy: 0.6608
Epoch 16/500
521/521 - 27s - loss: 0.0086 - accuracy: 0.9978 - val_loss: 2.4962 - val_accuracy: 0.6608
Epoch 17/500
521/521 - 27s - loss: 0.0056 - accuracy: 0.9988 - val_loss: 2.6181 - val_accuracy: 0.6552
Epoch 18/500
521/521 - 27s - loss: 0.0103 - accuracy: 0.9971 - val_loss: 2.7881 - val_accuracy: 0.6488
Epoch 19/500
521/521 - 27s - loss: 0.0259 - accuracy: 0.9926 - val_loss: 2.6410 - val_accuracy: 0.6448
Epoch 20/500
521/521 - 27s - loss: 0.0164 - accuracy: 0.9954 - val_loss: 2.5397 - val_accuracy: 0.6496
Epoch 21/500
521/521 - 27s - loss: 0.0087 - accuracy: 0.9975 - val_loss: 2.7480 - val_accuracy: 0.6544
Epoch 22/500
521/521 - 27s - loss: 0.0052 - accuracy: 0.9985 - val_loss: 2.7154 - val_accuracy: 0.6656
Epoch 23/500
521/521 - 27s - loss: 0.0056 - accuracy: 0.9989 - val_loss: 2.9480 - val_accuracy: 0.6608
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 10:54:18.821332: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 10:54:18.821480: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 10:54:18.821515: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 10:54:18.878980: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 10:54:18.879084: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00023: early stopping
Length split part:  16667
Labels in this part of split:  [1629, 1681, 1647, 1628, 1684, 1727, 1642, 1677, 1665, 1687]
Train for 521 steps, validate for 40 steps
Epoch 1/500
521/521 - 32s - loss: 1.4282 - accuracy: 0.5027 - val_loss: 1.0803 - val_accuracy: 0.6296
Epoch 2/500
521/521 - 27s - loss: 0.7634 - accuracy: 0.7361 - val_loss: 1.1839 - val_accuracy: 0.6232
Epoch 3/500
521/521 - 27s - loss: 0.3842 - accuracy: 0.8750 - val_loss: 1.2719 - val_accuracy: 0.6488
Epoch 4/500
521/521 - 27s - loss: 0.1575 - accuracy: 0.9610 - val_loss: 1.6262 - val_accuracy: 0.6512
Epoch 5/500
521/521 - 27s - loss: 0.0611 - accuracy: 0.9879 - val_loss: 1.9572 - val_accuracy: 0.6432
Epoch 6/500
521/521 - 27s - loss: 0.0324 - accuracy: 0.9936 - val_loss: 2.2049 - val_accuracy: 0.6496
Epoch 7/500
521/521 - 27s - loss: 0.0234 - accuracy: 0.9941 - val_loss: 2.2357 - val_accuracy: 0.6408
Epoch 8/500
521/521 - 27s - loss: 0.0209 - accuracy: 0.9954 - val_loss: 2.5024 - val_accuracy: 0.6504
Epoch 9/500
521/521 - 27s - loss: 0.0167 - accuracy: 0.9955 - val_loss: 2.6280 - val_accuracy: 0.6384
Epoch 10/500
521/521 - 27s - loss: 0.0229 - accuracy: 0.9939 - val_loss: 3.0512 - val_accuracy: 0.6480
Epoch 11/500
521/521 - 27s - loss: 0.0338 - accuracy: 0.9912 - val_loss: 3.1373 - val_accuracy: 0.6376
Epoch 12/500
521/521 - 27s - loss: 0.0129 - accuracy: 0.9973 - val_loss: 3.0652 - val_accuracy: 0.6480
Epoch 13/500
521/521 - 27s - loss: 0.0031 - accuracy: 0.9996 - val_loss: 3.1539 - val_accuracy: 0.6496
Epoch 14/500
521/521 - 27s - loss: 0.0044 - accuracy: 0.9989 - val_loss: 3.2873 - val_accuracy: 0.6512
Epoch 15/500
521/521 - 27s - loss: 0.0036 - accuracy: 0.9992 - val_loss: 3.3277 - val_accuracy: 0.6480
Epoch 16/500
521/521 - 27s - loss: 0.0056 - accuracy: 0.9990 - val_loss: 3.1907 - val_accuracy: 0.6496
Epoch 17/500
521/521 - 27s - loss: 0.0516 - accuracy: 0.9830 - val_loss: 3.3579 - val_accuracy: 0.6440
Epoch 18/500
521/521 - 27s - loss: 0.0177 - accuracy: 0.9951 - val_loss: 3.4736 - val_accuracy: 0.6536
Epoch 19/500
521/521 - 27s - loss: 0.0071 - accuracy: 0.9983 - val_loss: 3.9519 - val_accuracy: 0.6576
Epoch 20/500
521/521 - 27s - loss: 0.0101 - accuracy: 0.9971 - val_loss: 3.4148 - val_accuracy: 0.6488
Epoch 21/500
521/521 - 27s - loss: 0.0085 - accuracy: 0.9981 - val_loss: 3.7963 - val_accuracy: 0.6520
Epoch 22/500
521/521 - 27s - loss: 0.0027 - accuracy: 0.9996 - val_loss: 4.3434 - val_accuracy: 0.6632
Epoch 23/500
521/521 - 27s - loss: 3.4219e-04 - accuracy: 1.0000 - val_loss: 3.8697 - val_accuracy: 0.6640
Epoch 24/500
521/521 - 27s - loss: 1.3659e-04 - accuracy: 1.0000 - val_loss: 3.9550 - val_accuracy: 0.6688
Epoch 25/500
521/521 - 27s - loss: 9.6850e-05 - accuracy: 1.0000 - val_loss: 4.1424 - val_accuracy: 0.6656
Epoch 26/500
521/521 - 27s - loss: 7.2585e-05 - accuracy: 1.0000 - val_loss: 4.0422 - val_accuracy: 0.6672
Epoch 27/500
521/521 - 27s - loss: 5.5480e-05 - accuracy: 1.0000 - val_loss: 4.1651 - val_accuracy: 0.6664
Epoch 28/500
521/521 - 27s - loss: 4.2721e-05 - accuracy: 1.0000 - val_loss: 4.1939 - val_accuracy: 0.6656
Epoch 29/500
521/521 - 27s - loss: 3.3071e-05 - accuracy: 1.0000 - val_loss: 3.9333 - val_accuracy: 0.6704
Epoch 30/500
521/521 - 27s - loss: 2.5596e-05 - accuracy: 1.0000 - val_loss: 4.5516 - val_accuracy: 0.6664
Epoch 31/500
521/521 - 27s - loss: 1.9832e-05 - accuracy: 1.0000 - val_loss: 4.3682 - val_accuracy: 0.6672
Epoch 32/500
521/521 - 27s - loss: 1.5343e-05 - accuracy: 1.0000 - val_loss: 4.4549 - val_accuracy: 0.6624
Epoch 33/500
521/521 - 27s - loss: 1.1857e-05 - accuracy: 1.0000 - val_loss: 4.6821 - val_accuracy: 0.6672
Epoch 34/500
521/521 - 27s - loss: 9.1564e-06 - accuracy: 1.0000 - val_loss: 4.8303 - val_accuracy: 0.6680
Epoch 35/500
521/521 - 27s - loss: 7.0647e-06 - accuracy: 1.0000 - val_loss: 4.8923 - val_accuracy: 0.6656
Epoch 36/500
521/521 - 27s - loss: 5.4486e-06 - accuracy: 1.0000 - val_loss: 5.0195 - val_accuracy: 0.6624
Epoch 37/500
521/521 - 27s - loss: 4.1925e-06 - accuracy: 1.0000 - val_loss: 5.0412 - val_accuracy: 0.6648
Epoch 38/500
521/521 - 27s - loss: 3.2304e-06 - accuracy: 1.0000 - val_loss: 4.8908 - val_accuracy: 0.6672
Epoch 39/500
521/521 - 27s - loss: 2.4858e-06 - accuracy: 1.0000 - val_loss: 5.2601 - val_accuracy: 0.6648
Epoch 40/500
521/521 - 27s - loss: 1.9169e-06 - accuracy: 1.0000 - val_loss: 5.2071 - val_accuracy: 0.6664
Epoch 41/500
521/521 - 27s - loss: 1.4752e-06 - accuracy: 1.0000 - val_loss: 5.0925 - val_accuracy: 0.6664
Epoch 42/500
521/521 - 27s - loss: 1.1392e-06 - accuracy: 1.0000 - val_loss: 5.5908 - val_accuracy: 0.6640
Epoch 43/500
521/521 - 27s - loss: 8.8115e-07 - accuracy: 1.0000 - val_loss: 5.3228 - val_accuracy: 0.6688
Epoch 44/500
521/521 - 27s - loss: 6.8542e-07 - accuracy: 1.0000 - val_loss: 5.5832 - val_accuracy: 0.6680
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 11:14:06.830260: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 11:14:06.830407: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 11:14:06.830451: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 11:14:06.887199: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 11:14:06.887291: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00044: early stopping
Length split part:  16666
Labels in this part of split:  [1704, 1663, 1641, 1690, 1641, 1694, 1655, 1636, 1654, 1688]
Train for 521 steps, validate for 40 steps
Epoch 1/500
521/521 - 30s - loss: 1.2724 - accuracy: 0.5633 - val_loss: 0.9369 - val_accuracy: 0.6776
Epoch 2/500
521/521 - 27s - loss: 0.6801 - accuracy: 0.7640 - val_loss: 0.9459 - val_accuracy: 0.6712
Epoch 3/500
521/521 - 27s - loss: 0.3491 - accuracy: 0.8868 - val_loss: 0.9910 - val_accuracy: 0.6896
Epoch 4/500
521/521 - 27s - loss: 0.1363 - accuracy: 0.9654 - val_loss: 1.2152 - val_accuracy: 0.6824
Epoch 5/500
521/521 - 27s - loss: 0.0409 - accuracy: 0.9938 - val_loss: 1.3713 - val_accuracy: 0.6840
Epoch 6/500
521/521 - 27s - loss: 0.0155 - accuracy: 0.9981 - val_loss: 1.5198 - val_accuracy: 0.6952
Epoch 7/500
521/521 - 27s - loss: 0.0040 - accuracy: 0.9999 - val_loss: 1.6523 - val_accuracy: 0.6896
Epoch 8/500
521/521 - 27s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.7453 - val_accuracy: 0.6968
Epoch 9/500
521/521 - 27s - loss: 9.9225e-04 - accuracy: 1.0000 - val_loss: 1.8262 - val_accuracy: 0.6960
Epoch 10/500
521/521 - 27s - loss: 6.3266e-04 - accuracy: 1.0000 - val_loss: 1.8944 - val_accuracy: 0.6936
Epoch 11/500
521/521 - 27s - loss: 4.2524e-04 - accuracy: 1.0000 - val_loss: 1.9808 - val_accuracy: 0.6968
Epoch 12/500
521/521 - 27s - loss: 2.9276e-04 - accuracy: 1.0000 - val_loss: 2.0421 - val_accuracy: 0.6960
Epoch 13/500
521/521 - 27s - loss: 2.0485e-04 - accuracy: 1.0000 - val_loss: 2.1170 - val_accuracy: 0.6928
Epoch 14/500
521/521 - 27s - loss: 1.4513e-04 - accuracy: 1.0000 - val_loss: 2.1767 - val_accuracy: 0.6928
Epoch 15/500
521/521 - 27s - loss: 1.0326e-04 - accuracy: 1.0000 - val_loss: 2.2248 - val_accuracy: 0.6936
Epoch 16/500
521/521 - 27s - loss: 7.3982e-05 - accuracy: 1.0000 - val_loss: 2.2999 - val_accuracy: 0.6928
Epoch 17/500
521/521 - 27s - loss: 5.3375e-05 - accuracy: 1.0000 - val_loss: 2.3533 - val_accuracy: 0.6936
Epoch 18/500
521/521 - 27s - loss: 3.8659e-05 - accuracy: 1.0000 - val_loss: 2.4308 - val_accuracy: 0.6896
Epoch 19/500
521/521 - 27s - loss: 2.8148e-05 - accuracy: 1.0000 - val_loss: 2.4807 - val_accuracy: 0.6936
Epoch 20/500
521/521 - 27s - loss: 2.0572e-05 - accuracy: 1.0000 - val_loss: 2.5378 - val_accuracy: 0.6944
Epoch 21/500
521/521 - 27s - loss: 1.5026e-05 - accuracy: 1.0000 - val_loss: 2.5973 - val_accuracy: 0.6928
Epoch 22/500
521/521 - 27s - loss: 1.1037e-05 - accuracy: 1.0000 - val_loss: 2.6570 - val_accuracy: 0.6968
Epoch 23/500
521/521 - 27s - loss: 8.1307e-06 - accuracy: 1.0000 - val_loss: 2.7111 - val_accuracy: 0.6912
Epoch 24/500
521/521 - 27s - loss: 6.0076e-06 - accuracy: 1.0000 - val_loss: 2.7634 - val_accuracy: 0.6920
Epoch 25/500
521/521 - 27s - loss: 4.4528e-06 - accuracy: 1.0000 - val_loss: 2.8300 - val_accuracy: 0.6912
Epoch 26/500
521/521 - 27s - loss: 3.3038e-06 - accuracy: 1.0000 - val_loss: 2.8867 - val_accuracy: 0.6864
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 11:26:03.136029: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 11:26:03.136174: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 11:26:03.136207: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 11:26:03.165920: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 11:26:03.166005: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00026: early stopping
VGG16
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 75, 75, 3)]       0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 75, 75, 64)        1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 75, 75, 64)        36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 37, 37, 64)        0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 37, 37, 128)       73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 37, 37, 128)       147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 18, 18, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 18, 18, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 18, 18, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 18, 18, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 9, 9, 256)         0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 9, 9, 512)         1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         
_________________________________________________________________
flatten (Flatten)            (None, 2048)              0         
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              8392704   
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312  
_________________________________________________________________
predictions (Dense)          (None, 10)                40970     
=================================================================
Total params: 39,929,674
Trainable params: 39,929,674
Non-trainable params: 0
_________________________________________________________________
Start fitting ensemble models
Length split part:  16667
Labels in this part of split:  [1667, 1656, 1712, 1682, 1675, 1579, 1703, 1687, 1681, 1625]
Train for 521 steps, validate for 40 steps
Epoch 1/500
521/521 - 19s - loss: 1.2206 - accuracy: 0.5638 - val_loss: 0.9529 - val_accuracy: 0.6696
Epoch 2/500
521/521 - 16s - loss: 0.7926 - accuracy: 0.7246 - val_loss: 0.8058 - val_accuracy: 0.7088
Epoch 3/500
521/521 - 18s - loss: 0.6452 - accuracy: 0.7754 - val_loss: 0.7381 - val_accuracy: 0.7360
Epoch 4/500
521/521 - 15s - loss: 0.5266 - accuracy: 0.8153 - val_loss: 0.7517 - val_accuracy: 0.7360
Epoch 5/500
521/521 - 16s - loss: 0.4324 - accuracy: 0.8478 - val_loss: 0.7261 - val_accuracy: 0.7728
Epoch 6/500
521/521 - 15s - loss: 0.3532 - accuracy: 0.8749 - val_loss: 0.7332 - val_accuracy: 0.7704
Epoch 7/500
521/521 - 15s - loss: 0.2630 - accuracy: 0.9087 - val_loss: 0.7278 - val_accuracy: 0.7728
Epoch 8/500
521/521 - 15s - loss: 0.2041 - accuracy: 0.9302 - val_loss: 0.7946 - val_accuracy: 0.7824
Epoch 9/500
521/521 - 15s - loss: 0.1639 - accuracy: 0.9441 - val_loss: 0.8997 - val_accuracy: 0.7840
Epoch 10/500
521/521 - 15s - loss: 0.1129 - accuracy: 0.9621 - val_loss: 1.0267 - val_accuracy: 0.7832
Epoch 11/500
521/521 - 15s - loss: 0.0870 - accuracy: 0.9714 - val_loss: 1.1040 - val_accuracy: 0.7648
Epoch 12/500
521/521 - 15s - loss: 0.0611 - accuracy: 0.9804 - val_loss: 1.1516 - val_accuracy: 0.7704
Epoch 13/500
521/521 - 15s - loss: 0.0651 - accuracy: 0.9785 - val_loss: 1.1548 - val_accuracy: 0.7816
Epoch 14/500
521/521 - 15s - loss: 0.0588 - accuracy: 0.9807 - val_loss: 1.0081 - val_accuracy: 0.7696
Epoch 15/500
521/521 - 15s - loss: 0.0538 - accuracy: 0.9824 - val_loss: 1.1979 - val_accuracy: 0.7752
Epoch 16/500
521/521 - 15s - loss: 0.0459 - accuracy: 0.9839 - val_loss: 1.1253 - val_accuracy: 0.7760
Epoch 17/500
521/521 - 15s - loss: 0.0380 - accuracy: 0.9888 - val_loss: 1.2779 - val_accuracy: 0.7576
Epoch 18/500
521/521 - 15s - loss: 0.0341 - accuracy: 0.9891 - val_loss: 1.1513 - val_accuracy: 0.7568
Epoch 19/500
521/521 - 15s - loss: 0.0266 - accuracy: 0.9920 - val_loss: 1.1872 - val_accuracy: 0.7800
Epoch 20/500
521/521 - 15s - loss: 0.0361 - accuracy: 0.9881 - val_loss: 1.1851 - val_accuracy: 0.7960
Epoch 21/500
521/521 - 15s - loss: 0.0386 - accuracy: 0.9867 - val_loss: 1.2411 - val_accuracy: 0.7760
Epoch 22/500
521/521 - 15s - loss: 0.0174 - accuracy: 0.9945 - val_loss: 1.3070 - val_accuracy: 0.7648
Epoch 23/500
521/521 - 15s - loss: 0.0357 - accuracy: 0.9885 - val_loss: 1.1724 - val_accuracy: 0.7992
Epoch 24/500
521/521 - 15s - loss: 0.0310 - accuracy: 0.9897 - val_loss: 1.2346 - val_accuracy: 0.7728
Epoch 25/500
521/521 - 15s - loss: 0.0314 - accuracy: 0.9899 - val_loss: 1.1866 - val_accuracy: 0.7904
Epoch 26/500
521/521 - 15s - loss: 0.0253 - accuracy: 0.9912 - val_loss: 1.1181 - val_accuracy: 0.8056
Epoch 27/500
521/521 - 15s - loss: 0.0290 - accuracy: 0.9896 - val_loss: 1.1191 - val_accuracy: 0.7760
Epoch 28/500
521/521 - 15s - loss: 0.0257 - accuracy: 0.9911 - val_loss: 1.1720 - val_accuracy: 0.7888
Epoch 29/500
521/521 - 15s - loss: 0.0291 - accuracy: 0.9896 - val_loss: 1.1501 - val_accuracy: 0.7704
Epoch 30/500
521/521 - 15s - loss: 0.0195 - accuracy: 0.9932 - val_loss: 1.2222 - val_accuracy: 0.7792
Epoch 31/500
521/521 - 15s - loss: 0.0266 - accuracy: 0.9910 - val_loss: 1.1985 - val_accuracy: 0.7776
Epoch 32/500
521/521 - 15s - loss: 0.0160 - accuracy: 0.9950 - val_loss: 1.2335 - val_accuracy: 0.7680
Epoch 33/500
521/521 - 15s - loss: 0.0251 - accuracy: 0.9927 - val_loss: 1.2333 - val_accuracy: 0.7840
Epoch 34/500
521/521 - 15s - loss: 0.0133 - accuracy: 0.9962 - val_loss: 1.2625 - val_accuracy: 0.7928
Epoch 35/500
521/521 - 15s - loss: 0.0341 - accuracy: 0.9888 - val_loss: 1.2395 - val_accuracy: 0.7992
Epoch 36/500
521/521 - 15s - loss: 0.0137 - accuracy: 0.9960 - val_loss: 1.2443 - val_accuracy: 0.7736
Epoch 37/500
521/521 - 15s - loss: 0.0207 - accuracy: 0.9941 - val_loss: 1.2077 - val_accuracy: 0.8072
Epoch 38/500
521/521 - 15s - loss: 0.0038 - accuracy: 0.9995 - val_loss: 1.3327 - val_accuracy: 0.7968
Epoch 39/500
521/521 - 15s - loss: 0.0335 - accuracy: 0.9877 - val_loss: 1.2355 - val_accuracy: 0.7624
Epoch 40/500
521/521 - 15s - loss: 0.0250 - accuracy: 0.9915 - val_loss: 1.3454 - val_accuracy: 0.7776
Epoch 41/500
521/521 - 15s - loss: 0.0137 - accuracy: 0.9959 - val_loss: 1.2004 - val_accuracy: 0.7920
Epoch 42/500
521/521 - 15s - loss: 0.0156 - accuracy: 0.9951 - val_loss: 1.2852 - val_accuracy: 0.7824
Epoch 43/500
521/521 - 15s - loss: 0.0276 - accuracy: 0.9903 - val_loss: 1.4469 - val_accuracy: 0.7872
Epoch 44/500
521/521 - 15s - loss: 0.0216 - accuracy: 0.9927 - val_loss: 1.2153 - val_accuracy: 0.7808
Epoch 45/500
521/521 - 15s - loss: 0.0044 - accuracy: 0.9991 - val_loss: 1.3019 - val_accuracy: 0.8000
Epoch 46/500
521/521 - 15s - loss: 0.0173 - accuracy: 0.9945 - val_loss: 1.1562 - val_accuracy: 0.7792
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 11:37:46.829997: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 11:37:46.830140: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 11:37:46.830172: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 11:37:46.859575: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 11:37:46.859660: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00046: early stopping
Length split part:  16667
Labels in this part of split:  [1629, 1681, 1647, 1628, 1684, 1727, 1642, 1677, 1665, 1687]
Train for 521 steps, validate for 40 steps
Epoch 1/500
521/521 - 16s - loss: 1.2575 - accuracy: 0.5456 - val_loss: 1.0167 - val_accuracy: 0.6504
Epoch 2/500
521/521 - 18s - loss: 0.8171 - accuracy: 0.7160 - val_loss: 0.7831 - val_accuracy: 0.7176
Epoch 3/500
521/521 - 16s - loss: 0.6664 - accuracy: 0.7688 - val_loss: 0.7571 - val_accuracy: 0.7448
Epoch 4/500
521/521 - 18s - loss: 0.5599 - accuracy: 0.8058 - val_loss: 0.6685 - val_accuracy: 0.7608
Epoch 5/500
521/521 - 17s - loss: 0.4652 - accuracy: 0.8370 - val_loss: 0.6152 - val_accuracy: 0.7904
Epoch 6/500
521/521 - 15s - loss: 0.3813 - accuracy: 0.8694 - val_loss: 0.6230 - val_accuracy: 0.7864
Epoch 7/500
521/521 - 15s - loss: 0.2987 - accuracy: 0.8977 - val_loss: 0.6855 - val_accuracy: 0.7744
Epoch 8/500
521/521 - 15s - loss: 0.2325 - accuracy: 0.9192 - val_loss: 0.7407 - val_accuracy: 0.7624
Epoch 9/500
521/521 - 15s - loss: 0.1837 - accuracy: 0.9373 - val_loss: 0.7332 - val_accuracy: 0.7848
Epoch 10/500
521/521 - 15s - loss: 0.1330 - accuracy: 0.9546 - val_loss: 0.7526 - val_accuracy: 0.7784
Epoch 11/500
521/521 - 15s - loss: 0.0934 - accuracy: 0.9686 - val_loss: 0.9908 - val_accuracy: 0.7672
Epoch 12/500
521/521 - 15s - loss: 0.0699 - accuracy: 0.9775 - val_loss: 0.9592 - val_accuracy: 0.7760
Epoch 13/500
521/521 - 15s - loss: 0.0657 - accuracy: 0.9779 - val_loss: 0.9520 - val_accuracy: 0.7656
Epoch 14/500
521/521 - 15s - loss: 0.0535 - accuracy: 0.9825 - val_loss: 0.9948 - val_accuracy: 0.7752
Epoch 15/500
521/521 - 15s - loss: 0.0371 - accuracy: 0.9878 - val_loss: 0.9983 - val_accuracy: 0.7728
Epoch 16/500
521/521 - 15s - loss: 0.0421 - accuracy: 0.9858 - val_loss: 1.1539 - val_accuracy: 0.7688
Epoch 17/500
521/521 - 15s - loss: 0.0477 - accuracy: 0.9848 - val_loss: 0.9913 - val_accuracy: 0.7936
Epoch 18/500
521/521 - 15s - loss: 0.0243 - accuracy: 0.9926 - val_loss: 1.0870 - val_accuracy: 0.7944
Epoch 19/500
521/521 - 15s - loss: 0.0399 - accuracy: 0.9872 - val_loss: 1.0580 - val_accuracy: 0.7816
Epoch 20/500
521/521 - 15s - loss: 0.0394 - accuracy: 0.9882 - val_loss: 1.1570 - val_accuracy: 0.7808
Epoch 21/500
521/521 - 15s - loss: 0.0259 - accuracy: 0.9912 - val_loss: 1.1062 - val_accuracy: 0.7872
Epoch 22/500
521/521 - 15s - loss: 0.0239 - accuracy: 0.9923 - val_loss: 1.1941 - val_accuracy: 0.7736
Epoch 23/500
521/521 - 15s - loss: 0.0348 - accuracy: 0.9885 - val_loss: 1.1843 - val_accuracy: 0.7792
Epoch 24/500
521/521 - 15s - loss: 0.0234 - accuracy: 0.9922 - val_loss: 1.1096 - val_accuracy: 0.7720
Epoch 25/500
521/521 - 15s - loss: 0.0213 - accuracy: 0.9930 - val_loss: 1.1381 - val_accuracy: 0.8008
Epoch 26/500
521/521 - 15s - loss: 0.0343 - accuracy: 0.9875 - val_loss: 1.0546 - val_accuracy: 0.7928
Epoch 27/500
521/521 - 15s - loss: 0.0094 - accuracy: 0.9972 - val_loss: 1.0792 - val_accuracy: 0.7928
Epoch 28/500
521/521 - 15s - loss: 0.0202 - accuracy: 0.9936 - val_loss: 1.1811 - val_accuracy: 0.7912
Epoch 29/500
521/521 - 15s - loss: 0.0419 - accuracy: 0.9858 - val_loss: 1.0481 - val_accuracy: 0.8000
Epoch 30/500
521/521 - 15s - loss: 0.0152 - accuracy: 0.9951 - val_loss: 1.0788 - val_accuracy: 0.7904
Epoch 31/500
521/521 - 15s - loss: 0.0113 - accuracy: 0.9963 - val_loss: 1.1498 - val_accuracy: 0.7848
Epoch 32/500
521/521 - 15s - loss: 0.0294 - accuracy: 0.9902 - val_loss: 1.2165 - val_accuracy: 0.8016
Epoch 33/500
521/521 - 15s - loss: 0.0294 - accuracy: 0.9900 - val_loss: 1.2413 - val_accuracy: 0.7832
Epoch 34/500
521/521 - 15s - loss: 0.0207 - accuracy: 0.9933 - val_loss: 1.3018 - val_accuracy: 0.7808
Epoch 35/500
521/521 - 15s - loss: 0.0147 - accuracy: 0.9955 - val_loss: 1.2556 - val_accuracy: 0.8016
Epoch 36/500
521/521 - 15s - loss: 0.0250 - accuracy: 0.9914 - val_loss: 1.2334 - val_accuracy: 0.7824
Epoch 37/500
521/521 - 15s - loss: 0.0214 - accuracy: 0.9930 - val_loss: 1.2258 - val_accuracy: 0.7960
Epoch 38/500
521/521 - 15s - loss: 0.0095 - accuracy: 0.9975 - val_loss: 1.2404 - val_accuracy: 0.7960
Epoch 39/500
521/521 - 15s - loss: 0.0061 - accuracy: 0.9983 - val_loss: 1.3881 - val_accuracy: 0.7824
Epoch 40/500
521/521 - 15s - loss: 0.0339 - accuracy: 0.9887 - val_loss: 1.1819 - val_accuracy: 0.7736
Epoch 41/500
521/521 - 15s - loss: 0.0078 - accuracy: 0.9979 - val_loss: 1.4055 - val_accuracy: 0.7864
Epoch 42/500
521/521 - 15s - loss: 0.0272 - accuracy: 0.9914 - val_loss: 1.1889 - val_accuracy: 0.7848
Epoch 43/500
521/521 - 15s - loss: 0.0100 - accuracy: 0.9971 - val_loss: 1.2172 - val_accuracy: 0.7912
Epoch 44/500
521/521 - 15s - loss: 0.0158 - accuracy: 0.9947 - val_loss: 1.2523 - val_accuracy: 0.7960
Epoch 45/500
521/521 - 15s - loss: 0.0179 - accuracy: 0.9945 - val_loss: 1.1954 - val_accuracy: 0.7808
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 11:49:16.511249: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 11:49:16.511382: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 11:49:16.511414: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 11:49:16.540875: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 11:49:16.540957: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00045: early stopping
Length split part:  16666
Labels in this part of split:  [1704, 1663, 1641, 1690, 1641, 1694, 1655, 1636, 1654, 1688]
Train for 521 steps, validate for 40 steps
Epoch 1/500
521/521 - 19s - loss: 1.2607 - accuracy: 0.5449 - val_loss: 0.9337 - val_accuracy: 0.6576
Epoch 2/500
521/521 - 16s - loss: 0.8129 - accuracy: 0.7102 - val_loss: 0.8462 - val_accuracy: 0.6872
Epoch 3/500
521/521 - 18s - loss: 0.6543 - accuracy: 0.7711 - val_loss: 0.7160 - val_accuracy: 0.7616
Epoch 4/500
521/521 - 16s - loss: 0.5329 - accuracy: 0.8117 - val_loss: 0.6510 - val_accuracy: 0.7744
Epoch 5/500
521/521 - 18s - loss: 0.4400 - accuracy: 0.8466 - val_loss: 0.6427 - val_accuracy: 0.7808
Epoch 6/500
521/521 - 15s - loss: 0.3592 - accuracy: 0.8741 - val_loss: 0.6861 - val_accuracy: 0.7672
Epoch 7/500
521/521 - 15s - loss: 0.2802 - accuracy: 0.9020 - val_loss: 0.7123 - val_accuracy: 0.7576
Epoch 8/500
521/521 - 15s - loss: 0.2303 - accuracy: 0.9198 - val_loss: 0.7278 - val_accuracy: 0.7720
Epoch 9/500
521/521 - 15s - loss: 0.1700 - accuracy: 0.9413 - val_loss: 0.7000 - val_accuracy: 0.7968
Epoch 10/500
521/521 - 15s - loss: 0.1161 - accuracy: 0.9627 - val_loss: 0.8309 - val_accuracy: 0.7776
Epoch 11/500
521/521 - 15s - loss: 0.0935 - accuracy: 0.9686 - val_loss: 0.8441 - val_accuracy: 0.7912
Epoch 12/500
521/521 - 15s - loss: 0.0732 - accuracy: 0.9759 - val_loss: 0.9338 - val_accuracy: 0.7952
Epoch 13/500
521/521 - 15s - loss: 0.0621 - accuracy: 0.9786 - val_loss: 0.9162 - val_accuracy: 0.7952
Epoch 14/500
521/521 - 15s - loss: 0.0493 - accuracy: 0.9841 - val_loss: 0.9411 - val_accuracy: 0.7976
Epoch 15/500
521/521 - 15s - loss: 0.0259 - accuracy: 0.9925 - val_loss: 1.1511 - val_accuracy: 0.7560
Epoch 16/500
521/521 - 15s - loss: 0.0569 - accuracy: 0.9808 - val_loss: 1.0278 - val_accuracy: 0.7752
Epoch 17/500
521/521 - 15s - loss: 0.0548 - accuracy: 0.9810 - val_loss: 0.8752 - val_accuracy: 0.8080
Epoch 18/500
521/521 - 15s - loss: 0.0229 - accuracy: 0.9935 - val_loss: 1.0587 - val_accuracy: 0.7936
Epoch 19/500
521/521 - 15s - loss: 0.0427 - accuracy: 0.9864 - val_loss: 1.0725 - val_accuracy: 0.7760
Epoch 20/500
521/521 - 15s - loss: 0.0242 - accuracy: 0.9927 - val_loss: 1.1751 - val_accuracy: 0.7688
Epoch 21/500
521/521 - 15s - loss: 0.0306 - accuracy: 0.9908 - val_loss: 1.1681 - val_accuracy: 0.7704
Epoch 22/500
521/521 - 15s - loss: 0.0264 - accuracy: 0.9911 - val_loss: 1.0563 - val_accuracy: 0.7968
Epoch 23/500
521/521 - 15s - loss: 0.0102 - accuracy: 0.9972 - val_loss: 1.1663 - val_accuracy: 0.7984
Epoch 24/500
521/521 - 15s - loss: 3.9243e-04 - accuracy: 1.0000 - val_loss: 1.2187 - val_accuracy: 0.8024
Epoch 25/500
521/521 - 15s - loss: 1.7023e-04 - accuracy: 1.0000 - val_loss: 1.2725 - val_accuracy: 0.8040
Epoch 26/500
521/521 - 15s - loss: 1.0748e-04 - accuracy: 1.0000 - val_loss: 1.3200 - val_accuracy: 0.8056
Epoch 27/500
521/521 - 15s - loss: 7.6815e-05 - accuracy: 1.0000 - val_loss: 1.3561 - val_accuracy: 0.8088
Epoch 28/500
521/521 - 15s - loss: 5.6713e-05 - accuracy: 1.0000 - val_loss: 1.4039 - val_accuracy: 0.8080
Epoch 29/500
521/521 - 15s - loss: 4.1677e-05 - accuracy: 1.0000 - val_loss: 1.4420 - val_accuracy: 0.8088
Epoch 30/500
521/521 - 15s - loss: 3.1523e-05 - accuracy: 1.0000 - val_loss: 1.4730 - val_accuracy: 0.8104
Epoch 31/500
521/521 - 15s - loss: 2.3586e-05 - accuracy: 1.0000 - val_loss: 1.5163 - val_accuracy: 0.8096
Epoch 32/500
521/521 - 15s - loss: 1.7745e-05 - accuracy: 1.0000 - val_loss: 1.5580 - val_accuracy: 0.8112
Epoch 33/500
521/521 - 15s - loss: 1.3448e-05 - accuracy: 1.0000 - val_loss: 1.6005 - val_accuracy: 0.8120
Epoch 34/500
521/521 - 15s - loss: 9.9526e-06 - accuracy: 1.0000 - val_loss: 1.6398 - val_accuracy: 0.8120
Epoch 35/500
521/521 - 15s - loss: 7.5775e-06 - accuracy: 1.0000 - val_loss: 1.6788 - val_accuracy: 0.8128
Epoch 36/500
521/521 - 15s - loss: 5.6694e-06 - accuracy: 1.0000 - val_loss: 1.7233 - val_accuracy: 0.8112
Epoch 37/500
521/521 - 15s - loss: 4.2857e-06 - accuracy: 1.0000 - val_loss: 1.7619 - val_accuracy: 0.8112
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 11:58:55.261473: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 11:58:55.261697: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 11:58:55.261738: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 11:58:55.300717: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 11:58:55.300865: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00037: early stopping
VGG19
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 75, 75, 3)]       0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 75, 75, 64)        1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 75, 75, 64)        36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 37, 37, 64)        0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 37, 37, 128)       73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 37, 37, 128)       147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 18, 18, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 18, 18, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 18, 18, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 18, 18, 256)       590080    
_________________________________________________________________
block3_conv4 (Conv2D)        (None, 18, 18, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 9, 9, 256)         0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 9, 9, 512)         1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block4_conv4 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   
_________________________________________________________________
block5_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         
_________________________________________________________________
flatten (Flatten)            (None, 2048)              0         
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              8392704   
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312  
_________________________________________________________________
predictions (Dense)          (None, 10)                40970     
=================================================================
Total params: 45,239,370
Trainable params: 45,239,370
Non-trainable params: 0
_________________________________________________________________
Start fitting ensemble models
Length split part:  16667
Labels in this part of split:  [1667, 1656, 1712, 1682, 1675, 1579, 1703, 1687, 1681, 1625]
Train for 521 steps, validate for 40 steps
Epoch 1/500
521/521 - 24s - loss: 1.2058 - accuracy: 0.5688 - val_loss: 0.9452 - val_accuracy: 0.6712
Epoch 2/500
521/521 - 19s - loss: 0.7996 - accuracy: 0.7170 - val_loss: 0.8152 - val_accuracy: 0.7072
Epoch 3/500
521/521 - 19s - loss: 0.6569 - accuracy: 0.7681 - val_loss: 0.7268 - val_accuracy: 0.7464
Epoch 4/500
521/521 - 19s - loss: 0.5452 - accuracy: 0.8072 - val_loss: 0.7137 - val_accuracy: 0.7648
Epoch 5/500
521/521 - 18s - loss: 0.4589 - accuracy: 0.8377 - val_loss: 0.7262 - val_accuracy: 0.7584
Epoch 6/500
521/521 - 19s - loss: 0.3684 - accuracy: 0.8695 - val_loss: 0.6742 - val_accuracy: 0.7664
Epoch 7/500
521/521 - 18s - loss: 0.2942 - accuracy: 0.8969 - val_loss: 0.7013 - val_accuracy: 0.7696
Epoch 8/500
521/521 - 18s - loss: 0.2206 - accuracy: 0.9205 - val_loss: 0.7212 - val_accuracy: 0.7832
Epoch 9/500
521/521 - 18s - loss: 0.1756 - accuracy: 0.9390 - val_loss: 0.7910 - val_accuracy: 0.7744
Epoch 10/500
521/521 - 18s - loss: 0.1365 - accuracy: 0.9523 - val_loss: 0.8046 - val_accuracy: 0.7760
Epoch 11/500
521/521 - 18s - loss: 0.0967 - accuracy: 0.9675 - val_loss: 0.8912 - val_accuracy: 0.7680
Epoch 12/500
521/521 - 18s - loss: 0.0834 - accuracy: 0.9716 - val_loss: 0.9896 - val_accuracy: 0.7752
Epoch 13/500
521/521 - 18s - loss: 0.0735 - accuracy: 0.9745 - val_loss: 0.9493 - val_accuracy: 0.7960
Epoch 14/500
521/521 - 18s - loss: 0.0621 - accuracy: 0.9800 - val_loss: 1.0409 - val_accuracy: 0.7840
Epoch 15/500
521/521 - 18s - loss: 0.0530 - accuracy: 0.9837 - val_loss: 1.0670 - val_accuracy: 0.7928
Epoch 16/500
521/521 - 18s - loss: 0.0574 - accuracy: 0.9815 - val_loss: 1.0036 - val_accuracy: 0.7968
Epoch 17/500
521/521 - 18s - loss: 0.0388 - accuracy: 0.9870 - val_loss: 1.0366 - val_accuracy: 0.7824
Epoch 18/500
521/521 - 18s - loss: 0.0461 - accuracy: 0.9842 - val_loss: 1.0468 - val_accuracy: 0.7720
Epoch 19/500
521/521 - 18s - loss: 0.0399 - accuracy: 0.9864 - val_loss: 1.0839 - val_accuracy: 0.7744
Epoch 20/500
521/521 - 18s - loss: 0.0390 - accuracy: 0.9875 - val_loss: 1.2566 - val_accuracy: 0.7888
Epoch 21/500
521/521 - 18s - loss: 0.0265 - accuracy: 0.9915 - val_loss: 1.2229 - val_accuracy: 0.7928
Epoch 22/500
521/521 - 18s - loss: 0.0467 - accuracy: 0.9845 - val_loss: 1.1680 - val_accuracy: 0.7880
Epoch 23/500
521/521 - 18s - loss: 0.0312 - accuracy: 0.9896 - val_loss: 1.0847 - val_accuracy: 0.7904
Epoch 24/500
521/521 - 18s - loss: 0.0320 - accuracy: 0.9896 - val_loss: 1.1623 - val_accuracy: 0.7912
Epoch 25/500
521/521 - 18s - loss: 0.0295 - accuracy: 0.9915 - val_loss: 1.2348 - val_accuracy: 0.7760
Epoch 26/500
521/521 - 18s - loss: 0.0240 - accuracy: 0.9925 - val_loss: 1.0948 - val_accuracy: 0.8080
Epoch 27/500
521/521 - 18s - loss: 0.0012 - accuracy: 0.9999 - val_loss: 1.2395 - val_accuracy: 0.8160
Epoch 28/500
521/521 - 18s - loss: 1.5477e-04 - accuracy: 1.0000 - val_loss: 1.2984 - val_accuracy: 0.8144
Epoch 29/500
521/521 - 18s - loss: 7.8876e-05 - accuracy: 1.0000 - val_loss: 1.3491 - val_accuracy: 0.8184
Epoch 30/500
521/521 - 18s - loss: 5.3275e-05 - accuracy: 1.0000 - val_loss: 1.3970 - val_accuracy: 0.8176
Epoch 31/500
521/521 - 18s - loss: 3.7633e-05 - accuracy: 1.0000 - val_loss: 1.4427 - val_accuracy: 0.8192
Epoch 32/500
521/521 - 18s - loss: 2.7263e-05 - accuracy: 1.0000 - val_loss: 1.4854 - val_accuracy: 0.8184
Epoch 33/500
521/521 - 18s - loss: 2.0074e-05 - accuracy: 1.0000 - val_loss: 1.5269 - val_accuracy: 0.8200
Epoch 34/500
521/521 - 18s - loss: 1.4852e-05 - accuracy: 1.0000 - val_loss: 1.5752 - val_accuracy: 0.8192
Epoch 35/500
521/521 - 18s - loss: 1.1073e-05 - accuracy: 1.0000 - val_loss: 1.6139 - val_accuracy: 0.8192
Epoch 36/500
521/521 - 18s - loss: 8.2204e-06 - accuracy: 1.0000 - val_loss: 1.6572 - val_accuracy: 0.8176
Epoch 37/500
521/521 - 18s - loss: 6.1003e-06 - accuracy: 1.0000 - val_loss: 1.7095 - val_accuracy: 0.8184
Epoch 38/500
521/521 - 18s - loss: 4.5720e-06 - accuracy: 1.0000 - val_loss: 1.7488 - val_accuracy: 0.8192
Epoch 39/500
521/521 - 18s - loss: 3.3996e-06 - accuracy: 1.0000 - val_loss: 1.7917 - val_accuracy: 0.8176
Epoch 40/500
521/521 - 18s - loss: 2.5309e-06 - accuracy: 1.0000 - val_loss: 1.8377 - val_accuracy: 0.8160
Epoch 41/500
521/521 - 18s - loss: 1.8844e-06 - accuracy: 1.0000 - val_loss: 1.8881 - val_accuracy: 0.8160
Epoch 42/500
521/521 - 18s - loss: 1.4152e-06 - accuracy: 1.0000 - val_loss: 1.9345 - val_accuracy: 0.8136
Epoch 43/500
521/521 - 18s - loss: 1.0506e-06 - accuracy: 1.0000 - val_loss: 1.9741 - val_accuracy: 0.8144
Epoch 44/500
521/521 - 18s - loss: 7.8816e-07 - accuracy: 1.0000 - val_loss: 2.0218 - val_accuracy: 0.8112
Epoch 45/500
521/521 - 18s - loss: 5.8509e-07 - accuracy: 1.0000 - val_loss: 2.0632 - val_accuracy: 0.8128
Epoch 46/500
521/521 - 18s - loss: 4.3728e-07 - accuracy: 1.0000 - val_loss: 2.1189 - val_accuracy: 0.8096
Epoch 47/500
521/521 - 18s - loss: 3.2767e-07 - accuracy: 1.0000 - val_loss: 2.1620 - val_accuracy: 0.8080
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 12:13:16.002953: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 12:13:16.003102: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:13:16.003138: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:13:16.040337: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 12:13:16.040433: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00047: early stopping
Length split part:  16667
Labels in this part of split:  [1629, 1681, 1647, 1628, 1684, 1727, 1642, 1677, 1665, 1687]
Train for 521 steps, validate for 40 steps
Epoch 1/500
521/521 - 19s - loss: 1.1418 - accuracy: 0.5915 - val_loss: 0.8500 - val_accuracy: 0.6952
Epoch 2/500
521/521 - 20s - loss: 0.7085 - accuracy: 0.7552 - val_loss: 0.7323 - val_accuracy: 0.7312
Epoch 3/500
521/521 - 19s - loss: 0.5699 - accuracy: 0.8006 - val_loss: 0.6601 - val_accuracy: 0.7664
Epoch 4/500
521/521 - 18s - loss: 0.4544 - accuracy: 0.8406 - val_loss: 0.6694 - val_accuracy: 0.7752
Epoch 5/500
521/521 - 18s - loss: 0.3707 - accuracy: 0.8734 - val_loss: 0.6621 - val_accuracy: 0.7816
Epoch 6/500
521/521 - 18s - loss: 0.2851 - accuracy: 0.9017 - val_loss: 0.6989 - val_accuracy: 0.7792
Epoch 7/500
521/521 - 18s - loss: 0.2164 - accuracy: 0.9268 - val_loss: 0.8219 - val_accuracy: 0.7616
Epoch 8/500
521/521 - 18s - loss: 0.1559 - accuracy: 0.9476 - val_loss: 0.7520 - val_accuracy: 0.7864
Epoch 9/500
521/521 - 18s - loss: 0.1169 - accuracy: 0.9614 - val_loss: 0.9160 - val_accuracy: 0.7696
Epoch 10/500
521/521 - 18s - loss: 0.0770 - accuracy: 0.9749 - val_loss: 1.0377 - val_accuracy: 0.7648
Epoch 11/500
521/521 - 18s - loss: 0.0731 - accuracy: 0.9750 - val_loss: 0.9746 - val_accuracy: 0.7888
Epoch 12/500
521/521 - 18s - loss: 0.0531 - accuracy: 0.9824 - val_loss: 0.9935 - val_accuracy: 0.7840
Epoch 13/500
521/521 - 18s - loss: 0.0505 - accuracy: 0.9825 - val_loss: 1.1714 - val_accuracy: 0.7720
Epoch 14/500
521/521 - 18s - loss: 0.0485 - accuracy: 0.9842 - val_loss: 1.0678 - val_accuracy: 0.7912
Epoch 15/500
521/521 - 18s - loss: 0.0204 - accuracy: 0.9940 - val_loss: 1.3901 - val_accuracy: 0.7888
Epoch 16/500
521/521 - 18s - loss: 0.0554 - accuracy: 0.9827 - val_loss: 1.2516 - val_accuracy: 0.7728
Epoch 17/500
521/521 - 18s - loss: 0.0304 - accuracy: 0.9906 - val_loss: 1.1367 - val_accuracy: 0.7832
Epoch 18/500
521/521 - 18s - loss: 0.0433 - accuracy: 0.9860 - val_loss: 1.0495 - val_accuracy: 0.7600
Epoch 19/500
521/521 - 18s - loss: 0.0224 - accuracy: 0.9942 - val_loss: 1.1794 - val_accuracy: 0.7816
Epoch 20/500
521/521 - 18s - loss: 0.0237 - accuracy: 0.9919 - val_loss: 1.2647 - val_accuracy: 0.7800
Epoch 21/500
521/521 - 18s - loss: 0.0389 - accuracy: 0.9876 - val_loss: 1.3010 - val_accuracy: 0.7848
Epoch 22/500
521/521 - 18s - loss: 0.0212 - accuracy: 0.9925 - val_loss: 1.2260 - val_accuracy: 0.7936
Epoch 23/500
521/521 - 18s - loss: 0.0069 - accuracy: 0.9980 - val_loss: 1.3845 - val_accuracy: 0.7896
Epoch 24/500
521/521 - 18s - loss: 0.0514 - accuracy: 0.9831 - val_loss: 1.2163 - val_accuracy: 0.7752
Epoch 25/500
521/521 - 18s - loss: 0.0249 - accuracy: 0.9917 - val_loss: 1.2856 - val_accuracy: 0.7944
Epoch 26/500
521/521 - 18s - loss: 0.0016 - accuracy: 0.9998 - val_loss: 1.2635 - val_accuracy: 0.8000
Epoch 27/500
521/521 - 18s - loss: 1.8292e-04 - accuracy: 1.0000 - val_loss: 1.3093 - val_accuracy: 0.7984
Epoch 28/500
521/521 - 18s - loss: 1.1131e-04 - accuracy: 1.0000 - val_loss: 1.3527 - val_accuracy: 0.8016
Epoch 29/500
521/521 - 18s - loss: 7.8269e-05 - accuracy: 1.0000 - val_loss: 1.3934 - val_accuracy: 0.8000
Epoch 30/500
521/521 - 18s - loss: 5.6316e-05 - accuracy: 1.0000 - val_loss: 1.4304 - val_accuracy: 0.8024
Epoch 31/500
521/521 - 18s - loss: 4.1043e-05 - accuracy: 1.0000 - val_loss: 1.4689 - val_accuracy: 0.8000
Epoch 32/500
521/521 - 18s - loss: 3.0138e-05 - accuracy: 1.0000 - val_loss: 1.5077 - val_accuracy: 0.7992
Epoch 33/500
521/521 - 18s - loss: 2.2211e-05 - accuracy: 1.0000 - val_loss: 1.5403 - val_accuracy: 0.8016
Epoch 34/500
521/521 - 18s - loss: 1.6497e-05 - accuracy: 1.0000 - val_loss: 1.5833 - val_accuracy: 0.8016
Epoch 35/500
521/521 - 18s - loss: 1.2244e-05 - accuracy: 1.0000 - val_loss: 1.6227 - val_accuracy: 0.8032
Epoch 36/500
521/521 - 18s - loss: 9.0814e-06 - accuracy: 1.0000 - val_loss: 1.6603 - val_accuracy: 0.8032
Epoch 37/500
521/521 - 18s - loss: 6.7494e-06 - accuracy: 1.0000 - val_loss: 1.6978 - val_accuracy: 0.8000
Epoch 38/500
521/521 - 18s - loss: 5.0206e-06 - accuracy: 1.0000 - val_loss: 1.7401 - val_accuracy: 0.8016
Epoch 39/500
521/521 - 18s - loss: 3.7245e-06 - accuracy: 1.0000 - val_loss: 1.7790 - val_accuracy: 0.8008
Epoch 40/500
521/521 - 18s - loss: 2.7844e-06 - accuracy: 1.0000 - val_loss: 1.8212 - val_accuracy: 0.8016
Epoch 41/500
521/521 - 18s - loss: 2.0710e-06 - accuracy: 1.0000 - val_loss: 1.8595 - val_accuracy: 0.8024
Epoch 42/500
521/521 - 18s - loss: 1.5427e-06 - accuracy: 1.0000 - val_loss: 1.9018 - val_accuracy: 0.8016
Epoch 43/500
521/521 - 18s - loss: 1.1490e-06 - accuracy: 1.0000 - val_loss: 1.9441 - val_accuracy: 0.8016
Epoch 44/500
521/521 - 18s - loss: 8.5690e-07 - accuracy: 1.0000 - val_loss: 1.9845 - val_accuracy: 0.8024
Epoch 45/500
521/521 - 18s - loss: 6.3918e-07 - accuracy: 1.0000 - val_loss: 2.0275 - val_accuracy: 0.8016
Epoch 46/500
521/521 - 18s - loss: 4.7708e-07 - accuracy: 1.0000 - val_loss: 2.0627 - val_accuracy: 0.8040
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 12:27:10.277905: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 12:27:10.278042: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:27:10.278074: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:27:10.314791: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 12:27:10.314866: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00046: early stopping
Length split part:  16666
Labels in this part of split:  [1704, 1663, 1641, 1690, 1641, 1694, 1655, 1636, 1654, 1688]
Train for 521 steps, validate for 40 steps
Epoch 1/500
521/521 - 19s - loss: 1.1471 - accuracy: 0.5878 - val_loss: 0.8931 - val_accuracy: 0.6760
Epoch 2/500
521/521 - 19s - loss: 0.7232 - accuracy: 0.7453 - val_loss: 0.7394 - val_accuracy: 0.7504
Epoch 3/500
521/521 - 19s - loss: 0.5787 - accuracy: 0.7964 - val_loss: 0.7330 - val_accuracy: 0.7480
Epoch 4/500
521/521 - 19s - loss: 0.4779 - accuracy: 0.8328 - val_loss: 0.6622 - val_accuracy: 0.7728
Epoch 5/500
521/521 - 18s - loss: 0.3764 - accuracy: 0.8718 - val_loss: 0.6909 - val_accuracy: 0.7832
Epoch 6/500
521/521 - 18s - loss: 0.2976 - accuracy: 0.9000 - val_loss: 0.6914 - val_accuracy: 0.7704
Epoch 7/500
521/521 - 18s - loss: 0.2373 - accuracy: 0.9194 - val_loss: 0.7720 - val_accuracy: 0.7896
Epoch 8/500
521/521 - 18s - loss: 0.1778 - accuracy: 0.9383 - val_loss: 0.8340 - val_accuracy: 0.7832
Epoch 9/500
521/521 - 18s - loss: 0.1305 - accuracy: 0.9566 - val_loss: 0.8277 - val_accuracy: 0.7856
Epoch 10/500
521/521 - 18s - loss: 0.0891 - accuracy: 0.9723 - val_loss: 1.0477 - val_accuracy: 0.7640
Epoch 11/500
521/521 - 18s - loss: 0.0740 - accuracy: 0.9761 - val_loss: 1.1137 - val_accuracy: 0.7712
Epoch 12/500
521/521 - 18s - loss: 0.0684 - accuracy: 0.9765 - val_loss: 1.1312 - val_accuracy: 0.7832
Epoch 13/500
521/521 - 18s - loss: 0.0665 - accuracy: 0.9779 - val_loss: 1.2049 - val_accuracy: 0.7776
Epoch 14/500
521/521 - 18s - loss: 0.0410 - accuracy: 0.9875 - val_loss: 1.0686 - val_accuracy: 0.7856
Epoch 15/500
521/521 - 18s - loss: 0.0506 - accuracy: 0.9836 - val_loss: 1.0962 - val_accuracy: 0.7920
Epoch 16/500
521/521 - 18s - loss: 0.0352 - accuracy: 0.9888 - val_loss: 1.1787 - val_accuracy: 0.7832
Epoch 17/500
521/521 - 18s - loss: 0.0470 - accuracy: 0.9842 - val_loss: 1.1204 - val_accuracy: 0.7904
Epoch 18/500
521/521 - 18s - loss: 0.0261 - accuracy: 0.9913 - val_loss: 1.2177 - val_accuracy: 0.7928
Epoch 19/500
521/521 - 18s - loss: 0.0347 - accuracy: 0.9889 - val_loss: 1.1189 - val_accuracy: 0.7992
Epoch 20/500
521/521 - 18s - loss: 0.0390 - accuracy: 0.9870 - val_loss: 1.1361 - val_accuracy: 0.7864
Epoch 21/500
521/521 - 18s - loss: 0.0267 - accuracy: 0.9913 - val_loss: 1.3040 - val_accuracy: 0.7824
Epoch 22/500
521/521 - 18s - loss: 0.0254 - accuracy: 0.9917 - val_loss: 1.2407 - val_accuracy: 0.7744
Epoch 23/500
521/521 - 18s - loss: 0.0379 - accuracy: 0.9882 - val_loss: 1.1922 - val_accuracy: 0.8008
Epoch 24/500
521/521 - 18s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2009 - val_accuracy: 0.8024
Epoch 25/500
521/521 - 18s - loss: 2.7339e-04 - accuracy: 1.0000 - val_loss: 1.2501 - val_accuracy: 0.8088
Epoch 26/500
521/521 - 18s - loss: 1.4906e-04 - accuracy: 1.0000 - val_loss: 1.2889 - val_accuracy: 0.8080
Epoch 27/500
521/521 - 18s - loss: 1.0269e-04 - accuracy: 1.0000 - val_loss: 1.3323 - val_accuracy: 0.8080
Epoch 28/500
521/521 - 18s - loss: 7.3255e-05 - accuracy: 1.0000 - val_loss: 1.3674 - val_accuracy: 0.8072
Epoch 29/500
521/521 - 18s - loss: 5.3467e-05 - accuracy: 1.0000 - val_loss: 1.4088 - val_accuracy: 0.8080
Epoch 30/500
521/521 - 18s - loss: 3.9117e-05 - accuracy: 1.0000 - val_loss: 1.4502 - val_accuracy: 0.8088
Epoch 31/500
521/521 - 18s - loss: 2.8704e-05 - accuracy: 1.0000 - val_loss: 1.4907 - val_accuracy: 0.8072
Epoch 32/500
521/521 - 18s - loss: 2.1098e-05 - accuracy: 1.0000 - val_loss: 1.5299 - val_accuracy: 0.8080
Epoch 33/500
521/521 - 18s - loss: 1.5689e-05 - accuracy: 1.0000 - val_loss: 1.5684 - val_accuracy: 0.8072
Epoch 34/500
521/521 - 18s - loss: 1.1517e-05 - accuracy: 1.0000 - val_loss: 1.6105 - val_accuracy: 0.8080
Epoch 35/500
521/521 - 18s - loss: 8.4550e-06 - accuracy: 1.0000 - val_loss: 1.6484 - val_accuracy: 0.8072
Epoch 36/500
521/521 - 18s - loss: 6.2642e-06 - accuracy: 1.0000 - val_loss: 1.6911 - val_accuracy: 0.8072
Epoch 37/500
521/521 - 18s - loss: 4.6136e-06 - accuracy: 1.0000 - val_loss: 1.7360 - val_accuracy: 0.8072
Epoch 38/500
521/521 - 18s - loss: 3.4125e-06 - accuracy: 1.0000 - val_loss: 1.7693 - val_accuracy: 0.8056
Epoch 39/500
521/521 - 18s - loss: 2.5216e-06 - accuracy: 1.0000 - val_loss: 1.8122 - val_accuracy: 0.8080
Epoch 40/500
521/521 - 18s - loss: 1.8697e-06 - accuracy: 1.0000 - val_loss: 1.8486 - val_accuracy: 0.8072
Epoch 41/500
521/521 - 18s - loss: 1.3838e-06 - accuracy: 1.0000 - val_loss: 1.8982 - val_accuracy: 0.8072
Epoch 42/500
521/521 - 18s - loss: 1.0249e-06 - accuracy: 1.0000 - val_loss: 1.9408 - val_accuracy: 0.8064
Epoch 43/500
521/521 - 18s - loss: 7.6339e-07 - accuracy: 1.0000 - val_loss: 1.9771 - val_accuracy: 0.8088
Epoch 44/500
521/521 - 18s - loss: 5.6908e-07 - accuracy: 1.0000 - val_loss: 2.0151 - val_accuracy: 0.8088
Epoch 45/500
521/521 - 18s - loss: 4.2208e-07 - accuracy: 1.0000 - val_loss: 2.0595 - val_accuracy: 0.8096
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 12:41:04.304301: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 12:41:04.304459: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:41:04.304495: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:41:04.348892: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 12:41:04.348975: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00045: early stopping
ResNet50
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 75, 75, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 81, 81, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 38, 38, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 38, 38, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 38, 38, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 40, 40, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 19, 19, 64)   0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 19, 19, 64)   4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 19, 19, 64)   0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 19, 19, 64)   36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 19, 19, 64)   0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 19, 19, 256)  16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 19, 19, 256)  16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 19, 19, 256)  1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 19, 19, 256)  1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 19, 19, 256)  0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 19, 19, 256)  0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 19, 19, 64)   16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 19, 19, 64)   0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 19, 19, 64)   36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 19, 19, 64)   0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 19, 19, 256)  16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 19, 19, 256)  1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 19, 19, 256)  0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 19, 19, 256)  0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 19, 19, 64)   16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 19, 19, 64)   0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 19, 19, 64)   36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 19, 19, 64)   0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 19, 19, 256)  16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 19, 19, 256)  1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 19, 19, 256)  0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 19, 19, 256)  0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 10, 10, 128)  32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 10, 10, 128)  0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 10, 10, 128)  147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 10, 10, 128)  0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 10, 10, 512)  131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 10, 10, 512)  2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 10, 10, 512)  2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 10, 10, 512)  0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 10, 10, 512)  0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 10, 10, 128)  65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 10, 10, 128)  0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 10, 10, 128)  147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 10, 10, 128)  0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 10, 10, 512)  2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 10, 10, 512)  0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 10, 10, 512)  0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 10, 10, 128)  65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 10, 10, 128)  0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 10, 10, 128)  147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 10, 10, 128)  0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 10, 10, 512)  2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 10, 10, 512)  0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 10, 10, 512)  0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 10, 10, 128)  65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 10, 10, 128)  0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 10, 10, 128)  147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 10, 10, 128)  0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 10, 10, 512)  2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 10, 10, 512)  0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 10, 10, 512)  0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 5, 5, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 5, 5, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 5, 5, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 5, 5, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 5, 5, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 5, 5, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 5, 5, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 5, 5, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 5, 5, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 5, 5, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 5, 5, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 5, 5, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 5, 5, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 5, 5, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 5, 5, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 5, 5, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 5, 5, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 5, 5, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 5, 5, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 5, 5, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 5, 5, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 5, 5, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 5, 5, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 5, 5, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 5, 5, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 5, 5, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 3, 3, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 3, 3, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 3, 3, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 3, 3, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 3, 3, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 3, 3, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 3, 3, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 3, 3, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 3, 3, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 3, 3, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 3, 3, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 3, 3, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 3, 3, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 3, 3, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 3, 3, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 3, 3, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 3, 3, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 3, 3, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 3, 3, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 3, 3, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 3, 3, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 3, 3, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 3, 3, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 3, 3, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 3, 3, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 3, 3, 2048)   0           conv5_block3_add[0][0]           
__________________________________________________________________________________________________
flatten (Flatten)               (None, 18432)        0           conv5_block3_out[0][0]           
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         75501568    flatten[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
predictions (Dense)             (None, 10)           40970       fc2[0][0]                        
==================================================================================================
Total params: 115,911,562
Trainable params: 115,858,442
Non-trainable params: 53,120
__________________________________________________________________________________________________
Start fitting ensemble models
Length split part:  16667
Labels in this part of split:  [1667, 1656, 1712, 1682, 1675, 1579, 1703, 1687, 1681, 1625]
Train for 521 steps, validate for 40 steps
Epoch 1/500
521/521 - 39s - loss: 1.4082 - accuracy: 0.5143 - val_loss: 2.6186 - val_accuracy: 0.0952
Epoch 2/500
521/521 - 27s - loss: 0.4615 - accuracy: 0.8676 - val_loss: 1.5135 - val_accuracy: 0.4768
Epoch 3/500
521/521 - 26s - loss: 0.0912 - accuracy: 0.9921 - val_loss: 1.1934 - val_accuracy: 0.6304
Epoch 4/500
521/521 - 22s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.2798 - val_accuracy: 0.6336
Epoch 5/500
521/521 - 22s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.3673 - val_accuracy: 0.6352
Epoch 6/500
521/521 - 22s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.4062 - val_accuracy: 0.6400
Epoch 7/500
521/521 - 22s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.4464 - val_accuracy: 0.6424
Epoch 8/500
521/521 - 23s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5074 - val_accuracy: 0.6432
Epoch 9/500
521/521 - 23s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5438 - val_accuracy: 0.6448
Epoch 10/500
521/521 - 22s - loss: 8.5587e-04 - accuracy: 1.0000 - val_loss: 1.5986 - val_accuracy: 0.6408
Epoch 11/500
521/521 - 23s - loss: 6.0552e-04 - accuracy: 1.0000 - val_loss: 1.6427 - val_accuracy: 0.6448
Epoch 12/500
521/521 - 22s - loss: 4.3115e-04 - accuracy: 1.0000 - val_loss: 1.6922 - val_accuracy: 0.6464
Epoch 13/500
521/521 - 22s - loss: 3.0922e-04 - accuracy: 1.0000 - val_loss: 1.7396 - val_accuracy: 0.6416
Epoch 14/500
521/521 - 22s - loss: 2.2207e-04 - accuracy: 1.0000 - val_loss: 1.7761 - val_accuracy: 0.6408
Epoch 15/500
521/521 - 22s - loss: 1.6039e-04 - accuracy: 1.0000 - val_loss: 1.8177 - val_accuracy: 0.6480
Epoch 16/500
521/521 - 22s - loss: 1.1605e-04 - accuracy: 1.0000 - val_loss: 1.8604 - val_accuracy: 0.6448
Epoch 17/500
521/521 - 22s - loss: 8.4213e-05 - accuracy: 1.0000 - val_loss: 1.9115 - val_accuracy: 0.6384
Epoch 18/500
521/521 - 22s - loss: 6.1337e-05 - accuracy: 1.0000 - val_loss: 1.9554 - val_accuracy: 0.6384
Epoch 19/500
521/521 - 23s - loss: 4.4677e-05 - accuracy: 1.0000 - val_loss: 2.0192 - val_accuracy: 0.6400
Epoch 20/500
521/521 - 22s - loss: 3.2625e-05 - accuracy: 1.0000 - val_loss: 2.0336 - val_accuracy: 0.6440
Epoch 21/500
521/521 - 22s - loss: 2.3856e-05 - accuracy: 1.0000 - val_loss: 2.0976 - val_accuracy: 0.6416
Epoch 22/500
521/521 - 22s - loss: 1.7479e-05 - accuracy: 1.0000 - val_loss: 2.1447 - val_accuracy: 0.6416
Epoch 23/500
521/521 - 23s - loss: 1.2810e-05 - accuracy: 1.0000 - val_loss: 2.1903 - val_accuracy: 0.6440
Epoch 24/500
521/521 - 23s - loss: 9.4261e-06 - accuracy: 1.0000 - val_loss: 2.2222 - val_accuracy: 0.6432
Epoch 25/500
521/521 - 22s - loss: 6.9394e-06 - accuracy: 1.0000 - val_loss: 2.2653 - val_accuracy: 0.6472
Epoch 26/500
521/521 - 22s - loss: 5.1161e-06 - accuracy: 1.0000 - val_loss: 2.3261 - val_accuracy: 0.6448
Epoch 27/500
521/521 - 22s - loss: 3.7853e-06 - accuracy: 1.0000 - val_loss: 2.3606 - val_accuracy: 0.6448
Epoch 28/500
521/521 - 22s - loss: 2.8079e-06 - accuracy: 1.0000 - val_loss: 2.4014 - val_accuracy: 0.6472
Epoch 29/500
521/521 - 22s - loss: 2.0841e-06 - accuracy: 1.0000 - val_loss: 2.4454 - val_accuracy: 0.6440
Epoch 30/500
521/521 - 22s - loss: 1.5531e-06 - accuracy: 1.0000 - val_loss: 2.4913 - val_accuracy: 0.6496
Epoch 31/500
521/521 - 22s - loss: 1.1619e-06 - accuracy: 1.0000 - val_loss: 2.5269 - val_accuracy: 0.6480
Epoch 32/500
521/521 - 22s - loss: 8.7434e-07 - accuracy: 1.0000 - val_loss: 2.5722 - val_accuracy: 0.6488
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 12:53:44.823376: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 12:53:44.823530: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:53:44.823567: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:53:44.870699: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 12:53:44.870776: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00032: early stopping
Length split part:  16667
Labels in this part of split:  [1629, 1681, 1647, 1628, 1684, 1727, 1642, 1677, 1665, 1687]
Train for 521 steps, validate for 40 steps
Epoch 1/500
521/521 - 26s - loss: 1.2315 - accuracy: 0.5796 - val_loss: 3.2163 - val_accuracy: 0.1080
Epoch 2/500
521/521 - 26s - loss: 0.3430 - accuracy: 0.8983 - val_loss: 1.4094 - val_accuracy: 0.5448
Epoch 3/500
521/521 - 26s - loss: 0.0522 - accuracy: 0.9952 - val_loss: 1.0708 - val_accuracy: 0.6888
Epoch 4/500
521/521 - 22s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.1689 - val_accuracy: 0.6896
Epoch 5/500
521/521 - 22s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.2299 - val_accuracy: 0.6904
Epoch 6/500
521/521 - 22s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2916 - val_accuracy: 0.6896
Epoch 7/500
521/521 - 22s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3507 - val_accuracy: 0.6904
Epoch 8/500
521/521 - 22s - loss: 9.5798e-04 - accuracy: 1.0000 - val_loss: 1.3877 - val_accuracy: 0.6968
Epoch 9/500
521/521 - 22s - loss: 6.6479e-04 - accuracy: 1.0000 - val_loss: 1.4308 - val_accuracy: 0.6960
Epoch 10/500
521/521 - 22s - loss: 4.6603e-04 - accuracy: 1.0000 - val_loss: 1.4810 - val_accuracy: 0.6904
Epoch 11/500
521/521 - 22s - loss: 3.3118e-04 - accuracy: 1.0000 - val_loss: 1.5309 - val_accuracy: 0.6888
Epoch 12/500
521/521 - 22s - loss: 2.3619e-04 - accuracy: 1.0000 - val_loss: 1.5726 - val_accuracy: 0.6952
Epoch 13/500
521/521 - 23s - loss: 1.6958e-04 - accuracy: 1.0000 - val_loss: 1.6195 - val_accuracy: 0.6936
Epoch 14/500
521/521 - 22s - loss: 1.2216e-04 - accuracy: 1.0000 - val_loss: 1.6549 - val_accuracy: 0.6920
Epoch 15/500
521/521 - 22s - loss: 8.8324e-05 - accuracy: 1.0000 - val_loss: 1.6997 - val_accuracy: 0.6928
Epoch 16/500
521/521 - 22s - loss: 6.3954e-05 - accuracy: 1.0000 - val_loss: 1.7322 - val_accuracy: 0.6928
Epoch 17/500
521/521 - 23s - loss: 4.6469e-05 - accuracy: 1.0000 - val_loss: 1.7921 - val_accuracy: 0.6920
Epoch 18/500
521/521 - 22s - loss: 3.3856e-05 - accuracy: 1.0000 - val_loss: 1.8311 - val_accuracy: 0.6920
Epoch 19/500
521/521 - 22s - loss: 2.4668e-05 - accuracy: 1.0000 - val_loss: 1.8704 - val_accuracy: 0.6952
Epoch 20/500
521/521 - 23s - loss: 1.8036e-05 - accuracy: 1.0000 - val_loss: 1.9198 - val_accuracy: 0.6912
Epoch 21/500
521/521 - 22s - loss: 1.3212e-05 - accuracy: 1.0000 - val_loss: 1.9578 - val_accuracy: 0.6936
Epoch 22/500
521/521 - 23s - loss: 9.6957e-06 - accuracy: 1.0000 - val_loss: 2.0042 - val_accuracy: 0.6920
Epoch 23/500
521/521 - 22s - loss: 7.1157e-06 - accuracy: 1.0000 - val_loss: 2.0420 - val_accuracy: 0.6920
Epoch 24/500
521/521 - 22s - loss: 5.2528e-06 - accuracy: 1.0000 - val_loss: 2.0804 - val_accuracy: 0.6992
Epoch 25/500
521/521 - 23s - loss: 3.8687e-06 - accuracy: 1.0000 - val_loss: 2.1301 - val_accuracy: 0.6936
Epoch 26/500
521/521 - 22s - loss: 2.8638e-06 - accuracy: 1.0000 - val_loss: 2.1683 - val_accuracy: 0.6976
Epoch 27/500
521/521 - 22s - loss: 2.1258e-06 - accuracy: 1.0000 - val_loss: 2.2118 - val_accuracy: 0.6936
Epoch 28/500
521/521 - 22s - loss: 1.5827e-06 - accuracy: 1.0000 - val_loss: 2.2505 - val_accuracy: 0.6968
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 13:04:39.038595: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 13:04:39.038754: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 13:04:39.038787: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 13:04:39.086151: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 13:04:39.086240: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00028: early stopping
Length split part:  16666
Labels in this part of split:  [1704, 1663, 1641, 1690, 1641, 1694, 1655, 1636, 1654, 1688]
Train for 521 steps, validate for 40 steps
Epoch 1/500
521/521 - 27s - loss: 1.2585 - accuracy: 0.5701 - val_loss: 2.3978 - val_accuracy: 0.0976
Epoch 2/500
521/521 - 26s - loss: 0.3534 - accuracy: 0.8941 - val_loss: 1.2486 - val_accuracy: 0.5896
Epoch 3/500
521/521 - 26s - loss: 0.0541 - accuracy: 0.9950 - val_loss: 1.1099 - val_accuracy: 0.6880
Epoch 4/500
521/521 - 22s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.2314 - val_accuracy: 0.6952
Epoch 5/500
521/521 - 23s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3107 - val_accuracy: 0.6944
Epoch 6/500
521/521 - 22s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3777 - val_accuracy: 0.6896
Epoch 7/500
521/521 - 22s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4542 - val_accuracy: 0.6944
Epoch 8/500
521/521 - 22s - loss: 9.9985e-04 - accuracy: 1.0000 - val_loss: 1.5093 - val_accuracy: 0.6928
Epoch 9/500
521/521 - 22s - loss: 6.8898e-04 - accuracy: 1.0000 - val_loss: 1.5602 - val_accuracy: 0.6904
Epoch 10/500
521/521 - 22s - loss: 4.8262e-04 - accuracy: 1.0000 - val_loss: 1.6181 - val_accuracy: 0.6912
Epoch 11/500
521/521 - 22s - loss: 3.4051e-04 - accuracy: 1.0000 - val_loss: 1.6696 - val_accuracy: 0.6912
Epoch 12/500
521/521 - 22s - loss: 2.4227e-04 - accuracy: 1.0000 - val_loss: 1.7263 - val_accuracy: 0.6920
Epoch 13/500
521/521 - 22s - loss: 1.7335e-04 - accuracy: 1.0000 - val_loss: 1.7694 - val_accuracy: 0.6904
Epoch 14/500
521/521 - 22s - loss: 1.2483e-04 - accuracy: 1.0000 - val_loss: 1.8324 - val_accuracy: 0.6912
Epoch 15/500
521/521 - 22s - loss: 8.9906e-05 - accuracy: 1.0000 - val_loss: 1.8802 - val_accuracy: 0.6936
Epoch 16/500
521/521 - 22s - loss: 6.5034e-05 - accuracy: 1.0000 - val_loss: 1.9226 - val_accuracy: 0.6960
Epoch 17/500
521/521 - 22s - loss: 4.7131e-05 - accuracy: 1.0000 - val_loss: 1.9874 - val_accuracy: 0.6912
Epoch 18/500
521/521 - 22s - loss: 3.4299e-05 - accuracy: 1.0000 - val_loss: 2.0301 - val_accuracy: 0.6936
Epoch 19/500
521/521 - 22s - loss: 2.4961e-05 - accuracy: 1.0000 - val_loss: 2.0880 - val_accuracy: 0.6920
Epoch 20/500
521/521 - 22s - loss: 1.8222e-05 - accuracy: 1.0000 - val_loss: 2.1399 - val_accuracy: 0.6928
Epoch 21/500
521/521 - 22s - loss: 1.3321e-05 - accuracy: 1.0000 - val_loss: 2.1811 - val_accuracy: 0.6920
Epoch 22/500
521/521 - 22s - loss: 9.7534e-06 - accuracy: 1.0000 - val_loss: 2.2391 - val_accuracy: 0.6896
Epoch 23/500
521/521 - 22s - loss: 7.1779e-06 - accuracy: 1.0000 - val_loss: 2.2829 - val_accuracy: 0.6960
Epoch 24/500
521/521 - 22s - loss: 5.2719e-06 - accuracy: 1.0000 - val_loss: 2.3280 - val_accuracy: 0.6912
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 13:14:38.519013: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 13:14:38.519154: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 13:14:38.519188: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 13:14:38.596827: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 13:14:38.596921: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00024: early stopping
ResNet101
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 75, 75, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 81, 81, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 38, 38, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 38, 38, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 38, 38, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 40, 40, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 19, 19, 64)   0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 19, 19, 64)   4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 19, 19, 64)   0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 19, 19, 64)   36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 19, 19, 64)   0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 19, 19, 256)  16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 19, 19, 256)  16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 19, 19, 256)  1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 19, 19, 256)  1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 19, 19, 256)  0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 19, 19, 256)  0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 19, 19, 64)   16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 19, 19, 64)   0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 19, 19, 64)   36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 19, 19, 64)   0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 19, 19, 256)  16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 19, 19, 256)  1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 19, 19, 256)  0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 19, 19, 256)  0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 19, 19, 64)   16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 19, 19, 64)   0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 19, 19, 64)   36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 19, 19, 64)   0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 19, 19, 256)  16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 19, 19, 256)  1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 19, 19, 256)  0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 19, 19, 256)  0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 10, 10, 128)  32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 10, 10, 128)  0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 10, 10, 128)  147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 10, 10, 128)  0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 10, 10, 512)  131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 10, 10, 512)  2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 10, 10, 512)  2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 10, 10, 512)  0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 10, 10, 512)  0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 10, 10, 128)  65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 10, 10, 128)  0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 10, 10, 128)  147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 10, 10, 128)  0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 10, 10, 512)  2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 10, 10, 512)  0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 10, 10, 512)  0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 10, 10, 128)  65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 10, 10, 128)  0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 10, 10, 128)  147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 10, 10, 128)  0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 10, 10, 512)  2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 10, 10, 512)  0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 10, 10, 512)  0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 10, 10, 128)  65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 10, 10, 128)  0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 10, 10, 128)  147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 10, 10, 128)  0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 10, 10, 512)  2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 10, 10, 512)  0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 10, 10, 512)  0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 5, 5, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 5, 5, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 5, 5, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 5, 5, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 5, 5, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 5, 5, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 5, 5, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 5, 5, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 5, 5, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 5, 5, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 5, 5, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 5, 5, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 5, 5, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 5, 5, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 5, 5, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 5, 5, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 5, 5, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 5, 5, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 5, 5, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 5, 5, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 5, 5, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 5, 5, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 5, 5, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 5, 5, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 5, 5, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 5, 5, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv4_block7_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv4_block7_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block7_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_1_relu (Activation (None, 5, 5, 256)    0           conv4_block7_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block7_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block7_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block7_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block7_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_2_relu (Activation (None, 5, 5, 256)    0           conv4_block7_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block7_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block7_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block7_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block7_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_add (Add)          (None, 5, 5, 1024)   0           conv4_block6_out[0][0]           
                                                                 conv4_block7_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block7_out (Activation)   (None, 5, 5, 1024)   0           conv4_block7_add[0][0]           
__________________________________________________________________________________________________
conv4_block8_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block7_out[0][0]           
__________________________________________________________________________________________________
conv4_block8_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block8_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_1_relu (Activation (None, 5, 5, 256)    0           conv4_block8_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block8_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block8_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block8_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block8_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_2_relu (Activation (None, 5, 5, 256)    0           conv4_block8_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block8_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block8_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block8_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block8_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_add (Add)          (None, 5, 5, 1024)   0           conv4_block7_out[0][0]           
                                                                 conv4_block8_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block8_out (Activation)   (None, 5, 5, 1024)   0           conv4_block8_add[0][0]           
__________________________________________________________________________________________________
conv4_block9_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block8_out[0][0]           
__________________________________________________________________________________________________
conv4_block9_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block9_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_1_relu (Activation (None, 5, 5, 256)    0           conv4_block9_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block9_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block9_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block9_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block9_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_2_relu (Activation (None, 5, 5, 256)    0           conv4_block9_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block9_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block9_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block9_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block9_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_add (Add)          (None, 5, 5, 1024)   0           conv4_block8_out[0][0]           
                                                                 conv4_block9_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block9_out (Activation)   (None, 5, 5, 1024)   0           conv4_block9_add[0][0]           
__________________________________________________________________________________________________
conv4_block10_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block9_out[0][0]           
__________________________________________________________________________________________________
conv4_block10_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block10_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block10_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block10_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block10_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block10_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block10_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block10_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block10_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block10_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block10_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block10_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block10_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block10_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block10_add (Add)         (None, 5, 5, 1024)   0           conv4_block9_out[0][0]           
                                                                 conv4_block10_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block10_out (Activation)  (None, 5, 5, 1024)   0           conv4_block10_add[0][0]          
__________________________________________________________________________________________________
conv4_block11_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block10_out[0][0]          
__________________________________________________________________________________________________
conv4_block11_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block11_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block11_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block11_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block11_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block11_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block11_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block11_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block11_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block11_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block11_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block11_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_add (Add)         (None, 5, 5, 1024)   0           conv4_block10_out[0][0]          
                                                                 conv4_block11_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block11_out (Activation)  (None, 5, 5, 1024)   0           conv4_block11_add[0][0]          
__________________________________________________________________________________________________
conv4_block12_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block11_out[0][0]          
__________________________________________________________________________________________________
conv4_block12_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block12_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block12_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block12_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block12_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block12_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block12_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block12_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block12_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block12_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block12_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block12_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_add (Add)         (None, 5, 5, 1024)   0           conv4_block11_out[0][0]          
                                                                 conv4_block12_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block12_out (Activation)  (None, 5, 5, 1024)   0           conv4_block12_add[0][0]          
__________________________________________________________________________________________________
conv4_block13_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block12_out[0][0]          
__________________________________________________________________________________________________
conv4_block13_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block13_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block13_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block13_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block13_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block13_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block13_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block13_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block13_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block13_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block13_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block13_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_add (Add)         (None, 5, 5, 1024)   0           conv4_block12_out[0][0]          
                                                                 conv4_block13_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block13_out (Activation)  (None, 5, 5, 1024)   0           conv4_block13_add[0][0]          
__________________________________________________________________________________________________
conv4_block14_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block13_out[0][0]          
__________________________________________________________________________________________________
conv4_block14_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block14_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block14_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block14_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block14_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block14_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block14_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block14_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block14_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block14_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block14_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block14_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_add (Add)         (None, 5, 5, 1024)   0           conv4_block13_out[0][0]          
                                                                 conv4_block14_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block14_out (Activation)  (None, 5, 5, 1024)   0           conv4_block14_add[0][0]          
__________________________________________________________________________________________________
conv4_block15_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block14_out[0][0]          
__________________________________________________________________________________________________
conv4_block15_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block15_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block15_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block15_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block15_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block15_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block15_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block15_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block15_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block15_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block15_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block15_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_add (Add)         (None, 5, 5, 1024)   0           conv4_block14_out[0][0]          
                                                                 conv4_block15_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block15_out (Activation)  (None, 5, 5, 1024)   0           conv4_block15_add[0][0]          
__________________________________________________________________________________________________
conv4_block16_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block15_out[0][0]          
__________________________________________________________________________________________________
conv4_block16_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block16_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block16_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block16_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block16_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block16_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block16_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block16_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block16_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block16_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block16_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block16_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_add (Add)         (None, 5, 5, 1024)   0           conv4_block15_out[0][0]          
                                                                 conv4_block16_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block16_out (Activation)  (None, 5, 5, 1024)   0           conv4_block16_add[0][0]          
__________________________________________________________________________________________________
conv4_block17_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block16_out[0][0]          
__________________________________________________________________________________________________
conv4_block17_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block17_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block17_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block17_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block17_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block17_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block17_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block17_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block17_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block17_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block17_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block17_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_add (Add)         (None, 5, 5, 1024)   0           conv4_block16_out[0][0]          
                                                                 conv4_block17_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block17_out (Activation)  (None, 5, 5, 1024)   0           conv4_block17_add[0][0]          
__________________________________________________________________________________________________
conv4_block18_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block17_out[0][0]          
__________________________________________________________________________________________________
conv4_block18_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block18_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block18_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block18_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block18_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block18_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block18_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block18_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block18_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block18_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block18_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block18_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_add (Add)         (None, 5, 5, 1024)   0           conv4_block17_out[0][0]          
                                                                 conv4_block18_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block18_out (Activation)  (None, 5, 5, 1024)   0           conv4_block18_add[0][0]          
__________________________________________________________________________________________________
conv4_block19_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block18_out[0][0]          
__________________________________________________________________________________________________
conv4_block19_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block19_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block19_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block19_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block19_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block19_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block19_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block19_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block19_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block19_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block19_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block19_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_add (Add)         (None, 5, 5, 1024)   0           conv4_block18_out[0][0]          
                                                                 conv4_block19_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block19_out (Activation)  (None, 5, 5, 1024)   0           conv4_block19_add[0][0]          
__________________________________________________________________________________________________
conv4_block20_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block19_out[0][0]          
__________________________________________________________________________________________________
conv4_block20_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block20_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block20_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block20_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block20_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block20_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block20_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block20_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block20_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block20_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block20_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block20_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_add (Add)         (None, 5, 5, 1024)   0           conv4_block19_out[0][0]          
                                                                 conv4_block20_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block20_out (Activation)  (None, 5, 5, 1024)   0           conv4_block20_add[0][0]          
__________________________________________________________________________________________________
conv4_block21_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block20_out[0][0]          
__________________________________________________________________________________________________
conv4_block21_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block21_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block21_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block21_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block21_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block21_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block21_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block21_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block21_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block21_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block21_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block21_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_add (Add)         (None, 5, 5, 1024)   0           conv4_block20_out[0][0]          
                                                                 conv4_block21_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block21_out (Activation)  (None, 5, 5, 1024)   0           conv4_block21_add[0][0]          
__________________________________________________________________________________________________
conv4_block22_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block21_out[0][0]          
__________________________________________________________________________________________________
conv4_block22_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block22_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block22_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block22_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block22_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block22_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block22_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block22_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block22_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block22_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block22_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block22_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_add (Add)         (None, 5, 5, 1024)   0           conv4_block21_out[0][0]          
                                                                 conv4_block22_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block22_out (Activation)  (None, 5, 5, 1024)   0           conv4_block22_add[0][0]          
__________________________________________________________________________________________________
conv4_block23_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block22_out[0][0]          
__________________________________________________________________________________________________
conv4_block23_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block23_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block23_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block23_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block23_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block23_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block23_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block23_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block23_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block23_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block23_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block23_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_add (Add)         (None, 5, 5, 1024)   0           conv4_block22_out[0][0]          
                                                                 conv4_block23_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block23_out (Activation)  (None, 5, 5, 1024)   0           conv4_block23_add[0][0]          
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 3, 3, 512)    524800      conv4_block23_out[0][0]          
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 3, 3, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 3, 3, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 3, 3, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 3, 3, 2048)   2099200     conv4_block23_out[0][0]          
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 3, 3, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 3, 3, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 3, 3, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 3, 3, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 3, 3, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 3, 3, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 3, 3, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 3, 3, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 3, 3, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 3, 3, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 3, 3, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 3, 3, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 3, 3, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 3, 3, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 3, 3, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 3, 3, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 3, 3, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 3, 3, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 3, 3, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 3, 3, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 3, 3, 2048)   0           conv5_block3_add[0][0]           
__________________________________________________________________________________________________
flatten (Flatten)               (None, 18432)        0           conv5_block3_out[0][0]           
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         75501568    flatten[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
predictions (Dense)             (None, 10)           40970       fc2[0][0]                        
==================================================================================================
Total params: 134,982,026
Trainable params: 134,876,682
Non-trainable params: 105,344
__________________________________________________________________________________________________
Start fitting ensemble models
Length split part:  16667
Labels in this part of split:  [1667, 1656, 1712, 1682, 1675, 1579, 1703, 1687, 1681, 1625]
Train for 521 steps, validate for 40 steps
Epoch 1/500
521/521 - 65s - loss: 1.3999 - accuracy: 0.5142 - val_loss: 3.0209 - val_accuracy: 0.0856
Epoch 2/500
521/521 - 43s - loss: 0.4952 - accuracy: 0.8499 - val_loss: 1.5376 - val_accuracy: 0.4632
Epoch 3/500
521/521 - 43s - loss: 0.2173 - accuracy: 0.9474 - val_loss: 1.3254 - val_accuracy: 0.6224
Epoch 4/500
521/521 - 37s - loss: 0.0906 - accuracy: 0.9804 - val_loss: 1.5689 - val_accuracy: 0.6136
Epoch 5/500
521/521 - 37s - loss: 0.0422 - accuracy: 0.9923 - val_loss: 1.5350 - val_accuracy: 0.6328
Epoch 6/500
521/521 - 37s - loss: 0.0129 - accuracy: 0.9982 - val_loss: 1.5510 - val_accuracy: 0.6432
Epoch 7/500
521/521 - 37s - loss: 0.0045 - accuracy: 0.9996 - val_loss: 1.6981 - val_accuracy: 0.6432
Epoch 8/500
521/521 - 37s - loss: 0.0029 - accuracy: 0.9999 - val_loss: 1.6268 - val_accuracy: 0.6496
Epoch 9/500
521/521 - 37s - loss: 0.0164 - accuracy: 0.9952 - val_loss: 2.0486 - val_accuracy: 0.6040
Epoch 10/500
521/521 - 37s - loss: 0.2202 - accuracy: 0.9249 - val_loss: 1.5983 - val_accuracy: 0.6336
Epoch 11/500
521/521 - 37s - loss: 0.0251 - accuracy: 0.9945 - val_loss: 1.7569 - val_accuracy: 0.6464
Epoch 12/500
521/521 - 37s - loss: 0.0033 - accuracy: 0.9998 - val_loss: 1.5307 - val_accuracy: 0.6632
Epoch 13/500
521/521 - 37s - loss: 0.0030 - accuracy: 0.9994 - val_loss: 1.6065 - val_accuracy: 0.6744
Epoch 14/500
521/521 - 37s - loss: 9.9345e-04 - accuracy: 1.0000 - val_loss: 1.6239 - val_accuracy: 0.6768
Epoch 15/500
521/521 - 37s - loss: 3.7885e-04 - accuracy: 1.0000 - val_loss: 1.6513 - val_accuracy: 0.6816
Epoch 16/500
521/521 - 37s - loss: 2.4419e-04 - accuracy: 1.0000 - val_loss: 1.6942 - val_accuracy: 0.6808
Epoch 17/500
521/521 - 37s - loss: 1.7546e-04 - accuracy: 1.0000 - val_loss: 1.7216 - val_accuracy: 0.6744
Epoch 18/500
521/521 - 37s - loss: 1.2988e-04 - accuracy: 1.0000 - val_loss: 1.7422 - val_accuracy: 0.6816
Epoch 19/500
521/521 - 37s - loss: 9.7451e-05 - accuracy: 1.0000 - val_loss: 1.7780 - val_accuracy: 0.6800
Epoch 20/500
521/521 - 37s - loss: 7.3553e-05 - accuracy: 1.0000 - val_loss: 1.8179 - val_accuracy: 0.6800
Epoch 21/500
521/521 - 37s - loss: 5.5727e-05 - accuracy: 1.0000 - val_loss: 1.8458 - val_accuracy: 0.6792
Epoch 22/500
521/521 - 37s - loss: 4.2381e-05 - accuracy: 1.0000 - val_loss: 1.8789 - val_accuracy: 0.6800
Epoch 23/500
521/521 - 37s - loss: 3.2184e-05 - accuracy: 1.0000 - val_loss: 1.9080 - val_accuracy: 0.6776
Epoch 24/500
521/521 - 37s - loss: 2.4471e-05 - accuracy: 1.0000 - val_loss: 1.9376 - val_accuracy: 0.6776
Epoch 25/500
521/521 - 37s - loss: 1.8591e-05 - accuracy: 1.0000 - val_loss: 1.9750 - val_accuracy: 0.6792
Epoch 26/500
521/521 - 37s - loss: 1.4125e-05 - accuracy: 1.0000 - val_loss: 2.0188 - val_accuracy: 0.6816
Epoch 27/500
521/521 - 37s - loss: 1.0711e-05 - accuracy: 1.0000 - val_loss: 2.0544 - val_accuracy: 0.6824
Epoch 28/500
521/521 - 37s - loss: 8.1341e-06 - accuracy: 1.0000 - val_loss: 2.0765 - val_accuracy: 0.6808
Epoch 29/500
521/521 - 37s - loss: 6.1635e-06 - accuracy: 1.0000 - val_loss: 2.1151 - val_accuracy: 0.6824
Epoch 30/500
521/521 - 37s - loss: 4.6756e-06 - accuracy: 1.0000 - val_loss: 2.1447 - val_accuracy: 0.6776
Epoch 31/500
521/521 - 37s - loss: 3.5441e-06 - accuracy: 1.0000 - val_loss: 2.1877 - val_accuracy: 0.6856
Epoch 32/500
521/521 - 37s - loss: 2.6871e-06 - accuracy: 1.0000 - val_loss: 2.2123 - val_accuracy: 0.6800
Epoch 33/500
521/521 - 37s - loss: 2.0361e-06 - accuracy: 1.0000 - val_loss: 2.2472 - val_accuracy: 0.6800
Epoch 34/500
521/521 - 37s - loss: 1.5448e-06 - accuracy: 1.0000 - val_loss: 2.2875 - val_accuracy: 0.6808
Epoch 35/500
521/521 - 37s - loss: 1.1728e-06 - accuracy: 1.0000 - val_loss: 2.3199 - val_accuracy: 0.6824
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 13:37:01.684652: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 13:37:01.684794: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 13:37:01.684827: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 13:37:01.762373: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 13:37:01.762478: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00035: early stopping
Length split part:  16667
Labels in this part of split:  [1629, 1681, 1647, 1628, 1684, 1727, 1642, 1677, 1665, 1687]
Train for 521 steps, validate for 40 steps
Epoch 1/500
521/521 - 43s - loss: 1.2341 - accuracy: 0.5804 - val_loss: 2.8079 - val_accuracy: 0.0928
Epoch 2/500
521/521 - 45s - loss: 0.4142 - accuracy: 0.8679 - val_loss: 1.3790 - val_accuracy: 0.5192
Epoch 3/500
521/521 - 42s - loss: 0.0975 - accuracy: 0.9785 - val_loss: 1.0552 - val_accuracy: 0.6816
Epoch 4/500
521/521 - 37s - loss: 0.0280 - accuracy: 0.9954 - val_loss: 1.1901 - val_accuracy: 0.6896
Epoch 5/500
521/521 - 37s - loss: 0.0099 - accuracy: 0.9987 - val_loss: 1.2543 - val_accuracy: 0.7008
Epoch 6/500
521/521 - 37s - loss: 0.0045 - accuracy: 0.9994 - val_loss: 1.2730 - val_accuracy: 0.6968
Epoch 7/500
521/521 - 37s - loss: 0.0069 - accuracy: 0.9984 - val_loss: 1.3308 - val_accuracy: 0.7008
Epoch 8/500
521/521 - 37s - loss: 0.0071 - accuracy: 0.9984 - val_loss: 1.5456 - val_accuracy: 0.6792
Epoch 9/500
521/521 - 37s - loss: 0.1196 - accuracy: 0.9602 - val_loss: 1.3293 - val_accuracy: 0.6760
Epoch 10/500
521/521 - 37s - loss: 0.0589 - accuracy: 0.9825 - val_loss: 1.4316 - val_accuracy: 0.6928
Epoch 11/500
521/521 - 37s - loss: 0.0083 - accuracy: 0.9988 - val_loss: 1.4315 - val_accuracy: 0.6976
Epoch 12/500
521/521 - 37s - loss: 0.0018 - accuracy: 0.9996 - val_loss: 1.5232 - val_accuracy: 0.6968
Epoch 13/500
521/521 - 37s - loss: 5.8299e-04 - accuracy: 1.0000 - val_loss: 1.5188 - val_accuracy: 0.7048
Epoch 14/500
521/521 - 37s - loss: 4.9829e-04 - accuracy: 0.9999 - val_loss: 1.5579 - val_accuracy: 0.7096
Epoch 15/500
521/521 - 37s - loss: 0.0037 - accuracy: 0.9991 - val_loss: 1.6750 - val_accuracy: 0.7088
Epoch 16/500
521/521 - 37s - loss: 0.1269 - accuracy: 0.9567 - val_loss: 1.4959 - val_accuracy: 0.6832
Epoch 17/500
521/521 - 37s - loss: 0.0347 - accuracy: 0.9897 - val_loss: 1.4679 - val_accuracy: 0.7080
Epoch 18/500
521/521 - 37s - loss: 0.0043 - accuracy: 0.9995 - val_loss: 1.5576 - val_accuracy: 0.7160
Epoch 19/500
521/521 - 37s - loss: 5.8930e-04 - accuracy: 1.0000 - val_loss: 1.5800 - val_accuracy: 0.7128
Epoch 20/500
521/521 - 37s - loss: 2.4947e-04 - accuracy: 1.0000 - val_loss: 1.6001 - val_accuracy: 0.7184
Epoch 21/500
521/521 - 37s - loss: 1.7161e-04 - accuracy: 1.0000 - val_loss: 1.6234 - val_accuracy: 0.7136
Epoch 22/500
521/521 - 37s - loss: 1.2500e-04 - accuracy: 1.0000 - val_loss: 1.6478 - val_accuracy: 0.7200
Epoch 23/500
521/521 - 37s - loss: 9.2944e-05 - accuracy: 1.0000 - val_loss: 1.6788 - val_accuracy: 0.7232
Epoch 24/500
521/521 - 37s - loss: 6.9887e-05 - accuracy: 1.0000 - val_loss: 1.6981 - val_accuracy: 0.7224
Epoch 25/500
521/521 - 37s - loss: 5.2853e-05 - accuracy: 1.0000 - val_loss: 1.7307 - val_accuracy: 0.7232
Epoch 26/500
521/521 - 37s - loss: 4.0072e-05 - accuracy: 1.0000 - val_loss: 1.7582 - val_accuracy: 0.7272
Epoch 27/500
521/521 - 37s - loss: 3.0404e-05 - accuracy: 1.0000 - val_loss: 1.7879 - val_accuracy: 0.7256
Epoch 28/500
521/521 - 37s - loss: 2.3101e-05 - accuracy: 1.0000 - val_loss: 1.8134 - val_accuracy: 0.7240
Epoch 29/500
521/521 - 37s - loss: 1.7530e-05 - accuracy: 1.0000 - val_loss: 1.8417 - val_accuracy: 0.7272
Epoch 30/500
521/521 - 37s - loss: 1.3313e-05 - accuracy: 1.0000 - val_loss: 1.8648 - val_accuracy: 0.7272
Epoch 31/500
521/521 - 37s - loss: 1.0097e-05 - accuracy: 1.0000 - val_loss: 1.8938 - val_accuracy: 0.7256
Epoch 32/500
521/521 - 37s - loss: 7.6568e-06 - accuracy: 1.0000 - val_loss: 1.9216 - val_accuracy: 0.7264
Epoch 33/500
521/521 - 37s - loss: 5.7993e-06 - accuracy: 1.0000 - val_loss: 1.9621 - val_accuracy: 0.7280
Epoch 34/500
521/521 - 37s - loss: 4.3903e-06 - accuracy: 1.0000 - val_loss: 1.9754 - val_accuracy: 0.7232
Epoch 35/500
521/521 - 37s - loss: 3.3302e-06 - accuracy: 1.0000 - val_loss: 2.0038 - val_accuracy: 0.7256
Epoch 36/500
521/521 - 37s - loss: 2.5219e-06 - accuracy: 1.0000 - val_loss: 2.0500 - val_accuracy: 0.7264
Epoch 37/500
521/521 - 37s - loss: 1.9112e-06 - accuracy: 1.0000 - val_loss: 2.0695 - val_accuracy: 0.7264
Epoch 38/500
521/521 - 37s - loss: 1.4483e-06 - accuracy: 1.0000 - val_loss: 2.1071 - val_accuracy: 0.7256
Epoch 39/500
521/521 - 37s - loss: 1.0979e-06 - accuracy: 1.0000 - val_loss: 2.1370 - val_accuracy: 0.7248
Epoch 40/500
521/521 - 37s - loss: 8.3380e-07 - accuracy: 1.0000 - val_loss: 2.1621 - val_accuracy: 0.7272
Epoch 41/500
521/521 - 37s - loss: 6.3414e-07 - accuracy: 1.0000 - val_loss: 2.1800 - val_accuracy: 0.7272
Epoch 42/500
521/521 - 37s - loss: 4.8344e-07 - accuracy: 1.0000 - val_loss: 2.2194 - val_accuracy: 0.7248
Epoch 43/500
521/521 - 37s - loss: 3.6933e-07 - accuracy: 1.0000 - val_loss: 2.2474 - val_accuracy: 0.7272
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 14:04:21.052509: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 14:04:21.052647: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 14:04:21.052679: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 14:04:21.126940: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 14:04:21.127030: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00043: early stopping
Length split part:  16666
Labels in this part of split:  [1704, 1663, 1641, 1690, 1641, 1694, 1655, 1636, 1654, 1688]
Train for 521 steps, validate for 40 steps
Epoch 1/500
521/521 - 41s - loss: 1.2664 - accuracy: 0.5655 - val_loss: 2.6683 - val_accuracy: 0.0856
Epoch 2/500
521/521 - 41s - loss: 0.3886 - accuracy: 0.8795 - val_loss: 1.5349 - val_accuracy: 0.4864
Epoch 3/500
521/521 - 42s - loss: 0.0645 - accuracy: 0.9906 - val_loss: 1.0567 - val_accuracy: 0.7040
Epoch 4/500
521/521 - 37s - loss: 0.0081 - accuracy: 0.9999 - val_loss: 1.1438 - val_accuracy: 0.7016
Epoch 5/500
521/521 - 38s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2117 - val_accuracy: 0.7024
Epoch 6/500
521/521 - 38s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2604 - val_accuracy: 0.7040
Epoch 7/500
521/521 - 37s - loss: 9.5758e-04 - accuracy: 1.0000 - val_loss: 1.3131 - val_accuracy: 0.7064
Epoch 8/500
521/521 - 37s - loss: 6.4702e-04 - accuracy: 1.0000 - val_loss: 1.3471 - val_accuracy: 0.7056
Epoch 9/500
521/521 - 38s - loss: 4.4787e-04 - accuracy: 1.0000 - val_loss: 1.4018 - val_accuracy: 0.7112
Epoch 10/500
521/521 - 37s - loss: 3.1602e-04 - accuracy: 1.0000 - val_loss: 1.4293 - val_accuracy: 0.7120
Epoch 11/500
521/521 - 37s - loss: 2.2496e-04 - accuracy: 1.0000 - val_loss: 1.4700 - val_accuracy: 0.7080
Epoch 12/500
521/521 - 37s - loss: 1.6144e-04 - accuracy: 1.0000 - val_loss: 1.5039 - val_accuracy: 0.7080
Epoch 13/500
521/521 - 38s - loss: 1.1631e-04 - accuracy: 1.0000 - val_loss: 1.5584 - val_accuracy: 0.7120
Epoch 14/500
521/521 - 37s - loss: 8.4207e-05 - accuracy: 1.0000 - val_loss: 1.5953 - val_accuracy: 0.7104
Epoch 15/500
521/521 - 38s - loss: 6.1175e-05 - accuracy: 1.0000 - val_loss: 1.6327 - val_accuracy: 0.7104
Epoch 16/500
521/521 - 38s - loss: 4.4532e-05 - accuracy: 1.0000 - val_loss: 1.6613 - val_accuracy: 0.7048
Epoch 17/500
521/521 - 37s - loss: 3.2398e-05 - accuracy: 1.0000 - val_loss: 1.7164 - val_accuracy: 0.7096
Epoch 18/500
521/521 - 37s - loss: 2.3720e-05 - accuracy: 1.0000 - val_loss: 1.7417 - val_accuracy: 0.7104
Epoch 19/500
521/521 - 37s - loss: 1.7331e-05 - accuracy: 1.0000 - val_loss: 1.7808 - val_accuracy: 0.7112
Epoch 20/500
521/521 - 37s - loss: 1.2713e-05 - accuracy: 1.0000 - val_loss: 1.8272 - val_accuracy: 0.7112
Epoch 21/500
521/521 - 37s - loss: 9.3290e-06 - accuracy: 1.0000 - val_loss: 1.8641 - val_accuracy: 0.7088
Epoch 22/500
521/521 - 37s - loss: 6.8647e-06 - accuracy: 1.0000 - val_loss: 1.9023 - val_accuracy: 0.7144
Epoch 23/500
521/521 - 37s - loss: 5.0517e-06 - accuracy: 1.0000 - val_loss: 1.9410 - val_accuracy: 0.7128
Epoch 24/500
521/521 - 38s - loss: 3.7253e-06 - accuracy: 1.0000 - val_loss: 1.9835 - val_accuracy: 0.7104
Epoch 25/500
521/521 - 37s - loss: 2.7544e-06 - accuracy: 1.0000 - val_loss: 2.0166 - val_accuracy: 0.7120
Epoch 26/500
521/521 - 37s - loss: 2.0415e-06 - accuracy: 1.0000 - val_loss: 2.0570 - val_accuracy: 0.7120
Epoch 27/500
521/521 - 37s - loss: 1.5150e-06 - accuracy: 1.0000 - val_loss: 2.0847 - val_accuracy: 0.7112
Epoch 28/500
521/521 - 37s - loss: 1.1261e-06 - accuracy: 1.0000 - val_loss: 2.1234 - val_accuracy: 0.7120
Epoch 29/500
521/521 - 37s - loss: 8.4168e-07 - accuracy: 1.0000 - val_loss: 2.1599 - val_accuracy: 0.7136
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 14:23:58.339315: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 14:23:58.339496: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 14:23:58.339531: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 14:23:58.447037: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 14:23:58.447126: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00029: early stopping
ResNet152
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 75, 75, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 81, 81, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 38, 38, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 38, 38, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 38, 38, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 40, 40, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 19, 19, 64)   0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 19, 19, 64)   4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 19, 19, 64)   0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 19, 19, 64)   36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 19, 19, 64)   0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 19, 19, 256)  16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 19, 19, 256)  16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 19, 19, 256)  1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 19, 19, 256)  1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 19, 19, 256)  0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 19, 19, 256)  0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 19, 19, 64)   16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 19, 19, 64)   0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 19, 19, 64)   36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 19, 19, 64)   0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 19, 19, 256)  16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 19, 19, 256)  1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 19, 19, 256)  0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 19, 19, 256)  0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 19, 19, 64)   16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 19, 19, 64)   0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 19, 19, 64)   36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 19, 19, 64)   0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 19, 19, 256)  16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 19, 19, 256)  1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 19, 19, 256)  0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 19, 19, 256)  0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 10, 10, 128)  32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 10, 10, 128)  0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 10, 10, 128)  147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 10, 10, 128)  0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 10, 10, 512)  131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 10, 10, 512)  2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 10, 10, 512)  2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 10, 10, 512)  0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 10, 10, 512)  0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 10, 10, 128)  65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 10, 10, 128)  0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 10, 10, 128)  147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 10, 10, 128)  0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 10, 10, 512)  2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 10, 10, 512)  0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 10, 10, 512)  0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 10, 10, 128)  65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 10, 10, 128)  0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 10, 10, 128)  147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 10, 10, 128)  0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 10, 10, 512)  2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 10, 10, 512)  0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 10, 10, 512)  0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 10, 10, 128)  65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 10, 10, 128)  0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 10, 10, 128)  147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 10, 10, 128)  0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 10, 10, 512)  2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 10, 10, 512)  0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 10, 10, 512)  0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv3_block5_1_conv (Conv2D)    (None, 10, 10, 128)  65664       conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv3_block5_1_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block5_1_relu (Activation (None, 10, 10, 128)  0           conv3_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block5_2_conv (Conv2D)    (None, 10, 10, 128)  147584      conv3_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block5_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block5_2_relu (Activation (None, 10, 10, 128)  0           conv3_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block5_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block5_3_bn (BatchNormali (None, 10, 10, 512)  2048        conv3_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block5_add (Add)          (None, 10, 10, 512)  0           conv3_block4_out[0][0]           
                                                                 conv3_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block5_out (Activation)   (None, 10, 10, 512)  0           conv3_block5_add[0][0]           
__________________________________________________________________________________________________
conv3_block6_1_conv (Conv2D)    (None, 10, 10, 128)  65664       conv3_block5_out[0][0]           
__________________________________________________________________________________________________
conv3_block6_1_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block6_1_relu (Activation (None, 10, 10, 128)  0           conv3_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block6_2_conv (Conv2D)    (None, 10, 10, 128)  147584      conv3_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block6_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block6_2_relu (Activation (None, 10, 10, 128)  0           conv3_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block6_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block6_3_bn (BatchNormali (None, 10, 10, 512)  2048        conv3_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block6_add (Add)          (None, 10, 10, 512)  0           conv3_block5_out[0][0]           
                                                                 conv3_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block6_out (Activation)   (None, 10, 10, 512)  0           conv3_block6_add[0][0]           
__________________________________________________________________________________________________
conv3_block7_1_conv (Conv2D)    (None, 10, 10, 128)  65664       conv3_block6_out[0][0]           
__________________________________________________________________________________________________
conv3_block7_1_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block7_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block7_1_relu (Activation (None, 10, 10, 128)  0           conv3_block7_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block7_2_conv (Conv2D)    (None, 10, 10, 128)  147584      conv3_block7_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block7_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block7_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block7_2_relu (Activation (None, 10, 10, 128)  0           conv3_block7_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block7_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block7_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block7_3_bn (BatchNormali (None, 10, 10, 512)  2048        conv3_block7_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block7_add (Add)          (None, 10, 10, 512)  0           conv3_block6_out[0][0]           
                                                                 conv3_block7_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block7_out (Activation)   (None, 10, 10, 512)  0           conv3_block7_add[0][0]           
__________________________________________________________________________________________________
conv3_block8_1_conv (Conv2D)    (None, 10, 10, 128)  65664       conv3_block7_out[0][0]           
__________________________________________________________________________________________________
conv3_block8_1_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block8_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block8_1_relu (Activation (None, 10, 10, 128)  0           conv3_block8_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block8_2_conv (Conv2D)    (None, 10, 10, 128)  147584      conv3_block8_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block8_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block8_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block8_2_relu (Activation (None, 10, 10, 128)  0           conv3_block8_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block8_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block8_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block8_3_bn (BatchNormali (None, 10, 10, 512)  2048        conv3_block8_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block8_add (Add)          (None, 10, 10, 512)  0           conv3_block7_out[0][0]           
                                                                 conv3_block8_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block8_out (Activation)   (None, 10, 10, 512)  0           conv3_block8_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 5, 5, 256)    131328      conv3_block8_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 5, 5, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 5, 5, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 5, 5, 1024)   525312      conv3_block8_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 5, 5, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 5, 5, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 5, 5, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 5, 5, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 5, 5, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 5, 5, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 5, 5, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 5, 5, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 5, 5, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 5, 5, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 5, 5, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 5, 5, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 5, 5, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 5, 5, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 5, 5, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 5, 5, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 5, 5, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 5, 5, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 5, 5, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 5, 5, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 5, 5, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 5, 5, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv4_block7_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv4_block7_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block7_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_1_relu (Activation (None, 5, 5, 256)    0           conv4_block7_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block7_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block7_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block7_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block7_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_2_relu (Activation (None, 5, 5, 256)    0           conv4_block7_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block7_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block7_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block7_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block7_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_add (Add)          (None, 5, 5, 1024)   0           conv4_block6_out[0][0]           
                                                                 conv4_block7_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block7_out (Activation)   (None, 5, 5, 1024)   0           conv4_block7_add[0][0]           
__________________________________________________________________________________________________
conv4_block8_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block7_out[0][0]           
__________________________________________________________________________________________________
conv4_block8_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block8_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_1_relu (Activation (None, 5, 5, 256)    0           conv4_block8_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block8_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block8_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block8_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block8_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_2_relu (Activation (None, 5, 5, 256)    0           conv4_block8_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block8_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block8_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block8_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block8_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_add (Add)          (None, 5, 5, 1024)   0           conv4_block7_out[0][0]           
                                                                 conv4_block8_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block8_out (Activation)   (None, 5, 5, 1024)   0           conv4_block8_add[0][0]           
__________________________________________________________________________________________________
conv4_block9_1_conv (Conv2D)    (None, 5, 5, 256)    262400      conv4_block8_out[0][0]           
__________________________________________________________________________________________________
conv4_block9_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block9_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_1_relu (Activation (None, 5, 5, 256)    0           conv4_block9_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block9_2_conv (Conv2D)    (None, 5, 5, 256)    590080      conv4_block9_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block9_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block9_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_2_relu (Activation (None, 5, 5, 256)    0           conv4_block9_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block9_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block9_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block9_3_bn (BatchNormali (None, 5, 5, 1024)   4096        conv4_block9_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_add (Add)          (None, 5, 5, 1024)   0           conv4_block8_out[0][0]           
                                                                 conv4_block9_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block9_out (Activation)   (None, 5, 5, 1024)   0           conv4_block9_add[0][0]           
__________________________________________________________________________________________________
conv4_block10_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block9_out[0][0]           
__________________________________________________________________________________________________
conv4_block10_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block10_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block10_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block10_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block10_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block10_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block10_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block10_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block10_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block10_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block10_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block10_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block10_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block10_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block10_add (Add)         (None, 5, 5, 1024)   0           conv4_block9_out[0][0]           
                                                                 conv4_block10_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block10_out (Activation)  (None, 5, 5, 1024)   0           conv4_block10_add[0][0]          
__________________________________________________________________________________________________
conv4_block11_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block10_out[0][0]          
__________________________________________________________________________________________________
conv4_block11_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block11_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block11_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block11_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block11_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block11_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block11_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block11_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block11_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block11_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block11_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block11_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_add (Add)         (None, 5, 5, 1024)   0           conv4_block10_out[0][0]          
                                                                 conv4_block11_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block11_out (Activation)  (None, 5, 5, 1024)   0           conv4_block11_add[0][0]          
__________________________________________________________________________________________________
conv4_block12_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block11_out[0][0]          
__________________________________________________________________________________________________
conv4_block12_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block12_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block12_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block12_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block12_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block12_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block12_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block12_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block12_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block12_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block12_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block12_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_add (Add)         (None, 5, 5, 1024)   0           conv4_block11_out[0][0]          
                                                                 conv4_block12_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block12_out (Activation)  (None, 5, 5, 1024)   0           conv4_block12_add[0][0]          
__________________________________________________________________________________________________
conv4_block13_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block12_out[0][0]          
__________________________________________________________________________________________________
conv4_block13_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block13_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block13_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block13_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block13_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block13_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block13_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block13_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block13_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block13_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block13_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block13_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_add (Add)         (None, 5, 5, 1024)   0           conv4_block12_out[0][0]          
                                                                 conv4_block13_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block13_out (Activation)  (None, 5, 5, 1024)   0           conv4_block13_add[0][0]          
__________________________________________________________________________________________________
conv4_block14_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block13_out[0][0]          
__________________________________________________________________________________________________
conv4_block14_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block14_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block14_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block14_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block14_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block14_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block14_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block14_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block14_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block14_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block14_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block14_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_add (Add)         (None, 5, 5, 1024)   0           conv4_block13_out[0][0]          
                                                                 conv4_block14_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block14_out (Activation)  (None, 5, 5, 1024)   0           conv4_block14_add[0][0]          
__________________________________________________________________________________________________
conv4_block15_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block14_out[0][0]          
__________________________________________________________________________________________________
conv4_block15_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block15_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block15_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block15_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block15_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block15_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block15_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block15_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block15_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block15_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block15_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block15_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_add (Add)         (None, 5, 5, 1024)   0           conv4_block14_out[0][0]          
                                                                 conv4_block15_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block15_out (Activation)  (None, 5, 5, 1024)   0           conv4_block15_add[0][0]          
__________________________________________________________________________________________________
conv4_block16_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block15_out[0][0]          
__________________________________________________________________________________________________
conv4_block16_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block16_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block16_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block16_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block16_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block16_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block16_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block16_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block16_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block16_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block16_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block16_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_add (Add)         (None, 5, 5, 1024)   0           conv4_block15_out[0][0]          
                                                                 conv4_block16_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block16_out (Activation)  (None, 5, 5, 1024)   0           conv4_block16_add[0][0]          
__________________________________________________________________________________________________
conv4_block17_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block16_out[0][0]          
__________________________________________________________________________________________________
conv4_block17_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block17_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block17_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block17_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block17_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block17_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block17_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block17_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block17_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block17_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block17_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block17_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_add (Add)         (None, 5, 5, 1024)   0           conv4_block16_out[0][0]          
                                                                 conv4_block17_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block17_out (Activation)  (None, 5, 5, 1024)   0           conv4_block17_add[0][0]          
__________________________________________________________________________________________________
conv4_block18_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block17_out[0][0]          
__________________________________________________________________________________________________
conv4_block18_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block18_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block18_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block18_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block18_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block18_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block18_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block18_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block18_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block18_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block18_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block18_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_add (Add)         (None, 5, 5, 1024)   0           conv4_block17_out[0][0]          
                                                                 conv4_block18_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block18_out (Activation)  (None, 5, 5, 1024)   0           conv4_block18_add[0][0]          
__________________________________________________________________________________________________
conv4_block19_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block18_out[0][0]          
__________________________________________________________________________________________________
conv4_block19_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block19_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block19_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block19_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block19_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block19_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block19_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block19_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block19_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block19_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block19_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block19_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_add (Add)         (None, 5, 5, 1024)   0           conv4_block18_out[0][0]          
                                                                 conv4_block19_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block19_out (Activation)  (None, 5, 5, 1024)   0           conv4_block19_add[0][0]          
__________________________________________________________________________________________________
conv4_block20_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block19_out[0][0]          
__________________________________________________________________________________________________
conv4_block20_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block20_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block20_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block20_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block20_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block20_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block20_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block20_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block20_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block20_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block20_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block20_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_add (Add)         (None, 5, 5, 1024)   0           conv4_block19_out[0][0]          
                                                                 conv4_block20_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block20_out (Activation)  (None, 5, 5, 1024)   0           conv4_block20_add[0][0]          
__________________________________________________________________________________________________
conv4_block21_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block20_out[0][0]          
__________________________________________________________________________________________________
conv4_block21_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block21_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block21_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block21_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block21_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block21_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block21_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block21_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block21_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block21_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block21_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block21_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_add (Add)         (None, 5, 5, 1024)   0           conv4_block20_out[0][0]          
                                                                 conv4_block21_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block21_out (Activation)  (None, 5, 5, 1024)   0           conv4_block21_add[0][0]          
__________________________________________________________________________________________________
conv4_block22_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block21_out[0][0]          
__________________________________________________________________________________________________
conv4_block22_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block22_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block22_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block22_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block22_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block22_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block22_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block22_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block22_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block22_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block22_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block22_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_add (Add)         (None, 5, 5, 1024)   0           conv4_block21_out[0][0]          
                                                                 conv4_block22_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block22_out (Activation)  (None, 5, 5, 1024)   0           conv4_block22_add[0][0]          
__________________________________________________________________________________________________
conv4_block23_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block22_out[0][0]          
__________________________________________________________________________________________________
conv4_block23_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block23_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block23_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block23_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block23_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block23_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block23_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block23_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block23_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block23_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block23_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block23_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_add (Add)         (None, 5, 5, 1024)   0           conv4_block22_out[0][0]          
                                                                 conv4_block23_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block23_out (Activation)  (None, 5, 5, 1024)   0           conv4_block23_add[0][0]          
__________________________________________________________________________________________________
conv4_block24_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block23_out[0][0]          
__________________________________________________________________________________________________
conv4_block24_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block24_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block24_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block24_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block24_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block24_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block24_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block24_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block24_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block24_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block24_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block24_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block24_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block24_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block24_add (Add)         (None, 5, 5, 1024)   0           conv4_block23_out[0][0]          
                                                                 conv4_block24_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block24_out (Activation)  (None, 5, 5, 1024)   0           conv4_block24_add[0][0]          
__________________________________________________________________________________________________
conv4_block25_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block24_out[0][0]          
__________________________________________________________________________________________________
conv4_block25_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block25_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block25_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block25_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block25_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block25_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block25_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block25_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block25_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block25_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block25_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block25_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block25_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block25_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block25_add (Add)         (None, 5, 5, 1024)   0           conv4_block24_out[0][0]          
                                                                 conv4_block25_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block25_out (Activation)  (None, 5, 5, 1024)   0           conv4_block25_add[0][0]          
__________________________________________________________________________________________________
conv4_block26_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block25_out[0][0]          
__________________________________________________________________________________________________
conv4_block26_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block26_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block26_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block26_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block26_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block26_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block26_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block26_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block26_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block26_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block26_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block26_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block26_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block26_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block26_add (Add)         (None, 5, 5, 1024)   0           conv4_block25_out[0][0]          
                                                                 conv4_block26_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block26_out (Activation)  (None, 5, 5, 1024)   0           conv4_block26_add[0][0]          
__________________________________________________________________________________________________
conv4_block27_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block26_out[0][0]          
__________________________________________________________________________________________________
conv4_block27_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block27_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block27_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block27_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block27_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block27_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block27_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block27_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block27_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block27_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block27_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block27_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block27_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block27_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block27_add (Add)         (None, 5, 5, 1024)   0           conv4_block26_out[0][0]          
                                                                 conv4_block27_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block27_out (Activation)  (None, 5, 5, 1024)   0           conv4_block27_add[0][0]          
__________________________________________________________________________________________________
conv4_block28_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block27_out[0][0]          
__________________________________________________________________________________________________
conv4_block28_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block28_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block28_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block28_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block28_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block28_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block28_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block28_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block28_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block28_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block28_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block28_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block28_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block28_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block28_add (Add)         (None, 5, 5, 1024)   0           conv4_block27_out[0][0]          
                                                                 conv4_block28_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block28_out (Activation)  (None, 5, 5, 1024)   0           conv4_block28_add[0][0]          
__________________________________________________________________________________________________
conv4_block29_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block28_out[0][0]          
__________________________________________________________________________________________________
conv4_block29_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block29_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block29_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block29_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block29_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block29_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block29_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block29_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block29_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block29_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block29_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block29_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block29_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block29_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block29_add (Add)         (None, 5, 5, 1024)   0           conv4_block28_out[0][0]          
                                                                 conv4_block29_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block29_out (Activation)  (None, 5, 5, 1024)   0           conv4_block29_add[0][0]          
__________________________________________________________________________________________________
conv4_block30_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block29_out[0][0]          
__________________________________________________________________________________________________
conv4_block30_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block30_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block30_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block30_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block30_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block30_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block30_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block30_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block30_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block30_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block30_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block30_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block30_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block30_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block30_add (Add)         (None, 5, 5, 1024)   0           conv4_block29_out[0][0]          
                                                                 conv4_block30_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block30_out (Activation)  (None, 5, 5, 1024)   0           conv4_block30_add[0][0]          
__________________________________________________________________________________________________
conv4_block31_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block30_out[0][0]          
__________________________________________________________________________________________________
conv4_block31_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block31_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block31_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block31_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block31_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block31_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block31_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block31_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block31_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block31_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block31_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block31_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block31_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block31_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block31_add (Add)         (None, 5, 5, 1024)   0           conv4_block30_out[0][0]          
                                                                 conv4_block31_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block31_out (Activation)  (None, 5, 5, 1024)   0           conv4_block31_add[0][0]          
__________________________________________________________________________________________________
conv4_block32_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block31_out[0][0]          
__________________________________________________________________________________________________
conv4_block32_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block32_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block32_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block32_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block32_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block32_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block32_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block32_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block32_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block32_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block32_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block32_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block32_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block32_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block32_add (Add)         (None, 5, 5, 1024)   0           conv4_block31_out[0][0]          
                                                                 conv4_block32_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block32_out (Activation)  (None, 5, 5, 1024)   0           conv4_block32_add[0][0]          
__________________________________________________________________________________________________
conv4_block33_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block32_out[0][0]          
__________________________________________________________________________________________________
conv4_block33_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block33_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block33_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block33_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block33_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block33_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block33_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block33_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block33_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block33_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block33_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block33_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block33_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block33_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block33_add (Add)         (None, 5, 5, 1024)   0           conv4_block32_out[0][0]          
                                                                 conv4_block33_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block33_out (Activation)  (None, 5, 5, 1024)   0           conv4_block33_add[0][0]          
__________________________________________________________________________________________________
conv4_block34_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block33_out[0][0]          
__________________________________________________________________________________________________
conv4_block34_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block34_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block34_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block34_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block34_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block34_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block34_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block34_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block34_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block34_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block34_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block34_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block34_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block34_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block34_add (Add)         (None, 5, 5, 1024)   0           conv4_block33_out[0][0]          
                                                                 conv4_block34_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block34_out (Activation)  (None, 5, 5, 1024)   0           conv4_block34_add[0][0]          
__________________________________________________________________________________________________
conv4_block35_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block34_out[0][0]          
__________________________________________________________________________________________________
conv4_block35_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block35_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block35_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block35_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block35_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block35_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block35_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block35_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block35_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block35_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block35_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block35_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block35_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block35_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block35_add (Add)         (None, 5, 5, 1024)   0           conv4_block34_out[0][0]          
                                                                 conv4_block35_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block35_out (Activation)  (None, 5, 5, 1024)   0           conv4_block35_add[0][0]          
__________________________________________________________________________________________________
conv4_block36_1_conv (Conv2D)   (None, 5, 5, 256)    262400      conv4_block35_out[0][0]          
__________________________________________________________________________________________________
conv4_block36_1_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block36_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block36_1_relu (Activatio (None, 5, 5, 256)    0           conv4_block36_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block36_2_conv (Conv2D)   (None, 5, 5, 256)    590080      conv4_block36_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block36_2_bn (BatchNormal (None, 5, 5, 256)    1024        conv4_block36_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block36_2_relu (Activatio (None, 5, 5, 256)    0           conv4_block36_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block36_3_conv (Conv2D)   (None, 5, 5, 1024)   263168      conv4_block36_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block36_3_bn (BatchNormal (None, 5, 5, 1024)   4096        conv4_block36_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block36_add (Add)         (None, 5, 5, 1024)   0           conv4_block35_out[0][0]          
                                                                 conv4_block36_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block36_out (Activation)  (None, 5, 5, 1024)   0           conv4_block36_add[0][0]          
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 3, 3, 512)    524800      conv4_block36_out[0][0]          
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 3, 3, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 3, 3, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 3, 3, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 3, 3, 2048)   2099200     conv4_block36_out[0][0]          
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 3, 3, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 3, 3, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 3, 3, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 3, 3, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 3, 3, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 3, 3, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 3, 3, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 3, 3, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 3, 3, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 3, 3, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 3, 3, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 3, 3, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 3, 3, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 3, 3, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 3, 3, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 3, 3, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 3, 3, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 3, 3, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 3, 3, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 3, 3, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 3, 3, 2048)   0           conv5_block3_add[0][0]           
__________________________________________________________________________________________________
flatten (Flatten)               (None, 18432)        0           conv5_block3_out[0][0]           
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         75501568    flatten[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
predictions (Dense)             (None, 10)           40970       fc2[0][0]                        
==================================================================================================
Total params: 150,694,794
Trainable params: 150,543,370
Non-trainable params: 151,424
__________________________________________________________________________________________________
Start fitting ensemble models
Length split part:  16667
Labels in this part of split:  [1667, 1656, 1712, 1682, 1675, 1579, 1703, 1687, 1681, 1625]
Train for 521 steps, validate for 40 steps
Epoch 1/500
521/521 - 95s - loss: 1.4027 - accuracy: 0.5081 - val_loss: 2.4809 - val_accuracy: 0.0824
Epoch 2/500
521/521 - 57s - loss: 0.4901 - accuracy: 0.8499 - val_loss: 1.6996 - val_accuracy: 0.4080
Epoch 3/500
521/521 - 57s - loss: 0.1096 - accuracy: 0.9826 - val_loss: 1.2833 - val_accuracy: 0.6336
Epoch 4/500
521/521 - 52s - loss: 0.0377 - accuracy: 0.9942 - val_loss: 1.7097 - val_accuracy: 0.6304
Epoch 5/500
521/521 - 51s - loss: 0.0312 - accuracy: 0.9940 - val_loss: 1.5752 - val_accuracy: 0.6464
Epoch 6/500
521/521 - 51s - loss: 0.0127 - accuracy: 0.9975 - val_loss: 1.5489 - val_accuracy: 0.6536
Epoch 7/500
521/521 - 51s - loss: 0.0892 - accuracy: 0.9726 - val_loss: 2.9356 - val_accuracy: 0.6104
Epoch 8/500
521/521 - 51s - loss: 0.1440 - accuracy: 0.9511 - val_loss: 1.7835 - val_accuracy: 0.6464
Epoch 9/500
521/521 - 51s - loss: 0.0393 - accuracy: 0.9902 - val_loss: 1.8997 - val_accuracy: 0.6280
Epoch 10/500
521/521 - 51s - loss: 0.0324 - accuracy: 0.9915 - val_loss: 1.7176 - val_accuracy: 0.6512
Epoch 11/500
521/521 - 51s - loss: 0.0282 - accuracy: 0.9913 - val_loss: 1.8404 - val_accuracy: 0.6448
Epoch 12/500
521/521 - 51s - loss: 0.0281 - accuracy: 0.9924 - val_loss: 1.8107 - val_accuracy: 0.6712
Epoch 13/500
521/521 - 51s - loss: 0.0116 - accuracy: 0.9968 - val_loss: 2.0220 - val_accuracy: 0.6592
Epoch 14/500
521/521 - 51s - loss: 0.0538 - accuracy: 0.9822 - val_loss: 2.2595 - val_accuracy: 0.6320
Epoch 15/500
521/521 - 51s - loss: 0.0437 - accuracy: 0.9857 - val_loss: 1.9810 - val_accuracy: 0.6528
Epoch 16/500
521/521 - 51s - loss: 0.0083 - accuracy: 0.9980 - val_loss: 2.0526 - val_accuracy: 0.6696
Epoch 17/500
521/521 - 51s - loss: 0.0045 - accuracy: 0.9987 - val_loss: 2.0924 - val_accuracy: 0.6816
Epoch 18/500
521/521 - 51s - loss: 0.0084 - accuracy: 0.9974 - val_loss: 2.2502 - val_accuracy: 0.6552
Epoch 19/500
521/521 - 51s - loss: 0.0892 - accuracy: 0.9699 - val_loss: 2.0583 - val_accuracy: 0.6664
Epoch 20/500
521/521 - 51s - loss: 0.0364 - accuracy: 0.9887 - val_loss: 1.9637 - val_accuracy: 0.6808
Epoch 21/500
521/521 - 51s - loss: 0.0052 - accuracy: 0.9990 - val_loss: 1.9537 - val_accuracy: 0.6792
Epoch 22/500
521/521 - 51s - loss: 7.1748e-04 - accuracy: 1.0000 - val_loss: 1.9456 - val_accuracy: 0.6848
Epoch 23/500
521/521 - 51s - loss: 2.6882e-04 - accuracy: 1.0000 - val_loss: 1.9459 - val_accuracy: 0.6848
Epoch 24/500
521/521 - 51s - loss: 1.2374e-04 - accuracy: 1.0000 - val_loss: 1.9552 - val_accuracy: 0.6808
Epoch 25/500
521/521 - 51s - loss: 9.0466e-05 - accuracy: 1.0000 - val_loss: 1.9723 - val_accuracy: 0.6856
Epoch 26/500
521/521 - 51s - loss: 6.8590e-05 - accuracy: 1.0000 - val_loss: 1.9815 - val_accuracy: 0.6832
Epoch 27/500
521/521 - 51s - loss: 5.2781e-05 - accuracy: 1.0000 - val_loss: 2.0182 - val_accuracy: 0.6872
Epoch 28/500
521/521 - 51s - loss: 4.0847e-05 - accuracy: 1.0000 - val_loss: 2.0228 - val_accuracy: 0.6824
Epoch 29/500
521/521 - 51s - loss: 3.1709e-05 - accuracy: 1.0000 - val_loss: 2.0568 - val_accuracy: 0.6888
Epoch 30/500
521/521 - 51s - loss: 2.4608e-05 - accuracy: 1.0000 - val_loss: 2.0673 - val_accuracy: 0.6872
Epoch 31/500
521/521 - 51s - loss: 1.9060e-05 - accuracy: 1.0000 - val_loss: 2.0968 - val_accuracy: 0.6848
Epoch 32/500
521/521 - 51s - loss: 1.4752e-05 - accuracy: 1.0000 - val_loss: 2.1116 - val_accuracy: 0.6848
Epoch 33/500
521/521 - 51s - loss: 1.1381e-05 - accuracy: 1.0000 - val_loss: 2.1504 - val_accuracy: 0.6880
Epoch 34/500
521/521 - 51s - loss: 8.7737e-06 - accuracy: 1.0000 - val_loss: 2.1640 - val_accuracy: 0.6896
Epoch 35/500
521/521 - 51s - loss: 6.7456e-06 - accuracy: 1.0000 - val_loss: 2.1957 - val_accuracy: 0.6896
Epoch 36/500
521/521 - 51s - loss: 5.1790e-06 - accuracy: 1.0000 - val_loss: 2.1978 - val_accuracy: 0.6952
Epoch 37/500
521/521 - 51s - loss: 3.9683e-06 - accuracy: 1.0000 - val_loss: 2.2301 - val_accuracy: 0.6936
Epoch 38/500
521/521 - 51s - loss: 3.0388e-06 - accuracy: 1.0000 - val_loss: 2.2532 - val_accuracy: 0.6864
Epoch 39/500
521/521 - 51s - loss: 2.3248e-06 - accuracy: 1.0000 - val_loss: 2.2929 - val_accuracy: 0.6912
Epoch 40/500
521/521 - 51s - loss: 1.7778e-06 - accuracy: 1.0000 - val_loss: 2.3165 - val_accuracy: 0.6896
Epoch 41/500
521/521 - 51s - loss: 1.3570e-06 - accuracy: 1.0000 - val_loss: 2.3367 - val_accuracy: 0.6928
Epoch 42/500
521/521 - 51s - loss: 1.0362e-06 - accuracy: 1.0000 - val_loss: 2.3724 - val_accuracy: 0.6944
Epoch 43/500
521/521 - 51s - loss: 7.9232e-07 - accuracy: 1.0000 - val_loss: 2.4121 - val_accuracy: 0.6904
Epoch 44/500
521/521 - 51s - loss: 6.0654e-07 - accuracy: 1.0000 - val_loss: 2.4137 - val_accuracy: 0.6904
Epoch 45/500
521/521 - 51s - loss: 4.6356e-07 - accuracy: 1.0000 - val_loss: 2.4506 - val_accuracy: 0.6936
Epoch 46/500
521/521 - 51s - loss: 3.5553e-07 - accuracy: 1.0000 - val_loss: 2.4749 - val_accuracy: 0.6928
Epoch 47/500
521/521 - 51s - loss: 2.7318e-07 - accuracy: 1.0000 - val_loss: 2.5187 - val_accuracy: 0.6960
Epoch 48/500
521/521 - 51s - loss: 2.0966e-07 - accuracy: 1.0000 - val_loss: 2.5214 - val_accuracy: 0.6904
Epoch 49/500
521/521 - 51s - loss: 1.6219e-07 - accuracy: 1.0000 - val_loss: 2.5575 - val_accuracy: 0.6928
Epoch 50/500
521/521 - 51s - loss: 1.2536e-07 - accuracy: 1.0000 - val_loss: 2.5665 - val_accuracy: 0.6952
Epoch 51/500
521/521 - 51s - loss: 9.7559e-08 - accuracy: 1.0000 - val_loss: 2.5870 - val_accuracy: 0.6936
Epoch 52/500
521/521 - 51s - loss: 7.5810e-08 - accuracy: 1.0000 - val_loss: 2.6289 - val_accuracy: 0.6992
Epoch 53/500
521/521 - 51s - loss: 5.9363e-08 - accuracy: 1.0000 - val_loss: 2.6334 - val_accuracy: 0.6936
Epoch 54/500
521/521 - 51s - loss: 4.6072e-08 - accuracy: 1.0000 - val_loss: 2.6605 - val_accuracy: 0.6952
Epoch 55/500
521/521 - 51s - loss: 3.6145e-08 - accuracy: 1.0000 - val_loss: 2.6843 - val_accuracy: 0.6976
Epoch 56/500
521/521 - 51s - loss: 2.7751e-08 - accuracy: 1.0000 - val_loss: 2.6717 - val_accuracy: 0.6976
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 15:13:12.019924: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 15:13:12.020075: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 15:13:12.020108: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 15:13:12.122380: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 15:13:12.122478: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00056: early stopping
Length split part:  16667
Labels in this part of split:  [1629, 1681, 1647, 1628, 1684, 1727, 1642, 1677, 1665, 1687]
Train for 521 steps, validate for 40 steps
Epoch 1/500
521/521 - 57s - loss: 1.1909 - accuracy: 0.5951 - val_loss: 2.4903 - val_accuracy: 0.1008
Epoch 2/500
521/521 - 57s - loss: 0.3989 - accuracy: 0.8741 - val_loss: 1.3176 - val_accuracy: 0.5720
Epoch 3/500
521/521 - 59s - loss: 0.0785 - accuracy: 0.9843 - val_loss: 1.0928 - val_accuracy: 0.6992
Epoch 4/500
521/521 - 51s - loss: 0.0217 - accuracy: 0.9963 - val_loss: 1.2580 - val_accuracy: 0.7040
Epoch 5/500
521/521 - 51s - loss: 0.0071 - accuracy: 0.9990 - val_loss: 1.3085 - val_accuracy: 0.7120
Epoch 6/500
521/521 - 51s - loss: 0.0018 - accuracy: 0.9999 - val_loss: 1.3894 - val_accuracy: 0.7128
Epoch 7/500
521/521 - 51s - loss: 0.0011 - accuracy: 0.9999 - val_loss: 1.4767 - val_accuracy: 0.7128
Epoch 8/500
521/521 - 51s - loss: 6.3519e-04 - accuracy: 1.0000 - val_loss: 1.5293 - val_accuracy: 0.7064
Epoch 9/500
521/521 - 51s - loss: 4.2765e-04 - accuracy: 1.0000 - val_loss: 1.5969 - val_accuracy: 0.7128
Epoch 10/500
521/521 - 51s - loss: 2.6546e-04 - accuracy: 1.0000 - val_loss: 1.5952 - val_accuracy: 0.7128
Epoch 11/500
521/521 - 51s - loss: 1.8616e-04 - accuracy: 1.0000 - val_loss: 1.6527 - val_accuracy: 0.7112
Epoch 12/500
521/521 - 51s - loss: 1.3397e-04 - accuracy: 1.0000 - val_loss: 1.6953 - val_accuracy: 0.7120
Epoch 13/500
521/521 - 51s - loss: 9.7282e-05 - accuracy: 1.0000 - val_loss: 1.7357 - val_accuracy: 0.7080
Epoch 14/500
521/521 - 51s - loss: 7.1154e-05 - accuracy: 1.0000 - val_loss: 1.7667 - val_accuracy: 0.7112
Epoch 15/500
521/521 - 51s - loss: 5.2150e-05 - accuracy: 1.0000 - val_loss: 1.8616 - val_accuracy: 0.7128
Epoch 16/500
521/521 - 51s - loss: 3.8380e-05 - accuracy: 1.0000 - val_loss: 1.8884 - val_accuracy: 0.7072
Epoch 17/500
521/521 - 51s - loss: 2.8268e-05 - accuracy: 1.0000 - val_loss: 1.9189 - val_accuracy: 0.7072
Epoch 18/500
521/521 - 51s - loss: 2.0824e-05 - accuracy: 1.0000 - val_loss: 1.9863 - val_accuracy: 0.7096
Epoch 19/500
521/521 - 51s - loss: 1.5385e-05 - accuracy: 1.0000 - val_loss: 1.9972 - val_accuracy: 0.7120
Epoch 20/500
521/521 - 51s - loss: 1.1353e-05 - accuracy: 1.0000 - val_loss: 2.0219 - val_accuracy: 0.7112
Epoch 21/500
521/521 - 51s - loss: 8.3927e-06 - accuracy: 1.0000 - val_loss: 2.0486 - val_accuracy: 0.7136
Epoch 22/500
521/521 - 51s - loss: 6.2003e-06 - accuracy: 1.0000 - val_loss: 2.1043 - val_accuracy: 0.7136
Epoch 23/500
521/521 - 51s - loss: 4.5931e-06 - accuracy: 1.0000 - val_loss: 2.2019 - val_accuracy: 0.7096
Epoch 24/500
521/521 - 51s - loss: 3.4051e-06 - accuracy: 1.0000 - val_loss: 2.2285 - val_accuracy: 0.7088
Epoch 25/500
521/521 - 51s - loss: 2.5268e-06 - accuracy: 1.0000 - val_loss: 2.2346 - val_accuracy: 0.7096
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 15:35:33.824568: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 15:35:33.824711: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 15:35:33.824744: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 15:35:33.931336: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 15:35:33.931429: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00025: early stopping
Length split part:  16666
Labels in this part of split:  [1704, 1663, 1641, 1690, 1641, 1694, 1655, 1636, 1654, 1688]
Train for 521 steps, validate for 40 steps
Epoch 1/500
521/521 - 57s - loss: 1.1889 - accuracy: 0.5901 - val_loss: 2.8541 - val_accuracy: 0.1048
Epoch 2/500
521/521 - 57s - loss: 0.4160 - accuracy: 0.8655 - val_loss: 1.3993 - val_accuracy: 0.5592
Epoch 3/500
521/521 - 51s - loss: 0.0789 - accuracy: 0.9845 - val_loss: 1.6407 - val_accuracy: 0.7056
Epoch 4/500
521/521 - 51s - loss: 0.0127 - accuracy: 0.9989 - val_loss: 1.9329 - val_accuracy: 0.7104
Epoch 5/500
521/521 - 51s - loss: 0.0135 - accuracy: 0.9973 - val_loss: 7.7292 - val_accuracy: 0.6496
Epoch 6/500
521/521 - 51s - loss: 0.0266 - accuracy: 0.9935 - val_loss: 1.6293 - val_accuracy: 0.6888
Epoch 7/500
521/521 - 52s - loss: 0.0131 - accuracy: 0.9971 - val_loss: 1.9115 - val_accuracy: 0.7024
Epoch 8/500
521/521 - 51s - loss: 0.0054 - accuracy: 0.9987 - val_loss: 2.4948 - val_accuracy: 0.6856
Epoch 9/500
521/521 - 51s - loss: 0.1117 - accuracy: 0.9621 - val_loss: 1.9108 - val_accuracy: 0.6800
Epoch 10/500
521/521 - 51s - loss: 0.0503 - accuracy: 0.9842 - val_loss: 1.8364 - val_accuracy: 0.6936
Epoch 11/500
521/521 - 51s - loss: 0.0119 - accuracy: 0.9971 - val_loss: 2.0190 - val_accuracy: 0.6992
Epoch 12/500
521/521 - 51s - loss: 0.0022 - accuracy: 0.9998 - val_loss: 2.2264 - val_accuracy: 0.7080
Epoch 13/500
521/521 - 52s - loss: 3.4880e-04 - accuracy: 1.0000 - val_loss: 2.1781 - val_accuracy: 0.7064
Epoch 14/500
521/521 - 51s - loss: 1.9736e-04 - accuracy: 1.0000 - val_loss: 2.1354 - val_accuracy: 0.7120
Epoch 15/500
521/521 - 52s - loss: 1.3891e-04 - accuracy: 1.0000 - val_loss: 2.1559 - val_accuracy: 0.7144
Epoch 16/500
521/521 - 52s - loss: 1.0221e-04 - accuracy: 1.0000 - val_loss: 2.2131 - val_accuracy: 0.7168
Epoch 17/500
521/521 - 52s - loss: 7.6355e-05 - accuracy: 1.0000 - val_loss: 2.3222 - val_accuracy: 0.7176
Epoch 18/500
521/521 - 52s - loss: 5.7508e-05 - accuracy: 1.0000 - val_loss: 2.3219 - val_accuracy: 0.7144
Epoch 19/500
521/521 - 52s - loss: 4.3512e-05 - accuracy: 1.0000 - val_loss: 2.6212 - val_accuracy: 0.7128
Epoch 20/500
521/521 - 52s - loss: 3.2992e-05 - accuracy: 1.0000 - val_loss: 2.4303 - val_accuracy: 0.7112
Epoch 21/500
521/521 - 52s - loss: 2.5016e-05 - accuracy: 1.0000 - val_loss: 2.4664 - val_accuracy: 0.7176
Epoch 22/500
521/521 - 51s - loss: 1.8978e-05 - accuracy: 1.0000 - val_loss: 2.3264 - val_accuracy: 0.7192
Epoch 23/500
521/521 - 51s - loss: 1.4389e-05 - accuracy: 1.0000 - val_loss: 2.5280 - val_accuracy: 0.7184
Epoch 24/500
521/521 - 52s - loss: 1.0911e-05 - accuracy: 1.0000 - val_loss: 2.6713 - val_accuracy: 0.7176
Epoch 25/500
521/521 - 52s - loss: 8.2631e-06 - accuracy: 1.0000 - val_loss: 2.5334 - val_accuracy: 0.7184
Epoch 26/500
521/521 - 52s - loss: 6.2534e-06 - accuracy: 1.0000 - val_loss: 2.6824 - val_accuracy: 0.7168
Epoch 27/500
521/521 - 52s - loss: 4.7332e-06 - accuracy: 1.0000 - val_loss: 2.7764 - val_accuracy: 0.7168
Epoch 28/500
521/521 - 52s - loss: 3.5803e-06 - accuracy: 1.0000 - val_loss: 2.8204 - val_accuracy: 0.7160
Epoch 29/500
521/521 - 52s - loss: 2.7086e-06 - accuracy: 1.0000 - val_loss: 2.9287 - val_accuracy: 0.7176
Epoch 30/500
521/521 - 52s - loss: 2.0491e-06 - accuracy: 1.0000 - val_loss: 2.6342 - val_accuracy: 0.7208
Epoch 31/500
521/521 - 52s - loss: 1.5534e-06 - accuracy: 1.0000 - val_loss: 2.8303 - val_accuracy: 0.7200
Epoch 32/500
521/521 - 51s - loss: 1.1736e-06 - accuracy: 1.0000 - val_loss: 2.9259 - val_accuracy: 0.7176
Epoch 33/500
521/521 - 51s - loss: 8.8847e-07 - accuracy: 1.0000 - val_loss: 3.0178 - val_accuracy: 0.7184
Epoch 34/500
521/521 - 51s - loss: 6.7434e-07 - accuracy: 1.0000 - val_loss: 2.9992 - val_accuracy: 0.7200
Epoch 35/500
521/521 - 51s - loss: 5.1294e-07 - accuracy: 1.0000 - val_loss: 3.1457 - val_accuracy: 0.7176
Epoch 36/500
521/521 - 52s - loss: 3.9063e-07 - accuracy: 1.0000 - val_loss: 3.4310 - val_accuracy: 0.7160
Epoch 37/500
521/521 - 52s - loss: 2.9819e-07 - accuracy: 1.0000 - val_loss: 3.1271 - val_accuracy: 0.7200
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 16:08:38.487125: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 16:08:38.487275: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 16:08:38.487329: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 16:08:38.529824: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 16:08:38.529909: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00037: early stopping
ResNet50V2
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 75, 75, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 81, 81, 3)    0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 38, 38, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 40, 40, 64)   0           conv1_conv[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 19, 19, 64)   0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_preact_bn (BatchNo (None, 19, 19, 64)   256         pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_preact_relu (Activ (None, 19, 19, 64)   0           conv2_block1_preact_bn[0][0]     
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 19, 19, 64)   4096        conv2_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 19, 19, 64)   0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_pad (ZeroPadding (None, 21, 21, 64)   0           conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 19, 19, 64)   36864       conv2_block1_2_pad[0][0]         
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 19, 19, 64)   0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 19, 19, 256)  16640       conv2_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 19, 19, 256)  16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_out (Add)          (None, 19, 19, 256)  0           conv2_block1_0_conv[0][0]        
                                                                 conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_preact_bn (BatchNo (None, 19, 19, 256)  1024        conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_preact_relu (Activ (None, 19, 19, 256)  0           conv2_block2_preact_bn[0][0]     
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 19, 19, 64)   16384       conv2_block2_preact_relu[0][0]   
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 19, 19, 64)   0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_pad (ZeroPadding (None, 21, 21, 64)   0           conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 19, 19, 64)   36864       conv2_block2_2_pad[0][0]         
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 19, 19, 64)   0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 19, 19, 256)  16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_out (Add)          (None, 19, 19, 256)  0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_preact_bn (BatchNo (None, 19, 19, 256)  1024        conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_preact_relu (Activ (None, 19, 19, 256)  0           conv2_block3_preact_bn[0][0]     
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 19, 19, 64)   16384       conv2_block3_preact_relu[0][0]   
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 19, 19, 64)   0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_pad (ZeroPadding (None, 21, 21, 64)   0           conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 10, 10, 64)   36864       conv2_block3_2_pad[0][0]         
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 10, 10, 64)   256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 10, 10, 64)   0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 10, 10, 256)  0           conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 10, 10, 256)  16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_out (Add)          (None, 10, 10, 256)  0           max_pooling2d[0][0]              
                                                                 conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_preact_bn (BatchNo (None, 10, 10, 256)  1024        conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_preact_relu (Activ (None, 10, 10, 256)  0           conv3_block1_preact_bn[0][0]     
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 10, 10, 128)  32768       conv3_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 10, 10, 128)  0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_pad (ZeroPadding (None, 12, 12, 128)  0           conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 10, 10, 128)  147456      conv3_block1_2_pad[0][0]         
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 10, 10, 128)  0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 10, 10, 512)  131584      conv3_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_out (Add)          (None, 10, 10, 512)  0           conv3_block1_0_conv[0][0]        
                                                                 conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_preact_bn (BatchNo (None, 10, 10, 512)  2048        conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_preact_relu (Activ (None, 10, 10, 512)  0           conv3_block2_preact_bn[0][0]     
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 10, 10, 128)  65536       conv3_block2_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 10, 10, 128)  0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_pad (ZeroPadding (None, 12, 12, 128)  0           conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 10, 10, 128)  147456      conv3_block2_2_pad[0][0]         
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 10, 10, 128)  0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_out (Add)          (None, 10, 10, 512)  0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_preact_bn (BatchNo (None, 10, 10, 512)  2048        conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_preact_relu (Activ (None, 10, 10, 512)  0           conv3_block3_preact_bn[0][0]     
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 10, 10, 128)  65536       conv3_block3_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 10, 10, 128)  0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_pad (ZeroPadding (None, 12, 12, 128)  0           conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 10, 10, 128)  147456      conv3_block3_2_pad[0][0]         
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 10, 10, 128)  0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_out (Add)          (None, 10, 10, 512)  0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_preact_bn (BatchNo (None, 10, 10, 512)  2048        conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_preact_relu (Activ (None, 10, 10, 512)  0           conv3_block4_preact_bn[0][0]     
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 10, 10, 128)  65536       conv3_block4_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 10, 10, 128)  0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_pad (ZeroPadding (None, 12, 12, 128)  0           conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 5, 5, 128)    147456      conv3_block4_2_pad[0][0]         
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 5, 5, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 5, 5, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 5, 5, 512)    0           conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 5, 5, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_out (Add)          (None, 5, 5, 512)    0           max_pooling2d_1[0][0]            
                                                                 conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_preact_bn (BatchNo (None, 5, 5, 512)    2048        conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_preact_relu (Activ (None, 5, 5, 512)    0           conv4_block1_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 5, 5, 256)    131072      conv4_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 5, 5, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_pad (ZeroPadding (None, 7, 7, 256)    0           conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 5, 5, 256)    589824      conv4_block1_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 5, 5, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 5, 5, 1024)   525312      conv4_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_out (Add)          (None, 5, 5, 1024)   0           conv4_block1_0_conv[0][0]        
                                                                 conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_preact_bn (BatchNo (None, 5, 5, 1024)   4096        conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_preact_relu (Activ (None, 5, 5, 1024)   0           conv4_block2_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 5, 5, 256)    262144      conv4_block2_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 5, 5, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_pad (ZeroPadding (None, 7, 7, 256)    0           conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 5, 5, 256)    589824      conv4_block2_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 5, 5, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_out (Add)          (None, 5, 5, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_preact_bn (BatchNo (None, 5, 5, 1024)   4096        conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_preact_relu (Activ (None, 5, 5, 1024)   0           conv4_block3_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 5, 5, 256)    262144      conv4_block3_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 5, 5, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_pad (ZeroPadding (None, 7, 7, 256)    0           conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 5, 5, 256)    589824      conv4_block3_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 5, 5, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_out (Add)          (None, 5, 5, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_preact_bn (BatchNo (None, 5, 5, 1024)   4096        conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_preact_relu (Activ (None, 5, 5, 1024)   0           conv4_block4_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 5, 5, 256)    262144      conv4_block4_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 5, 5, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_pad (ZeroPadding (None, 7, 7, 256)    0           conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 5, 5, 256)    589824      conv4_block4_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 5, 5, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_out (Add)          (None, 5, 5, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_preact_bn (BatchNo (None, 5, 5, 1024)   4096        conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_preact_relu (Activ (None, 5, 5, 1024)   0           conv4_block5_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 5, 5, 256)    262144      conv4_block5_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 5, 5, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_pad (ZeroPadding (None, 7, 7, 256)    0           conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 5, 5, 256)    589824      conv4_block5_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 5, 5, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_out (Add)          (None, 5, 5, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_preact_bn (BatchNo (None, 5, 5, 1024)   4096        conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_preact_relu (Activ (None, 5, 5, 1024)   0           conv4_block6_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 5, 5, 256)    262144      conv4_block6_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 5, 5, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_pad (ZeroPadding (None, 7, 7, 256)    0           conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 3, 3, 256)    589824      conv4_block6_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 3, 3, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 1024)   0           conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 3, 3, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_out (Add)          (None, 3, 3, 1024)   0           max_pooling2d_2[0][0]            
                                                                 conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_preact_bn (BatchNo (None, 3, 3, 1024)   4096        conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_preact_relu (Activ (None, 3, 3, 1024)   0           conv5_block1_preact_bn[0][0]     
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 3, 3, 512)    524288      conv5_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 3, 3, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_pad (ZeroPadding (None, 5, 5, 512)    0           conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 3, 3, 512)    2359296     conv5_block1_2_pad[0][0]         
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 3, 3, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 3, 3, 2048)   2099200     conv5_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 3, 3, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_out (Add)          (None, 3, 3, 2048)   0           conv5_block1_0_conv[0][0]        
                                                                 conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_preact_bn (BatchNo (None, 3, 3, 2048)   8192        conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_preact_relu (Activ (None, 3, 3, 2048)   0           conv5_block2_preact_bn[0][0]     
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 3, 3, 512)    1048576     conv5_block2_preact_relu[0][0]   
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 3, 3, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_pad (ZeroPadding (None, 5, 5, 512)    0           conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 3, 3, 512)    2359296     conv5_block2_2_pad[0][0]         
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 3, 3, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 3, 3, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_out (Add)          (None, 3, 3, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_preact_bn (BatchNo (None, 3, 3, 2048)   8192        conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_preact_relu (Activ (None, 3, 3, 2048)   0           conv5_block3_preact_bn[0][0]     
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 3, 3, 512)    1048576     conv5_block3_preact_relu[0][0]   
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 3, 3, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_pad (ZeroPadding (None, 5, 5, 512)    0           conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 3, 3, 512)    2359296     conv5_block3_2_pad[0][0]         
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 3, 3, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 3, 3, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_out (Add)          (None, 3, 3, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
post_bn (BatchNormalization)    (None, 3, 3, 2048)   8192        conv5_block3_out[0][0]           
__________________________________________________________________________________________________
post_relu (Activation)          (None, 3, 3, 2048)   0           post_bn[0][0]                    
__________________________________________________________________________________________________
flatten (Flatten)               (None, 18432)        0           post_relu[0][0]                  
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         75501568    flatten[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
predictions (Dense)             (None, 10)           40970       fc2[0][0]                        
==================================================================================================
Total params: 115,888,650
Trainable params: 115,843,210
Non-trainable params: 45,440
__________________________________________________________________________________________________
Start fitting ensemble models
Length split part:  16667
Labels in this part of split:  [1667, 1656, 1712, 1682, 1675, 1579, 1703, 1687, 1681, 1625]
Train for 521 steps, validate for 40 steps
Epoch 1/500
521/521 - 37s - loss: 1.6866 - accuracy: 0.4111 - val_loss: 1.4026 - val_accuracy: 0.5088
Epoch 2/500
521/521 - 21s - loss: 0.8146 - accuracy: 0.7388 - val_loss: 1.4228 - val_accuracy: 0.5256
Epoch 3/500
521/521 - 21s - loss: 0.2405 - accuracy: 0.9535 - val_loss: 1.5738 - val_accuracy: 0.5488
Epoch 4/500
521/521 - 21s - loss: 0.0401 - accuracy: 0.9989 - val_loss: 1.6306 - val_accuracy: 0.5584
Epoch 5/500
521/521 - 21s - loss: 0.0083 - accuracy: 0.9999 - val_loss: 1.7377 - val_accuracy: 0.5632
Epoch 6/500
521/521 - 21s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.7954 - val_accuracy: 0.5600
Epoch 7/500
521/521 - 21s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.8574 - val_accuracy: 0.5576
Epoch 8/500
521/521 - 21s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.9285 - val_accuracy: 0.5560
Epoch 9/500
521/521 - 21s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.9820 - val_accuracy: 0.5584
Epoch 10/500
521/521 - 21s - loss: 7.6625e-04 - accuracy: 1.0000 - val_loss: 2.0337 - val_accuracy: 0.5584
Epoch 11/500
521/521 - 21s - loss: 5.4546e-04 - accuracy: 1.0000 - val_loss: 2.0810 - val_accuracy: 0.5616
Epoch 12/500
521/521 - 21s - loss: 3.9259e-04 - accuracy: 1.0000 - val_loss: 2.1335 - val_accuracy: 0.5584
Epoch 13/500
521/521 - 21s - loss: 2.8436e-04 - accuracy: 1.0000 - val_loss: 2.1802 - val_accuracy: 0.5552
Epoch 14/500
521/521 - 21s - loss: 2.0705e-04 - accuracy: 1.0000 - val_loss: 2.2370 - val_accuracy: 0.5576
Epoch 15/500
521/521 - 21s - loss: 1.5092e-04 - accuracy: 1.0000 - val_loss: 2.2938 - val_accuracy: 0.5648
Epoch 16/500
521/521 - 21s - loss: 1.1060e-04 - accuracy: 1.0000 - val_loss: 2.3397 - val_accuracy: 0.5544
Epoch 17/500
521/521 - 21s - loss: 8.1118e-05 - accuracy: 1.0000 - val_loss: 2.4050 - val_accuracy: 0.5624
Epoch 18/500
521/521 - 21s - loss: 5.9568e-05 - accuracy: 1.0000 - val_loss: 2.4597 - val_accuracy: 0.5600
Epoch 19/500
521/521 - 21s - loss: 4.3812e-05 - accuracy: 1.0000 - val_loss: 2.4982 - val_accuracy: 0.5624
Epoch 20/500
521/521 - 21s - loss: 3.2302e-05 - accuracy: 1.0000 - val_loss: 2.5458 - val_accuracy: 0.5608
Epoch 21/500
521/521 - 21s - loss: 2.3842e-05 - accuracy: 1.0000 - val_loss: 2.5921 - val_accuracy: 0.5560
Epoch 22/500
521/521 - 21s - loss: 1.7593e-05 - accuracy: 1.0000 - val_loss: 2.6723 - val_accuracy: 0.5672
Epoch 23/500
521/521 - 21s - loss: 1.3022e-05 - accuracy: 1.0000 - val_loss: 2.7131 - val_accuracy: 0.5624
Epoch 24/500
521/521 - 21s - loss: 9.6324e-06 - accuracy: 1.0000 - val_loss: 2.7762 - val_accuracy: 0.5632
Epoch 25/500
521/521 - 21s - loss: 7.1388e-06 - accuracy: 1.0000 - val_loss: 2.8211 - val_accuracy: 0.5648
Epoch 26/500
521/521 - 21s - loss: 5.3027e-06 - accuracy: 1.0000 - val_loss: 2.8683 - val_accuracy: 0.5608
Epoch 27/500
521/521 - 21s - loss: 3.9419e-06 - accuracy: 1.0000 - val_loss: 2.9150 - val_accuracy: 0.5648
Epoch 28/500
521/521 - 21s - loss: 2.9331e-06 - accuracy: 1.0000 - val_loss: 2.9475 - val_accuracy: 0.5624
Epoch 29/500
521/521 - 21s - loss: 2.1859e-06 - accuracy: 1.0000 - val_loss: 3.0014 - val_accuracy: 0.5656
Epoch 30/500
521/521 - 21s - loss: 1.6348e-06 - accuracy: 1.0000 - val_loss: 3.0412 - val_accuracy: 0.5672
Epoch 31/500
521/521 - 21s - loss: 1.2232e-06 - accuracy: 1.0000 - val_loss: 3.0955 - val_accuracy: 0.5600
Epoch 32/500
521/521 - 21s - loss: 9.1835e-07 - accuracy: 1.0000 - val_loss: 3.1378 - val_accuracy: 0.5648
Epoch 33/500
521/521 - 21s - loss: 6.9326e-07 - accuracy: 1.0000 - val_loss: 3.1946 - val_accuracy: 0.5616
Epoch 34/500
521/521 - 21s - loss: 5.2276e-07 - accuracy: 1.0000 - val_loss: 3.2436 - val_accuracy: 0.5664
Epoch 35/500
521/521 - 21s - loss: 3.9747e-07 - accuracy: 1.0000 - val_loss: 3.3039 - val_accuracy: 0.5672
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 16:21:17.500471: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 16:21:17.500609: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 16:21:17.500642: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 16:21:17.545076: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 16:21:17.545157: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00035: early stopping
Length split part:  16667
Labels in this part of split:  [1629, 1681, 1647, 1628, 1684, 1727, 1642, 1677, 1665, 1687]
Train for 521 steps, validate for 40 steps
Epoch 1/500
521/521 - 24s - loss: 1.4649 - accuracy: 0.4928 - val_loss: 1.2320 - val_accuracy: 0.5568
Epoch 2/500
521/521 - 25s - loss: 0.6707 - accuracy: 0.7782 - val_loss: 1.2255 - val_accuracy: 0.5832
Epoch 3/500
521/521 - 21s - loss: 0.1727 - accuracy: 0.9639 - val_loss: 1.4039 - val_accuracy: 0.6032
Epoch 4/500
521/521 - 21s - loss: 0.0207 - accuracy: 0.9994 - val_loss: 1.5268 - val_accuracy: 0.6112
Epoch 5/500
521/521 - 21s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.6279 - val_accuracy: 0.6192
Epoch 6/500
521/521 - 21s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.7051 - val_accuracy: 0.6168
Epoch 7/500
521/521 - 21s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7618 - val_accuracy: 0.6200
Epoch 8/500
521/521 - 21s - loss: 9.3410e-04 - accuracy: 1.0000 - val_loss: 1.8235 - val_accuracy: 0.6168
Epoch 9/500
521/521 - 21s - loss: 6.4718e-04 - accuracy: 1.0000 - val_loss: 1.8742 - val_accuracy: 0.6184
Epoch 10/500
521/521 - 21s - loss: 4.5695e-04 - accuracy: 1.0000 - val_loss: 1.9251 - val_accuracy: 0.6136
Epoch 11/500
521/521 - 21s - loss: 3.2652e-04 - accuracy: 1.0000 - val_loss: 1.9900 - val_accuracy: 0.6176
Epoch 12/500
521/521 - 21s - loss: 2.3550e-04 - accuracy: 1.0000 - val_loss: 2.0289 - val_accuracy: 0.6136
Epoch 13/500
521/521 - 21s - loss: 1.7091e-04 - accuracy: 1.0000 - val_loss: 2.0841 - val_accuracy: 0.6144
Epoch 14/500
521/521 - 21s - loss: 1.2434e-04 - accuracy: 1.0000 - val_loss: 2.1337 - val_accuracy: 0.6096
Epoch 15/500
521/521 - 21s - loss: 9.0950e-05 - accuracy: 1.0000 - val_loss: 2.1834 - val_accuracy: 0.6144
Epoch 16/500
521/521 - 21s - loss: 6.6598e-05 - accuracy: 1.0000 - val_loss: 2.2352 - val_accuracy: 0.6152
Epoch 17/500
521/521 - 21s - loss: 4.8834e-05 - accuracy: 1.0000 - val_loss: 2.2820 - val_accuracy: 0.6160
Epoch 18/500
521/521 - 21s - loss: 3.5929e-05 - accuracy: 1.0000 - val_loss: 2.3435 - val_accuracy: 0.6160
Epoch 19/500
521/521 - 21s - loss: 2.6459e-05 - accuracy: 1.0000 - val_loss: 2.3918 - val_accuracy: 0.6176
Epoch 20/500
521/521 - 21s - loss: 1.9500e-05 - accuracy: 1.0000 - val_loss: 2.4323 - val_accuracy: 0.6168
Epoch 21/500
521/521 - 21s - loss: 1.4408e-05 - accuracy: 1.0000 - val_loss: 2.4890 - val_accuracy: 0.6168
Epoch 22/500
521/521 - 21s - loss: 1.0651e-05 - accuracy: 1.0000 - val_loss: 2.5387 - val_accuracy: 0.6168
Epoch 23/500
521/521 - 21s - loss: 7.8830e-06 - accuracy: 1.0000 - val_loss: 2.5934 - val_accuracy: 0.6176
Epoch 24/500
521/521 - 21s - loss: 5.8471e-06 - accuracy: 1.0000 - val_loss: 2.6485 - val_accuracy: 0.6096
Epoch 25/500
521/521 - 21s - loss: 4.3401e-06 - accuracy: 1.0000 - val_loss: 2.6729 - val_accuracy: 0.6128
[pg-gpu28:29232] *** Process received signal ***
[pg-gpu28:29232] Signal: Segmentation fault (11)
[pg-gpu28:29232] Signal code: Address not mapped (1)
[pg-gpu28:29232] Failing at address: (nil)
[pg-gpu28:29232] [ 0] /lib64/libpthread.so.0(+0xf5f0)[0x7f2817a715f0]
[pg-gpu28:29232] [ 1] /software/software/HDF5/1.10.5-gompic-2019b/lib/libhdf5.so.103(H5D_close+0x72)[0x7f280e5f0a42]
[pg-gpu28:29232] [ 2] /software/software/HDF5/1.10.5-gompic-2019b/lib/libhdf5.so.103(+0xc7411)[0x7f280e5f1411]
[pg-gpu28:29232] [ 3] /software/software/HDF5/1.10.5-gompic-2019b/lib/libhdf5.so.103(H5I_dec_ref+0xbe)[0x7f280e6976de]
[pg-gpu28:29232] [ 4] /software/software/HDF5/1.10.5-gompic-2019b/lib/libhdf5.so.103(H5I_dec_app_ref+0x3c)[0x7f280e69785c]
[pg-gpu28:29232] [ 5] /software/software/HDF5/1.10.5-gompic-2019b/lib/libhdf5.so.103(H5Idec_ref+0x41)[0x7f280e697991]
[pg-gpu28:29232] [ 6] /software/software/h5py/2.10.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/h5py-2.10.0-py3.7-linux-x86_64.egg/h5py/defs.cpython-37m-x86_64-linux-gnu.so(+0x24d73)[0x7f28072e3d73]
[pg-gpu28:29232] [ 7] /software/software/h5py/2.10.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/h5py-2.10.0-py3.7-linux-x86_64.egg/h5py/h5i.cpython-37m-x86_64-linux-gnu.so(+0x6c3b)[0x7f2805287c3b]
[pg-gpu28:29232] [ 8] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(_PyMethodDef_RawFastCallDict+0x359)[0x7f281846aff9]
[pg-gpu28:29232] [ 9] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(_PyCFunction_FastCallDict+0x25)[0x7f281846b035]
[pg-gpu28:29232] [10] /software/software/h5py/2.10.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/h5py-2.10.0-py3.7-linux-x86_64.egg/h5py/_objects.cpython-37m-x86_64-linux-gnu.so(+0x18385)[0x7f28072b6385]
[pg-gpu28:29232] [11] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0xd2)[0x7f281846aa02]
[pg-gpu28:29232] [12] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x6533)[0x7f2818448d23]
[pg-gpu28:29232] [13] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(_PyEval_EvalCodeWithName+0x9bd)[0x7f281851e61d]
[pg-gpu28:29232] [14] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(_PyFunction_FastCallKeywords+0x93)[0x7f281846a343]
[pg-gpu28:29232] [15] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x869b)[0x7f281844ae8b]
[pg-gpu28:29232] [16] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(_PyEval_EvalCodeWithName+0x9bd)[0x7f281851e61d]
[pg-gpu28:29232] [17] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(_PyFunction_FastCallDict+0xae)[0x7f281846a07e]
[pg-gpu28:29232] [18] /software/software/h5py/2.10.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/h5py-2.10.0-py3.7-linux-x86_64.egg/h5py/_objects.cpython-37m-x86_64-linux-gnu.so(+0x18385)[0x7f28072b6385]
[pg-gpu28:29232] [19] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(_PyObject_FastCallDict+0x8a)[0x7f281846b0da]
[pg-gpu28:29232] [20] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(_PyObject_Call_Prepend+0xcd)[0x7f281846b38d]
[pg-gpu28:29232] [21] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(_PyObject_FastCallDict+0x8a)[0x7f281846b0da]
[pg-gpu28:29232] [22] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x1dba)[0x7f28184445aa]
[pg-gpu28:29232] [23] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(_PyEval_EvalCodeWithName+0x9bd)[0x7f281851e61d]
[pg-gpu28:29232] [24] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(_PyFunction_FastCallKeywords+0x93)[0x7f281846a343]
[pg-gpu28:29232] [25] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x869b)[0x7f281844ae8b]
[pg-gpu28:29232] [26] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(+0x86639)[0x7f2818441639]
[pg-gpu28:29232] [27] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x6c53)[0x7f2818449443]
[pg-gpu28:29232] [28] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(_PyEval_EvalCodeWithName+0x9bd)[0x7f281851e61d]
[pg-gpu28:29232] [29] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(_PyFunction_FastCallKeywords+0x93)[0x7f281846a343]
[pg-gpu28:29232] *** End of error message ***
/var/spool/slurmd/job11723053/slurm_script: line 14: 29232 Segmentation fault      python CIFAR10_Multi_Ensemble.py


###############################################################################
Peregrine Cluster
Job 11723053 for user 's2934833'
Finished at: Mon May 25 16:30:25 CEST 2020

Job details:
============

Name                : CIFEN
User                : s2934833
Partition           : gpu
Nodes               : pg-gpu28
Cores               : 12
State               : FAILED
Submit              : 2020-05-25T10:42:36
Start               : 2020-05-25T10:43:00
End                 : 2020-05-25T16:30:25
Reserved walltime   : 1-00:00:00
Used walltime       :   05:47:25
Used CPU time       :   05:30:42 (efficiency:  7.93%)
% User (Computation): 80.55%
% System (I/O)      : 19.45%
Mem reserved        : 125G/node
Max Mem used        : 16.43G (pg-gpu28)
Max Disk Write      : 153.60K (pg-gpu28)
Max Disk Read       : 5.83M (pg-gpu28)
Average GPU usage   : 79.7% (pg-gpu28)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/additional_information/scientific_output

################################################################################
