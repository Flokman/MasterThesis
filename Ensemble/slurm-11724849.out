
The following have been reloaded with a version change:
  1) FFTW/3.3.8-gompic-2019b => FFTW/3.3.8-gompi-2019b
  2) OpenMPI/3.1.4-gcccuda-2019b => OpenMPI/3.1.4-GCC-8.3.0
  3) ScaLAPACK/2.0.2-gompic-2019b => ScaLAPACK/2.0.2-gompi-2019b
  4) SciPy-bundle/2019.10-fosscuda-2019b-Python-3.7.4 => SciPy-bundle/2019.10-foss-2019b-Python-3.7.4

2020-05-25 11:25:04.435107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-25 11:25:17.652526: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-05-25 11:25:17.658880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-25 11:25:17.659369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-25 11:25:17.659420: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-25 11:25:17.664018: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-25 11:25:17.667548: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-25 11:25:17.669291: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-25 11:25:17.672916: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-25 11:25:17.675299: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-25 11:25:17.681237: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-25 11:25:17.681428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-25 11:25:17.681982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-25 11:25:17.682372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-05-25 11:25:17.685037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-25 11:25:17.685468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-25 11:25:17.685514: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-25 11:25:17.685547: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-25 11:25:17.685568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-25 11:25:17.685588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-25 11:25:17.685608: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-25 11:25:17.685628: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-25 11:25:17.685648: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-25 11:25:17.685750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-25 11:25:17.686201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-25 11:25:17.686575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-05-25 11:25:17.686626: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-25 11:25:18.329401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-25 11:25:18.329489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-05-25 11:25:18.329506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-05-25 11:25:18.329773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-25 11:25:18.330417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-25 11:25:18.330922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-25 11:25:18.331354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28652 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2020-05-25 11:25:18.331674: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 11:25:38.712968: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-25 11:25:38.998136: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-25 11:25:41.883724: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 11:25:41.883823: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1259] Profiler found 1 GPUs
2020-05-25 11:25:41.886353: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1
2020-05-25 11:25:41.986931: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-05-25 11:25:41.987491: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-05-25 11:25:42.371822: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 11:25:42.371916: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
loaded data
dataset_name = /Messidor2_PNG_AUG_256.hdf5, batch_size = 32, num_classes = 5, epochs = 500,
          test_img_idx = 49, train_test_split = 0.7, to_shuffle = False,
          augmentation = False, label_count = [840, 840, 839, 838, 836], label_normalizer = False,
          save_augmentation_to_hdf5 = False, learn rate = 1e-05, train_all_layers = True,
          weights_to_use = imagenet, es_patience = 20, train_val_split = 0.875,
          N_ENSEMBLE_MEMBERS = 3, MIN_DELTA = 0.005, Early_monitor = val_accuracy
x_train shape: (4193, 256, 256, 3)
4193 train samples
346 test samples
Total labels in train set:  [840, 840, 839, 838, 836]
Labels in validation set:  [119, 22, 28, 7, 3]
Labels in test set:  [202, 58, 70, 10, 6]
Xception
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            
__________________________________________________________________________________________________
block1_conv1 (Conv2D)           (None, 127, 127, 32) 864         input_1[0][0]                    
__________________________________________________________________________________________________
block1_conv1_bn (BatchNormaliza (None, 127, 127, 32) 128         block1_conv1[0][0]               
__________________________________________________________________________________________________
block1_conv1_act (Activation)   (None, 127, 127, 32) 0           block1_conv1_bn[0][0]            
__________________________________________________________________________________________________
block1_conv2 (Conv2D)           (None, 125, 125, 64) 18432       block1_conv1_act[0][0]           
__________________________________________________________________________________________________
block1_conv2_bn (BatchNormaliza (None, 125, 125, 64) 256         block1_conv2[0][0]               
__________________________________________________________________________________________________
block1_conv2_act (Activation)   (None, 125, 125, 64) 0           block1_conv2_bn[0][0]            
__________________________________________________________________________________________________
block2_sepconv1 (SeparableConv2 (None, 125, 125, 128 8768        block1_conv2_act[0][0]           
__________________________________________________________________________________________________
block2_sepconv1_bn (BatchNormal (None, 125, 125, 128 512         block2_sepconv1[0][0]            
__________________________________________________________________________________________________
block2_sepconv2_act (Activation (None, 125, 125, 128 0           block2_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block2_sepconv2 (SeparableConv2 (None, 125, 125, 128 17536       block2_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block2_sepconv2_bn (BatchNormal (None, 125, 125, 128 512         block2_sepconv2[0][0]            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 63, 63, 128)  8192        block1_conv2_act[0][0]           
__________________________________________________________________________________________________
block2_pool (MaxPooling2D)      (None, 63, 63, 128)  0           block2_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 63, 63, 128)  512         conv2d[0][0]                     
__________________________________________________________________________________________________
add (Add)                       (None, 63, 63, 128)  0           block2_pool[0][0]                
                                                                 batch_normalization[0][0]        
__________________________________________________________________________________________________
block3_sepconv1_act (Activation (None, 63, 63, 128)  0           add[0][0]                        
__________________________________________________________________________________________________
block3_sepconv1 (SeparableConv2 (None, 63, 63, 256)  33920       block3_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block3_sepconv1_bn (BatchNormal (None, 63, 63, 256)  1024        block3_sepconv1[0][0]            
__________________________________________________________________________________________________
block3_sepconv2_act (Activation (None, 63, 63, 256)  0           block3_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block3_sepconv2 (SeparableConv2 (None, 63, 63, 256)  67840       block3_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block3_sepconv2_bn (BatchNormal (None, 63, 63, 256)  1024        block3_sepconv2[0][0]            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 256)  32768       add[0][0]                        
__________________________________________________________________________________________________
block3_pool (MaxPooling2D)      (None, 32, 32, 256)  0           block3_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 256)  1024        conv2d_1[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 256)  0           block3_pool[0][0]                
                                                                 batch_normalization_1[0][0]      
__________________________________________________________________________________________________
block4_sepconv1_act (Activation (None, 32, 32, 256)  0           add_1[0][0]                      
__________________________________________________________________________________________________
block4_sepconv1 (SeparableConv2 (None, 32, 32, 728)  188672      block4_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block4_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block4_sepconv1[0][0]            
__________________________________________________________________________________________________
block4_sepconv2_act (Activation (None, 32, 32, 728)  0           block4_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block4_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block4_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block4_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block4_sepconv2[0][0]            
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 16, 16, 728)  186368      add_1[0][0]                      
__________________________________________________________________________________________________
block4_pool (MaxPooling2D)      (None, 16, 16, 728)  0           block4_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 16, 16, 728)  2912        conv2d_2[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, 16, 16, 728)  0           block4_pool[0][0]                
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
block5_sepconv1_act (Activation (None, 16, 16, 728)  0           add_2[0][0]                      
__________________________________________________________________________________________________
block5_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block5_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv1[0][0]            
__________________________________________________________________________________________________
block5_sepconv2_act (Activation (None, 16, 16, 728)  0           block5_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block5_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block5_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv2[0][0]            
__________________________________________________________________________________________________
block5_sepconv3_act (Activation (None, 16, 16, 728)  0           block5_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block5_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block5_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv3[0][0]            
__________________________________________________________________________________________________
add_3 (Add)                     (None, 16, 16, 728)  0           block5_sepconv3_bn[0][0]         
                                                                 add_2[0][0]                      
__________________________________________________________________________________________________
block6_sepconv1_act (Activation (None, 16, 16, 728)  0           add_3[0][0]                      
__________________________________________________________________________________________________
block6_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block6_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv1[0][0]            
__________________________________________________________________________________________________
block6_sepconv2_act (Activation (None, 16, 16, 728)  0           block6_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block6_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block6_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv2[0][0]            
__________________________________________________________________________________________________
block6_sepconv3_act (Activation (None, 16, 16, 728)  0           block6_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block6_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block6_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv3[0][0]            
__________________________________________________________________________________________________
add_4 (Add)                     (None, 16, 16, 728)  0           block6_sepconv3_bn[0][0]         
                                                                 add_3[0][0]                      
__________________________________________________________________________________________________
block7_sepconv1_act (Activation (None, 16, 16, 728)  0           add_4[0][0]                      
__________________________________________________________________________________________________
block7_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block7_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv1[0][0]            
__________________________________________________________________________________________________
block7_sepconv2_act (Activation (None, 16, 16, 728)  0           block7_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block7_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block7_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv2[0][0]            
__________________________________________________________________________________________________
block7_sepconv3_act (Activation (None, 16, 16, 728)  0           block7_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block7_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block7_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv3[0][0]            
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 728)  0           block7_sepconv3_bn[0][0]         
                                                                 add_4[0][0]                      
__________________________________________________________________________________________________
block8_sepconv1_act (Activation (None, 16, 16, 728)  0           add_5[0][0]                      
__________________________________________________________________________________________________
block8_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block8_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv1[0][0]            
__________________________________________________________________________________________________
block8_sepconv2_act (Activation (None, 16, 16, 728)  0           block8_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block8_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block8_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv2[0][0]            
__________________________________________________________________________________________________
block8_sepconv3_act (Activation (None, 16, 16, 728)  0           block8_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block8_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block8_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv3[0][0]            
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 728)  0           block8_sepconv3_bn[0][0]         
                                                                 add_5[0][0]                      
__________________________________________________________________________________________________
block9_sepconv1_act (Activation (None, 16, 16, 728)  0           add_6[0][0]                      
__________________________________________________________________________________________________
block9_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block9_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv1[0][0]            
__________________________________________________________________________________________________
block9_sepconv2_act (Activation (None, 16, 16, 728)  0           block9_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block9_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block9_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv2[0][0]            
__________________________________________________________________________________________________
block9_sepconv3_act (Activation (None, 16, 16, 728)  0           block9_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block9_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block9_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv3[0][0]            
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 728)  0           block9_sepconv3_bn[0][0]         
                                                                 add_6[0][0]                      
__________________________________________________________________________________________________
block10_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_7[0][0]                      
__________________________________________________________________________________________________
block10_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block10_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv1[0][0]           
__________________________________________________________________________________________________
block10_sepconv2_act (Activatio (None, 16, 16, 728)  0           block10_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block10_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block10_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv2[0][0]           
__________________________________________________________________________________________________
block10_sepconv3_act (Activatio (None, 16, 16, 728)  0           block10_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
block10_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv3_act[0][0]       
__________________________________________________________________________________________________
block10_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv3[0][0]           
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 728)  0           block10_sepconv3_bn[0][0]        
                                                                 add_7[0][0]                      
__________________________________________________________________________________________________
block11_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_8[0][0]                      
__________________________________________________________________________________________________
block11_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block11_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv1[0][0]           
__________________________________________________________________________________________________
block11_sepconv2_act (Activatio (None, 16, 16, 728)  0           block11_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block11_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block11_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv2[0][0]           
__________________________________________________________________________________________________
block11_sepconv3_act (Activatio (None, 16, 16, 728)  0           block11_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
block11_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv3_act[0][0]       
__________________________________________________________________________________________________
block11_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv3[0][0]           
__________________________________________________________________________________________________
add_9 (Add)                     (None, 16, 16, 728)  0           block11_sepconv3_bn[0][0]        
                                                                 add_8[0][0]                      
__________________________________________________________________________________________________
block12_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_9[0][0]                      
__________________________________________________________________________________________________
block12_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block12_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv1[0][0]           
__________________________________________________________________________________________________
block12_sepconv2_act (Activatio (None, 16, 16, 728)  0           block12_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block12_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block12_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv2[0][0]           
__________________________________________________________________________________________________
block12_sepconv3_act (Activatio (None, 16, 16, 728)  0           block12_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
block12_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv3_act[0][0]       
__________________________________________________________________________________________________
block12_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv3[0][0]           
__________________________________________________________________________________________________
add_10 (Add)                    (None, 16, 16, 728)  0           block12_sepconv3_bn[0][0]        
                                                                 add_9[0][0]                      
__________________________________________________________________________________________________
block13_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_10[0][0]                     
__________________________________________________________________________________________________
block13_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block13_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block13_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block13_sepconv1[0][0]           
__________________________________________________________________________________________________
block13_sepconv2_act (Activatio (None, 16, 16, 728)  0           block13_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block13_sepconv2 (SeparableConv (None, 16, 16, 1024) 752024      block13_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block13_sepconv2_bn (BatchNorma (None, 16, 16, 1024) 4096        block13_sepconv2[0][0]           
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 8, 8, 1024)   745472      add_10[0][0]                     
__________________________________________________________________________________________________
block13_pool (MaxPooling2D)     (None, 8, 8, 1024)   0           block13_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 8, 8, 1024)   4096        conv2d_3[0][0]                   
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 8, 1024)   0           block13_pool[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
block14_sepconv1 (SeparableConv (None, 8, 8, 1536)   1582080     add_11[0][0]                     
__________________________________________________________________________________________________
block14_sepconv1_bn (BatchNorma (None, 8, 8, 1536)   6144        block14_sepconv1[0][0]           
__________________________________________________________________________________________________
block14_sepconv1_act (Activatio (None, 8, 8, 1536)   0           block14_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block14_sepconv2 (SeparableConv (None, 8, 8, 2048)   3159552     block14_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block14_sepconv2_bn (BatchNorma (None, 8, 8, 2048)   8192        block14_sepconv2[0][0]           
__________________________________________________________________________________________________
block14_sepconv2_act (Activatio (None, 8, 8, 2048)   0           block14_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
flatten (Flatten)               (None, 131072)       0           block14_sepconv2_act[0][0]       
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         536875008   flatten[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
predictions (Dense)             (None, 5)            20485       fc2[0][0]                        
==================================================================================================
Total params: 574,538,285
Trainable params: 574,483,757
Non-trainable params: 54,528
__________________________________________________________________________________________________
Start fitting ensemble models
Random seed for replication: 73
Length split part:  1398
Labels in this part of split:  [271, 288, 281, 270, 288]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 47s - loss: 1.4091 - accuracy: 0.4142 - val_loss: 3.2633 - val_accuracy: 0.0838
Epoch 2/500
44/44 - 17s - loss: 0.5652 - accuracy: 0.8326 - val_loss: 3.5174 - val_accuracy: 0.0838
Epoch 3/500
44/44 - 17s - loss: 0.1305 - accuracy: 0.9814 - val_loss: 3.9399 - val_accuracy: 0.1229
Epoch 4/500
44/44 - 34s - loss: 0.0401 - accuracy: 0.9964 - val_loss: 2.8423 - val_accuracy: 0.3408
Epoch 5/500
44/44 - 34s - loss: 0.0130 - accuracy: 1.0000 - val_loss: 2.2862 - val_accuracy: 0.3687
Epoch 6/500
44/44 - 38s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.7816 - val_accuracy: 0.4637
Epoch 7/500
44/44 - 34s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.6674 - val_accuracy: 0.5531
Epoch 8/500
44/44 - 38s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.6585 - val_accuracy: 0.5642
Epoch 9/500
44/44 - 36s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.6433 - val_accuracy: 0.5866
Epoch 10/500
44/44 - 35s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6413 - val_accuracy: 0.5866
Epoch 11/500
44/44 - 17s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6420 - val_accuracy: 0.5922
Epoch 12/500
44/44 - 17s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6457 - val_accuracy: 0.6145
Epoch 13/500
44/44 - 17s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6606 - val_accuracy: 0.6034
Epoch 14/500
44/44 - 17s - loss: 9.1982e-04 - accuracy: 1.0000 - val_loss: 1.6787 - val_accuracy: 0.6257
Epoch 15/500
44/44 - 17s - loss: 8.0801e-04 - accuracy: 1.0000 - val_loss: 1.6958 - val_accuracy: 0.6257
Epoch 16/500
44/44 - 17s - loss: 7.1415e-04 - accuracy: 1.0000 - val_loss: 1.7145 - val_accuracy: 0.6257
Epoch 17/500
44/44 - 17s - loss: 6.3743e-04 - accuracy: 1.0000 - val_loss: 1.7310 - val_accuracy: 0.6201
Epoch 18/500
44/44 - 17s - loss: 5.6958e-04 - accuracy: 1.0000 - val_loss: 1.7461 - val_accuracy: 0.6201
Epoch 19/500
44/44 - 17s - loss: 5.1598e-04 - accuracy: 1.0000 - val_loss: 1.7623 - val_accuracy: 0.6201
Epoch 20/500
44/44 - 17s - loss: 4.6646e-04 - accuracy: 1.0000 - val_loss: 1.7773 - val_accuracy: 0.6145
Epoch 21/500
44/44 - 17s - loss: 4.2333e-04 - accuracy: 1.0000 - val_loss: 1.7929 - val_accuracy: 0.6145
Epoch 22/500
44/44 - 17s - loss: 3.8710e-04 - accuracy: 1.0000 - val_loss: 1.8088 - val_accuracy: 0.6145
Epoch 23/500
44/44 - 17s - loss: 3.5244e-04 - accuracy: 1.0000 - val_loss: 1.8239 - val_accuracy: 0.6145
Epoch 24/500
44/44 - 17s - loss: 3.2325e-04 - accuracy: 1.0000 - val_loss: 1.8380 - val_accuracy: 0.6145
Epoch 25/500
44/44 - 17s - loss: 2.9715e-04 - accuracy: 1.0000 - val_loss: 1.8531 - val_accuracy: 0.6145
Epoch 26/500
44/44 - 17s - loss: 2.7443e-04 - accuracy: 1.0000 - val_loss: 1.8672 - val_accuracy: 0.6201
Epoch 27/500
44/44 - 17s - loss: 2.5358e-04 - accuracy: 1.0000 - val_loss: 1.8804 - val_accuracy: 0.6201
Epoch 28/500
44/44 - 17s - loss: 2.3408e-04 - accuracy: 1.0000 - val_loss: 1.8928 - val_accuracy: 0.6145
Epoch 29/500
44/44 - 17s - loss: 2.1659e-04 - accuracy: 1.0000 - val_loss: 1.9090 - val_accuracy: 0.6089
Epoch 30/500
44/44 - 17s - loss: 2.0089e-04 - accuracy: 1.0000 - val_loss: 1.9211 - val_accuracy: 0.6089
Epoch 31/500
44/44 - 17s - loss: 1.8654e-04 - accuracy: 1.0000 - val_loss: 1.9343 - val_accuracy: 0.6145
Epoch 32/500
44/44 - 17s - loss: 1.7363e-04 - accuracy: 1.0000 - val_loss: 1.9446 - val_accuracy: 0.6145
Epoch 33/500
44/44 - 17s - loss: 1.6223e-04 - accuracy: 1.0000 - val_loss: 1.9570 - val_accuracy: 0.6089
Epoch 34/500
44/44 - 17s - loss: 1.5141e-04 - accuracy: 1.0000 - val_loss: 1.9693 - val_accuracy: 0.6145
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 11:38:20.980942: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 11:38:20.981091: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 11:38:20.981124: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 11:38:21.366241: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 11:38:21.366356: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00034: early stopping
Length split part:  1398
Labels in this part of split:  [290, 261, 274, 290, 283]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 33s - loss: 1.4487 - accuracy: 0.4149 - val_loss: 1.2130 - val_accuracy: 0.4916
Epoch 2/500
44/44 - 35s - loss: 0.5919 - accuracy: 0.7868 - val_loss: 1.1957 - val_accuracy: 0.5922
Epoch 3/500
44/44 - 17s - loss: 0.0862 - accuracy: 0.9828 - val_loss: 2.4259 - val_accuracy: 0.4190
Epoch 4/500
44/44 - 17s - loss: 0.0210 - accuracy: 0.9971 - val_loss: 1.9244 - val_accuracy: 0.4860
Epoch 5/500
44/44 - 17s - loss: 0.0119 - accuracy: 0.9971 - val_loss: 2.1614 - val_accuracy: 0.4860
Epoch 6/500
44/44 - 17s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.1098 - val_accuracy: 0.5642
Epoch 7/500
44/44 - 17s - loss: 7.2591e-04 - accuracy: 1.0000 - val_loss: 2.2135 - val_accuracy: 0.5810
Epoch 8/500
44/44 - 17s - loss: 4.9875e-04 - accuracy: 1.0000 - val_loss: 2.3029 - val_accuracy: 0.5866
Epoch 9/500
44/44 - 17s - loss: 3.8616e-04 - accuracy: 1.0000 - val_loss: 2.3691 - val_accuracy: 0.5754
Epoch 10/500
44/44 - 17s - loss: 3.1994e-04 - accuracy: 1.0000 - val_loss: 2.3382 - val_accuracy: 0.5866
Epoch 11/500
44/44 - 17s - loss: 2.7376e-04 - accuracy: 1.0000 - val_loss: 2.4122 - val_accuracy: 0.5866
Epoch 12/500
44/44 - 17s - loss: 2.3899e-04 - accuracy: 1.0000 - val_loss: 2.4009 - val_accuracy: 0.5922
Epoch 13/500
44/44 - 17s - loss: 2.1122e-04 - accuracy: 1.0000 - val_loss: 2.4897 - val_accuracy: 0.5922
Epoch 14/500
44/44 - 17s - loss: 1.8860e-04 - accuracy: 1.0000 - val_loss: 2.4359 - val_accuracy: 0.5866
Epoch 15/500
44/44 - 17s - loss: 1.7047e-04 - accuracy: 1.0000 - val_loss: 2.4358 - val_accuracy: 0.5978
Epoch 16/500
44/44 - 17s - loss: 1.5516e-04 - accuracy: 1.0000 - val_loss: 2.4418 - val_accuracy: 0.6145
Epoch 17/500
44/44 - 17s - loss: 1.4206e-04 - accuracy: 1.0000 - val_loss: 2.4618 - val_accuracy: 0.6034
Epoch 18/500
44/44 - 17s - loss: 1.3066e-04 - accuracy: 1.0000 - val_loss: 2.4791 - val_accuracy: 0.5978
Epoch 19/500
44/44 - 17s - loss: 1.2069e-04 - accuracy: 1.0000 - val_loss: 2.4959 - val_accuracy: 0.5978
Epoch 20/500
44/44 - 17s - loss: 1.1204e-04 - accuracy: 1.0000 - val_loss: 2.5124 - val_accuracy: 0.5978
Epoch 21/500
44/44 - 17s - loss: 1.0428e-04 - accuracy: 1.0000 - val_loss: 2.5274 - val_accuracy: 0.5978
Epoch 22/500
44/44 - 17s - loss: 9.7551e-05 - accuracy: 1.0000 - val_loss: 2.5398 - val_accuracy: 0.5978
Epoch 23/500
44/44 - 17s - loss: 9.1269e-05 - accuracy: 1.0000 - val_loss: 2.5517 - val_accuracy: 0.5978
Epoch 24/500
44/44 - 17s - loss: 8.5732e-05 - accuracy: 1.0000 - val_loss: 2.5663 - val_accuracy: 0.5978
Epoch 25/500
44/44 - 17s - loss: 8.0688e-05 - accuracy: 1.0000 - val_loss: 2.5815 - val_accuracy: 0.5978
Epoch 26/500
44/44 - 17s - loss: 7.6147e-05 - accuracy: 1.0000 - val_loss: 2.5941 - val_accuracy: 0.5978
Epoch 27/500
44/44 - 17s - loss: 7.1874e-05 - accuracy: 1.0000 - val_loss: 2.6075 - val_accuracy: 0.5978
Epoch 28/500
44/44 - 17s - loss: 6.8060e-05 - accuracy: 1.0000 - val_loss: 2.6192 - val_accuracy: 0.5978
Epoch 29/500
44/44 - 17s - loss: 6.4482e-05 - accuracy: 1.0000 - val_loss: 2.6284 - val_accuracy: 0.5978
Epoch 30/500
44/44 - 17s - loss: 6.1350e-05 - accuracy: 1.0000 - val_loss: 2.6395 - val_accuracy: 0.5978
Epoch 31/500
44/44 - 17s - loss: 5.8292e-05 - accuracy: 1.0000 - val_loss: 2.6516 - val_accuracy: 0.5978
Epoch 32/500
44/44 - 17s - loss: 5.5456e-05 - accuracy: 1.0000 - val_loss: 2.6634 - val_accuracy: 0.5978
Epoch 33/500
44/44 - 17s - loss: 5.2858e-05 - accuracy: 1.0000 - val_loss: 2.6726 - val_accuracy: 0.5978
Epoch 34/500
44/44 - 17s - loss: 5.0466e-05 - accuracy: 1.0000 - val_loss: 2.6798 - val_accuracy: 0.5978
Epoch 35/500
44/44 - 17s - loss: 4.8156e-05 - accuracy: 1.0000 - val_loss: 2.6883 - val_accuracy: 0.5978
Epoch 36/500
44/44 - 17s - loss: 4.6050e-05 - accuracy: 1.0000 - val_loss: 2.6974 - val_accuracy: 0.5978
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 11:49:37.142359: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 11:49:37.142521: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 11:49:37.142558: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 11:49:37.527392: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 11:49:37.527498: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00036: early stopping
Length split part:  1397
Labels in this part of split:  [279, 291, 284, 278, 265]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 35s - loss: 1.6367 - accuracy: 0.3658 - val_loss: 3.1322 - val_accuracy: 0.1173
Epoch 2/500
44/44 - 36s - loss: 0.9934 - accuracy: 0.6206 - val_loss: 3.0993 - val_accuracy: 0.0615
Epoch 3/500
44/44 - 33s - loss: 0.3813 - accuracy: 0.8776 - val_loss: 2.4691 - val_accuracy: 0.1955
Epoch 4/500
44/44 - 34s - loss: 0.0712 - accuracy: 0.9864 - val_loss: 2.1496 - val_accuracy: 0.3575
Epoch 5/500
44/44 - 17s - loss: 0.0242 - accuracy: 0.9964 - val_loss: 2.5638 - val_accuracy: 0.2793
Epoch 6/500
44/44 - 34s - loss: 0.0116 - accuracy: 0.9979 - val_loss: 2.0198 - val_accuracy: 0.4134
Epoch 7/500
44/44 - 17s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.1128 - val_accuracy: 0.4804
Epoch 8/500
44/44 - 17s - loss: 9.9902e-04 - accuracy: 1.0000 - val_loss: 2.1375 - val_accuracy: 0.4916
Epoch 9/500
44/44 - 17s - loss: 6.9509e-04 - accuracy: 1.0000 - val_loss: 2.1352 - val_accuracy: 0.5084
Epoch 10/500
44/44 - 17s - loss: 5.4252e-04 - accuracy: 1.0000 - val_loss: 2.2112 - val_accuracy: 0.5475
Epoch 11/500
44/44 - 17s - loss: 4.4281e-04 - accuracy: 1.0000 - val_loss: 2.3266 - val_accuracy: 0.5531
Epoch 12/500
44/44 - 17s - loss: 3.7258e-04 - accuracy: 1.0000 - val_loss: 2.3947 - val_accuracy: 0.5531
Epoch 13/500
44/44 - 17s - loss: 3.2065e-04 - accuracy: 1.0000 - val_loss: 2.4501 - val_accuracy: 0.5754
Epoch 14/500
44/44 - 17s - loss: 2.8079e-04 - accuracy: 1.0000 - val_loss: 2.5042 - val_accuracy: 0.5531
Epoch 15/500
44/44 - 17s - loss: 2.4901e-04 - accuracy: 1.0000 - val_loss: 2.5090 - val_accuracy: 0.5475
Epoch 16/500
44/44 - 17s - loss: 2.2244e-04 - accuracy: 1.0000 - val_loss: 2.5196 - val_accuracy: 0.5531
Epoch 17/500
44/44 - 17s - loss: 2.0123e-04 - accuracy: 1.0000 - val_loss: 2.5378 - val_accuracy: 0.5475
Epoch 18/500
44/44 - 17s - loss: 1.8304e-04 - accuracy: 1.0000 - val_loss: 2.5558 - val_accuracy: 0.5531
Epoch 19/500
44/44 - 17s - loss: 1.6758e-04 - accuracy: 1.0000 - val_loss: 2.5748 - val_accuracy: 0.5531
Epoch 20/500
44/44 - 17s - loss: 1.5424e-04 - accuracy: 1.0000 - val_loss: 2.5929 - val_accuracy: 0.5531
Epoch 21/500
44/44 - 17s - loss: 1.4269e-04 - accuracy: 1.0000 - val_loss: 2.6112 - val_accuracy: 0.5531
Epoch 22/500
44/44 - 17s - loss: 1.3208e-04 - accuracy: 1.0000 - val_loss: 2.6298 - val_accuracy: 0.5587
Epoch 23/500
44/44 - 17s - loss: 1.2296e-04 - accuracy: 1.0000 - val_loss: 2.6473 - val_accuracy: 0.5587
Epoch 24/500
44/44 - 17s - loss: 1.1497e-04 - accuracy: 1.0000 - val_loss: 2.6632 - val_accuracy: 0.5587
Epoch 25/500
44/44 - 17s - loss: 1.0747e-04 - accuracy: 1.0000 - val_loss: 2.6775 - val_accuracy: 0.5531
Epoch 26/500
44/44 - 17s - loss: 1.0102e-04 - accuracy: 1.0000 - val_loss: 2.6949 - val_accuracy: 0.5531
Epoch 27/500
44/44 - 17s - loss: 9.5113e-05 - accuracy: 1.0000 - val_loss: 2.7097 - val_accuracy: 0.5531
Epoch 28/500
44/44 - 17s - loss: 8.9596e-05 - accuracy: 1.0000 - val_loss: 2.7250 - val_accuracy: 0.5531
Epoch 29/500
44/44 - 17s - loss: 8.4544e-05 - accuracy: 1.0000 - val_loss: 2.7379 - val_accuracy: 0.5475
Epoch 30/500
44/44 - 17s - loss: 8.0083e-05 - accuracy: 1.0000 - val_loss: 2.7487 - val_accuracy: 0.5475
Epoch 31/500
44/44 - 17s - loss: 7.5970e-05 - accuracy: 1.0000 - val_loss: 2.7605 - val_accuracy: 0.5531
Epoch 32/500
44/44 - 17s - loss: 7.2074e-05 - accuracy: 1.0000 - val_loss: 2.7735 - val_accuracy: 0.5531
Epoch 33/500
44/44 - 17s - loss: 6.8496e-05 - accuracy: 1.0000 - val_loss: 2.7844 - val_accuracy: 0.5475
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 12:00:58.713315: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 12:00:58.713484: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:00:58.713518: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:00:58.914597: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 12:00:58.914713: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00033: early stopping
VGG16
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 256, 256, 3)]     0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         
_________________________________________________________________
flatten (Flatten)            (None, 32768)             0         
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              134221824 
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312  
_________________________________________________________________
predictions (Dense)          (None, 5)                 20485     
=================================================================
Total params: 165,738,309
Trainable params: 165,738,309
Non-trainable params: 0
_________________________________________________________________
Start fitting ensemble models
Random seed for replication: 72
Length split part:  1398
Labels in this part of split:  [284, 283, 265, 287, 279]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 22s - loss: 1.5168 - accuracy: 0.3262 - val_loss: 1.0530 - val_accuracy: 0.6648
Epoch 2/500
44/44 - 16s - loss: 1.3390 - accuracy: 0.4328 - val_loss: 1.0124 - val_accuracy: 0.6592
Epoch 3/500
44/44 - 14s - loss: 1.1829 - accuracy: 0.5336 - val_loss: 0.9984 - val_accuracy: 0.6257
Epoch 4/500
44/44 - 9s - loss: 1.0004 - accuracy: 0.6109 - val_loss: 1.1693 - val_accuracy: 0.5587
Epoch 5/500
44/44 - 9s - loss: 0.8231 - accuracy: 0.6931 - val_loss: 1.0810 - val_accuracy: 0.5587
Epoch 6/500
44/44 - 9s - loss: 0.6603 - accuracy: 0.7525 - val_loss: 1.0366 - val_accuracy: 0.5754
Epoch 7/500
44/44 - 9s - loss: 0.4773 - accuracy: 0.8312 - val_loss: 1.1182 - val_accuracy: 0.6089
Epoch 8/500
44/44 - 9s - loss: 0.3129 - accuracy: 0.8984 - val_loss: 1.0614 - val_accuracy: 0.5866
Epoch 9/500
44/44 - 9s - loss: 0.2378 - accuracy: 0.9199 - val_loss: 1.1006 - val_accuracy: 0.6257
Epoch 10/500
44/44 - 9s - loss: 0.1601 - accuracy: 0.9571 - val_loss: 1.4315 - val_accuracy: 0.5363
Epoch 11/500
44/44 - 9s - loss: 0.1248 - accuracy: 0.9657 - val_loss: 1.6183 - val_accuracy: 0.4972
Epoch 12/500
44/44 - 9s - loss: 0.0817 - accuracy: 0.9807 - val_loss: 1.4968 - val_accuracy: 0.5754
Epoch 13/500
44/44 - 9s - loss: 0.0518 - accuracy: 0.9928 - val_loss: 1.6710 - val_accuracy: 0.5419
Epoch 14/500
44/44 - 9s - loss: 0.0481 - accuracy: 0.9886 - val_loss: 1.5694 - val_accuracy: 0.5698
Epoch 15/500
44/44 - 9s - loss: 0.0670 - accuracy: 0.9864 - val_loss: 2.1161 - val_accuracy: 0.4749
Epoch 16/500
44/44 - 9s - loss: 0.0415 - accuracy: 0.9893 - val_loss: 2.1396 - val_accuracy: 0.4637
Epoch 17/500
44/44 - 9s - loss: 0.0466 - accuracy: 0.9900 - val_loss: 1.8090 - val_accuracy: 0.5587
Epoch 18/500
44/44 - 9s - loss: 0.0614 - accuracy: 0.9886 - val_loss: 2.0574 - val_accuracy: 0.5028
Epoch 19/500
44/44 - 9s - loss: 0.0492 - accuracy: 0.9900 - val_loss: 2.3274 - val_accuracy: 0.4804
Epoch 20/500
44/44 - 9s - loss: 0.0488 - accuracy: 0.9850 - val_loss: 1.6784 - val_accuracy: 0.5642
Epoch 21/500
44/44 - 9s - loss: 0.0460 - accuracy: 0.9878 - val_loss: 1.6630 - val_accuracy: 0.6201
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 12:04:38.930220: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 12:04:38.930382: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:04:38.930416: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:04:39.134050: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 12:04:39.134170: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00021: early stopping
Length split part:  1398
Labels in this part of split:  [269, 291, 275, 285, 278]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 13s - loss: 1.5722 - accuracy: 0.2897 - val_loss: 1.4420 - val_accuracy: 0.3520
Epoch 2/500
44/44 - 14s - loss: 1.4556 - accuracy: 0.3727 - val_loss: 1.0030 - val_accuracy: 0.6648
Epoch 3/500
44/44 - 9s - loss: 1.3177 - accuracy: 0.4585 - val_loss: 1.3056 - val_accuracy: 0.4190
Epoch 4/500
44/44 - 15s - loss: 1.2082 - accuracy: 0.5143 - val_loss: 0.9553 - val_accuracy: 0.6704
Epoch 5/500
44/44 - 9s - loss: 1.0899 - accuracy: 0.5701 - val_loss: 1.0282 - val_accuracy: 0.5698
Epoch 6/500
44/44 - 9s - loss: 0.9683 - accuracy: 0.6266 - val_loss: 0.9924 - val_accuracy: 0.6816
Epoch 7/500
44/44 - 15s - loss: 0.8278 - accuracy: 0.6917 - val_loss: 0.9426 - val_accuracy: 0.6425
Epoch 8/500
44/44 - 9s - loss: 0.6887 - accuracy: 0.7504 - val_loss: 1.2867 - val_accuracy: 0.4302
Epoch 9/500
44/44 - 9s - loss: 0.6120 - accuracy: 0.7804 - val_loss: 1.0218 - val_accuracy: 0.6201
Epoch 10/500
44/44 - 14s - loss: 0.4863 - accuracy: 0.8255 - val_loss: 0.9330 - val_accuracy: 0.6816
Epoch 11/500
44/44 - 9s - loss: 0.3844 - accuracy: 0.8648 - val_loss: 1.2760 - val_accuracy: 0.4637
Epoch 12/500
44/44 - 9s - loss: 0.3336 - accuracy: 0.8834 - val_loss: 1.0843 - val_accuracy: 0.6313
Epoch 13/500
44/44 - 9s - loss: 0.2403 - accuracy: 0.9256 - val_loss: 1.1690 - val_accuracy: 0.6480
Epoch 14/500
44/44 - 9s - loss: 0.1705 - accuracy: 0.9521 - val_loss: 1.1844 - val_accuracy: 0.6313
Epoch 15/500
44/44 - 9s - loss: 0.1741 - accuracy: 0.9428 - val_loss: 1.2157 - val_accuracy: 0.5531
Epoch 16/500
44/44 - 9s - loss: 0.1097 - accuracy: 0.9649 - val_loss: 1.2104 - val_accuracy: 0.6425
Epoch 17/500
44/44 - 9s - loss: 0.0857 - accuracy: 0.9750 - val_loss: 1.3242 - val_accuracy: 0.5475
Epoch 18/500
44/44 - 9s - loss: 0.0418 - accuracy: 0.9943 - val_loss: 1.3971 - val_accuracy: 0.5978
Epoch 19/500
44/44 - 9s - loss: 0.0389 - accuracy: 0.9893 - val_loss: 1.4058 - val_accuracy: 0.6704
Epoch 20/500
44/44 - 9s - loss: 0.0328 - accuracy: 0.9928 - val_loss: 1.4783 - val_accuracy: 0.5698
Epoch 21/500
44/44 - 9s - loss: 0.0269 - accuracy: 0.9943 - val_loss: 1.4459 - val_accuracy: 0.6536
Epoch 22/500
44/44 - 9s - loss: 0.0321 - accuracy: 0.9943 - val_loss: 1.4439 - val_accuracy: 0.6425
Epoch 23/500
44/44 - 9s - loss: 0.0192 - accuracy: 0.9964 - val_loss: 1.5596 - val_accuracy: 0.5922
Epoch 24/500
44/44 - 9s - loss: 0.0198 - accuracy: 0.9964 - val_loss: 1.4511 - val_accuracy: 0.6536
Epoch 25/500
44/44 - 9s - loss: 0.0287 - accuracy: 0.9943 - val_loss: 1.5101 - val_accuracy: 0.6034
Epoch 26/500
44/44 - 9s - loss: 0.0323 - accuracy: 0.9914 - val_loss: 1.6253 - val_accuracy: 0.6034
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 12:09:11.452158: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 12:09:11.452314: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:09:11.452359: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:09:11.653658: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 12:09:11.653753: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00026: early stopping
Length split part:  1397
Labels in this part of split:  [287, 266, 299, 266, 279]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 15s - loss: 1.5913 - accuracy: 0.2820 - val_loss: 1.2102 - val_accuracy: 0.6592
Epoch 2/500
44/44 - 9s - loss: 1.4495 - accuracy: 0.3858 - val_loss: 1.2799 - val_accuracy: 0.5196
Epoch 3/500
44/44 - 16s - loss: 1.3864 - accuracy: 0.4073 - val_loss: 1.0626 - val_accuracy: 0.6034
Epoch 4/500
44/44 - 9s - loss: 1.2532 - accuracy: 0.4782 - val_loss: 1.0884 - val_accuracy: 0.5475
Epoch 5/500
44/44 - 9s - loss: 1.1794 - accuracy: 0.5218 - val_loss: 1.1526 - val_accuracy: 0.5475
Epoch 6/500
44/44 - 9s - loss: 1.0245 - accuracy: 0.6106 - val_loss: 1.1548 - val_accuracy: 0.5363
Epoch 7/500
44/44 - 16s - loss: 0.9061 - accuracy: 0.6500 - val_loss: 0.9669 - val_accuracy: 0.6313
Epoch 8/500
44/44 - 9s - loss: 0.7637 - accuracy: 0.7101 - val_loss: 1.0248 - val_accuracy: 0.5922
Epoch 9/500
44/44 - 9s - loss: 0.7163 - accuracy: 0.7323 - val_loss: 1.0529 - val_accuracy: 0.6201
Epoch 10/500
44/44 - 9s - loss: 0.5324 - accuracy: 0.8189 - val_loss: 1.0430 - val_accuracy: 0.6369
Epoch 11/500
44/44 - 9s - loss: 0.3584 - accuracy: 0.8890 - val_loss: 1.1843 - val_accuracy: 0.6145
Epoch 12/500
44/44 - 9s - loss: 0.2907 - accuracy: 0.8998 - val_loss: 1.0456 - val_accuracy: 0.6313
Epoch 13/500
44/44 - 9s - loss: 0.2390 - accuracy: 0.9270 - val_loss: 1.3046 - val_accuracy: 0.5531
Epoch 14/500
44/44 - 9s - loss: 0.1759 - accuracy: 0.9492 - val_loss: 1.3645 - val_accuracy: 0.6145
Epoch 15/500
44/44 - 9s - loss: 0.0939 - accuracy: 0.9742 - val_loss: 1.3105 - val_accuracy: 0.6480
Epoch 16/500
44/44 - 9s - loss: 0.0627 - accuracy: 0.9885 - val_loss: 1.5963 - val_accuracy: 0.5363
Epoch 17/500
44/44 - 9s - loss: 0.0588 - accuracy: 0.9857 - val_loss: 1.7931 - val_accuracy: 0.6480
Epoch 18/500
44/44 - 9s - loss: 0.0623 - accuracy: 0.9821 - val_loss: 1.5999 - val_accuracy: 0.5866
Epoch 19/500
44/44 - 9s - loss: 0.0413 - accuracy: 0.9928 - val_loss: 1.7379 - val_accuracy: 0.6034
Epoch 20/500
44/44 - 9s - loss: 0.0336 - accuracy: 0.9936 - val_loss: 1.7691 - val_accuracy: 0.5978
Epoch 21/500
44/44 - 9s - loss: 0.0382 - accuracy: 0.9907 - val_loss: 1.6221 - val_accuracy: 0.5587
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 12:12:55.340747: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 12:12:55.340896: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:12:55.340928: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:12:55.574262: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 12:12:55.574371: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00021: early stopping
VGG19
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 256, 256, 3)]     0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         
_________________________________________________________________
flatten (Flatten)            (None, 32768)             0         
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              134221824 
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312  
_________________________________________________________________
predictions (Dense)          (None, 5)                 20485     
=================================================================
Total params: 171,048,005
Trainable params: 171,048,005
Non-trainable params: 0
_________________________________________________________________
Start fitting ensemble models
Random seed for replication: 93
Length split part:  1398
Labels in this part of split:  [261, 299, 264, 286, 288]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 19s - loss: 1.5180 - accuracy: 0.3169 - val_loss: 1.1035 - val_accuracy: 0.5810
Epoch 2/500
44/44 - 16s - loss: 1.3194 - accuracy: 0.4514 - val_loss: 0.9718 - val_accuracy: 0.6648
Epoch 3/500
44/44 - 11s - loss: 1.2105 - accuracy: 0.5072 - val_loss: 1.0113 - val_accuracy: 0.6648
Epoch 4/500
44/44 - 17s - loss: 1.0047 - accuracy: 0.5951 - val_loss: 0.9497 - val_accuracy: 0.6816
Epoch 5/500
44/44 - 11s - loss: 0.7975 - accuracy: 0.7024 - val_loss: 1.0057 - val_accuracy: 0.6313
Epoch 6/500
44/44 - 11s - loss: 0.5909 - accuracy: 0.7969 - val_loss: 1.0046 - val_accuracy: 0.6480
Epoch 7/500
44/44 - 11s - loss: 0.4631 - accuracy: 0.8319 - val_loss: 1.2156 - val_accuracy: 0.5251
Epoch 8/500
44/44 - 11s - loss: 0.3066 - accuracy: 0.8977 - val_loss: 1.1565 - val_accuracy: 0.6257
Epoch 9/500
44/44 - 11s - loss: 0.2466 - accuracy: 0.9220 - val_loss: 1.7040 - val_accuracy: 0.4022
Epoch 10/500
44/44 - 11s - loss: 0.2098 - accuracy: 0.9306 - val_loss: 1.3307 - val_accuracy: 0.6201
Epoch 11/500
44/44 - 11s - loss: 0.1528 - accuracy: 0.9528 - val_loss: 1.3906 - val_accuracy: 0.4972
Epoch 12/500
44/44 - 11s - loss: 0.0971 - accuracy: 0.9793 - val_loss: 1.4065 - val_accuracy: 0.6480
Epoch 13/500
44/44 - 11s - loss: 0.0663 - accuracy: 0.9850 - val_loss: 1.7107 - val_accuracy: 0.5531
Epoch 14/500
44/44 - 11s - loss: 0.0750 - accuracy: 0.9785 - val_loss: 1.5714 - val_accuracy: 0.6257
Epoch 15/500
44/44 - 11s - loss: 0.0421 - accuracy: 0.9900 - val_loss: 1.6335 - val_accuracy: 0.6201
Epoch 16/500
44/44 - 11s - loss: 0.0326 - accuracy: 0.9907 - val_loss: 1.9063 - val_accuracy: 0.6425
Epoch 17/500
44/44 - 11s - loss: 0.0160 - accuracy: 0.9971 - val_loss: 1.6180 - val_accuracy: 0.6145
Epoch 18/500
44/44 - 11s - loss: 0.0218 - accuracy: 0.9921 - val_loss: 1.7095 - val_accuracy: 0.6145
Epoch 19/500
44/44 - 11s - loss: 0.0335 - accuracy: 0.9914 - val_loss: 2.1919 - val_accuracy: 0.4637
Epoch 20/500
44/44 - 11s - loss: 0.0267 - accuracy: 0.9971 - val_loss: 1.8430 - val_accuracy: 0.5922
Epoch 21/500
44/44 - 11s - loss: 0.0191 - accuracy: 0.9971 - val_loss: 1.7162 - val_accuracy: 0.6089
Epoch 22/500
44/44 - 11s - loss: 0.0141 - accuracy: 0.9964 - val_loss: 1.8620 - val_accuracy: 0.5810
Epoch 23/500
44/44 - 11s - loss: 0.0144 - accuracy: 0.9979 - val_loss: 2.0259 - val_accuracy: 0.5922
Epoch 24/500
44/44 - 11s - loss: 0.0185 - accuracy: 0.9971 - val_loss: 2.1290 - val_accuracy: 0.5363
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 12:17:35.711554: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 12:17:35.711700: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:17:35.711734: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:17:35.946146: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 12:17:35.946244: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00024: early stopping
Length split part:  1398
Labels in this part of split:  [294, 276, 310, 248, 270]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 16s - loss: 1.5962 - accuracy: 0.2775 - val_loss: 1.6317 - val_accuracy: 0.1899
Epoch 2/500
44/44 - 18s - loss: 1.4355 - accuracy: 0.3834 - val_loss: 1.0236 - val_accuracy: 0.6648
Epoch 3/500
44/44 - 18s - loss: 1.3649 - accuracy: 0.4134 - val_loss: 1.0002 - val_accuracy: 0.6313
Epoch 4/500
44/44 - 11s - loss: 1.2667 - accuracy: 0.4800 - val_loss: 1.1385 - val_accuracy: 0.5140
Epoch 5/500
44/44 - 11s - loss: 1.1802 - accuracy: 0.5200 - val_loss: 1.1483 - val_accuracy: 0.5196
Epoch 6/500
44/44 - 11s - loss: 1.0921 - accuracy: 0.5730 - val_loss: 1.1171 - val_accuracy: 0.5698
Epoch 7/500
44/44 - 16s - loss: 0.9376 - accuracy: 0.6359 - val_loss: 0.9772 - val_accuracy: 0.6369
Epoch 8/500
44/44 - 11s - loss: 0.8043 - accuracy: 0.6974 - val_loss: 1.2130 - val_accuracy: 0.4525
Epoch 9/500
44/44 - 15s - loss: 0.6149 - accuracy: 0.7754 - val_loss: 0.9614 - val_accuracy: 0.6201
Epoch 10/500
44/44 - 11s - loss: 0.5103 - accuracy: 0.8290 - val_loss: 1.1539 - val_accuracy: 0.5531
Epoch 11/500
44/44 - 11s - loss: 0.4548 - accuracy: 0.8362 - val_loss: 1.0693 - val_accuracy: 0.6145
Epoch 12/500
44/44 - 11s - loss: 0.3548 - accuracy: 0.8770 - val_loss: 1.0640 - val_accuracy: 0.6369
Epoch 13/500
44/44 - 11s - loss: 0.2818 - accuracy: 0.9041 - val_loss: 1.2078 - val_accuracy: 0.5978
Epoch 14/500
44/44 - 11s - loss: 0.1614 - accuracy: 0.9514 - val_loss: 1.1151 - val_accuracy: 0.6648
Epoch 15/500
44/44 - 11s - loss: 0.1406 - accuracy: 0.9571 - val_loss: 1.3558 - val_accuracy: 0.5922
Epoch 16/500
44/44 - 11s - loss: 0.1117 - accuracy: 0.9578 - val_loss: 1.6708 - val_accuracy: 0.4637
Epoch 17/500
44/44 - 11s - loss: 0.0774 - accuracy: 0.9785 - val_loss: 1.4592 - val_accuracy: 0.6648
Epoch 18/500
44/44 - 11s - loss: 0.0719 - accuracy: 0.9800 - val_loss: 1.4358 - val_accuracy: 0.6704
Epoch 19/500
44/44 - 11s - loss: 0.0397 - accuracy: 0.9907 - val_loss: 1.4257 - val_accuracy: 0.6536
Epoch 20/500
44/44 - 11s - loss: 0.0520 - accuracy: 0.9878 - val_loss: 1.5781 - val_accuracy: 0.6872
Epoch 21/500
44/44 - 11s - loss: 0.0489 - accuracy: 0.9893 - val_loss: 1.6538 - val_accuracy: 0.6425
Epoch 22/500
44/44 - 11s - loss: 0.0378 - accuracy: 0.9893 - val_loss: 1.4493 - val_accuracy: 0.6480
Epoch 23/500
44/44 - 11s - loss: 0.0343 - accuracy: 0.9886 - val_loss: 1.7630 - val_accuracy: 0.5866
Epoch 24/500
44/44 - 11s - loss: 0.0501 - accuracy: 0.9871 - val_loss: 1.5362 - val_accuracy: 0.6089
Epoch 25/500
44/44 - 11s - loss: 0.0359 - accuracy: 0.9893 - val_loss: 1.4896 - val_accuracy: 0.6369
Epoch 26/500
44/44 - 11s - loss: 0.0328 - accuracy: 0.9921 - val_loss: 1.4890 - val_accuracy: 0.5866
Epoch 27/500
44/44 - 11s - loss: 0.0439 - accuracy: 0.9857 - val_loss: 1.7225 - val_accuracy: 0.6648
Epoch 28/500
44/44 - 11s - loss: 0.0365 - accuracy: 0.9893 - val_loss: 1.5586 - val_accuracy: 0.6257
Epoch 29/500
44/44 - 11s - loss: 0.0293 - accuracy: 0.9914 - val_loss: 1.6006 - val_accuracy: 0.5754
Epoch 30/500
44/44 - 11s - loss: 0.0258 - accuracy: 0.9907 - val_loss: 1.4902 - val_accuracy: 0.6145
Epoch 31/500
44/44 - 11s - loss: 0.0287 - accuracy: 0.9907 - val_loss: 1.5644 - val_accuracy: 0.5978
Epoch 32/500
44/44 - 11s - loss: 0.0241 - accuracy: 0.9900 - val_loss: 1.6956 - val_accuracy: 0.5363
Epoch 33/500
44/44 - 11s - loss: 0.0211 - accuracy: 0.9936 - val_loss: 1.7468 - val_accuracy: 0.6145
Epoch 34/500
44/44 - 11s - loss: 0.0240 - accuracy: 0.9907 - val_loss: 1.4848 - val_accuracy: 0.5978
Epoch 35/500
44/44 - 11s - loss: 0.0208 - accuracy: 0.9914 - val_loss: 1.6779 - val_accuracy: 0.6872
Epoch 36/500
44/44 - 11s - loss: 0.0184 - accuracy: 0.9928 - val_loss: 1.5786 - val_accuracy: 0.6313
Epoch 37/500
44/44 - 11s - loss: 0.0181 - accuracy: 0.9921 - val_loss: 1.5236 - val_accuracy: 0.6480
Epoch 38/500
44/44 - 11s - loss: 0.0161 - accuracy: 0.9943 - val_loss: 1.6291 - val_accuracy: 0.6536
Epoch 39/500
44/44 - 11s - loss: 0.0240 - accuracy: 0.9907 - val_loss: 2.0833 - val_accuracy: 0.5363
Epoch 40/500
44/44 - 11s - loss: 0.0406 - accuracy: 0.9835 - val_loss: 1.4601 - val_accuracy: 0.6592
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 12:25:18.778738: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 12:25:18.778914: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:25:18.778956: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:25:19.014232: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 12:25:19.014344: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00040: early stopping
Length split part:  1397
Labels in this part of split:  [285, 265, 265, 304, 278]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 15s - loss: 1.5567 - accuracy: 0.3114 - val_loss: 1.0832 - val_accuracy: 0.6704
Epoch 2/500
44/44 - 17s - loss: 1.4490 - accuracy: 0.3858 - val_loss: 1.0539 - val_accuracy: 0.6201
Epoch 3/500
44/44 - 15s - loss: 1.2714 - accuracy: 0.4868 - val_loss: 0.9925 - val_accuracy: 0.6592
Epoch 4/500
44/44 - 11s - loss: 1.1748 - accuracy: 0.5140 - val_loss: 1.0028 - val_accuracy: 0.6704
Epoch 5/500
44/44 - 11s - loss: 1.0774 - accuracy: 0.5719 - val_loss: 1.0126 - val_accuracy: 0.6536
Epoch 6/500
44/44 - 19s - loss: 0.9628 - accuracy: 0.6249 - val_loss: 0.9897 - val_accuracy: 0.6592
Epoch 7/500
44/44 - 18s - loss: 0.8557 - accuracy: 0.6693 - val_loss: 0.9772 - val_accuracy: 0.5978
Epoch 8/500
44/44 - 11s - loss: 0.7057 - accuracy: 0.7323 - val_loss: 1.0690 - val_accuracy: 0.6313
Epoch 9/500
44/44 - 11s - loss: 0.5268 - accuracy: 0.7960 - val_loss: 1.0185 - val_accuracy: 0.6089
Epoch 10/500
44/44 - 11s - loss: 0.4169 - accuracy: 0.8447 - val_loss: 1.0993 - val_accuracy: 0.6257
Epoch 11/500
44/44 - 11s - loss: 0.3008 - accuracy: 0.8955 - val_loss: 1.2428 - val_accuracy: 0.5754
Epoch 12/500
44/44 - 11s - loss: 0.1976 - accuracy: 0.9384 - val_loss: 1.3659 - val_accuracy: 0.6313
Epoch 13/500
44/44 - 11s - loss: 0.1879 - accuracy: 0.9370 - val_loss: 1.4890 - val_accuracy: 0.4693
Epoch 14/500
44/44 - 11s - loss: 0.1482 - accuracy: 0.9563 - val_loss: 1.5605 - val_accuracy: 0.6201
Epoch 15/500
44/44 - 11s - loss: 0.0446 - accuracy: 0.9928 - val_loss: 1.7231 - val_accuracy: 0.6704
Epoch 16/500
44/44 - 11s - loss: 0.0472 - accuracy: 0.9864 - val_loss: 1.9554 - val_accuracy: 0.6089
Epoch 17/500
44/44 - 11s - loss: 0.0554 - accuracy: 0.9814 - val_loss: 1.8404 - val_accuracy: 0.6592
Epoch 18/500
44/44 - 11s - loss: 0.0297 - accuracy: 0.9936 - val_loss: 1.9806 - val_accuracy: 0.6201
Epoch 19/500
44/44 - 11s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.1391 - val_accuracy: 0.6369
Epoch 20/500
44/44 - 11s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1551 - val_accuracy: 0.6369
Epoch 21/500
44/44 - 11s - loss: 9.3627e-04 - accuracy: 1.0000 - val_loss: 2.1995 - val_accuracy: 0.6369
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 12:30:05.183961: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 12:30:05.436224: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:30:05.438096: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:30:05.622874: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 12:30:05.622973: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00021: early stopping
ResNet50
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           
__________________________________________________________________________________________________
flatten (Flatten)               (None, 131072)       0           conv5_block3_out[0][0]           
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         536875008   flatten[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
predictions (Dense)             (None, 5)            20485       fc2[0][0]                        
==================================================================================================
Total params: 577,264,517
Trainable params: 577,211,397
Non-trainable params: 53,120
__________________________________________________________________________________________________
Start fitting ensemble models
Random seed for replication: 189
Length split part:  1398
Labels in this part of split:  [282, 296, 287, 274, 259]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 40s - loss: 1.6455 - accuracy: 0.4807 - val_loss: 1.0662 - val_accuracy: 0.6648
Epoch 2/500
44/44 - 8s - loss: 0.1007 - accuracy: 0.9728 - val_loss: 1.7007 - val_accuracy: 0.1229
Epoch 3/500
44/44 - 8s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.1757 - val_accuracy: 0.6480
Epoch 4/500
44/44 - 8s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.4926 - val_accuracy: 0.1285
Epoch 5/500
44/44 - 8s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9549 - val_accuracy: 0.1229
Epoch 6/500
44/44 - 8s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.2638 - val_accuracy: 0.1006
Epoch 7/500
44/44 - 8s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.3878 - val_accuracy: 0.0726
Epoch 8/500
44/44 - 8s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.3657 - val_accuracy: 0.0670
Epoch 9/500
44/44 - 8s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.1957 - val_accuracy: 0.1564
Epoch 10/500
44/44 - 8s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.1051 - val_accuracy: 0.1676
Epoch 11/500
44/44 - 8s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.2603 - val_accuracy: 0.1955
Epoch 12/500
44/44 - 8s - loss: 8.9975e-04 - accuracy: 1.0000 - val_loss: 2.8168 - val_accuracy: 0.1173
Epoch 13/500
44/44 - 8s - loss: 8.0874e-04 - accuracy: 1.0000 - val_loss: 3.5827 - val_accuracy: 0.0503
Epoch 14/500
44/44 - 8s - loss: 7.3014e-04 - accuracy: 1.0000 - val_loss: 4.1810 - val_accuracy: 0.0447
Epoch 15/500
44/44 - 8s - loss: 6.6165e-04 - accuracy: 1.0000 - val_loss: 4.4710 - val_accuracy: 0.0391
Epoch 16/500
44/44 - 8s - loss: 6.0265e-04 - accuracy: 1.0000 - val_loss: 4.4107 - val_accuracy: 0.0391
Epoch 17/500
44/44 - 8s - loss: 5.5222e-04 - accuracy: 1.0000 - val_loss: 4.2076 - val_accuracy: 0.0391
Epoch 18/500
44/44 - 8s - loss: 5.0795e-04 - accuracy: 1.0000 - val_loss: 4.1821 - val_accuracy: 0.0447
Epoch 19/500
44/44 - 8s - loss: 4.7001e-04 - accuracy: 1.0000 - val_loss: 4.0301 - val_accuracy: 0.0503
Epoch 20/500
44/44 - 8s - loss: 4.3471e-04 - accuracy: 1.0000 - val_loss: 3.8671 - val_accuracy: 0.0559
Epoch 21/500
44/44 - 8s - loss: 4.0392e-04 - accuracy: 1.0000 - val_loss: 3.6500 - val_accuracy: 0.0670
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 12:33:55.732968: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 12:33:55.735750: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:33:55.738248: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:33:55.924571: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 12:33:55.935257: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00021: early stopping
Length split part:  1398
Labels in this part of split:  [282, 266, 270, 278, 302]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 24s - loss: 1.8516 - accuracy: 0.4964 - val_loss: 1.8597 - val_accuracy: 0.1564
Epoch 2/500
44/44 - 29s - loss: 0.2402 - accuracy: 0.9177 - val_loss: 1.5956 - val_accuracy: 0.1229
Epoch 3/500
44/44 - 8s - loss: 0.0453 - accuracy: 0.9907 - val_loss: 1.8425 - val_accuracy: 0.1229
Epoch 4/500
44/44 - 8s - loss: 0.0255 - accuracy: 0.9943 - val_loss: 1.7777 - val_accuracy: 0.1229
Epoch 5/500
44/44 - 8s - loss: 0.0073 - accuracy: 0.9979 - val_loss: 2.3321 - val_accuracy: 0.1229
Epoch 6/500
44/44 - 8s - loss: 0.0044 - accuracy: 0.9993 - val_loss: 2.1918 - val_accuracy: 0.1173
Epoch 7/500
44/44 - 8s - loss: 0.0027 - accuracy: 0.9993 - val_loss: 2.4324 - val_accuracy: 0.1173
Epoch 8/500
44/44 - 8s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.4352 - val_accuracy: 0.1006
Epoch 9/500
44/44 - 8s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.7669 - val_accuracy: 0.0894
Epoch 10/500
44/44 - 8s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.3539 - val_accuracy: 0.0615
Epoch 11/500
44/44 - 8s - loss: 9.1181e-04 - accuracy: 1.0000 - val_loss: 4.1908 - val_accuracy: 0.0391
Epoch 12/500
44/44 - 8s - loss: 8.2179e-04 - accuracy: 1.0000 - val_loss: 4.8629 - val_accuracy: 0.0391
Epoch 13/500
44/44 - 8s - loss: 7.4545e-04 - accuracy: 1.0000 - val_loss: 5.2953 - val_accuracy: 0.0391
Epoch 14/500
44/44 - 8s - loss: 6.7996e-04 - accuracy: 1.0000 - val_loss: 5.2971 - val_accuracy: 0.0391
Epoch 15/500
44/44 - 8s - loss: 6.2515e-04 - accuracy: 1.0000 - val_loss: 5.0926 - val_accuracy: 0.0391
Epoch 16/500
44/44 - 8s - loss: 5.7643e-04 - accuracy: 1.0000 - val_loss: 4.8346 - val_accuracy: 0.0391
Epoch 17/500
44/44 - 8s - loss: 5.3441e-04 - accuracy: 1.0000 - val_loss: 4.5246 - val_accuracy: 0.0391
Epoch 18/500
44/44 - 8s - loss: 4.9696e-04 - accuracy: 1.0000 - val_loss: 4.3244 - val_accuracy: 0.0391
Epoch 19/500
44/44 - 8s - loss: 4.6284e-04 - accuracy: 1.0000 - val_loss: 4.1335 - val_accuracy: 0.0559
Epoch 20/500
44/44 - 8s - loss: 4.3342e-04 - accuracy: 1.0000 - val_loss: 3.9729 - val_accuracy: 0.0726
Epoch 21/500
44/44 - 8s - loss: 4.0624e-04 - accuracy: 1.0000 - val_loss: 3.6785 - val_accuracy: 0.0894
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 12:37:57.601346: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 12:37:57.603551: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:37:57.605284: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:37:57.792086: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 12:37:57.794210: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00021: early stopping
Length split part:  1397
Labels in this part of split:  [276, 278, 282, 286, 275]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 26s - loss: 1.9856 - accuracy: 0.4982 - val_loss: 1.5244 - val_accuracy: 0.1564
Epoch 2/500
44/44 - 28s - loss: 0.1704 - accuracy: 0.9456 - val_loss: 1.3706 - val_accuracy: 0.6648
Epoch 3/500
44/44 - 8s - loss: 0.0203 - accuracy: 0.9957 - val_loss: 1.6578 - val_accuracy: 0.1117
Epoch 4/500
44/44 - 8s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.3448 - val_accuracy: 0.1173
Epoch 5/500
44/44 - 8s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.8334 - val_accuracy: 0.1173
Epoch 6/500
44/44 - 8s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.3697 - val_accuracy: 0.1229
Epoch 7/500
44/44 - 8s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.7790 - val_accuracy: 0.1117
Epoch 8/500
44/44 - 8s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.0501 - val_accuracy: 0.1173
Epoch 9/500
44/44 - 8s - loss: 8.8858e-04 - accuracy: 1.0000 - val_loss: 4.1848 - val_accuracy: 0.1061
Epoch 10/500
44/44 - 8s - loss: 7.8744e-04 - accuracy: 1.0000 - val_loss: 4.2035 - val_accuracy: 0.1006
Epoch 11/500
44/44 - 8s - loss: 7.0606e-04 - accuracy: 1.0000 - val_loss: 4.2917 - val_accuracy: 0.0838
Epoch 12/500
44/44 - 8s - loss: 6.3857e-04 - accuracy: 1.0000 - val_loss: 4.5771 - val_accuracy: 0.0503
Epoch 13/500
44/44 - 8s - loss: 5.8135e-04 - accuracy: 1.0000 - val_loss: 4.8661 - val_accuracy: 0.0391
Epoch 14/500
44/44 - 8s - loss: 5.3247e-04 - accuracy: 1.0000 - val_loss: 5.0344 - val_accuracy: 0.0503
Epoch 15/500
44/44 - 8s - loss: 4.9042e-04 - accuracy: 1.0000 - val_loss: 5.0414 - val_accuracy: 0.0670
Epoch 16/500
44/44 - 8s - loss: 4.5410e-04 - accuracy: 1.0000 - val_loss: 4.9881 - val_accuracy: 0.0782
Epoch 17/500
44/44 - 8s - loss: 4.2145e-04 - accuracy: 1.0000 - val_loss: 4.9349 - val_accuracy: 0.0782
Epoch 18/500
44/44 - 8s - loss: 3.9344e-04 - accuracy: 1.0000 - val_loss: 4.8745 - val_accuracy: 0.0726
Epoch 19/500
44/44 - 8s - loss: 3.6715e-04 - accuracy: 1.0000 - val_loss: 4.8343 - val_accuracy: 0.0670
Epoch 20/500
44/44 - 8s - loss: 3.4401e-04 - accuracy: 1.0000 - val_loss: 4.6899 - val_accuracy: 0.0726
Epoch 21/500
44/44 - 8s - loss: 3.2389e-04 - accuracy: 1.0000 - val_loss: 4.4615 - val_accuracy: 0.0615
Epoch 22/500
44/44 - 8s - loss: 3.0477e-04 - accuracy: 1.0000 - val_loss: 4.0942 - val_accuracy: 0.0670
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 12:42:44.415343: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 12:42:44.443458: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:42:44.444842: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:42:44.728113: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 12:42:44.732023: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00022: early stopping
ResNet101
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv4_block7_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv4_block7_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block7_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_1_relu (Activation (None, 16, 16, 256)  0           conv4_block7_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block7_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block7_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block7_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block7_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_2_relu (Activation (None, 16, 16, 256)  0           conv4_block7_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block7_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block7_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block7_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block7_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_add (Add)          (None, 16, 16, 1024) 0           conv4_block6_out[0][0]           
                                                                 conv4_block7_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block7_out (Activation)   (None, 16, 16, 1024) 0           conv4_block7_add[0][0]           
__________________________________________________________________________________________________
conv4_block8_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block7_out[0][0]           
__________________________________________________________________________________________________
conv4_block8_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block8_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_1_relu (Activation (None, 16, 16, 256)  0           conv4_block8_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block8_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block8_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block8_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block8_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_2_relu (Activation (None, 16, 16, 256)  0           conv4_block8_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block8_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block8_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block8_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block8_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_add (Add)          (None, 16, 16, 1024) 0           conv4_block7_out[0][0]           
                                                                 conv4_block8_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block8_out (Activation)   (None, 16, 16, 1024) 0           conv4_block8_add[0][0]           
__________________________________________________________________________________________________
conv4_block9_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block8_out[0][0]           
__________________________________________________________________________________________________
conv4_block9_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block9_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_1_relu (Activation (None, 16, 16, 256)  0           conv4_block9_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block9_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block9_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block9_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block9_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_2_relu (Activation (None, 16, 16, 256)  0           conv4_block9_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block9_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block9_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block9_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block9_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_add (Add)          (None, 16, 16, 1024) 0           conv4_block8_out[0][0]           
                                                                 conv4_block9_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block9_out (Activation)   (None, 16, 16, 1024) 0           conv4_block9_add[0][0]           
__________________________________________________________________________________________________
conv4_block10_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block9_out[0][0]           
__________________________________________________________________________________________________
conv4_block10_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block10_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block10_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block10_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block10_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block10_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block10_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block10_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block10_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block10_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block10_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block10_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block10_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block10_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block10_add (Add)         (None, 16, 16, 1024) 0           conv4_block9_out[0][0]           
                                                                 conv4_block10_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block10_out (Activation)  (None, 16, 16, 1024) 0           conv4_block10_add[0][0]          
__________________________________________________________________________________________________
conv4_block11_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block10_out[0][0]          
__________________________________________________________________________________________________
conv4_block11_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block11_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block11_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block11_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block11_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block11_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block11_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block11_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block11_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block11_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block11_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block11_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_add (Add)         (None, 16, 16, 1024) 0           conv4_block10_out[0][0]          
                                                                 conv4_block11_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block11_out (Activation)  (None, 16, 16, 1024) 0           conv4_block11_add[0][0]          
__________________________________________________________________________________________________
conv4_block12_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block11_out[0][0]          
__________________________________________________________________________________________________
conv4_block12_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block12_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block12_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block12_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block12_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block12_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block12_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block12_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block12_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block12_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block12_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block12_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_add (Add)         (None, 16, 16, 1024) 0           conv4_block11_out[0][0]          
                                                                 conv4_block12_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block12_out (Activation)  (None, 16, 16, 1024) 0           conv4_block12_add[0][0]          
__________________________________________________________________________________________________
conv4_block13_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block12_out[0][0]          
__________________________________________________________________________________________________
conv4_block13_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block13_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block13_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block13_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block13_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block13_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block13_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block13_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block13_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block13_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block13_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block13_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_add (Add)         (None, 16, 16, 1024) 0           conv4_block12_out[0][0]          
                                                                 conv4_block13_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block13_out (Activation)  (None, 16, 16, 1024) 0           conv4_block13_add[0][0]          
__________________________________________________________________________________________________
conv4_block14_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block13_out[0][0]          
__________________________________________________________________________________________________
conv4_block14_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block14_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block14_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block14_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block14_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block14_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block14_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block14_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block14_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block14_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block14_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block14_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_add (Add)         (None, 16, 16, 1024) 0           conv4_block13_out[0][0]          
                                                                 conv4_block14_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block14_out (Activation)  (None, 16, 16, 1024) 0           conv4_block14_add[0][0]          
__________________________________________________________________________________________________
conv4_block15_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block14_out[0][0]          
__________________________________________________________________________________________________
conv4_block15_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block15_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block15_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block15_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block15_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block15_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block15_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block15_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block15_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block15_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block15_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block15_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_add (Add)         (None, 16, 16, 1024) 0           conv4_block14_out[0][0]          
                                                                 conv4_block15_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block15_out (Activation)  (None, 16, 16, 1024) 0           conv4_block15_add[0][0]          
__________________________________________________________________________________________________
conv4_block16_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block15_out[0][0]          
__________________________________________________________________________________________________
conv4_block16_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block16_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block16_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block16_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block16_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block16_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block16_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block16_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block16_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block16_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block16_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block16_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_add (Add)         (None, 16, 16, 1024) 0           conv4_block15_out[0][0]          
                                                                 conv4_block16_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block16_out (Activation)  (None, 16, 16, 1024) 0           conv4_block16_add[0][0]          
__________________________________________________________________________________________________
conv4_block17_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block16_out[0][0]          
__________________________________________________________________________________________________
conv4_block17_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block17_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block17_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block17_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block17_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block17_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block17_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block17_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block17_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block17_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block17_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block17_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_add (Add)         (None, 16, 16, 1024) 0           conv4_block16_out[0][0]          
                                                                 conv4_block17_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block17_out (Activation)  (None, 16, 16, 1024) 0           conv4_block17_add[0][0]          
__________________________________________________________________________________________________
conv4_block18_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block17_out[0][0]          
__________________________________________________________________________________________________
conv4_block18_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block18_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block18_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block18_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block18_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block18_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block18_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block18_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block18_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block18_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block18_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block18_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_add (Add)         (None, 16, 16, 1024) 0           conv4_block17_out[0][0]          
                                                                 conv4_block18_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block18_out (Activation)  (None, 16, 16, 1024) 0           conv4_block18_add[0][0]          
__________________________________________________________________________________________________
conv4_block19_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block18_out[0][0]          
__________________________________________________________________________________________________
conv4_block19_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block19_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block19_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block19_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block19_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block19_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block19_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block19_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block19_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block19_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block19_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block19_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_add (Add)         (None, 16, 16, 1024) 0           conv4_block18_out[0][0]          
                                                                 conv4_block19_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block19_out (Activation)  (None, 16, 16, 1024) 0           conv4_block19_add[0][0]          
__________________________________________________________________________________________________
conv4_block20_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block19_out[0][0]          
__________________________________________________________________________________________________
conv4_block20_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block20_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block20_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block20_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block20_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block20_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block20_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block20_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block20_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block20_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block20_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block20_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_add (Add)         (None, 16, 16, 1024) 0           conv4_block19_out[0][0]          
                                                                 conv4_block20_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block20_out (Activation)  (None, 16, 16, 1024) 0           conv4_block20_add[0][0]          
__________________________________________________________________________________________________
conv4_block21_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block20_out[0][0]          
__________________________________________________________________________________________________
conv4_block21_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block21_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block21_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block21_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block21_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block21_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block21_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block21_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block21_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block21_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block21_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block21_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_add (Add)         (None, 16, 16, 1024) 0           conv4_block20_out[0][0]          
                                                                 conv4_block21_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block21_out (Activation)  (None, 16, 16, 1024) 0           conv4_block21_add[0][0]          
__________________________________________________________________________________________________
conv4_block22_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block21_out[0][0]          
__________________________________________________________________________________________________
conv4_block22_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block22_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block22_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block22_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block22_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block22_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block22_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block22_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block22_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block22_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block22_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block22_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_add (Add)         (None, 16, 16, 1024) 0           conv4_block21_out[0][0]          
                                                                 conv4_block22_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block22_out (Activation)  (None, 16, 16, 1024) 0           conv4_block22_add[0][0]          
__________________________________________________________________________________________________
conv4_block23_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block22_out[0][0]          
__________________________________________________________________________________________________
conv4_block23_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block23_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block23_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block23_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block23_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block23_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block23_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block23_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block23_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block23_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block23_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block23_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_add (Add)         (None, 16, 16, 1024) 0           conv4_block22_out[0][0]          
                                                                 conv4_block23_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block23_out (Activation)  (None, 16, 16, 1024) 0           conv4_block23_add[0][0]          
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block23_out[0][0]          
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block23_out[0][0]          
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           
__________________________________________________________________________________________________
flatten (Flatten)               (None, 131072)       0           conv5_block3_out[0][0]           
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         536875008   flatten[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
predictions (Dense)             (None, 5)            20485       fc2[0][0]                        
==================================================================================================
Total params: 596,334,981
Trainable params: 596,229,637
Non-trainable params: 105,344
__________________________________________________________________________________________________
Start fitting ensemble models
Random seed for replication: 332
Length split part:  1398
Labels in this part of split:  [276, 265, 273, 292, 292]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 64s - loss: 1.5132 - accuracy: 0.5014 - val_loss: 1.1519 - val_accuracy: 0.6648
Epoch 2/500
44/44 - 13s - loss: 0.0916 - accuracy: 0.9735 - val_loss: 1.3744 - val_accuracy: 0.5028
Epoch 3/500
44/44 - 13s - loss: 0.0149 - accuracy: 0.9971 - val_loss: 1.8672 - val_accuracy: 0.1341
Epoch 4/500
44/44 - 13s - loss: 0.0108 - accuracy: 0.9993 - val_loss: 1.9689 - val_accuracy: 0.1229
Epoch 5/500
44/44 - 13s - loss: 0.0086 - accuracy: 0.9993 - val_loss: 1.9522 - val_accuracy: 0.0503
Epoch 6/500
44/44 - 13s - loss: 0.0050 - accuracy: 0.9993 - val_loss: 2.1984 - val_accuracy: 0.0615
Epoch 7/500
44/44 - 13s - loss: 0.0034 - accuracy: 0.9993 - val_loss: 2.9340 - val_accuracy: 0.0391
Epoch 8/500
44/44 - 13s - loss: 0.0024 - accuracy: 0.9993 - val_loss: 3.7633 - val_accuracy: 0.0391
Epoch 9/500
44/44 - 13s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.3696 - val_accuracy: 0.0391
Epoch 10/500
44/44 - 13s - loss: 8.4761e-04 - accuracy: 1.0000 - val_loss: 4.6808 - val_accuracy: 0.0391
Epoch 11/500
44/44 - 13s - loss: 7.4049e-04 - accuracy: 1.0000 - val_loss: 4.7605 - val_accuracy: 0.0391
Epoch 12/500
44/44 - 13s - loss: 6.6011e-04 - accuracy: 1.0000 - val_loss: 4.7161 - val_accuracy: 0.0391
Epoch 13/500
44/44 - 13s - loss: 5.9289e-04 - accuracy: 1.0000 - val_loss: 4.6457 - val_accuracy: 0.0391
Epoch 14/500
44/44 - 13s - loss: 5.3707e-04 - accuracy: 1.0000 - val_loss: 4.4994 - val_accuracy: 0.0391
Epoch 15/500
44/44 - 13s - loss: 4.8828e-04 - accuracy: 1.0000 - val_loss: 4.3840 - val_accuracy: 0.0391
Epoch 16/500
44/44 - 13s - loss: 4.4638e-04 - accuracy: 1.0000 - val_loss: 4.2494 - val_accuracy: 0.0391
Epoch 17/500
44/44 - 13s - loss: 4.1121e-04 - accuracy: 1.0000 - val_loss: 4.1265 - val_accuracy: 0.0391
Epoch 18/500
44/44 - 13s - loss: 3.7940e-04 - accuracy: 1.0000 - val_loss: 4.0902 - val_accuracy: 0.0391
Epoch 19/500
44/44 - 13s - loss: 3.5113e-04 - accuracy: 1.0000 - val_loss: 3.8741 - val_accuracy: 0.0447
Epoch 20/500
44/44 - 13s - loss: 3.2649e-04 - accuracy: 1.0000 - val_loss: 3.5747 - val_accuracy: 0.0503
Epoch 21/500
44/44 - 13s - loss: 3.0421e-04 - accuracy: 1.0000 - val_loss: 3.2234 - val_accuracy: 0.0447
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 12:48:53.858066: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 12:48:53.858221: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:48:53.858254: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:48:54.139853: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 12:48:54.139952: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00021: early stopping
Length split part:  1398
Labels in this part of split:  [303, 292, 266, 277, 260]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 27s - loss: 1.9952 - accuracy: 0.5029 - val_loss: 1.6372 - val_accuracy: 0.1564
Epoch 2/500
44/44 - 13s - loss: 0.3152 - accuracy: 0.8848 - val_loss: 2.7731 - val_accuracy: 0.1229
Epoch 3/500
44/44 - 13s - loss: 0.0299 - accuracy: 0.9943 - val_loss: 3.0240 - val_accuracy: 0.1229
Epoch 4/500
44/44 - 13s - loss: 0.0184 - accuracy: 0.9979 - val_loss: 3.0013 - val_accuracy: 0.1229
Epoch 5/500
44/44 - 13s - loss: 0.0081 - accuracy: 0.9979 - val_loss: 3.5731 - val_accuracy: 0.1061
Epoch 6/500
44/44 - 13s - loss: 0.0025 - accuracy: 0.9993 - val_loss: 4.0057 - val_accuracy: 0.0670
Epoch 7/500
44/44 - 13s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.3398 - val_accuracy: 0.0726
Epoch 8/500
44/44 - 13s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.5254 - val_accuracy: 0.0950
Epoch 9/500
44/44 - 13s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.5578 - val_accuracy: 0.1229
Epoch 10/500
44/44 - 13s - loss: 9.3620e-04 - accuracy: 1.0000 - val_loss: 4.4968 - val_accuracy: 0.1173
Epoch 11/500
44/44 - 13s - loss: 8.2492e-04 - accuracy: 1.0000 - val_loss: 4.4790 - val_accuracy: 0.1061
Epoch 12/500
44/44 - 13s - loss: 7.3776e-04 - accuracy: 1.0000 - val_loss: 4.4161 - val_accuracy: 0.1006
Epoch 13/500
44/44 - 13s - loss: 6.6764e-04 - accuracy: 1.0000 - val_loss: 4.3062 - val_accuracy: 0.1173
Epoch 14/500
44/44 - 13s - loss: 6.0714e-04 - accuracy: 1.0000 - val_loss: 4.1338 - val_accuracy: 0.1173
Epoch 15/500
44/44 - 13s - loss: 5.5326e-04 - accuracy: 1.0000 - val_loss: 3.9062 - val_accuracy: 0.1285
Epoch 16/500
44/44 - 13s - loss: 5.0962e-04 - accuracy: 1.0000 - val_loss: 3.7006 - val_accuracy: 0.1061
Epoch 17/500
44/44 - 13s - loss: 4.6967e-04 - accuracy: 1.0000 - val_loss: 3.5560 - val_accuracy: 0.1285
Epoch 18/500
44/44 - 13s - loss: 4.3558e-04 - accuracy: 1.0000 - val_loss: 3.4739 - val_accuracy: 0.1341
Epoch 19/500
44/44 - 13s - loss: 4.0499e-04 - accuracy: 1.0000 - val_loss: 3.4072 - val_accuracy: 0.1564
Epoch 20/500
44/44 - 13s - loss: 3.7801e-04 - accuracy: 1.0000 - val_loss: 3.2928 - val_accuracy: 0.1508
Epoch 21/500
44/44 - 13s - loss: 3.5350e-04 - accuracy: 1.0000 - val_loss: 3.2096 - val_accuracy: 0.1397
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 12:54:15.336141: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 12:54:15.336292: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:54:15.336338: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 12:54:15.618485: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 12:54:15.618587: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00021: early stopping
Length split part:  1397
Labels in this part of split:  [261, 283, 300, 269, 284]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 28s - loss: 1.8393 - accuracy: 0.5061 - val_loss: 1.5055 - val_accuracy: 0.2682
Epoch 2/500
44/44 - 13s - loss: 0.2424 - accuracy: 0.9198 - val_loss: 1.7792 - val_accuracy: 0.1397
Epoch 3/500
44/44 - 13s - loss: 0.0173 - accuracy: 0.9979 - val_loss: 1.9390 - val_accuracy: 0.1564
Epoch 4/500
44/44 - 13s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.0197 - val_accuracy: 0.1564
Epoch 5/500
44/44 - 13s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1528 - val_accuracy: 0.1564
Epoch 6/500
44/44 - 13s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.2718 - val_accuracy: 0.1564
Epoch 7/500
44/44 - 13s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.3558 - val_accuracy: 0.1397
Epoch 8/500
44/44 - 13s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.4051 - val_accuracy: 0.1117
Epoch 9/500
44/44 - 13s - loss: 8.9058e-04 - accuracy: 1.0000 - val_loss: 2.4846 - val_accuracy: 0.0950
Epoch 10/500
44/44 - 13s - loss: 7.8808e-04 - accuracy: 1.0000 - val_loss: 2.6058 - val_accuracy: 0.0838
Epoch 11/500
44/44 - 13s - loss: 7.0398e-04 - accuracy: 1.0000 - val_loss: 2.7872 - val_accuracy: 0.0559
Epoch 12/500
44/44 - 13s - loss: 6.3287e-04 - accuracy: 1.0000 - val_loss: 3.0104 - val_accuracy: 0.0447
Epoch 13/500
44/44 - 13s - loss: 5.7495e-04 - accuracy: 1.0000 - val_loss: 3.2771 - val_accuracy: 0.0447
Epoch 14/500
44/44 - 13s - loss: 5.2678e-04 - accuracy: 1.0000 - val_loss: 3.5774 - val_accuracy: 0.0503
Epoch 15/500
44/44 - 13s - loss: 4.8258e-04 - accuracy: 1.0000 - val_loss: 3.8602 - val_accuracy: 0.0559
Epoch 16/500
44/44 - 13s - loss: 4.4536e-04 - accuracy: 1.0000 - val_loss: 4.1247 - val_accuracy: 0.0559
Epoch 17/500
44/44 - 13s - loss: 4.1273e-04 - accuracy: 1.0000 - val_loss: 4.3379 - val_accuracy: 0.0559
Epoch 18/500
44/44 - 13s - loss: 3.8450e-04 - accuracy: 1.0000 - val_loss: 4.4977 - val_accuracy: 0.0447
Epoch 19/500
44/44 - 13s - loss: 3.5855e-04 - accuracy: 1.0000 - val_loss: 4.5879 - val_accuracy: 0.0559
Epoch 20/500
44/44 - 13s - loss: 3.3588e-04 - accuracy: 1.0000 - val_loss: 4.5872 - val_accuracy: 0.1006
Epoch 21/500
44/44 - 13s - loss: 3.1526e-04 - accuracy: 1.0000 - val_loss: 4.5188 - val_accuracy: 0.1285
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 13:00:34.492979: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 13:00:34.493141: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 13:00:34.493175: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 13:00:34.878902: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 13:00:34.878994: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00021: early stopping
ResNet152
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv3_block5_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv3_block5_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block5_1_relu (Activation (None, 32, 32, 128)  0           conv3_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block5_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block5_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block5_2_relu (Activation (None, 32, 32, 128)  0           conv3_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block5_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block5_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block5_add (Add)          (None, 32, 32, 512)  0           conv3_block4_out[0][0]           
                                                                 conv3_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block5_out (Activation)   (None, 32, 32, 512)  0           conv3_block5_add[0][0]           
__________________________________________________________________________________________________
conv3_block6_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block5_out[0][0]           
__________________________________________________________________________________________________
conv3_block6_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block6_1_relu (Activation (None, 32, 32, 128)  0           conv3_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block6_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block6_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block6_2_relu (Activation (None, 32, 32, 128)  0           conv3_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block6_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block6_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block6_add (Add)          (None, 32, 32, 512)  0           conv3_block5_out[0][0]           
                                                                 conv3_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block6_out (Activation)   (None, 32, 32, 512)  0           conv3_block6_add[0][0]           
__________________________________________________________________________________________________
conv3_block7_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block6_out[0][0]           
__________________________________________________________________________________________________
conv3_block7_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block7_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block7_1_relu (Activation (None, 32, 32, 128)  0           conv3_block7_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block7_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block7_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block7_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block7_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block7_2_relu (Activation (None, 32, 32, 128)  0           conv3_block7_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block7_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block7_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block7_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block7_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block7_add (Add)          (None, 32, 32, 512)  0           conv3_block6_out[0][0]           
                                                                 conv3_block7_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block7_out (Activation)   (None, 32, 32, 512)  0           conv3_block7_add[0][0]           
__________________________________________________________________________________________________
conv3_block8_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block7_out[0][0]           
__________________________________________________________________________________________________
conv3_block8_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block8_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block8_1_relu (Activation (None, 32, 32, 128)  0           conv3_block8_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block8_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block8_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block8_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block8_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block8_2_relu (Activation (None, 32, 32, 128)  0           conv3_block8_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block8_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block8_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block8_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block8_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block8_add (Add)          (None, 32, 32, 512)  0           conv3_block7_out[0][0]           
                                                                 conv3_block8_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block8_out (Activation)   (None, 32, 32, 512)  0           conv3_block8_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block8_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block8_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv4_block7_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv4_block7_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block7_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_1_relu (Activation (None, 16, 16, 256)  0           conv4_block7_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block7_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block7_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block7_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block7_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_2_relu (Activation (None, 16, 16, 256)  0           conv4_block7_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block7_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block7_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block7_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block7_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_add (Add)          (None, 16, 16, 1024) 0           conv4_block6_out[0][0]           
                                                                 conv4_block7_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block7_out (Activation)   (None, 16, 16, 1024) 0           conv4_block7_add[0][0]           
__________________________________________________________________________________________________
conv4_block8_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block7_out[0][0]           
__________________________________________________________________________________________________
conv4_block8_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block8_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_1_relu (Activation (None, 16, 16, 256)  0           conv4_block8_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block8_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block8_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block8_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block8_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_2_relu (Activation (None, 16, 16, 256)  0           conv4_block8_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block8_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block8_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block8_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block8_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_add (Add)          (None, 16, 16, 1024) 0           conv4_block7_out[0][0]           
                                                                 conv4_block8_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block8_out (Activation)   (None, 16, 16, 1024) 0           conv4_block8_add[0][0]           
__________________________________________________________________________________________________
conv4_block9_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block8_out[0][0]           
__________________________________________________________________________________________________
conv4_block9_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block9_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_1_relu (Activation (None, 16, 16, 256)  0           conv4_block9_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block9_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block9_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block9_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block9_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_2_relu (Activation (None, 16, 16, 256)  0           conv4_block9_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block9_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block9_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block9_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block9_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_add (Add)          (None, 16, 16, 1024) 0           conv4_block8_out[0][0]           
                                                                 conv4_block9_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block9_out (Activation)   (None, 16, 16, 1024) 0           conv4_block9_add[0][0]           
__________________________________________________________________________________________________
conv4_block10_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block9_out[0][0]           
__________________________________________________________________________________________________
conv4_block10_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block10_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block10_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block10_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block10_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block10_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block10_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block10_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block10_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block10_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block10_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block10_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block10_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block10_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block10_add (Add)         (None, 16, 16, 1024) 0           conv4_block9_out[0][0]           
                                                                 conv4_block10_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block10_out (Activation)  (None, 16, 16, 1024) 0           conv4_block10_add[0][0]          
__________________________________________________________________________________________________
conv4_block11_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block10_out[0][0]          
__________________________________________________________________________________________________
conv4_block11_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block11_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block11_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block11_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block11_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block11_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block11_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block11_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block11_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block11_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block11_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block11_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_add (Add)         (None, 16, 16, 1024) 0           conv4_block10_out[0][0]          
                                                                 conv4_block11_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block11_out (Activation)  (None, 16, 16, 1024) 0           conv4_block11_add[0][0]          
__________________________________________________________________________________________________
conv4_block12_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block11_out[0][0]          
__________________________________________________________________________________________________
conv4_block12_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block12_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block12_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block12_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block12_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block12_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block12_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block12_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block12_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block12_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block12_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block12_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_add (Add)         (None, 16, 16, 1024) 0           conv4_block11_out[0][0]          
                                                                 conv4_block12_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block12_out (Activation)  (None, 16, 16, 1024) 0           conv4_block12_add[0][0]          
__________________________________________________________________________________________________
conv4_block13_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block12_out[0][0]          
__________________________________________________________________________________________________
conv4_block13_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block13_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block13_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block13_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block13_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block13_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block13_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block13_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block13_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block13_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block13_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block13_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_add (Add)         (None, 16, 16, 1024) 0           conv4_block12_out[0][0]          
                                                                 conv4_block13_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block13_out (Activation)  (None, 16, 16, 1024) 0           conv4_block13_add[0][0]          
__________________________________________________________________________________________________
conv4_block14_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block13_out[0][0]          
__________________________________________________________________________________________________
conv4_block14_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block14_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block14_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block14_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block14_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block14_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block14_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block14_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block14_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block14_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block14_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block14_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_add (Add)         (None, 16, 16, 1024) 0           conv4_block13_out[0][0]          
                                                                 conv4_block14_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block14_out (Activation)  (None, 16, 16, 1024) 0           conv4_block14_add[0][0]          
__________________________________________________________________________________________________
conv4_block15_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block14_out[0][0]          
__________________________________________________________________________________________________
conv4_block15_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block15_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block15_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block15_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block15_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block15_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block15_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block15_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block15_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block15_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block15_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block15_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_add (Add)         (None, 16, 16, 1024) 0           conv4_block14_out[0][0]          
                                                                 conv4_block15_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block15_out (Activation)  (None, 16, 16, 1024) 0           conv4_block15_add[0][0]          
__________________________________________________________________________________________________
conv4_block16_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block15_out[0][0]          
__________________________________________________________________________________________________
conv4_block16_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block16_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block16_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block16_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block16_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block16_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block16_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block16_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block16_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block16_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block16_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block16_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_add (Add)         (None, 16, 16, 1024) 0           conv4_block15_out[0][0]          
                                                                 conv4_block16_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block16_out (Activation)  (None, 16, 16, 1024) 0           conv4_block16_add[0][0]          
__________________________________________________________________________________________________
conv4_block17_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block16_out[0][0]          
__________________________________________________________________________________________________
conv4_block17_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block17_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block17_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block17_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block17_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block17_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block17_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block17_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block17_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block17_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block17_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block17_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_add (Add)         (None, 16, 16, 1024) 0           conv4_block16_out[0][0]          
                                                                 conv4_block17_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block17_out (Activation)  (None, 16, 16, 1024) 0           conv4_block17_add[0][0]          
__________________________________________________________________________________________________
conv4_block18_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block17_out[0][0]          
__________________________________________________________________________________________________
conv4_block18_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block18_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block18_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block18_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block18_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block18_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block18_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block18_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block18_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block18_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block18_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block18_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_add (Add)         (None, 16, 16, 1024) 0           conv4_block17_out[0][0]          
                                                                 conv4_block18_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block18_out (Activation)  (None, 16, 16, 1024) 0           conv4_block18_add[0][0]          
__________________________________________________________________________________________________
conv4_block19_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block18_out[0][0]          
__________________________________________________________________________________________________
conv4_block19_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block19_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block19_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block19_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block19_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block19_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block19_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block19_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block19_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block19_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block19_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block19_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_add (Add)         (None, 16, 16, 1024) 0           conv4_block18_out[0][0]          
                                                                 conv4_block19_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block19_out (Activation)  (None, 16, 16, 1024) 0           conv4_block19_add[0][0]          
__________________________________________________________________________________________________
conv4_block20_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block19_out[0][0]          
__________________________________________________________________________________________________
conv4_block20_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block20_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block20_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block20_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block20_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block20_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block20_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block20_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block20_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block20_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block20_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block20_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_add (Add)         (None, 16, 16, 1024) 0           conv4_block19_out[0][0]          
                                                                 conv4_block20_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block20_out (Activation)  (None, 16, 16, 1024) 0           conv4_block20_add[0][0]          
__________________________________________________________________________________________________
conv4_block21_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block20_out[0][0]          
__________________________________________________________________________________________________
conv4_block21_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block21_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block21_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block21_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block21_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block21_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block21_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block21_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block21_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block21_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block21_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block21_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_add (Add)         (None, 16, 16, 1024) 0           conv4_block20_out[0][0]          
                                                                 conv4_block21_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block21_out (Activation)  (None, 16, 16, 1024) 0           conv4_block21_add[0][0]          
__________________________________________________________________________________________________
conv4_block22_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block21_out[0][0]          
__________________________________________________________________________________________________
conv4_block22_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block22_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block22_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block22_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block22_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block22_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block22_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block22_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block22_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block22_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block22_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block22_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_add (Add)         (None, 16, 16, 1024) 0           conv4_block21_out[0][0]          
                                                                 conv4_block22_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block22_out (Activation)  (None, 16, 16, 1024) 0           conv4_block22_add[0][0]          
__________________________________________________________________________________________________
conv4_block23_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block22_out[0][0]          
__________________________________________________________________________________________________
conv4_block23_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block23_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block23_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block23_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block23_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block23_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block23_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block23_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block23_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block23_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block23_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block23_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_add (Add)         (None, 16, 16, 1024) 0           conv4_block22_out[0][0]          
                                                                 conv4_block23_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block23_out (Activation)  (None, 16, 16, 1024) 0           conv4_block23_add[0][0]          
__________________________________________________________________________________________________
conv4_block24_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block23_out[0][0]          
__________________________________________________________________________________________________
conv4_block24_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block24_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block24_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block24_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block24_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block24_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block24_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block24_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block24_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block24_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block24_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block24_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block24_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block24_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block24_add (Add)         (None, 16, 16, 1024) 0           conv4_block23_out[0][0]          
                                                                 conv4_block24_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block24_out (Activation)  (None, 16, 16, 1024) 0           conv4_block24_add[0][0]          
__________________________________________________________________________________________________
conv4_block25_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block24_out[0][0]          
__________________________________________________________________________________________________
conv4_block25_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block25_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block25_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block25_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block25_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block25_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block25_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block25_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block25_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block25_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block25_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block25_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block25_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block25_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block25_add (Add)         (None, 16, 16, 1024) 0           conv4_block24_out[0][0]          
                                                                 conv4_block25_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block25_out (Activation)  (None, 16, 16, 1024) 0           conv4_block25_add[0][0]          
__________________________________________________________________________________________________
conv4_block26_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block25_out[0][0]          
__________________________________________________________________________________________________
conv4_block26_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block26_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block26_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block26_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block26_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block26_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block26_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block26_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block26_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block26_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block26_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block26_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block26_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block26_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block26_add (Add)         (None, 16, 16, 1024) 0           conv4_block25_out[0][0]          
                                                                 conv4_block26_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block26_out (Activation)  (None, 16, 16, 1024) 0           conv4_block26_add[0][0]          
__________________________________________________________________________________________________
conv4_block27_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block26_out[0][0]          
__________________________________________________________________________________________________
conv4_block27_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block27_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block27_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block27_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block27_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block27_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block27_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block27_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block27_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block27_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block27_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block27_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block27_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block27_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block27_add (Add)         (None, 16, 16, 1024) 0           conv4_block26_out[0][0]          
                                                                 conv4_block27_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block27_out (Activation)  (None, 16, 16, 1024) 0           conv4_block27_add[0][0]          
__________________________________________________________________________________________________
conv4_block28_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block27_out[0][0]          
__________________________________________________________________________________________________
conv4_block28_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block28_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block28_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block28_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block28_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block28_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block28_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block28_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block28_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block28_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block28_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block28_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block28_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block28_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block28_add (Add)         (None, 16, 16, 1024) 0           conv4_block27_out[0][0]          
                                                                 conv4_block28_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block28_out (Activation)  (None, 16, 16, 1024) 0           conv4_block28_add[0][0]          
__________________________________________________________________________________________________
conv4_block29_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block28_out[0][0]          
__________________________________________________________________________________________________
conv4_block29_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block29_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block29_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block29_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block29_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block29_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block29_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block29_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block29_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block29_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block29_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block29_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block29_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block29_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block29_add (Add)         (None, 16, 16, 1024) 0           conv4_block28_out[0][0]          
                                                                 conv4_block29_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block29_out (Activation)  (None, 16, 16, 1024) 0           conv4_block29_add[0][0]          
__________________________________________________________________________________________________
conv4_block30_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block29_out[0][0]          
__________________________________________________________________________________________________
conv4_block30_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block30_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block30_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block30_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block30_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block30_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block30_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block30_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block30_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block30_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block30_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block30_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block30_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block30_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block30_add (Add)         (None, 16, 16, 1024) 0           conv4_block29_out[0][0]          
                                                                 conv4_block30_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block30_out (Activation)  (None, 16, 16, 1024) 0           conv4_block30_add[0][0]          
__________________________________________________________________________________________________
conv4_block31_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block30_out[0][0]          
__________________________________________________________________________________________________
conv4_block31_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block31_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block31_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block31_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block31_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block31_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block31_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block31_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block31_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block31_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block31_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block31_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block31_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block31_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block31_add (Add)         (None, 16, 16, 1024) 0           conv4_block30_out[0][0]          
                                                                 conv4_block31_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block31_out (Activation)  (None, 16, 16, 1024) 0           conv4_block31_add[0][0]          
__________________________________________________________________________________________________
conv4_block32_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block31_out[0][0]          
__________________________________________________________________________________________________
conv4_block32_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block32_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block32_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block32_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block32_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block32_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block32_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block32_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block32_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block32_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block32_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block32_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block32_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block32_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block32_add (Add)         (None, 16, 16, 1024) 0           conv4_block31_out[0][0]          
                                                                 conv4_block32_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block32_out (Activation)  (None, 16, 16, 1024) 0           conv4_block32_add[0][0]          
__________________________________________________________________________________________________
conv4_block33_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block32_out[0][0]          
__________________________________________________________________________________________________
conv4_block33_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block33_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block33_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block33_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block33_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block33_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block33_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block33_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block33_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block33_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block33_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block33_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block33_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block33_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block33_add (Add)         (None, 16, 16, 1024) 0           conv4_block32_out[0][0]          
                                                                 conv4_block33_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block33_out (Activation)  (None, 16, 16, 1024) 0           conv4_block33_add[0][0]          
__________________________________________________________________________________________________
conv4_block34_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block33_out[0][0]          
__________________________________________________________________________________________________
conv4_block34_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block34_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block34_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block34_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block34_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block34_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block34_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block34_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block34_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block34_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block34_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block34_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block34_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block34_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block34_add (Add)         (None, 16, 16, 1024) 0           conv4_block33_out[0][0]          
                                                                 conv4_block34_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block34_out (Activation)  (None, 16, 16, 1024) 0           conv4_block34_add[0][0]          
__________________________________________________________________________________________________
conv4_block35_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block34_out[0][0]          
__________________________________________________________________________________________________
conv4_block35_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block35_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block35_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block35_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block35_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block35_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block35_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block35_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block35_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block35_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block35_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block35_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block35_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block35_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block35_add (Add)         (None, 16, 16, 1024) 0           conv4_block34_out[0][0]          
                                                                 conv4_block35_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block35_out (Activation)  (None, 16, 16, 1024) 0           conv4_block35_add[0][0]          
__________________________________________________________________________________________________
conv4_block36_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block35_out[0][0]          
__________________________________________________________________________________________________
conv4_block36_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block36_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block36_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block36_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block36_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block36_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block36_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block36_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block36_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block36_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block36_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block36_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block36_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block36_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block36_add (Add)         (None, 16, 16, 1024) 0           conv4_block35_out[0][0]          
                                                                 conv4_block36_3_bn[0][0]         
__________________________________________________________________________________________________
conv4_block36_out (Activation)  (None, 16, 16, 1024) 0           conv4_block36_add[0][0]          
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block36_out[0][0]          
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block36_out[0][0]          
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           
__________________________________________________________________________________________________
flatten (Flatten)               (None, 131072)       0           conv5_block3_out[0][0]           
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         536875008   flatten[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
predictions (Dense)             (None, 5)            20485       fc2[0][0]                        
==================================================================================================
Total params: 612,047,749
Trainable params: 611,896,325
Non-trainable params: 151,424
__________________________________________________________________________________________________
Start fitting ensemble models
Random seed for replication: 387
Length split part:  1398
Labels in this part of split:  [265, 277, 280, 273, 303]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 73s - loss: 1.4576 - accuracy: 0.5000 - val_loss: 2.0505 - val_accuracy: 0.0615
Epoch 2/500
44/44 - 17s - loss: 0.0795 - accuracy: 0.9785 - val_loss: 2.4790 - val_accuracy: 0.0782
Epoch 3/500
44/44 - 17s - loss: 0.0166 - accuracy: 0.9993 - val_loss: 2.9583 - val_accuracy: 0.0726
Epoch 4/500
44/44 - 17s - loss: 0.0112 - accuracy: 0.9993 - val_loss: 2.7954 - val_accuracy: 0.0503
Epoch 5/500
44/44 - 17s - loss: 0.0052 - accuracy: 0.9993 - val_loss: 3.1672 - val_accuracy: 0.0279
Epoch 6/500
44/44 - 18s - loss: 0.0074 - accuracy: 0.9993 - val_loss: 3.7042 - val_accuracy: 0.0168
Epoch 7/500
44/44 - 18s - loss: 0.0037 - accuracy: 0.9993 - val_loss: 4.4020 - val_accuracy: 0.0168
Epoch 8/500
44/44 - 17s - loss: 0.0061 - accuracy: 0.9993 - val_loss: 5.0663 - val_accuracy: 0.0168
Epoch 9/500
44/44 - 18s - loss: 0.0036 - accuracy: 0.9993 - val_loss: 4.9788 - val_accuracy: 0.0168
Epoch 10/500
44/44 - 17s - loss: 0.0049 - accuracy: 0.9993 - val_loss: 4.9766 - val_accuracy: 0.0168
Epoch 11/500
44/44 - 18s - loss: 0.0035 - accuracy: 0.9993 - val_loss: 4.4906 - val_accuracy: 0.0168
Epoch 12/500
44/44 - 18s - loss: 0.0037 - accuracy: 0.9993 - val_loss: 4.5015 - val_accuracy: 0.0168
Epoch 13/500
44/44 - 18s - loss: 0.0029 - accuracy: 0.9993 - val_loss: 4.1077 - val_accuracy: 0.0168
Epoch 14/500
44/44 - 18s - loss: 0.0032 - accuracy: 0.9993 - val_loss: 4.1309 - val_accuracy: 0.0223
Epoch 15/500
44/44 - 18s - loss: 0.0028 - accuracy: 0.9993 - val_loss: 3.7752 - val_accuracy: 0.0279
Epoch 16/500
44/44 - 18s - loss: 0.0027 - accuracy: 0.9993 - val_loss: 3.6767 - val_accuracy: 0.0223
Epoch 17/500
44/44 - 18s - loss: 0.0024 - accuracy: 0.9993 - val_loss: 3.2735 - val_accuracy: 0.0503
Epoch 18/500
44/44 - 18s - loss: 0.0022 - accuracy: 0.9993 - val_loss: 3.2303 - val_accuracy: 0.0670
Epoch 19/500
44/44 - 18s - loss: 0.0025 - accuracy: 0.9993 - val_loss: 2.8657 - val_accuracy: 0.0894
Epoch 20/500
44/44 - 18s - loss: 0.0022 - accuracy: 0.9993 - val_loss: 2.8169 - val_accuracy: 0.1061
Epoch 21/500
44/44 - 18s - loss: 0.0022 - accuracy: 0.9993 - val_loss: 2.5229 - val_accuracy: 0.1285
Epoch 22/500
44/44 - 18s - loss: 0.0020 - accuracy: 0.9993 - val_loss: 2.4965 - val_accuracy: 0.1453
Epoch 23/500
44/44 - 18s - loss: 0.0018 - accuracy: 0.9993 - val_loss: 2.1763 - val_accuracy: 0.1788
Epoch 24/500
44/44 - 18s - loss: 0.0019 - accuracy: 0.9993 - val_loss: 2.1797 - val_accuracy: 0.1508
Epoch 25/500
44/44 - 35s - loss: 0.0019 - accuracy: 0.9993 - val_loss: 1.9155 - val_accuracy: 0.2011
Epoch 26/500
44/44 - 18s - loss: 0.0017 - accuracy: 0.9993 - val_loss: 1.9647 - val_accuracy: 0.1955
Epoch 27/500
44/44 - 38s - loss: 0.0017 - accuracy: 0.9993 - val_loss: 1.7236 - val_accuracy: 0.2849
Epoch 28/500
44/44 - 18s - loss: 0.0018 - accuracy: 0.9993 - val_loss: 1.7951 - val_accuracy: 0.3017
Epoch 29/500
44/44 - 40s - loss: 0.0014 - accuracy: 0.9993 - val_loss: 1.5516 - val_accuracy: 0.3966
Epoch 30/500
44/44 - 40s - loss: 0.0012 - accuracy: 0.9993 - val_loss: 1.4421 - val_accuracy: 0.4469
Epoch 31/500
44/44 - 39s - loss: 0.0012 - accuracy: 0.9993 - val_loss: 1.3099 - val_accuracy: 0.5307
Epoch 32/500
44/44 - 37s - loss: 0.0012 - accuracy: 0.9993 - val_loss: 1.2827 - val_accuracy: 0.5531
Epoch 33/500
44/44 - 18s - loss: 0.0013 - accuracy: 0.9993 - val_loss: 1.3146 - val_accuracy: 0.6201
Epoch 34/500
44/44 - 18s - loss: 0.0016 - accuracy: 0.9993 - val_loss: 1.3728 - val_accuracy: 0.6034
Epoch 35/500
44/44 - 18s - loss: 0.0016 - accuracy: 0.9993 - val_loss: 1.3985 - val_accuracy: 0.6480
Epoch 36/500
44/44 - 18s - loss: 0.0016 - accuracy: 0.9993 - val_loss: 1.4532 - val_accuracy: 0.6480
Epoch 37/500
44/44 - 18s - loss: 0.0018 - accuracy: 0.9993 - val_loss: 1.4814 - val_accuracy: 0.6648
Epoch 38/500
44/44 - 18s - loss: 0.0017 - accuracy: 0.9993 - val_loss: 1.5044 - val_accuracy: 0.6313
Epoch 39/500
44/44 - 18s - loss: 0.0017 - accuracy: 0.9993 - val_loss: 1.5371 - val_accuracy: 0.6648
Epoch 40/500
44/44 - 18s - loss: 0.0017 - accuracy: 0.9993 - val_loss: 1.5321 - val_accuracy: 0.6536
Epoch 41/500
44/44 - 18s - loss: 0.0016 - accuracy: 0.9993 - val_loss: 1.5517 - val_accuracy: 0.6536
Epoch 42/500
44/44 - 18s - loss: 0.0015 - accuracy: 0.9993 - val_loss: 1.5488 - val_accuracy: 0.6369
Epoch 43/500
44/44 - 18s - loss: 0.0015 - accuracy: 0.9993 - val_loss: 1.5687 - val_accuracy: 0.6536
Epoch 44/500
44/44 - 18s - loss: 0.0015 - accuracy: 0.9993 - val_loss: 1.5696 - val_accuracy: 0.6592
Epoch 45/500
44/44 - 18s - loss: 0.0014 - accuracy: 0.9993 - val_loss: 1.5813 - val_accuracy: 0.6536
Epoch 46/500
44/44 - 18s - loss: 0.0013 - accuracy: 0.9993 - val_loss: 1.5751 - val_accuracy: 0.6425
Epoch 47/500
44/44 - 18s - loss: 0.0013 - accuracy: 0.9993 - val_loss: 1.5928 - val_accuracy: 0.6536
Epoch 48/500
44/44 - 18s - loss: 0.0013 - accuracy: 0.9993 - val_loss: 1.5821 - val_accuracy: 0.6369
Epoch 49/500
44/44 - 18s - loss: 0.0013 - accuracy: 0.9993 - val_loss: 1.6005 - val_accuracy: 0.6536
Epoch 50/500
44/44 - 18s - loss: 0.0013 - accuracy: 0.9993 - val_loss: 1.5928 - val_accuracy: 0.6369
Epoch 51/500
44/44 - 18s - loss: 0.0013 - accuracy: 0.9993 - val_loss: 1.6108 - val_accuracy: 0.6648
Epoch 52/500
44/44 - 18s - loss: 0.0013 - accuracy: 0.9993 - val_loss: 1.6003 - val_accuracy: 0.6425
Epoch 53/500
44/44 - 18s - loss: 0.0013 - accuracy: 0.9993 - val_loss: 1.6219 - val_accuracy: 0.6592
Epoch 54/500
44/44 - 18s - loss: 0.0013 - accuracy: 0.9993 - val_loss: 1.6039 - val_accuracy: 0.6425
Epoch 55/500
44/44 - 18s - loss: 0.0012 - accuracy: 0.9993 - val_loss: 1.6177 - val_accuracy: 0.6592
Epoch 56/500
44/44 - 18s - loss: 0.0011 - accuracy: 0.9993 - val_loss: 1.6120 - val_accuracy: 0.6592
Epoch 57/500
44/44 - 18s - loss: 0.0011 - accuracy: 0.9993 - val_loss: 1.6288 - val_accuracy: 0.6648
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 13:20:37.057088: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 13:20:37.057251: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 13:20:37.057285: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 13:20:37.444780: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 13:20:37.444882: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00057: early stopping
Length split part:  1398
Labels in this part of split:  [288, 288, 280, 289, 253]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 40s - loss: 1.9840 - accuracy: 0.5079 - val_loss: 2.5209 - val_accuracy: 0.0615
Epoch 2/500
44/44 - 47s - loss: 0.2499 - accuracy: 0.9220 - val_loss: 2.3500 - val_accuracy: 0.1620
Epoch 3/500
44/44 - 41s - loss: 0.0343 - accuracy: 0.9950 - val_loss: 2.3184 - val_accuracy: 0.1229
Epoch 4/500
44/44 - 39s - loss: 0.0167 - accuracy: 0.9979 - val_loss: 2.1462 - val_accuracy: 0.1229
Epoch 5/500
44/44 - 18s - loss: 0.0056 - accuracy: 0.9986 - val_loss: 2.1499 - val_accuracy: 0.1229
Epoch 6/500
44/44 - 17s - loss: 0.0040 - accuracy: 0.9993 - val_loss: 2.3919 - val_accuracy: 0.1173
Epoch 7/500
44/44 - 17s - loss: 0.0032 - accuracy: 0.9993 - val_loss: 2.6088 - val_accuracy: 0.1285
Epoch 8/500
44/44 - 18s - loss: 0.0024 - accuracy: 0.9993 - val_loss: 2.8511 - val_accuracy: 0.1229
Epoch 9/500
44/44 - 18s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.0397 - val_accuracy: 0.1453
Epoch 10/500
44/44 - 18s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.1280 - val_accuracy: 0.1620
Epoch 11/500
44/44 - 18s - loss: 8.7379e-04 - accuracy: 1.0000 - val_loss: 3.1807 - val_accuracy: 0.1564
Epoch 12/500
44/44 - 18s - loss: 7.6557e-04 - accuracy: 1.0000 - val_loss: 3.1744 - val_accuracy: 0.2011
Epoch 13/500
44/44 - 18s - loss: 6.8045e-04 - accuracy: 1.0000 - val_loss: 3.1196 - val_accuracy: 0.1732
Epoch 14/500
44/44 - 18s - loss: 6.0992e-04 - accuracy: 1.0000 - val_loss: 3.0554 - val_accuracy: 0.1453
Epoch 15/500
44/44 - 18s - loss: 5.5164e-04 - accuracy: 1.0000 - val_loss: 3.0350 - val_accuracy: 0.1285
Epoch 16/500
44/44 - 18s - loss: 5.0266e-04 - accuracy: 1.0000 - val_loss: 3.0206 - val_accuracy: 0.1173
Epoch 17/500
44/44 - 18s - loss: 4.5923e-04 - accuracy: 1.0000 - val_loss: 2.9943 - val_accuracy: 0.1006
Epoch 18/500
44/44 - 18s - loss: 4.2267e-04 - accuracy: 1.0000 - val_loss: 2.9621 - val_accuracy: 0.1285
Epoch 19/500
44/44 - 18s - loss: 3.9129e-04 - accuracy: 1.0000 - val_loss: 2.9028 - val_accuracy: 0.1508
Epoch 20/500
44/44 - 18s - loss: 3.6193e-04 - accuracy: 1.0000 - val_loss: 2.8648 - val_accuracy: 0.1341
Epoch 21/500
44/44 - 18s - loss: 3.3665e-04 - accuracy: 1.0000 - val_loss: 2.8424 - val_accuracy: 0.1453
Epoch 22/500
44/44 - 18s - loss: 3.1394e-04 - accuracy: 1.0000 - val_loss: 2.7762 - val_accuracy: 0.1397
Epoch 23/500
44/44 - 18s - loss: 2.9413e-04 - accuracy: 1.0000 - val_loss: 2.6802 - val_accuracy: 0.1397
Epoch 24/500
44/44 - 18s - loss: 2.7543e-04 - accuracy: 1.0000 - val_loss: 2.6030 - val_accuracy: 0.1453
Epoch 25/500
44/44 - 18s - loss: 2.5859e-04 - accuracy: 1.0000 - val_loss: 2.5344 - val_accuracy: 0.1620
Epoch 26/500
44/44 - 18s - loss: 2.4336e-04 - accuracy: 1.0000 - val_loss: 2.4110 - val_accuracy: 0.2123
Epoch 27/500
44/44 - 18s - loss: 2.2956e-04 - accuracy: 1.0000 - val_loss: 2.1864 - val_accuracy: 0.2458
Epoch 28/500
44/44 - 37s - loss: 2.1702e-04 - accuracy: 1.0000 - val_loss: 1.9353 - val_accuracy: 0.3240
Epoch 29/500
44/44 - 37s - loss: 2.0524e-04 - accuracy: 1.0000 - val_loss: 1.7058 - val_accuracy: 0.3855
Epoch 30/500
44/44 - 37s - loss: 1.9441e-04 - accuracy: 1.0000 - val_loss: 1.5646 - val_accuracy: 0.4860
Epoch 31/500
44/44 - 36s - loss: 1.8424e-04 - accuracy: 1.0000 - val_loss: 1.4603 - val_accuracy: 0.5307
Epoch 32/500
44/44 - 38s - loss: 1.7489e-04 - accuracy: 1.0000 - val_loss: 1.3768 - val_accuracy: 0.5866
Epoch 33/500
44/44 - 36s - loss: 1.6642e-04 - accuracy: 1.0000 - val_loss: 1.3510 - val_accuracy: 0.6592
Epoch 34/500
44/44 - 18s - loss: 1.5821e-04 - accuracy: 1.0000 - val_loss: 1.3816 - val_accuracy: 0.6648
Epoch 35/500
44/44 - 18s - loss: 1.5073e-04 - accuracy: 1.0000 - val_loss: 1.4302 - val_accuracy: 0.6313
Epoch 36/500
44/44 - 18s - loss: 1.4373e-04 - accuracy: 1.0000 - val_loss: 1.4815 - val_accuracy: 0.6313
Epoch 37/500
44/44 - 18s - loss: 1.3729e-04 - accuracy: 1.0000 - val_loss: 1.5190 - val_accuracy: 0.6257
Epoch 38/500
44/44 - 18s - loss: 1.3114e-04 - accuracy: 1.0000 - val_loss: 1.5404 - val_accuracy: 0.6257
Epoch 39/500
44/44 - 18s - loss: 1.2535e-04 - accuracy: 1.0000 - val_loss: 1.5561 - val_accuracy: 0.6257
Epoch 40/500
44/44 - 18s - loss: 1.1980e-04 - accuracy: 1.0000 - val_loss: 1.5674 - val_accuracy: 0.6257
Epoch 41/500
44/44 - 18s - loss: 1.1470e-04 - accuracy: 1.0000 - val_loss: 1.5791 - val_accuracy: 0.6257
Epoch 42/500
44/44 - 18s - loss: 1.0985e-04 - accuracy: 1.0000 - val_loss: 1.5880 - val_accuracy: 0.6257
Epoch 43/500
44/44 - 18s - loss: 1.0528e-04 - accuracy: 1.0000 - val_loss: 1.5958 - val_accuracy: 0.6257
Epoch 44/500
44/44 - 18s - loss: 1.0103e-04 - accuracy: 1.0000 - val_loss: 1.6025 - val_accuracy: 0.6257
Epoch 45/500
44/44 - 18s - loss: 9.6928e-05 - accuracy: 1.0000 - val_loss: 1.6091 - val_accuracy: 0.6313
Epoch 46/500
44/44 - 18s - loss: 9.3062e-05 - accuracy: 1.0000 - val_loss: 1.6137 - val_accuracy: 0.6313
Epoch 47/500
44/44 - 18s - loss: 8.9462e-05 - accuracy: 1.0000 - val_loss: 1.6206 - val_accuracy: 0.6313
Epoch 48/500
44/44 - 18s - loss: 8.5952e-05 - accuracy: 1.0000 - val_loss: 1.6265 - val_accuracy: 0.6313
Epoch 49/500
44/44 - 18s - loss: 8.2641e-05 - accuracy: 1.0000 - val_loss: 1.6311 - val_accuracy: 0.6313
Epoch 50/500
44/44 - 18s - loss: 7.9472e-05 - accuracy: 1.0000 - val_loss: 1.6374 - val_accuracy: 0.6313
Epoch 51/500
44/44 - 18s - loss: 7.6458e-05 - accuracy: 1.0000 - val_loss: 1.6431 - val_accuracy: 0.6313
Epoch 52/500
44/44 - 18s - loss: 7.3641e-05 - accuracy: 1.0000 - val_loss: 1.6484 - val_accuracy: 0.6313
Epoch 53/500
44/44 - 18s - loss: 7.0912e-05 - accuracy: 1.0000 - val_loss: 1.6535 - val_accuracy: 0.6313
Epoch 54/500
44/44 - 18s - loss: 6.8294e-05 - accuracy: 1.0000 - val_loss: 1.6577 - val_accuracy: 0.6313
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 13:40:47.626691: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 13:40:47.626844: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 13:40:47.626877: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 13:40:48.013690: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 13:40:48.013788: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00054: early stopping
Length split part:  1397
Labels in this part of split:  [287, 275, 279, 276, 280]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 34s - loss: 2.1116 - accuracy: 0.4875 - val_loss: 4.1188 - val_accuracy: 0.0335
Epoch 2/500
44/44 - 36s - loss: 0.2754 - accuracy: 0.9098 - val_loss: 1.9113 - val_accuracy: 0.0391
Epoch 3/500
44/44 - 18s - loss: 0.0395 - accuracy: 0.9950 - val_loss: 1.9947 - val_accuracy: 0.0391
Epoch 4/500
44/44 - 18s - loss: 0.0074 - accuracy: 0.9993 - val_loss: 2.0093 - val_accuracy: 0.0447
Epoch 5/500
44/44 - 18s - loss: 0.0074 - accuracy: 0.9993 - val_loss: 2.0825 - val_accuracy: 0.0615
Epoch 6/500
44/44 - 18s - loss: 0.0038 - accuracy: 0.9993 - val_loss: 2.1384 - val_accuracy: 0.0503
Epoch 7/500
44/44 - 18s - loss: 0.0040 - accuracy: 0.9986 - val_loss: 2.2004 - val_accuracy: 0.0447
Epoch 8/500
44/44 - 17s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.2858 - val_accuracy: 0.0503
Epoch 9/500
44/44 - 17s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.4084 - val_accuracy: 0.0559
Epoch 10/500
44/44 - 18s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.5210 - val_accuracy: 0.0503
Epoch 11/500
44/44 - 18s - loss: 9.7054e-04 - accuracy: 1.0000 - val_loss: 2.5737 - val_accuracy: 0.0335
Epoch 12/500
44/44 - 18s - loss: 8.5489e-04 - accuracy: 1.0000 - val_loss: 2.5472 - val_accuracy: 0.0615
Epoch 13/500
44/44 - 18s - loss: 7.6056e-04 - accuracy: 1.0000 - val_loss: 2.4711 - val_accuracy: 0.1061
Epoch 14/500
44/44 - 18s - loss: 6.8448e-04 - accuracy: 1.0000 - val_loss: 2.3721 - val_accuracy: 0.1229
Epoch 15/500
44/44 - 17s - loss: 6.1776e-04 - accuracy: 1.0000 - val_loss: 2.2871 - val_accuracy: 0.1229
Epoch 16/500
44/44 - 17s - loss: 5.6288e-04 - accuracy: 1.0000 - val_loss: 2.2258 - val_accuracy: 0.1285
Epoch 17/500
44/44 - 17s - loss: 5.1547e-04 - accuracy: 1.0000 - val_loss: 2.2040 - val_accuracy: 0.1341
Epoch 18/500
44/44 - 18s - loss: 4.7362e-04 - accuracy: 1.0000 - val_loss: 2.2152 - val_accuracy: 0.1341
Epoch 19/500
44/44 - 18s - loss: 4.3774e-04 - accuracy: 1.0000 - val_loss: 2.2451 - val_accuracy: 0.1341
Epoch 20/500
44/44 - 18s - loss: 4.0559e-04 - accuracy: 1.0000 - val_loss: 2.2540 - val_accuracy: 0.1397
Epoch 21/500
44/44 - 17s - loss: 3.7722e-04 - accuracy: 1.0000 - val_loss: 2.2155 - val_accuracy: 0.1397
Epoch 22/500
44/44 - 18s - loss: 3.5163e-04 - accuracy: 1.0000 - val_loss: 2.1283 - val_accuracy: 0.1564
Epoch 23/500
44/44 - 18s - loss: 3.2866e-04 - accuracy: 1.0000 - val_loss: 2.0489 - val_accuracy: 0.1732
Epoch 24/500
44/44 - 17s - loss: 3.0812e-04 - accuracy: 1.0000 - val_loss: 1.9208 - val_accuracy: 0.1899
Epoch 25/500
44/44 - 36s - loss: 2.8931e-04 - accuracy: 1.0000 - val_loss: 1.7970 - val_accuracy: 0.2849
Epoch 26/500
44/44 - 38s - loss: 2.7218e-04 - accuracy: 1.0000 - val_loss: 1.7037 - val_accuracy: 0.2961
Epoch 27/500
44/44 - 36s - loss: 2.5628e-04 - accuracy: 1.0000 - val_loss: 1.6927 - val_accuracy: 0.3352
Epoch 28/500
44/44 - 35s - loss: 2.4231e-04 - accuracy: 1.0000 - val_loss: 1.6571 - val_accuracy: 0.3520
Epoch 29/500
44/44 - 38s - loss: 2.2900e-04 - accuracy: 1.0000 - val_loss: 1.5687 - val_accuracy: 0.3911
Epoch 30/500
44/44 - 36s - loss: 2.1667e-04 - accuracy: 1.0000 - val_loss: 1.4987 - val_accuracy: 0.4749
Epoch 31/500
44/44 - 35s - loss: 2.0556e-04 - accuracy: 1.0000 - val_loss: 1.3855 - val_accuracy: 0.5196
Epoch 32/500
44/44 - 36s - loss: 1.9508e-04 - accuracy: 1.0000 - val_loss: 1.2975 - val_accuracy: 0.5810
Epoch 33/500
44/44 - 35s - loss: 1.8539e-04 - accuracy: 1.0000 - val_loss: 1.2609 - val_accuracy: 0.5978
Epoch 34/500
44/44 - 17s - loss: 1.7631e-04 - accuracy: 1.0000 - val_loss: 1.2743 - val_accuracy: 0.6257
Epoch 35/500
44/44 - 17s - loss: 1.6787e-04 - accuracy: 1.0000 - val_loss: 1.3222 - val_accuracy: 0.6425
Epoch 36/500
44/44 - 17s - loss: 1.6008e-04 - accuracy: 1.0000 - val_loss: 1.3756 - val_accuracy: 0.6536
Epoch 37/500
44/44 - 17s - loss: 1.5269e-04 - accuracy: 1.0000 - val_loss: 1.4137 - val_accuracy: 0.6480
Epoch 38/500
44/44 - 18s - loss: 1.4590e-04 - accuracy: 1.0000 - val_loss: 1.4406 - val_accuracy: 0.6536
Epoch 39/500
44/44 - 17s - loss: 1.3928e-04 - accuracy: 1.0000 - val_loss: 1.4606 - val_accuracy: 0.6536
Epoch 40/500
44/44 - 17s - loss: 1.3311e-04 - accuracy: 1.0000 - val_loss: 1.4742 - val_accuracy: 0.6592
Epoch 41/500
44/44 - 18s - loss: 1.2747e-04 - accuracy: 1.0000 - val_loss: 1.4861 - val_accuracy: 0.6592
Epoch 42/500
44/44 - 17s - loss: 1.2200e-04 - accuracy: 1.0000 - val_loss: 1.4936 - val_accuracy: 0.6592
Epoch 43/500
44/44 - 17s - loss: 1.1686e-04 - accuracy: 1.0000 - val_loss: 1.4999 - val_accuracy: 0.6592
Epoch 44/500
44/44 - 17s - loss: 1.1203e-04 - accuracy: 1.0000 - val_loss: 1.5063 - val_accuracy: 0.6592
Epoch 45/500
44/44 - 17s - loss: 1.0741e-04 - accuracy: 1.0000 - val_loss: 1.5121 - val_accuracy: 0.6592
Epoch 46/500
44/44 - 17s - loss: 1.0308e-04 - accuracy: 1.0000 - val_loss: 1.5182 - val_accuracy: 0.6592
Epoch 47/500
44/44 - 17s - loss: 9.9028e-05 - accuracy: 1.0000 - val_loss: 1.5232 - val_accuracy: 0.6592
Epoch 48/500
44/44 - 17s - loss: 9.5078e-05 - accuracy: 1.0000 - val_loss: 1.5293 - val_accuracy: 0.6592
Epoch 49/500
44/44 - 17s - loss: 9.1343e-05 - accuracy: 1.0000 - val_loss: 1.5331 - val_accuracy: 0.6592
Epoch 50/500
44/44 - 17s - loss: 8.7894e-05 - accuracy: 1.0000 - val_loss: 1.5374 - val_accuracy: 0.6592
Epoch 51/500
44/44 - 17s - loss: 8.4499e-05 - accuracy: 1.0000 - val_loss: 1.5433 - val_accuracy: 0.6592
Epoch 52/500
44/44 - 17s - loss: 8.1334e-05 - accuracy: 1.0000 - val_loss: 1.5480 - val_accuracy: 0.6592
Epoch 53/500
44/44 - 17s - loss: 7.8267e-05 - accuracy: 1.0000 - val_loss: 1.5512 - val_accuracy: 0.6592
Epoch 54/500
44/44 - 17s - loss: 7.5356e-05 - accuracy: 1.0000 - val_loss: 1.5569 - val_accuracy: 0.6592
Epoch 55/500
44/44 - 18s - loss: 7.2609e-05 - accuracy: 1.0000 - val_loss: 1.5620 - val_accuracy: 0.6592
Epoch 56/500
44/44 - 17s - loss: 6.9936e-05 - accuracy: 1.0000 - val_loss: 1.5671 - val_accuracy: 0.6592
Epoch 57/500
44/44 - 17s - loss: 6.7425e-05 - accuracy: 1.0000 - val_loss: 1.5713 - val_accuracy: 0.6592
Epoch 58/500
44/44 - 17s - loss: 6.5048e-05 - accuracy: 1.0000 - val_loss: 1.5766 - val_accuracy: 0.6592
Epoch 59/500
44/44 - 18s - loss: 6.2706e-05 - accuracy: 1.0000 - val_loss: 1.5800 - val_accuracy: 0.6592
Epoch 60/500
44/44 - 17s - loss: 6.0560e-05 - accuracy: 1.0000 - val_loss: 1.5838 - val_accuracy: 0.6592
Epoch 00060: early stopping
ResNet50V2
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5
    8192/94668760 [..............................] - ETA: 16:34   40960/94668760 [..............................] - ETA: 6:55    73728/94668760 [..............................] - ETA: 5:50  122880/94668760 [..............................] - ETA: 4:42  245760/94668760 [..............................] - ETA: 2:57  475136/94668760 [..............................] - ETA: 1:49  925696/94668760 [..............................] - ETA: 1:05 1835008/94668760 [..............................] - ETA: 37s  3637248/94668760 [>.............................] - ETA: 20s 6782976/94668760 [=>............................] - ETA: 12s 9912320/94668760 [==>...........................] - ETA: 8s 13058048/94668760 [===>..........................] - ETA: 6s16187392/94668760 [====>.........................] - ETA: 5s19316736/94668760 [=====>........................] - ETA: 5s22462464/94668760 [======>.......................] - ETA: 4s25591808/94668760 [=======>......................] - ETA: 4s28737536/94668760 [========>.....................] - ETA: 3s31866880/94668760 [=========>....................] - ETA: 3s35012608/94668760 [==========>...................] - ETA: 3s38141952/94668760 [===========>..................] - ETA: 2s41238528/94668760 [============>.................] - ETA: 2s41861120/94668760 [============>.................] - ETA: 2s44384256/94668760 [=============>................] - ETA: 2s47382528/94668760 [==============>...............] - ETA: 2s48103424/94668760 [==============>...............] - ETA: 2s50659328/94668760 [===============>..............] - ETA: 1s53477376/94668760 [===============>..............] - ETA: 1s54411264/94668760 [================>.............] - ETA: 1s56918016/94668760 [=================>............] - ETA: 1s59752448/94668760 [=================>............] - ETA: 1s60669952/94668760 [==================>...........] - ETA: 1s63193088/94668760 [===================>..........] - ETA: 1s66027520/94668760 [===================>..........] - ETA: 1s66928640/94668760 [====================>.........] - ETA: 1s69435392/94668760 [=====================>........] - ETA: 1s72286208/94668760 [=====================>........] - ETA: 0s73203712/94668760 [======================>.......] - ETA: 0s75505664/94668760 [======================>.......] - ETA: 0s76431360/94668760 [=======================>......] - ETA: 0s78708736/94668760 [=======================>......] - ETA: 0s81387520/94668760 [========================>.....] - ETA: 0s82558976/94668760 [=========================>....] - ETA: 0s84901888/94668760 [=========================>....] - ETA: 0s85835776/94668760 [==========================>...] - ETA: 0s88129536/94668760 [==========================>...] - ETA: 0s90423296/94668760 [===========================>..] - ETA: 0s91947008/94668760 [============================>.] - ETA: 0s94150656/94668760 [============================>.] - ETA: 0s94674944/94668760 [==============================] - 4s 0us/step
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 14:02:57.350616: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 14:02:57.350764: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 14:02:57.350798: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 14:02:57.519921: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 14:02:57.520022: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_conv[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_preact_bn (BatchNo (None, 64, 64, 64)   256         pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_preact_relu (Activ (None, 64, 64, 64)   0           conv2_block1_preact_bn[0][0]     
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4096        conv2_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block1_2_pad[0][0]         
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_out (Add)          (None, 64, 64, 256)  0           conv2_block1_0_conv[0][0]        
                                                                 conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_preact_relu (Activ (None, 64, 64, 256)  0           conv2_block2_preact_bn[0][0]     
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16384       conv2_block2_preact_relu[0][0]   
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block2_2_pad[0][0]         
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_out (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_preact_relu (Activ (None, 64, 64, 256)  0           conv2_block3_preact_bn[0][0]     
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16384       conv2_block3_preact_relu[0][0]   
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 32, 32, 64)   36864       conv2_block3_2_pad[0][0]         
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 32, 32, 64)   0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 32, 32, 256)  0           conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_out (Add)          (None, 32, 32, 256)  0           max_pooling2d[0][0]              
                                                                 conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_preact_bn (BatchNo (None, 32, 32, 256)  1024        conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_preact_relu (Activ (None, 32, 32, 256)  0           conv3_block1_preact_bn[0][0]     
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32768       conv3_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block1_2_pad[0][0]         
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv3_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_out (Add)          (None, 32, 32, 512)  0           conv3_block1_0_conv[0][0]        
                                                                 conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block2_preact_bn[0][0]     
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block2_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block2_2_pad[0][0]         
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_out (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block3_preact_bn[0][0]     
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block3_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block3_2_pad[0][0]         
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_out (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block4_preact_bn[0][0]     
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block4_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 16, 16, 128)  147456      conv3_block4_2_pad[0][0]         
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 16, 16, 128)  0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 512)  0           conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_out (Add)          (None, 16, 16, 512)  0           max_pooling2d_1[0][0]            
                                                                 conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_preact_bn (BatchNo (None, 16, 16, 512)  2048        conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_preact_relu (Activ (None, 16, 16, 512)  0           conv4_block1_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131072      conv4_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block1_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv4_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_out (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_conv[0][0]        
                                                                 conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block2_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block2_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block2_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_out (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block3_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block3_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block3_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_out (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block4_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block4_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block4_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_out (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block5_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block5_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block5_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_out (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block6_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block6_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 8, 8, 256)    589824      conv4_block6_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 8, 8, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 1024)   0           conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_out (Add)          (None, 8, 8, 1024)   0           max_pooling2d_2[0][0]            
                                                                 conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_preact_bn (BatchNo (None, 8, 8, 1024)   4096        conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_preact_relu (Activ (None, 8, 8, 1024)   0           conv5_block1_preact_bn[0][0]     
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524288      conv5_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block1_2_pad[0][0]         
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv5_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_out (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_conv[0][0]        
                                                                 conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_preact_bn (BatchNo (None, 8, 8, 2048)   8192        conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_preact_relu (Activ (None, 8, 8, 2048)   0           conv5_block2_preact_bn[0][0]     
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1048576     conv5_block2_preact_relu[0][0]   
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block2_2_pad[0][0]         
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_out (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_preact_bn (BatchNo (None, 8, 8, 2048)   8192        conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_preact_relu (Activ (None, 8, 8, 2048)   0           conv5_block3_preact_bn[0][0]     
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1048576     conv5_block3_preact_relu[0][0]   
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block3_2_pad[0][0]         
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_out (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
post_bn (BatchNormalization)    (None, 8, 8, 2048)   8192        conv5_block3_out[0][0]           
__________________________________________________________________________________________________
post_relu (Activation)          (None, 8, 8, 2048)   0           post_bn[0][0]                    
__________________________________________________________________________________________________
flatten (Flatten)               (None, 131072)       0           post_relu[0][0]                  
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         536875008   flatten[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
predictions (Dense)             (None, 5)            20485       fc2[0][0]                        
==================================================================================================
Total params: 577,241,605
Trainable params: 577,196,165
Non-trainable params: 45,440
__________________________________________________________________________________________________
Start fitting ensemble models
Random seed for replication: 319
Length split part:  1398
Labels in this part of split:  [279, 264, 297, 301, 257]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 34s - loss: 1.4464 - accuracy: 0.4657 - val_loss: 1.3974 - val_accuracy: 0.3911
Epoch 2/500
44/44 - 23s - loss: 0.0607 - accuracy: 0.9864 - val_loss: 1.1599 - val_accuracy: 0.5810
Epoch 3/500
44/44 - 8s - loss: 0.0208 - accuracy: 0.9979 - val_loss: 1.4179 - val_accuracy: 0.3743
Epoch 4/500
44/44 - 8s - loss: 0.0142 - accuracy: 0.9979 - val_loss: 1.2781 - val_accuracy: 0.6034
Epoch 5/500
44/44 - 8s - loss: 0.0068 - accuracy: 0.9986 - val_loss: 1.3436 - val_accuracy: 0.5140
Epoch 6/500
44/44 - 8s - loss: 0.0064 - accuracy: 0.9993 - val_loss: 1.2943 - val_accuracy: 0.6034
Epoch 7/500
44/44 - 8s - loss: 0.0045 - accuracy: 0.9993 - val_loss: 1.3380 - val_accuracy: 0.6536
Epoch 8/500
44/44 - 8s - loss: 0.0065 - accuracy: 0.9993 - val_loss: 1.2748 - val_accuracy: 0.5978
Epoch 9/500
44/44 - 8s - loss: 0.0035 - accuracy: 0.9993 - val_loss: 1.3053 - val_accuracy: 0.6145
Epoch 10/500
44/44 - 8s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2772 - val_accuracy: 0.6034
Epoch 11/500
44/44 - 8s - loss: 9.2522e-04 - accuracy: 1.0000 - val_loss: 1.2877 - val_accuracy: 0.5978
Epoch 12/500
44/44 - 8s - loss: 8.0829e-04 - accuracy: 1.0000 - val_loss: 1.3031 - val_accuracy: 0.6145
Epoch 13/500
44/44 - 8s - loss: 7.1666e-04 - accuracy: 1.0000 - val_loss: 1.3247 - val_accuracy: 0.6145
Epoch 14/500
44/44 - 8s - loss: 6.4125e-04 - accuracy: 1.0000 - val_loss: 1.3321 - val_accuracy: 0.6201
Epoch 15/500
44/44 - 8s - loss: 5.7803e-04 - accuracy: 1.0000 - val_loss: 1.3370 - val_accuracy: 0.6201
Epoch 16/500
44/44 - 8s - loss: 5.2549e-04 - accuracy: 1.0000 - val_loss: 1.3423 - val_accuracy: 0.6089
Epoch 17/500
44/44 - 8s - loss: 4.8017e-04 - accuracy: 1.0000 - val_loss: 1.3512 - val_accuracy: 0.6034
Epoch 18/500
44/44 - 8s - loss: 4.4009e-04 - accuracy: 1.0000 - val_loss: 1.3560 - val_accuracy: 0.5978
Epoch 19/500
44/44 - 8s - loss: 4.0626e-04 - accuracy: 1.0000 - val_loss: 1.3615 - val_accuracy: 0.5978
Epoch 20/500
44/44 - 8s - loss: 3.7563e-04 - accuracy: 1.0000 - val_loss: 1.3675 - val_accuracy: 0.5978
Epoch 21/500
44/44 - 8s - loss: 3.4886e-04 - accuracy: 1.0000 - val_loss: 1.3734 - val_accuracy: 0.5978
Epoch 22/500
44/44 - 8s - loss: 3.2456e-04 - accuracy: 1.0000 - val_loss: 1.3792 - val_accuracy: 0.6034
Epoch 23/500
44/44 - 8s - loss: 3.0373e-04 - accuracy: 1.0000 - val_loss: 1.3848 - val_accuracy: 0.6089
Epoch 24/500
44/44 - 8s - loss: 2.8374e-04 - accuracy: 1.0000 - val_loss: 1.3901 - val_accuracy: 0.6034
Epoch 25/500
44/44 - 8s - loss: 2.6618e-04 - accuracy: 1.0000 - val_loss: 1.3955 - val_accuracy: 0.6034
Epoch 26/500
44/44 - 8s - loss: 2.5006e-04 - accuracy: 1.0000 - val_loss: 1.3993 - val_accuracy: 0.6034
Epoch 27/500
44/44 - 8s - loss: 2.3561e-04 - accuracy: 1.0000 - val_loss: 1.4053 - val_accuracy: 0.6034
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 14:07:22.310714: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 14:07:22.310870: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 14:07:22.310924: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 14:07:22.480257: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 14:07:22.480372: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00027: early stopping
Length split part:  1398
Labels in this part of split:  [289, 287, 260, 277, 285]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 20s - loss: 1.6151 - accuracy: 0.5014 - val_loss: 1.2485 - val_accuracy: 0.6760
Epoch 2/500
44/44 - 8s - loss: 0.1849 - accuracy: 0.9449 - val_loss: 1.4972 - val_accuracy: 0.3855
Epoch 3/500
44/44 - 8s - loss: 0.0227 - accuracy: 0.9971 - val_loss: 1.4579 - val_accuracy: 0.4749
Epoch 4/500
44/44 - 23s - loss: 0.0045 - accuracy: 0.9993 - val_loss: 1.1326 - val_accuracy: 0.6034
Epoch 5/500
44/44 - 24s - loss: 0.0046 - accuracy: 0.9986 - val_loss: 1.0901 - val_accuracy: 0.6648
Epoch 6/500
44/44 - 8s - loss: 0.0035 - accuracy: 0.9993 - val_loss: 1.1283 - val_accuracy: 0.6816
Epoch 7/500
44/44 - 8s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1861 - val_accuracy: 0.6536
Epoch 8/500
44/44 - 8s - loss: 7.6892e-04 - accuracy: 1.0000 - val_loss: 1.2456 - val_accuracy: 0.6648
Epoch 9/500
44/44 - 8s - loss: 6.5666e-04 - accuracy: 1.0000 - val_loss: 1.2767 - val_accuracy: 0.6872
Epoch 10/500
44/44 - 8s - loss: 5.7411e-04 - accuracy: 1.0000 - val_loss: 1.3203 - val_accuracy: 0.6760
Epoch 11/500
44/44 - 8s - loss: 5.1073e-04 - accuracy: 1.0000 - val_loss: 1.3172 - val_accuracy: 0.6704
Epoch 12/500
44/44 - 8s - loss: 4.5857e-04 - accuracy: 1.0000 - val_loss: 1.3249 - val_accuracy: 0.6872
Epoch 13/500
44/44 - 8s - loss: 4.1563e-04 - accuracy: 1.0000 - val_loss: 1.3289 - val_accuracy: 0.6648
Epoch 14/500
44/44 - 8s - loss: 3.7896e-04 - accuracy: 1.0000 - val_loss: 1.3354 - val_accuracy: 0.6648
Epoch 15/500
44/44 - 8s - loss: 3.4782e-04 - accuracy: 1.0000 - val_loss: 1.3340 - val_accuracy: 0.6704
Epoch 16/500
44/44 - 8s - loss: 3.2176e-04 - accuracy: 1.0000 - val_loss: 1.3325 - val_accuracy: 0.6648
Epoch 17/500
44/44 - 8s - loss: 2.9821e-04 - accuracy: 1.0000 - val_loss: 1.3367 - val_accuracy: 0.6648
Epoch 18/500
44/44 - 8s - loss: 2.7755e-04 - accuracy: 1.0000 - val_loss: 1.3413 - val_accuracy: 0.6592
Epoch 19/500
44/44 - 8s - loss: 2.5919e-04 - accuracy: 1.0000 - val_loss: 1.3454 - val_accuracy: 0.6592
Epoch 20/500
44/44 - 8s - loss: 2.4238e-04 - accuracy: 1.0000 - val_loss: 1.3514 - val_accuracy: 0.6592
Epoch 21/500
44/44 - 8s - loss: 2.2779e-04 - accuracy: 1.0000 - val_loss: 1.3560 - val_accuracy: 0.6592
Epoch 22/500
44/44 - 8s - loss: 2.1428e-04 - accuracy: 1.0000 - val_loss: 1.3605 - val_accuracy: 0.6592
Epoch 23/500
44/44 - 8s - loss: 2.0201e-04 - accuracy: 1.0000 - val_loss: 1.3662 - val_accuracy: 0.6592
Epoch 24/500
44/44 - 8s - loss: 1.9090e-04 - accuracy: 1.0000 - val_loss: 1.3719 - val_accuracy: 0.6592
Epoch 25/500
44/44 - 8s - loss: 1.8063e-04 - accuracy: 1.0000 - val_loss: 1.3775 - val_accuracy: 0.6592
Epoch 26/500
44/44 - 8s - loss: 1.7139e-04 - accuracy: 1.0000 - val_loss: 1.3815 - val_accuracy: 0.6592
Epoch 27/500
44/44 - 8s - loss: 1.6271e-04 - accuracy: 1.0000 - val_loss: 1.3864 - val_accuracy: 0.6592
Epoch 28/500
44/44 - 8s - loss: 1.5472e-04 - accuracy: 1.0000 - val_loss: 1.3922 - val_accuracy: 0.6592
Epoch 29/500
44/44 - 8s - loss: 1.4734e-04 - accuracy: 1.0000 - val_loss: 1.3978 - val_accuracy: 0.6592
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 14:12:14.877150: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 14:12:14.880571: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 14:12:14.882382: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 14:12:15.053729: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 14:12:15.055653: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00029: early stopping
Length split part:  1397
Labels in this part of split:  [272, 289, 282, 260, 294]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 25s - loss: 1.8639 - accuracy: 0.4474 - val_loss: 1.0754 - val_accuracy: 0.6369
Epoch 2/500
44/44 - 8s - loss: 0.2094 - accuracy: 0.9363 - val_loss: 1.1041 - val_accuracy: 0.6536
Epoch 3/500
44/44 - 8s - loss: 0.0265 - accuracy: 0.9957 - val_loss: 1.6610 - val_accuracy: 0.4804
Epoch 4/500
44/44 - 8s - loss: 0.0118 - accuracy: 0.9971 - val_loss: 1.3138 - val_accuracy: 0.6536
Epoch 5/500
44/44 - 8s - loss: 0.0031 - accuracy: 0.9993 - val_loss: 1.3035 - val_accuracy: 0.6201
Epoch 6/500
44/44 - 8s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2850 - val_accuracy: 0.6369
Epoch 7/500
44/44 - 8s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2988 - val_accuracy: 0.6536
Epoch 8/500
44/44 - 8s - loss: 9.6159e-04 - accuracy: 1.0000 - val_loss: 1.3223 - val_accuracy: 0.6536
Epoch 9/500
44/44 - 8s - loss: 8.3266e-04 - accuracy: 1.0000 - val_loss: 1.3371 - val_accuracy: 0.6760
Epoch 10/500
44/44 - 8s - loss: 7.3137e-04 - accuracy: 1.0000 - val_loss: 1.3685 - val_accuracy: 0.6704
Epoch 11/500
44/44 - 8s - loss: 6.5318e-04 - accuracy: 1.0000 - val_loss: 1.3990 - val_accuracy: 0.6592
Epoch 12/500
44/44 - 8s - loss: 5.8791e-04 - accuracy: 1.0000 - val_loss: 1.4098 - val_accuracy: 0.6592
Epoch 13/500
44/44 - 8s - loss: 5.3462e-04 - accuracy: 1.0000 - val_loss: 1.4066 - val_accuracy: 0.6369
Epoch 14/500
44/44 - 8s - loss: 4.8760e-04 - accuracy: 1.0000 - val_loss: 1.4121 - val_accuracy: 0.6313
Epoch 15/500
44/44 - 8s - loss: 4.4807e-04 - accuracy: 1.0000 - val_loss: 1.4186 - val_accuracy: 0.6369
Epoch 16/500
44/44 - 8s - loss: 4.1346e-04 - accuracy: 1.0000 - val_loss: 1.4322 - val_accuracy: 0.6257
Epoch 17/500
44/44 - 8s - loss: 3.8339e-04 - accuracy: 1.0000 - val_loss: 1.4423 - val_accuracy: 0.6201
Epoch 18/500
44/44 - 8s - loss: 3.5635e-04 - accuracy: 1.0000 - val_loss: 1.4510 - val_accuracy: 0.6201
Epoch 19/500
44/44 - 8s - loss: 3.3280e-04 - accuracy: 1.0000 - val_loss: 1.4582 - val_accuracy: 0.6145
Epoch 20/500
44/44 - 8s - loss: 3.1126e-04 - accuracy: 1.0000 - val_loss: 1.4660 - val_accuracy: 0.6145
Epoch 21/500
44/44 - 8s - loss: 2.9201e-04 - accuracy: 1.0000 - val_loss: 1.4741 - val_accuracy: 0.6201
Epoch 22/500
44/44 - 8s - loss: 2.7495e-04 - accuracy: 1.0000 - val_loss: 1.4816 - val_accuracy: 0.6201
Epoch 23/500
44/44 - 8s - loss: 2.5910e-04 - accuracy: 1.0000 - val_loss: 1.4899 - val_accuracy: 0.6201
Epoch 24/500
44/44 - 8s - loss: 2.4452e-04 - accuracy: 1.0000 - val_loss: 1.4970 - val_accuracy: 0.6201
Epoch 25/500
44/44 - 8s - loss: 2.3131e-04 - accuracy: 1.0000 - val_loss: 1.5031 - val_accuracy: 0.6201
Epoch 26/500
44/44 - 8s - loss: 2.1938e-04 - accuracy: 1.0000 - val_loss: 1.5092 - val_accuracy: 0.6201
Epoch 27/500
44/44 - 8s - loss: 2.0812e-04 - accuracy: 1.0000 - val_loss: 1.5155 - val_accuracy: 0.6201
Epoch 28/500
44/44 - 8s - loss: 1.9756e-04 - accuracy: 1.0000 - val_loss: 1.5219 - val_accuracy: 0.6201
Epoch 29/500
44/44 - 8s - loss: 1.8795e-04 - accuracy: 1.0000 - val_loss: 1.5286 - val_accuracy: 0.6201
Epoch 00029: early stopping
ResNet101V2
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5
     8192/171317808 [..............................] - ETA: 1s    57344/171317808 [..............................] - ETA: 3:28   139264/171317808 [..............................] - ETA: 3:21   262144/171317808 [..............................] - ETA: 2:48   417792/171317808 [..............................] - ETA: 2:24   835584/171317808 [..............................] - ETA: 1:31  1433600/171317808 [..............................] - ETA: 1:04  2859008/171317808 [..............................] - ETA: 37s   4677632/171317808 [..............................] - ETA: 26s  7528448/171317808 [>.............................] - ETA: 18s 10657792/171317808 [>.............................] - ETA: 13s 13787136/171317808 [=>............................] - ETA: 11s 16932864/171317808 [=>............................] - ETA: 10s 19980288/171317808 [==>...........................] - ETA: 9s  23126016/171317808 [===>..........................] - ETA: 8s 26255360/171317808 [===>..........................] - ETA: 7s 29368320/171317808 [====>.........................] - ETA: 6s 29401088/171317808 [====>.........................] - ETA: 7s 32448512/171317808 [====>.........................] - ETA: 6s 35577856/171317808 [=====>........................] - ETA: 6s 38723584/171317808 [=====>........................] - ETA: 6s 41721856/171317808 [======>.......................] - ETA: 5s 41902080/171317808 [======>.......................] - ETA: 5s 44900352/171317808 [======>.......................] - ETA: 5s 47751168/171317808 [=======>......................] - ETA: 5s 48062464/171317808 [=======>......................] - ETA: 5s 51175424/171317808 [=======>......................] - ETA: 5s 53829632/171317808 [========>.....................] - ETA: 4s 54321152/171317808 [========>.....................] - ETA: 4s 57450496/171317808 [=========>....................] - ETA: 4s 60219392/171317808 [=========>....................] - ETA: 4s 60612608/171317808 [=========>....................] - ETA: 4s 63725568/171317808 [==========>...................] - ETA: 4s 66625536/171317808 [==========>...................] - ETA: 4s 66904064/171317808 [==========>...................] - ETA: 4s 69853184/171317808 [===========>..................] - ETA: 3s 72343552/171317808 [===========>..................] - ETA: 3s 73146368/171317808 [===========>..................] - ETA: 3s 75505664/171317808 [============>.................] - ETA: 3s 76324864/171317808 [============>.................] - ETA: 3s 78864384/171317808 [============>.................] - ETA: 3s 81190912/171317808 [=============>................] - ETA: 3s 82403328/171317808 [=============>................] - ETA: 3s 84746240/171317808 [=============>................] - ETA: 3s 85696512/171317808 [==============>...............] - ETA: 3s 87941120/171317808 [==============>...............] - ETA: 3s 88875008/171317808 [==============>...............] - ETA: 3s 91234304/171317808 [==============>...............] - ETA: 2s 92217344/171317808 [===============>..............] - ETA: 2s 94396416/171317808 [===============>..............] - ETA: 2s 96444416/171317808 [===============>..............] - ETA: 2s 97968128/171317808 [================>.............] - ETA: 2s 99672064/171317808 [================>.............] - ETA: 2s101294080/171317808 [================>.............] - ETA: 2s103243776/171317808 [=================>............] - ETA: 2s104538112/171317808 [=================>............] - ETA: 2s106848256/171317808 [=================>............] - ETA: 2s107765760/171317808 [=================>............] - ETA: 2s110026752/171317808 [==================>...........] - ETA: 2s112205824/171317808 [==================>...........] - ETA: 2s113254400/171317808 [==================>...........] - ETA: 2s115810304/171317808 [===================>..........] - ETA: 1s116809728/171317808 [===================>..........] - ETA: 1s119332864/171317808 [===================>..........] - ETA: 1s120315904/171317808 [====================>.........] - ETA: 1s122478592/171317808 [====================>.........] - ETA: 1s123658240/171317808 [====================>.........] - ETA: 1s125640704/171317808 [=====================>........] - ETA: 1s127574016/171317808 [=====================>........] - ETA: 1s128901120/171317808 [=====================>........] - ETA: 1s130850816/171317808 [=====================>........] - ETA: 1s132112384/171317808 [======================>.......] - ETA: 1s134225920/171317808 [======================>.......] - ETA: 1s135782400/171317808 [======================>.......] - ETA: 1s137707520/171317808 [=======================>......] - ETA: 1s139321344/171317808 [=======================>......] - ETA: 1s141320192/171317808 [=======================>......] - ETA: 1s142598144/171317808 [=======================>......] - ETA: 0s144596992/171317808 [========================>.....] - ETA: 0s146317312/171317808 [========================>.....] - ETA: 0s147808256/171317808 [========================>.....] - ETA: 0s149872640/171317808 [=========================>....] - ETA: 0s150970368/171317808 [=========================>....] - ETA: 0s153214976/171317808 [=========================>....] - ETA: 0s154189824/171317808 [==========================>...] - ETA: 0s156753920/171317808 [==========================>...] - ETA: 0s157687808/171317808 [==========================>...] - ETA: 0s159981568/171317808 [===========================>..] - ETA: 0s161390592/171317808 [===========================>..] - ETA: 0s163405824/171317808 [===========================>..] - ETA: 0s164601856/171317808 [===========================>..] - ETA: 0s166567936/171317808 [============================>.] - ETA: 0s167780352/171317808 [============================>.] - ETA: 0s169746432/171317808 [============================>.] - ETA: 0s171319296/171317808 [==============================] - 6s 0us/step
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 14:17:23.112521: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 14:17:23.175186: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 14:17:23.178695: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 14:17:23.448378: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 14:17:23.451245: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_conv[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_preact_bn (BatchNo (None, 64, 64, 64)   256         pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_preact_relu (Activ (None, 64, 64, 64)   0           conv2_block1_preact_bn[0][0]     
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4096        conv2_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block1_2_pad[0][0]         
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_out (Add)          (None, 64, 64, 256)  0           conv2_block1_0_conv[0][0]        
                                                                 conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_preact_relu (Activ (None, 64, 64, 256)  0           conv2_block2_preact_bn[0][0]     
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16384       conv2_block2_preact_relu[0][0]   
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block2_2_pad[0][0]         
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_out (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_preact_relu (Activ (None, 64, 64, 256)  0           conv2_block3_preact_bn[0][0]     
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16384       conv2_block3_preact_relu[0][0]   
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 32, 32, 64)   36864       conv2_block3_2_pad[0][0]         
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 32, 32, 64)   0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 32, 32, 256)  0           conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_out (Add)          (None, 32, 32, 256)  0           max_pooling2d[0][0]              
                                                                 conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_preact_bn (BatchNo (None, 32, 32, 256)  1024        conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_preact_relu (Activ (None, 32, 32, 256)  0           conv3_block1_preact_bn[0][0]     
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32768       conv3_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block1_2_pad[0][0]         
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv3_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_out (Add)          (None, 32, 32, 512)  0           conv3_block1_0_conv[0][0]        
                                                                 conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block2_preact_bn[0][0]     
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block2_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block2_2_pad[0][0]         
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_out (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block3_preact_bn[0][0]     
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block3_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block3_2_pad[0][0]         
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_out (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block4_preact_bn[0][0]     
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block4_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 16, 16, 128)  147456      conv3_block4_2_pad[0][0]         
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 16, 16, 128)  0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 512)  0           conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_out (Add)          (None, 16, 16, 512)  0           max_pooling2d_1[0][0]            
                                                                 conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_preact_bn (BatchNo (None, 16, 16, 512)  2048        conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_preact_relu (Activ (None, 16, 16, 512)  0           conv4_block1_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131072      conv4_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block1_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv4_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_out (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_conv[0][0]        
                                                                 conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block2_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block2_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block2_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_out (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block3_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block3_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block3_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_out (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block4_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block4_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block4_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_out (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block5_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block5_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block5_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_out (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block6_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block6_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block6_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_out (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv4_block7_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block7_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block7_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block7_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block7_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block7_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_1_relu (Activation (None, 16, 16, 256)  0           conv4_block7_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block7_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block7_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block7_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block7_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block7_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block7_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_2_relu (Activation (None, 16, 16, 256)  0           conv4_block7_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block7_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block7_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block7_out (Add)          (None, 16, 16, 1024) 0           conv4_block6_out[0][0]           
                                                                 conv4_block7_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block7_out[0][0]           
__________________________________________________________________________________________________
conv4_block8_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block8_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block8_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block8_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block8_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block8_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_1_relu (Activation (None, 16, 16, 256)  0           conv4_block8_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block8_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block8_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block8_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block8_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block8_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block8_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_2_relu (Activation (None, 16, 16, 256)  0           conv4_block8_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block8_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block8_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block8_out (Add)          (None, 16, 16, 1024) 0           conv4_block7_out[0][0]           
                                                                 conv4_block8_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block8_out[0][0]           
__________________________________________________________________________________________________
conv4_block9_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block9_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block9_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block9_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block9_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block9_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_1_relu (Activation (None, 16, 16, 256)  0           conv4_block9_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block9_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block9_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block9_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block9_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block9_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block9_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_2_relu (Activation (None, 16, 16, 256)  0           conv4_block9_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block9_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block9_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block9_out (Add)          (None, 16, 16, 1024) 0           conv4_block8_out[0][0]           
                                                                 conv4_block9_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block10_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block9_out[0][0]           
__________________________________________________________________________________________________
conv4_block10_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block10_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block10_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block10_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block10_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block10_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block10_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block10_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block10_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block10_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block10_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block10_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block10_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block10_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block10_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block10_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block10_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block10_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block10_out (Add)         (None, 16, 16, 1024) 0           conv4_block9_out[0][0]           
                                                                 conv4_block10_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block10_out[0][0]          
__________________________________________________________________________________________________
conv4_block11_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block11_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block11_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block11_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block11_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block11_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block11_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block11_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block11_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block11_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block11_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block11_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block11_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block11_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block11_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block11_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block11_out (Add)         (None, 16, 16, 1024) 0           conv4_block10_out[0][0]          
                                                                 conv4_block11_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block11_out[0][0]          
__________________________________________________________________________________________________
conv4_block12_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block12_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block12_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block12_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block12_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block12_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block12_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block12_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block12_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block12_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block12_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block12_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block12_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block12_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block12_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block12_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block12_out (Add)         (None, 16, 16, 1024) 0           conv4_block11_out[0][0]          
                                                                 conv4_block12_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block12_out[0][0]          
__________________________________________________________________________________________________
conv4_block13_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block13_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block13_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block13_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block13_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block13_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block13_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block13_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block13_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block13_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block13_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block13_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block13_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block13_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block13_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block13_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block13_out (Add)         (None, 16, 16, 1024) 0           conv4_block12_out[0][0]          
                                                                 conv4_block13_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block13_out[0][0]          
__________________________________________________________________________________________________
conv4_block14_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block14_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block14_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block14_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block14_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block14_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block14_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block14_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block14_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block14_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block14_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block14_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block14_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block14_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block14_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block14_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block14_out (Add)         (None, 16, 16, 1024) 0           conv4_block13_out[0][0]          
                                                                 conv4_block14_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block14_out[0][0]          
__________________________________________________________________________________________________
conv4_block15_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block15_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block15_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block15_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block15_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block15_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block15_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block15_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block15_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block15_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block15_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block15_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block15_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block15_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block15_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block15_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block15_out (Add)         (None, 16, 16, 1024) 0           conv4_block14_out[0][0]          
                                                                 conv4_block15_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block15_out[0][0]          
__________________________________________________________________________________________________
conv4_block16_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block16_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block16_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block16_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block16_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block16_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block16_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block16_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block16_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block16_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block16_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block16_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block16_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block16_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block16_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block16_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block16_out (Add)         (None, 16, 16, 1024) 0           conv4_block15_out[0][0]          
                                                                 conv4_block16_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block16_out[0][0]          
__________________________________________________________________________________________________
conv4_block17_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block17_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block17_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block17_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block17_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block17_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block17_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block17_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block17_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block17_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block17_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block17_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block17_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block17_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block17_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block17_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block17_out (Add)         (None, 16, 16, 1024) 0           conv4_block16_out[0][0]          
                                                                 conv4_block17_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block17_out[0][0]          
__________________________________________________________________________________________________
conv4_block18_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block18_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block18_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block18_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block18_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block18_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block18_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block18_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block18_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block18_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block18_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block18_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block18_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block18_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block18_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block18_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block18_out (Add)         (None, 16, 16, 1024) 0           conv4_block17_out[0][0]          
                                                                 conv4_block18_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block18_out[0][0]          
__________________________________________________________________________________________________
conv4_block19_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block19_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block19_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block19_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block19_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block19_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block19_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block19_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block19_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block19_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block19_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block19_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block19_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block19_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block19_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block19_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block19_out (Add)         (None, 16, 16, 1024) 0           conv4_block18_out[0][0]          
                                                                 conv4_block19_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block19_out[0][0]          
__________________________________________________________________________________________________
conv4_block20_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block20_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block20_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block20_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block20_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block20_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block20_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block20_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block20_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block20_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block20_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block20_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block20_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block20_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block20_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block20_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block20_out (Add)         (None, 16, 16, 1024) 0           conv4_block19_out[0][0]          
                                                                 conv4_block20_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block20_out[0][0]          
__________________________________________________________________________________________________
conv4_block21_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block21_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block21_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block21_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block21_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block21_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block21_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block21_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block21_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block21_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block21_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block21_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block21_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block21_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block21_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block21_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block21_out (Add)         (None, 16, 16, 1024) 0           conv4_block20_out[0][0]          
                                                                 conv4_block21_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block21_out[0][0]          
__________________________________________________________________________________________________
conv4_block22_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block22_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block22_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block22_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block22_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block22_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block22_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block22_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block22_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block22_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block22_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block22_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block22_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block22_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block22_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block22_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block22_out (Add)         (None, 16, 16, 1024) 0           conv4_block21_out[0][0]          
                                                                 conv4_block22_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block22_out[0][0]          
__________________________________________________________________________________________________
conv4_block23_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block23_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block23_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block23_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block23_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block23_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block23_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block23_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block23_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block23_2_conv (Conv2D)   (None, 8, 8, 256)    589824      conv4_block23_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block23_2_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block23_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_2_relu (Activatio (None, 8, 8, 256)    0           conv4_block23_2_bn[0][0]         
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 1024)   0           conv4_block22_out[0][0]          
__________________________________________________________________________________________________
conv4_block23_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      conv4_block23_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block23_out (Add)         (None, 8, 8, 1024)   0           max_pooling2d_2[0][0]            
                                                                 conv4_block23_3_conv[0][0]       
__________________________________________________________________________________________________
conv5_block1_preact_bn (BatchNo (None, 8, 8, 1024)   4096        conv4_block23_out[0][0]          
__________________________________________________________________________________________________
conv5_block1_preact_relu (Activ (None, 8, 8, 1024)   0           conv5_block1_preact_bn[0][0]     
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524288      conv5_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block1_2_pad[0][0]         
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv5_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_out (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_conv[0][0]        
                                                                 conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_preact_bn (BatchNo (None, 8, 8, 2048)   8192        conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_preact_relu (Activ (None, 8, 8, 2048)   0           conv5_block2_preact_bn[0][0]     
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1048576     conv5_block2_preact_relu[0][0]   
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block2_2_pad[0][0]         
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_out (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_preact_bn (BatchNo (None, 8, 8, 2048)   8192        conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_preact_relu (Activ (None, 8, 8, 2048)   0           conv5_block3_preact_bn[0][0]     
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1048576     conv5_block3_preact_relu[0][0]   
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block3_2_pad[0][0]         
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_out (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
post_bn (BatchNormalization)    (None, 8, 8, 2048)   8192        conv5_block3_out[0][0]           
__________________________________________________________________________________________________
post_relu (Activation)          (None, 8, 8, 2048)   0           post_bn[0][0]                    
__________________________________________________________________________________________________
flatten (Flatten)               (None, 131072)       0           post_relu[0][0]                  
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         536875008   flatten[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
predictions (Dense)             (None, 5)            20485       fc2[0][0]                        
==================================================================================================
Total params: 596,303,365
Trainable params: 596,205,701
Non-trainable params: 97,664
__________________________________________________________________________________________________
Start fitting ensemble models
Random seed for replication: 920
Length split part:  1398
Labels in this part of split:  [274, 263, 281, 280, 300]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 52s - loss: 1.5824 - accuracy: 0.4464 - val_loss: 1.4138 - val_accuracy: 0.3911
Epoch 2/500
44/44 - 35s - loss: 0.0537 - accuracy: 0.9957 - val_loss: 1.3820 - val_accuracy: 0.4134
Epoch 3/500
44/44 - 31s - loss: 0.0096 - accuracy: 0.9979 - val_loss: 1.3117 - val_accuracy: 0.4972
Epoch 4/500
44/44 - 12s - loss: 0.0065 - accuracy: 0.9993 - val_loss: 1.3642 - val_accuracy: 0.4972
Epoch 5/500
44/44 - 32s - loss: 0.0140 - accuracy: 0.9986 - val_loss: 1.2893 - val_accuracy: 0.5475
Epoch 6/500
44/44 - 12s - loss: 0.0029 - accuracy: 0.9993 - val_loss: 1.3375 - val_accuracy: 0.5475
Epoch 7/500
44/44 - 12s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3165 - val_accuracy: 0.5754
Epoch 8/500
44/44 - 12s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3250 - val_accuracy: 0.5531
Epoch 9/500
44/44 - 33s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2769 - val_accuracy: 0.5866
Epoch 10/500
44/44 - 32s - loss: 9.9527e-04 - accuracy: 1.0000 - val_loss: 1.2095 - val_accuracy: 0.6201
Epoch 11/500
44/44 - 34s - loss: 8.6403e-04 - accuracy: 1.0000 - val_loss: 1.1624 - val_accuracy: 0.6480
Epoch 12/500
44/44 - 12s - loss: 7.6376e-04 - accuracy: 1.0000 - val_loss: 1.1829 - val_accuracy: 0.6257
Epoch 13/500
44/44 - 12s - loss: 6.8050e-04 - accuracy: 1.0000 - val_loss: 1.2097 - val_accuracy: 0.6257
Epoch 14/500
44/44 - 12s - loss: 6.1287e-04 - accuracy: 1.0000 - val_loss: 1.2459 - val_accuracy: 0.6145
Epoch 15/500
44/44 - 12s - loss: 5.5537e-04 - accuracy: 1.0000 - val_loss: 1.2654 - val_accuracy: 0.6257
Epoch 16/500
44/44 - 12s - loss: 5.0449e-04 - accuracy: 1.0000 - val_loss: 1.2780 - val_accuracy: 0.6201
Epoch 17/500
44/44 - 12s - loss: 4.6157e-04 - accuracy: 1.0000 - val_loss: 1.2859 - val_accuracy: 0.6145
Epoch 18/500
44/44 - 12s - loss: 4.2467e-04 - accuracy: 1.0000 - val_loss: 1.2906 - val_accuracy: 0.6089
Epoch 19/500
44/44 - 12s - loss: 3.9106e-04 - accuracy: 1.0000 - val_loss: 1.2956 - val_accuracy: 0.6089
Epoch 20/500
44/44 - 12s - loss: 3.6171e-04 - accuracy: 1.0000 - val_loss: 1.3003 - val_accuracy: 0.6089
Epoch 21/500
44/44 - 12s - loss: 3.3615e-04 - accuracy: 1.0000 - val_loss: 1.3054 - val_accuracy: 0.6034
Epoch 22/500
44/44 - 12s - loss: 3.1276e-04 - accuracy: 1.0000 - val_loss: 1.3094 - val_accuracy: 0.6089
Epoch 23/500
44/44 - 12s - loss: 2.9189e-04 - accuracy: 1.0000 - val_loss: 1.3139 - val_accuracy: 0.6089
Epoch 24/500
44/44 - 12s - loss: 2.7336e-04 - accuracy: 1.0000 - val_loss: 1.3188 - val_accuracy: 0.6034
Epoch 25/500
44/44 - 12s - loss: 2.5624e-04 - accuracy: 1.0000 - val_loss: 1.3225 - val_accuracy: 0.6034
Epoch 26/500
44/44 - 12s - loss: 2.4072e-04 - accuracy: 1.0000 - val_loss: 1.3271 - val_accuracy: 0.6034
Epoch 27/500
44/44 - 12s - loss: 2.2668e-04 - accuracy: 1.0000 - val_loss: 1.3312 - val_accuracy: 0.5922
Epoch 28/500
44/44 - 12s - loss: 2.1390e-04 - accuracy: 1.0000 - val_loss: 1.3351 - val_accuracy: 0.6089
Epoch 29/500
44/44 - 12s - loss: 2.0212e-04 - accuracy: 1.0000 - val_loss: 1.3382 - val_accuracy: 0.5978
Epoch 30/500
44/44 - 12s - loss: 1.9098e-04 - accuracy: 1.0000 - val_loss: 1.3416 - val_accuracy: 0.5978
Epoch 31/500
44/44 - 12s - loss: 1.8099e-04 - accuracy: 1.0000 - val_loss: 1.3459 - val_accuracy: 0.5978
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 14:26:43.286461: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 14:26:43.286612: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 14:26:43.286645: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 14:26:43.555029: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 14:26:43.555129: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00031: early stopping
Length split part:  1398
Labels in this part of split:  [282, 293, 271, 264, 288]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 31s - loss: 1.8197 - accuracy: 0.4535 - val_loss: 1.2404 - val_accuracy: 0.6369
Epoch 2/500
44/44 - 12s - loss: 0.2314 - accuracy: 0.9235 - val_loss: 1.6077 - val_accuracy: 0.3408
Epoch 3/500
44/44 - 12s - loss: 0.0260 - accuracy: 0.9971 - val_loss: 1.8179 - val_accuracy: 0.3240
Epoch 4/500
44/44 - 12s - loss: 0.0222 - accuracy: 0.9964 - val_loss: 1.5027 - val_accuracy: 0.4972
Epoch 5/500
44/44 - 12s - loss: 0.0121 - accuracy: 0.9971 - val_loss: 1.7182 - val_accuracy: 0.3743
Epoch 6/500
44/44 - 12s - loss: 0.0053 - accuracy: 0.9979 - val_loss: 1.6789 - val_accuracy: 0.4022
Epoch 7/500
44/44 - 12s - loss: 0.0018 - accuracy: 0.9993 - val_loss: 1.5095 - val_accuracy: 0.4804
Epoch 8/500
44/44 - 13s - loss: 8.4475e-04 - accuracy: 1.0000 - val_loss: 1.3545 - val_accuracy: 0.5419
Epoch 9/500
44/44 - 12s - loss: 7.2185e-04 - accuracy: 1.0000 - val_loss: 1.2543 - val_accuracy: 0.5587
Epoch 10/500
44/44 - 29s - loss: 6.2478e-04 - accuracy: 1.0000 - val_loss: 1.2209 - val_accuracy: 0.5978
Epoch 11/500
44/44 - 12s - loss: 5.5056e-04 - accuracy: 1.0000 - val_loss: 1.2311 - val_accuracy: 0.6257
Epoch 12/500
44/44 - 12s - loss: 4.9291e-04 - accuracy: 1.0000 - val_loss: 1.2492 - val_accuracy: 0.6369
Epoch 13/500
44/44 - 12s - loss: 4.4553e-04 - accuracy: 1.0000 - val_loss: 1.2756 - val_accuracy: 0.6425
Epoch 14/500
44/44 - 12s - loss: 4.0517e-04 - accuracy: 1.0000 - val_loss: 1.2846 - val_accuracy: 0.6369
Epoch 15/500
44/44 - 12s - loss: 3.7146e-04 - accuracy: 1.0000 - val_loss: 1.2975 - val_accuracy: 0.6425
Epoch 16/500
44/44 - 12s - loss: 3.4183e-04 - accuracy: 1.0000 - val_loss: 1.3065 - val_accuracy: 0.6480
Epoch 17/500
44/44 - 12s - loss: 3.1603e-04 - accuracy: 1.0000 - val_loss: 1.3164 - val_accuracy: 0.6480
Epoch 18/500
44/44 - 12s - loss: 2.9344e-04 - accuracy: 1.0000 - val_loss: 1.3254 - val_accuracy: 0.6480
Epoch 19/500
44/44 - 12s - loss: 2.7359e-04 - accuracy: 1.0000 - val_loss: 1.3338 - val_accuracy: 0.6480
Epoch 20/500
44/44 - 12s - loss: 2.5554e-04 - accuracy: 1.0000 - val_loss: 1.3395 - val_accuracy: 0.6480
Epoch 21/500
44/44 - 12s - loss: 2.3970e-04 - accuracy: 1.0000 - val_loss: 1.3464 - val_accuracy: 0.6480
Epoch 22/500
44/44 - 12s - loss: 2.2525e-04 - accuracy: 1.0000 - val_loss: 1.3535 - val_accuracy: 0.6480
Epoch 23/500
44/44 - 12s - loss: 2.1202e-04 - accuracy: 1.0000 - val_loss: 1.3620 - val_accuracy: 0.6480
Epoch 24/500
44/44 - 12s - loss: 1.9998e-04 - accuracy: 1.0000 - val_loss: 1.3668 - val_accuracy: 0.6480
Epoch 25/500
44/44 - 12s - loss: 1.8913e-04 - accuracy: 1.0000 - val_loss: 1.3729 - val_accuracy: 0.6480
Epoch 26/500
44/44 - 12s - loss: 1.7910e-04 - accuracy: 1.0000 - val_loss: 1.3794 - val_accuracy: 0.6480
Epoch 27/500
44/44 - 12s - loss: 1.6962e-04 - accuracy: 1.0000 - val_loss: 1.3838 - val_accuracy: 0.6480
Epoch 28/500
44/44 - 12s - loss: 1.6115e-04 - accuracy: 1.0000 - val_loss: 1.3889 - val_accuracy: 0.6480
Epoch 29/500
44/44 - 12s - loss: 1.5323e-04 - accuracy: 1.0000 - val_loss: 1.3945 - val_accuracy: 0.6480
Epoch 30/500
44/44 - 12s - loss: 1.4583e-04 - accuracy: 1.0000 - val_loss: 1.4018 - val_accuracy: 0.6480
Epoch 31/500
44/44 - 12s - loss: 1.3895e-04 - accuracy: 1.0000 - val_loss: 1.4070 - val_accuracy: 0.6480
Epoch 32/500
44/44 - 12s - loss: 1.3275e-04 - accuracy: 1.0000 - val_loss: 1.4130 - val_accuracy: 0.6480
Epoch 33/500
44/44 - 12s - loss: 1.2665e-04 - accuracy: 1.0000 - val_loss: 1.4168 - val_accuracy: 0.6480
Epoch 34/500
44/44 - 12s - loss: 1.2111e-04 - accuracy: 1.0000 - val_loss: 1.4227 - val_accuracy: 0.6480
Epoch 35/500
44/44 - 12s - loss: 1.1583e-04 - accuracy: 1.0000 - val_loss: 1.4273 - val_accuracy: 0.6480
Epoch 36/500
44/44 - 12s - loss: 1.1097e-04 - accuracy: 1.0000 - val_loss: 1.4317 - val_accuracy: 0.6536
Epoch 37/500
44/44 - 12s - loss: 1.0639e-04 - accuracy: 1.0000 - val_loss: 1.4358 - val_accuracy: 0.6480
Epoch 38/500
44/44 - 12s - loss: 1.0202e-04 - accuracy: 1.0000 - val_loss: 1.4388 - val_accuracy: 0.6480
Epoch 39/500
44/44 - 12s - loss: 9.7822e-05 - accuracy: 1.0000 - val_loss: 1.4439 - val_accuracy: 0.6480
Epoch 40/500
44/44 - 12s - loss: 9.3962e-05 - accuracy: 1.0000 - val_loss: 1.4496 - val_accuracy: 0.6480
Epoch 41/500
44/44 - 12s - loss: 9.0270e-05 - accuracy: 1.0000 - val_loss: 1.4536 - val_accuracy: 0.6480
Epoch 42/500
44/44 - 12s - loss: 8.6838e-05 - accuracy: 1.0000 - val_loss: 1.4552 - val_accuracy: 0.6480
Epoch 43/500
44/44 - 12s - loss: 8.3505e-05 - accuracy: 1.0000 - val_loss: 1.4625 - val_accuracy: 0.6480
Epoch 44/500
44/44 - 12s - loss: 8.0377e-05 - accuracy: 1.0000 - val_loss: 1.4675 - val_accuracy: 0.6480
Epoch 45/500
44/44 - 12s - loss: 7.7380e-05 - accuracy: 1.0000 - val_loss: 1.4717 - val_accuracy: 0.6536
Epoch 46/500
44/44 - 12s - loss: 7.4565e-05 - accuracy: 1.0000 - val_loss: 1.4747 - val_accuracy: 0.6536
Epoch 47/500
44/44 - 12s - loss: 7.1882e-05 - accuracy: 1.0000 - val_loss: 1.4787 - val_accuracy: 0.6536
Epoch 48/500
44/44 - 12s - loss: 6.9255e-05 - accuracy: 1.0000 - val_loss: 1.4824 - val_accuracy: 0.6536
Epoch 49/500
44/44 - 12s - loss: 6.6805e-05 - accuracy: 1.0000 - val_loss: 1.4869 - val_accuracy: 0.6536
Epoch 50/500
44/44 - 12s - loss: 6.4526e-05 - accuracy: 1.0000 - val_loss: 1.4918 - val_accuracy: 0.6536
Epoch 51/500
44/44 - 12s - loss: 6.2231e-05 - accuracy: 1.0000 - val_loss: 1.4966 - val_accuracy: 0.6536
Epoch 52/500
44/44 - 12s - loss: 6.0119e-05 - accuracy: 1.0000 - val_loss: 1.5015 - val_accuracy: 0.6536
Epoch 53/500
44/44 - 12s - loss: 5.8102e-05 - accuracy: 1.0000 - val_loss: 1.5040 - val_accuracy: 0.6536
Epoch 54/500
44/44 - 12s - loss: 5.6141e-05 - accuracy: 1.0000 - val_loss: 1.5080 - val_accuracy: 0.6480
Epoch 55/500
44/44 - 12s - loss: 5.4262e-05 - accuracy: 1.0000 - val_loss: 1.5134 - val_accuracy: 0.6536
Epoch 56/500
44/44 - 12s - loss: 5.2473e-05 - accuracy: 1.0000 - val_loss: 1.5169 - val_accuracy: 0.6480
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 14:39:19.880519: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 14:39:19.880671: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 14:39:19.880704: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 14:39:20.149447: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 14:39:20.149545: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00056: early stopping
Length split part:  1397
Labels in this part of split:  [284, 284, 287, 294, 248]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 28s - loss: 1.8603 - accuracy: 0.4674 - val_loss: 1.9807 - val_accuracy: 0.1564
Epoch 2/500
44/44 - 30s - loss: 0.2437 - accuracy: 0.9291 - val_loss: 1.9262 - val_accuracy: 0.2346
Epoch 3/500
44/44 - 12s - loss: 0.0196 - accuracy: 0.9986 - val_loss: 2.1526 - val_accuracy: 0.2291
Epoch 4/500
44/44 - 12s - loss: 0.0084 - accuracy: 0.9993 - val_loss: 2.1259 - val_accuracy: 0.2458
Epoch 5/500
44/44 - 12s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.9652 - val_accuracy: 0.2905
Epoch 6/500
44/44 - 32s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.8457 - val_accuracy: 0.3743
Epoch 7/500
44/44 - 31s - loss: 8.1805e-04 - accuracy: 1.0000 - val_loss: 1.7715 - val_accuracy: 0.4134
Epoch 8/500
44/44 - 31s - loss: 6.7876e-04 - accuracy: 1.0000 - val_loss: 1.6195 - val_accuracy: 0.4916
Epoch 9/500
44/44 - 31s - loss: 5.8101e-04 - accuracy: 1.0000 - val_loss: 1.5290 - val_accuracy: 0.5363
Epoch 10/500
44/44 - 30s - loss: 5.0811e-04 - accuracy: 1.0000 - val_loss: 1.4692 - val_accuracy: 0.5363
Epoch 11/500
44/44 - 29s - loss: 4.4997e-04 - accuracy: 1.0000 - val_loss: 1.4441 - val_accuracy: 0.5698
Epoch 12/500
44/44 - 12s - loss: 4.0336e-04 - accuracy: 1.0000 - val_loss: 1.4523 - val_accuracy: 0.5754
Epoch 13/500
44/44 - 12s - loss: 3.6474e-04 - accuracy: 1.0000 - val_loss: 1.4743 - val_accuracy: 0.5810
Epoch 14/500
44/44 - 12s - loss: 3.3299e-04 - accuracy: 1.0000 - val_loss: 1.5032 - val_accuracy: 0.5922
Epoch 15/500
44/44 - 12s - loss: 3.0497e-04 - accuracy: 1.0000 - val_loss: 1.5317 - val_accuracy: 0.6034
Epoch 16/500
44/44 - 12s - loss: 2.8111e-04 - accuracy: 1.0000 - val_loss: 1.5515 - val_accuracy: 0.6257
Epoch 17/500
44/44 - 12s - loss: 2.6005e-04 - accuracy: 1.0000 - val_loss: 1.5662 - val_accuracy: 0.6313
Epoch 18/500
44/44 - 12s - loss: 2.4186e-04 - accuracy: 1.0000 - val_loss: 1.5796 - val_accuracy: 0.6369
Epoch 19/500
44/44 - 12s - loss: 2.2534e-04 - accuracy: 1.0000 - val_loss: 1.5905 - val_accuracy: 0.6369
Epoch 20/500
44/44 - 12s - loss: 2.1077e-04 - accuracy: 1.0000 - val_loss: 1.6006 - val_accuracy: 0.6425
Epoch 21/500
44/44 - 12s - loss: 1.9752e-04 - accuracy: 1.0000 - val_loss: 1.6107 - val_accuracy: 0.6480
Epoch 22/500
44/44 - 12s - loss: 1.8589e-04 - accuracy: 1.0000 - val_loss: 1.6185 - val_accuracy: 0.6480
Epoch 23/500
44/44 - 12s - loss: 1.7497e-04 - accuracy: 1.0000 - val_loss: 1.6270 - val_accuracy: 0.6480
Epoch 24/500
44/44 - 12s - loss: 1.6519e-04 - accuracy: 1.0000 - val_loss: 1.6343 - val_accuracy: 0.6480
Epoch 25/500
44/44 - 12s - loss: 1.5631e-04 - accuracy: 1.0000 - val_loss: 1.6418 - val_accuracy: 0.6480
Epoch 26/500
44/44 - 12s - loss: 1.4799e-04 - accuracy: 1.0000 - val_loss: 1.6493 - val_accuracy: 0.6480
Epoch 27/500
44/44 - 12s - loss: 1.4049e-04 - accuracy: 1.0000 - val_loss: 1.6572 - val_accuracy: 0.6480
Epoch 28/500
44/44 - 12s - loss: 1.3345e-04 - accuracy: 1.0000 - val_loss: 1.6628 - val_accuracy: 0.6425
Epoch 29/500
44/44 - 12s - loss: 1.2688e-04 - accuracy: 1.0000 - val_loss: 1.6694 - val_accuracy: 0.6425
Epoch 30/500
44/44 - 12s - loss: 1.2084e-04 - accuracy: 1.0000 - val_loss: 1.6763 - val_accuracy: 0.6480
Epoch 31/500
44/44 - 12s - loss: 1.1527e-04 - accuracy: 1.0000 - val_loss: 1.6816 - val_accuracy: 0.6480
Epoch 32/500
44/44 - 12s - loss: 1.0999e-04 - accuracy: 1.0000 - val_loss: 1.6880 - val_accuracy: 0.6425
Epoch 33/500
44/44 - 12s - loss: 1.0504e-04 - accuracy: 1.0000 - val_loss: 1.6945 - val_accuracy: 0.6425
Epoch 34/500
44/44 - 12s - loss: 1.0043e-04 - accuracy: 1.0000 - val_loss: 1.7004 - val_accuracy: 0.6480
Epoch 35/500
44/44 - 12s - loss: 9.6127e-05 - accuracy: 1.0000 - val_loss: 1.7051 - val_accuracy: 0.6425
Epoch 36/500
44/44 - 12s - loss: 9.2087e-05 - accuracy: 1.0000 - val_loss: 1.7123 - val_accuracy: 0.6425
Epoch 37/500
44/44 - 12s - loss: 8.8250e-05 - accuracy: 1.0000 - val_loss: 1.7180 - val_accuracy: 0.6425
Epoch 38/500
44/44 - 12s - loss: 8.4672e-05 - accuracy: 1.0000 - val_loss: 1.7232 - val_accuracy: 0.6425
Epoch 39/500
44/44 - 12s - loss: 8.1249e-05 - accuracy: 1.0000 - val_loss: 1.7286 - val_accuracy: 0.6480
Epoch 40/500
44/44 - 12s - loss: 7.8056e-05 - accuracy: 1.0000 - val_loss: 1.7337 - val_accuracy: 0.6425
Epoch 41/500
44/44 - 12s - loss: 7.5020e-05 - accuracy: 1.0000 - val_loss: 1.7383 - val_accuracy: 0.6425
Epoch 00041: early stopping
ResNet152V2
Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5
     8192/234545216 [..............................] - ETA: 2s    24576/234545216 [..............................] - ETA: 15:15    57344/234545216 [..............................] - ETA: 13:15   122880/234545216 [..............................] - ETA: 9:18    303104/234545216 [..............................] - ETA: 5:02   614400/234545216 [..............................] - ETA: 3:06  1253376/234545216 [..............................] - ETA: 1:49  2539520/234545216 [..............................] - ETA: 1:02  5095424/234545216 [..............................] - ETA: 35s   8241152/234545216 [>.............................] - ETA: 24s 11370496/234545216 [>.............................] - ETA: 19s 14499840/234545216 [>.............................] - ETA: 16s 17629184/234545216 [=>............................] - ETA: 14s 20774912/234545216 [=>............................] - ETA: 13s 23904256/234545216 [==>...........................] - ETA: 12s 27049984/234545216 [==>...........................] - ETA: 11s 30179328/234545216 [==>...........................] - ETA: 10s 33308672/234545216 [===>..........................] - ETA: 10s 36454400/234545216 [===>..........................] - ETA: 9s  39600128/234545216 [====>.........................] - ETA: 9s 42729472/234545216 [====>.........................] - ETA: 8s 45744128/234545216 [====>.........................] - ETA: 8s 46006272/234545216 [====>.........................] - ETA: 8s 49004544/234545216 [=====>........................] - ETA: 8s 51920896/234545216 [=====>........................] - ETA: 7s 52264960/234545216 [=====>........................] - ETA: 7s 55197696/234545216 [======>.......................] - ETA: 7s 55427072/234545216 [======>.......................] - ETA: 7s 58146816/234545216 [======>.......................] - ETA: 7s 58605568/234545216 [======>.......................] - ETA: 7s 61538304/234545216 [======>.......................] - ETA: 7s 63946752/234545216 [=======>......................] - ETA: 6s 64716800/234545216 [=======>......................] - ETA: 6s 67117056/234545216 [=======>......................] - ETA: 6s 68026368/234545216 [=======>......................] - ETA: 6s 70860800/234545216 [========>.....................] - ETA: 6s 71188480/234545216 [========>.....................] - ETA: 6s 74072064/234545216 [========>.....................] - ETA: 6s 76513280/234545216 [========>.....................] - ETA: 6s 77266944/234545216 [========>.....................] - ETA: 6s 79659008/234545216 [=========>....................] - ETA: 6s 80576512/234545216 [=========>....................] - ETA: 6s 83034112/234545216 [=========>....................] - ETA: 5s 83722240/234545216 [=========>....................] - ETA: 5s 86409216/234545216 [==========>...................] - ETA: 5s 86917120/234545216 [==========>...................] - ETA: 5s 89751552/234545216 [==========>...................] - ETA: 5s 91455488/234545216 [==========>...................] - ETA: 5s 92962816/234545216 [==========>...................] - ETA: 5s 94830592/234545216 [===========>..................] - ETA: 5s 95846400/234545216 [===========>..................] - ETA: 5s 98140160/234545216 [===========>..................] - ETA: 5s 99172352/234545216 [===========>..................] - ETA: 5s101449728/234545216 [===========>..................] - ETA: 4s102481920/234545216 [============>.................] - ETA: 4s104333312/234545216 [============>.................] - ETA: 4s105660416/234545216 [============>.................] - ETA: 4s107855872/234545216 [============>.................] - ETA: 4s108822528/234545216 [============>.................] - ETA: 4s111083520/234545216 [=============>................] - ETA: 4s113065984/234545216 [=============>................] - ETA: 4s114278400/234545216 [=============>................] - ETA: 4s116391936/234545216 [=============>................] - ETA: 4s117448704/234545216 [==============>...............] - ETA: 4s119701504/234545216 [==============>...............] - ETA: 4s120733696/234545216 [==============>...............] - ETA: 4s123002880/234545216 [==============>...............] - ETA: 4s124026880/234545216 [==============>...............] - ETA: 4s125861888/234545216 [===============>..............] - ETA: 3s127320064/234545216 [===============>..............] - ETA: 3s129155072/234545216 [===============>..............] - ETA: 3s130547712/234545216 [===============>..............] - ETA: 3s132448256/234545216 [===============>..............] - ETA: 3s133480448/234545216 [================>.............] - ETA: 3s135700480/234545216 [================>.............] - ETA: 3s136757248/234545216 [================>.............] - ETA: 3s139001856/234545216 [================>.............] - ETA: 3s140017664/234545216 [================>.............] - ETA: 3s141967360/234545216 [=================>............] - ETA: 3s143278080/234545216 [=================>............] - ETA: 3s145260544/234545216 [=================>............] - ETA: 3s146276352/234545216 [=================>............] - ETA: 3s148471808/234545216 [=================>............] - ETA: 3s149577728/234545216 [==================>...........] - ETA: 3s151519232/234545216 [==================>...........] - ETA: 2s152838144/234545216 [==================>...........] - ETA: 2s154615808/234545216 [==================>...........] - ETA: 2s155992064/234545216 [==================>...........] - ETA: 2s157990912/234545216 [===================>..........] - ETA: 2s159170560/234545216 [===================>..........] - ETA: 2s161234944/234545216 [===================>..........] - ETA: 2s162447360/234545216 [===================>..........] - ETA: 2s164462592/234545216 [====================>.........] - ETA: 2s165625856/234545216 [====================>.........] - ETA: 2s167624704/234545216 [====================>.........] - ETA: 2s168804352/234545216 [====================>.........] - ETA: 2s170803200/234545216 [====================>.........] - ETA: 2s171974656/234545216 [====================>.........] - ETA: 2s173998080/234545216 [=====================>........] - ETA: 2s175423488/234545216 [=====================>........] - ETA: 2s177160192/234545216 [=====================>........] - ETA: 2s179150848/234545216 [=====================>........] - ETA: 1s180338688/234545216 [======================>.......] - ETA: 1s182435840/234545216 [======================>.......] - ETA: 1s183500800/234545216 [======================>.......] - ETA: 1s185991168/234545216 [======================>.......] - ETA: 1s186793984/234545216 [======================>.......] - ETA: 1s188997632/234545216 [=======================>......] - ETA: 1s190070784/234545216 [=======================>......] - ETA: 1s192086016/234545216 [=======================>......] - ETA: 1s192946176/234545216 [=======================>......] - ETA: 1s195379200/234545216 [=======================>......] - ETA: 1s196231168/234545216 [========================>.....] - ETA: 1s198524928/234545216 [========================>.....] - ETA: 1s199524352/234545216 [========================>.....] - ETA: 1s201826304/234545216 [========================>.....] - ETA: 1s202817536/234545216 [========================>.....] - ETA: 1s204931072/234545216 [=========================>....] - ETA: 1s206110720/234545216 [=========================>....] - ETA: 0s208199680/234545216 [=========================>....] - ETA: 0s209018880/234545216 [=========================>....] - ETA: 0s211419136/234545216 [==========================>...] - ETA: 0s212320256/234545216 [==========================>...] - ETA: 0s214614016/234545216 [==========================>...] - ETA: 0s215777280/234545216 [==========================>...] - ETA: 0s217825280/234545216 [==========================>...] - ETA: 0s218955776/234545216 [===========================>..] - ETA: 0s220971008/234545216 [===========================>..] - ETA: 0s222134272/234545216 [===========================>..] - ETA: 0s224133120/234545216 [===========================>..] - ETA: 0s225296384/234545216 [===========================>..] - ETA: 0s227344384/234545216 [============================>.] - ETA: 0s228507648/234545216 [============================>.] - ETA: 0s230522880/234545216 [============================>.] - ETA: 0s231669760/234545216 [============================>.] - ETA: 0s233701376/234545216 [============================>.] - ETA: 0s234553344/234545216 [==============================] - 8s 0us/step
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 14:51:42.332945: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 14:51:42.333122: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 14:51:42.333156: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 14:51:42.707790: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 14:51:42.707889: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_conv[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_preact_bn (BatchNo (None, 64, 64, 64)   256         pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_preact_relu (Activ (None, 64, 64, 64)   0           conv2_block1_preact_bn[0][0]     
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4096        conv2_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block1_2_pad[0][0]         
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_out (Add)          (None, 64, 64, 256)  0           conv2_block1_0_conv[0][0]        
                                                                 conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_preact_relu (Activ (None, 64, 64, 256)  0           conv2_block2_preact_bn[0][0]     
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16384       conv2_block2_preact_relu[0][0]   
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block2_2_pad[0][0]         
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_out (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_preact_relu (Activ (None, 64, 64, 256)  0           conv2_block3_preact_bn[0][0]     
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16384       conv2_block3_preact_relu[0][0]   
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 32, 32, 64)   36864       conv2_block3_2_pad[0][0]         
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 32, 32, 64)   0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 32, 32, 256)  0           conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_out (Add)          (None, 32, 32, 256)  0           max_pooling2d[0][0]              
                                                                 conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_preact_bn (BatchNo (None, 32, 32, 256)  1024        conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_preact_relu (Activ (None, 32, 32, 256)  0           conv3_block1_preact_bn[0][0]     
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32768       conv3_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block1_2_pad[0][0]         
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv3_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_out (Add)          (None, 32, 32, 512)  0           conv3_block1_0_conv[0][0]        
                                                                 conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block2_preact_bn[0][0]     
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block2_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block2_2_pad[0][0]         
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_out (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block3_preact_bn[0][0]     
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block3_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block3_2_pad[0][0]         
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_out (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block4_preact_bn[0][0]     
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block4_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block4_2_pad[0][0]         
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_out (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block5_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv3_block5_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block5_preact_bn[0][0]     
__________________________________________________________________________________________________
conv3_block5_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block5_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block5_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block5_1_relu (Activation (None, 32, 32, 128)  0           conv3_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block5_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block5_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block5_2_pad[0][0]         
__________________________________________________________________________________________________
conv3_block5_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block5_2_relu (Activation (None, 32, 32, 128)  0           conv3_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block5_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block5_out (Add)          (None, 32, 32, 512)  0           conv3_block4_out[0][0]           
                                                                 conv3_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block6_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block5_out[0][0]           
__________________________________________________________________________________________________
conv3_block6_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block6_preact_bn[0][0]     
__________________________________________________________________________________________________
conv3_block6_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block6_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block6_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block6_1_relu (Activation (None, 32, 32, 128)  0           conv3_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block6_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block6_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block6_2_pad[0][0]         
__________________________________________________________________________________________________
conv3_block6_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block6_2_relu (Activation (None, 32, 32, 128)  0           conv3_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block6_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block6_out (Add)          (None, 32, 32, 512)  0           conv3_block5_out[0][0]           
                                                                 conv3_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block7_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block6_out[0][0]           
__________________________________________________________________________________________________
conv3_block7_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block7_preact_bn[0][0]     
__________________________________________________________________________________________________
conv3_block7_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block7_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block7_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block7_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block7_1_relu (Activation (None, 32, 32, 128)  0           conv3_block7_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block7_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block7_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block7_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block7_2_pad[0][0]         
__________________________________________________________________________________________________
conv3_block7_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block7_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block7_2_relu (Activation (None, 32, 32, 128)  0           conv3_block7_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block7_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block7_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block7_out (Add)          (None, 32, 32, 512)  0           conv3_block6_out[0][0]           
                                                                 conv3_block7_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block8_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block7_out[0][0]           
__________________________________________________________________________________________________
conv3_block8_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block8_preact_bn[0][0]     
__________________________________________________________________________________________________
conv3_block8_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block8_preact_relu[0][0]   
__________________________________________________________________________________________________
conv3_block8_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block8_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block8_1_relu (Activation (None, 32, 32, 128)  0           conv3_block8_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block8_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block8_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block8_2_conv (Conv2D)    (None, 16, 16, 128)  147456      conv3_block8_2_pad[0][0]         
__________________________________________________________________________________________________
conv3_block8_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block8_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block8_2_relu (Activation (None, 16, 16, 128)  0           conv3_block8_2_bn[0][0]          
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 512)  0           conv3_block7_out[0][0]           
__________________________________________________________________________________________________
conv3_block8_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block8_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block8_out (Add)          (None, 16, 16, 512)  0           max_pooling2d_1[0][0]            
                                                                 conv3_block8_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_preact_bn (BatchNo (None, 16, 16, 512)  2048        conv3_block8_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_preact_relu (Activ (None, 16, 16, 512)  0           conv4_block1_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131072      conv4_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block1_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv4_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_out (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_conv[0][0]        
                                                                 conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block2_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block2_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block2_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_out (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block3_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block3_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block3_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_out (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block4_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block4_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block4_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_out (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block5_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block5_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block5_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_out (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block6_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block6_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block6_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_out (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv4_block7_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block7_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block7_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block7_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block7_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block7_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_1_relu (Activation (None, 16, 16, 256)  0           conv4_block7_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block7_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block7_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block7_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block7_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block7_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block7_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_2_relu (Activation (None, 16, 16, 256)  0           conv4_block7_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block7_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block7_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block7_out (Add)          (None, 16, 16, 1024) 0           conv4_block6_out[0][0]           
                                                                 conv4_block7_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block7_out[0][0]           
__________________________________________________________________________________________________
conv4_block8_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block8_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block8_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block8_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block8_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block8_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_1_relu (Activation (None, 16, 16, 256)  0           conv4_block8_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block8_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block8_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block8_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block8_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block8_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block8_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_2_relu (Activation (None, 16, 16, 256)  0           conv4_block8_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block8_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block8_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block8_out (Add)          (None, 16, 16, 1024) 0           conv4_block7_out[0][0]           
                                                                 conv4_block8_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block8_out[0][0]           
__________________________________________________________________________________________________
conv4_block9_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block9_preact_bn[0][0]     
__________________________________________________________________________________________________
conv4_block9_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block9_preact_relu[0][0]   
__________________________________________________________________________________________________
conv4_block9_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block9_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_1_relu (Activation (None, 16, 16, 256)  0           conv4_block9_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block9_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block9_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block9_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block9_2_pad[0][0]         
__________________________________________________________________________________________________
conv4_block9_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block9_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_2_relu (Activation (None, 16, 16, 256)  0           conv4_block9_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block9_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block9_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block9_out (Add)          (None, 16, 16, 1024) 0           conv4_block8_out[0][0]           
                                                                 conv4_block9_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block10_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block9_out[0][0]           
__________________________________________________________________________________________________
conv4_block10_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block10_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block10_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block10_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block10_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block10_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block10_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block10_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block10_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block10_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block10_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block10_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block10_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block10_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block10_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block10_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block10_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block10_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block10_out (Add)         (None, 16, 16, 1024) 0           conv4_block9_out[0][0]           
                                                                 conv4_block10_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block10_out[0][0]          
__________________________________________________________________________________________________
conv4_block11_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block11_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block11_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block11_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block11_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block11_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block11_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block11_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block11_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block11_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block11_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block11_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block11_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block11_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block11_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block11_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block11_out (Add)         (None, 16, 16, 1024) 0           conv4_block10_out[0][0]          
                                                                 conv4_block11_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block11_out[0][0]          
__________________________________________________________________________________________________
conv4_block12_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block12_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block12_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block12_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block12_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block12_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block12_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block12_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block12_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block12_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block12_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block12_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block12_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block12_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block12_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block12_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block12_out (Add)         (None, 16, 16, 1024) 0           conv4_block11_out[0][0]          
                                                                 conv4_block12_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block12_out[0][0]          
__________________________________________________________________________________________________
conv4_block13_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block13_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block13_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block13_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block13_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block13_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block13_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block13_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block13_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block13_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block13_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block13_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block13_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block13_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block13_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block13_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block13_out (Add)         (None, 16, 16, 1024) 0           conv4_block12_out[0][0]          
                                                                 conv4_block13_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block13_out[0][0]          
__________________________________________________________________________________________________
conv4_block14_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block14_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block14_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block14_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block14_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block14_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block14_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block14_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block14_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block14_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block14_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block14_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block14_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block14_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block14_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block14_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block14_out (Add)         (None, 16, 16, 1024) 0           conv4_block13_out[0][0]          
                                                                 conv4_block14_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block14_out[0][0]          
__________________________________________________________________________________________________
conv4_block15_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block15_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block15_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block15_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block15_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block15_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block15_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block15_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block15_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block15_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block15_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block15_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block15_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block15_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block15_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block15_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block15_out (Add)         (None, 16, 16, 1024) 0           conv4_block14_out[0][0]          
                                                                 conv4_block15_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block15_out[0][0]          
__________________________________________________________________________________________________
conv4_block16_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block16_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block16_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block16_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block16_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block16_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block16_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block16_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block16_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block16_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block16_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block16_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block16_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block16_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block16_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block16_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block16_out (Add)         (None, 16, 16, 1024) 0           conv4_block15_out[0][0]          
                                                                 conv4_block16_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block16_out[0][0]          
__________________________________________________________________________________________________
conv4_block17_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block17_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block17_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block17_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block17_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block17_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block17_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block17_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block17_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block17_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block17_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block17_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block17_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block17_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block17_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block17_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block17_out (Add)         (None, 16, 16, 1024) 0           conv4_block16_out[0][0]          
                                                                 conv4_block17_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block17_out[0][0]          
__________________________________________________________________________________________________
conv4_block18_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block18_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block18_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block18_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block18_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block18_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block18_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block18_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block18_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block18_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block18_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block18_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block18_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block18_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block18_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block18_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block18_out (Add)         (None, 16, 16, 1024) 0           conv4_block17_out[0][0]          
                                                                 conv4_block18_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block18_out[0][0]          
__________________________________________________________________________________________________
conv4_block19_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block19_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block19_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block19_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block19_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block19_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block19_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block19_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block19_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block19_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block19_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block19_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block19_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block19_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block19_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block19_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block19_out (Add)         (None, 16, 16, 1024) 0           conv4_block18_out[0][0]          
                                                                 conv4_block19_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block19_out[0][0]          
__________________________________________________________________________________________________
conv4_block20_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block20_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block20_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block20_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block20_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block20_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block20_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block20_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block20_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block20_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block20_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block20_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block20_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block20_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block20_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block20_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block20_out (Add)         (None, 16, 16, 1024) 0           conv4_block19_out[0][0]          
                                                                 conv4_block20_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block20_out[0][0]          
__________________________________________________________________________________________________
conv4_block21_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block21_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block21_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block21_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block21_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block21_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block21_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block21_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block21_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block21_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block21_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block21_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block21_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block21_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block21_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block21_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block21_out (Add)         (None, 16, 16, 1024) 0           conv4_block20_out[0][0]          
                                                                 conv4_block21_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block21_out[0][0]          
__________________________________________________________________________________________________
conv4_block22_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block22_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block22_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block22_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block22_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block22_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block22_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block22_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block22_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block22_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block22_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block22_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block22_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block22_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block22_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block22_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block22_out (Add)         (None, 16, 16, 1024) 0           conv4_block21_out[0][0]          
                                                                 conv4_block22_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block22_out[0][0]          
__________________________________________________________________________________________________
conv4_block23_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block23_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block23_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block23_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block23_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block23_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block23_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block23_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block23_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block23_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block23_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block23_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block23_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block23_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block23_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block23_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block23_out (Add)         (None, 16, 16, 1024) 0           conv4_block22_out[0][0]          
                                                                 conv4_block23_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block24_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block23_out[0][0]          
__________________________________________________________________________________________________
conv4_block24_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block24_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block24_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block24_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block24_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block24_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block24_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block24_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block24_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block24_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block24_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block24_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block24_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block24_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block24_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block24_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block24_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block24_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block24_out (Add)         (None, 16, 16, 1024) 0           conv4_block23_out[0][0]          
                                                                 conv4_block24_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block25_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block24_out[0][0]          
__________________________________________________________________________________________________
conv4_block25_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block25_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block25_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block25_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block25_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block25_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block25_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block25_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block25_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block25_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block25_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block25_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block25_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block25_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block25_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block25_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block25_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block25_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block25_out (Add)         (None, 16, 16, 1024) 0           conv4_block24_out[0][0]          
                                                                 conv4_block25_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block26_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block25_out[0][0]          
__________________________________________________________________________________________________
conv4_block26_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block26_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block26_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block26_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block26_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block26_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block26_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block26_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block26_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block26_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block26_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block26_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block26_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block26_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block26_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block26_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block26_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block26_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block26_out (Add)         (None, 16, 16, 1024) 0           conv4_block25_out[0][0]          
                                                                 conv4_block26_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block27_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block26_out[0][0]          
__________________________________________________________________________________________________
conv4_block27_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block27_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block27_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block27_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block27_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block27_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block27_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block27_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block27_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block27_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block27_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block27_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block27_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block27_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block27_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block27_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block27_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block27_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block27_out (Add)         (None, 16, 16, 1024) 0           conv4_block26_out[0][0]          
                                                                 conv4_block27_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block28_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block27_out[0][0]          
__________________________________________________________________________________________________
conv4_block28_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block28_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block28_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block28_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block28_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block28_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block28_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block28_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block28_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block28_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block28_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block28_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block28_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block28_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block28_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block28_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block28_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block28_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block28_out (Add)         (None, 16, 16, 1024) 0           conv4_block27_out[0][0]          
                                                                 conv4_block28_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block29_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block28_out[0][0]          
__________________________________________________________________________________________________
conv4_block29_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block29_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block29_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block29_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block29_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block29_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block29_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block29_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block29_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block29_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block29_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block29_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block29_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block29_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block29_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block29_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block29_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block29_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block29_out (Add)         (None, 16, 16, 1024) 0           conv4_block28_out[0][0]          
                                                                 conv4_block29_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block30_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block29_out[0][0]          
__________________________________________________________________________________________________
conv4_block30_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block30_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block30_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block30_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block30_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block30_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block30_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block30_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block30_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block30_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block30_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block30_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block30_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block30_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block30_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block30_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block30_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block30_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block30_out (Add)         (None, 16, 16, 1024) 0           conv4_block29_out[0][0]          
                                                                 conv4_block30_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block31_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block30_out[0][0]          
__________________________________________________________________________________________________
conv4_block31_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block31_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block31_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block31_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block31_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block31_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block31_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block31_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block31_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block31_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block31_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block31_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block31_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block31_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block31_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block31_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block31_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block31_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block31_out (Add)         (None, 16, 16, 1024) 0           conv4_block30_out[0][0]          
                                                                 conv4_block31_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block32_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block31_out[0][0]          
__________________________________________________________________________________________________
conv4_block32_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block32_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block32_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block32_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block32_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block32_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block32_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block32_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block32_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block32_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block32_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block32_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block32_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block32_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block32_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block32_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block32_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block32_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block32_out (Add)         (None, 16, 16, 1024) 0           conv4_block31_out[0][0]          
                                                                 conv4_block32_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block33_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block32_out[0][0]          
__________________________________________________________________________________________________
conv4_block33_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block33_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block33_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block33_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block33_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block33_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block33_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block33_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block33_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block33_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block33_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block33_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block33_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block33_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block33_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block33_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block33_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block33_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block33_out (Add)         (None, 16, 16, 1024) 0           conv4_block32_out[0][0]          
                                                                 conv4_block33_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block34_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block33_out[0][0]          
__________________________________________________________________________________________________
conv4_block34_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block34_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block34_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block34_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block34_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block34_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block34_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block34_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block34_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block34_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block34_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block34_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block34_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block34_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block34_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block34_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block34_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block34_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block34_out (Add)         (None, 16, 16, 1024) 0           conv4_block33_out[0][0]          
                                                                 conv4_block34_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block35_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block34_out[0][0]          
__________________________________________________________________________________________________
conv4_block35_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block35_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block35_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block35_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block35_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block35_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block35_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block35_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block35_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block35_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block35_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block35_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block35_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block35_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block35_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block35_2_bn[0][0]         
__________________________________________________________________________________________________
conv4_block35_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block35_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block35_out (Add)         (None, 16, 16, 1024) 0           conv4_block34_out[0][0]          
                                                                 conv4_block35_3_conv[0][0]       
__________________________________________________________________________________________________
conv4_block36_preact_bn (BatchN (None, 16, 16, 1024) 4096        conv4_block35_out[0][0]          
__________________________________________________________________________________________________
conv4_block36_preact_relu (Acti (None, 16, 16, 1024) 0           conv4_block36_preact_bn[0][0]    
__________________________________________________________________________________________________
conv4_block36_1_conv (Conv2D)   (None, 16, 16, 256)  262144      conv4_block36_preact_relu[0][0]  
__________________________________________________________________________________________________
conv4_block36_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block36_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block36_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block36_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block36_2_pad (ZeroPaddin (None, 18, 18, 256)  0           conv4_block36_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block36_2_conv (Conv2D)   (None, 8, 8, 256)    589824      conv4_block36_2_pad[0][0]        
__________________________________________________________________________________________________
conv4_block36_2_bn (BatchNormal (None, 8, 8, 256)    1024        conv4_block36_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block36_2_relu (Activatio (None, 8, 8, 256)    0           conv4_block36_2_bn[0][0]         
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 1024)   0           conv4_block35_out[0][0]          
__________________________________________________________________________________________________
conv4_block36_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      conv4_block36_2_relu[0][0]       
__________________________________________________________________________________________________
conv4_block36_out (Add)         (None, 8, 8, 1024)   0           max_pooling2d_2[0][0]            
                                                                 conv4_block36_3_conv[0][0]       
__________________________________________________________________________________________________
conv5_block1_preact_bn (BatchNo (None, 8, 8, 1024)   4096        conv4_block36_out[0][0]          
__________________________________________________________________________________________________
conv5_block1_preact_relu (Activ (None, 8, 8, 1024)   0           conv5_block1_preact_bn[0][0]     
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524288      conv5_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block1_2_pad[0][0]         
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv5_block1_preact_relu[0][0]   
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_out (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_conv[0][0]        
                                                                 conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_preact_bn (BatchNo (None, 8, 8, 2048)   8192        conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_preact_relu (Activ (None, 8, 8, 2048)   0           conv5_block2_preact_bn[0][0]     
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1048576     conv5_block2_preact_relu[0][0]   
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block2_2_pad[0][0]         
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_out (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_preact_bn (BatchNo (None, 8, 8, 2048)   8192        conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_preact_relu (Activ (None, 8, 8, 2048)   0           conv5_block3_preact_bn[0][0]     
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1048576     conv5_block3_preact_relu[0][0]   
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block3_2_pad[0][0]         
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_out (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
post_bn (BatchNormalization)    (None, 8, 8, 2048)   8192        conv5_block3_out[0][0]           
__________________________________________________________________________________________________
post_relu (Activation)          (None, 8, 8, 2048)   0           post_bn[0][0]                    
__________________________________________________________________________________________________
flatten (Flatten)               (None, 131072)       0           post_relu[0][0]                  
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         536875008   flatten[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
predictions (Dense)             (None, 5)            20485       fc2[0][0]                        
==================================================================================================
Total params: 612,008,453
Trainable params: 611,864,709
Non-trainable params: 143,744
__________________________________________________________________________________________________
Start fitting ensemble models
Random seed for replication: 882
Length split part:  1398
Labels in this part of split:  [278, 275, 262, 304, 279]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 72s - loss: 1.4069 - accuracy: 0.4814 - val_loss: 1.5124 - val_accuracy: 0.6369
Epoch 2/500
44/44 - 38s - loss: 0.0661 - accuracy: 0.9886 - val_loss: 1.2858 - val_accuracy: 0.5754
Epoch 3/500
44/44 - 17s - loss: 0.0161 - accuracy: 0.9986 - val_loss: 1.3562 - val_accuracy: 0.5642
Epoch 4/500
44/44 - 37s - loss: 0.0070 - accuracy: 0.9986 - val_loss: 1.1954 - val_accuracy: 0.6034
Epoch 5/500
44/44 - 17s - loss: 0.0065 - accuracy: 0.9986 - val_loss: 1.2961 - val_accuracy: 0.6145
Epoch 6/500
44/44 - 17s - loss: 0.0095 - accuracy: 0.9986 - val_loss: 1.2102 - val_accuracy: 0.6145
Epoch 7/500
44/44 - 38s - loss: 0.0024 - accuracy: 0.9993 - val_loss: 1.1917 - val_accuracy: 0.6257
Epoch 8/500
44/44 - 41s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.1910 - val_accuracy: 0.6592
Epoch 9/500
44/44 - 17s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.2023 - val_accuracy: 0.6927
Epoch 10/500
44/44 - 17s - loss: 8.7170e-04 - accuracy: 1.0000 - val_loss: 1.1988 - val_accuracy: 0.6760
Epoch 11/500
44/44 - 17s - loss: 7.5667e-04 - accuracy: 1.0000 - val_loss: 1.2023 - val_accuracy: 0.6760
Epoch 12/500
44/44 - 17s - loss: 6.6474e-04 - accuracy: 1.0000 - val_loss: 1.2010 - val_accuracy: 0.6760
Epoch 13/500
44/44 - 17s - loss: 5.9228e-04 - accuracy: 1.0000 - val_loss: 1.1994 - val_accuracy: 0.6704
Epoch 14/500
44/44 - 17s - loss: 5.3074e-04 - accuracy: 1.0000 - val_loss: 1.2012 - val_accuracy: 0.6648
Epoch 15/500
44/44 - 17s - loss: 4.7853e-04 - accuracy: 1.0000 - val_loss: 1.2088 - val_accuracy: 0.6760
Epoch 16/500
44/44 - 17s - loss: 4.3502e-04 - accuracy: 1.0000 - val_loss: 1.2090 - val_accuracy: 0.6704
Epoch 17/500
44/44 - 17s - loss: 3.9716e-04 - accuracy: 1.0000 - val_loss: 1.2094 - val_accuracy: 0.6704
Epoch 18/500
44/44 - 17s - loss: 3.6401e-04 - accuracy: 1.0000 - val_loss: 1.2144 - val_accuracy: 0.6648
Epoch 19/500
44/44 - 17s - loss: 3.3537e-04 - accuracy: 1.0000 - val_loss: 1.2187 - val_accuracy: 0.6648
Epoch 20/500
44/44 - 17s - loss: 3.1026e-04 - accuracy: 1.0000 - val_loss: 1.2231 - val_accuracy: 0.6648
Epoch 21/500
44/44 - 17s - loss: 2.8771e-04 - accuracy: 1.0000 - val_loss: 1.2289 - val_accuracy: 0.6648
Epoch 22/500
44/44 - 17s - loss: 2.6762e-04 - accuracy: 1.0000 - val_loss: 1.2344 - val_accuracy: 0.6648
Epoch 23/500
44/44 - 17s - loss: 2.4959e-04 - accuracy: 1.0000 - val_loss: 1.2382 - val_accuracy: 0.6704
Epoch 24/500
44/44 - 17s - loss: 2.3333e-04 - accuracy: 1.0000 - val_loss: 1.2418 - val_accuracy: 0.6704
Epoch 25/500
44/44 - 17s - loss: 2.1867e-04 - accuracy: 1.0000 - val_loss: 1.2471 - val_accuracy: 0.6704
Epoch 26/500
44/44 - 17s - loss: 2.0566e-04 - accuracy: 1.0000 - val_loss: 1.2507 - val_accuracy: 0.6704
Epoch 27/500
44/44 - 17s - loss: 1.9314e-04 - accuracy: 1.0000 - val_loss: 1.2548 - val_accuracy: 0.6704
Epoch 28/500
44/44 - 17s - loss: 1.8204e-04 - accuracy: 1.0000 - val_loss: 1.2605 - val_accuracy: 0.6704
Epoch 29/500
44/44 - 17s - loss: 1.7172e-04 - accuracy: 1.0000 - val_loss: 1.2627 - val_accuracy: 0.6704
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 15:02:35.089404: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 15:02:35.089580: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 15:02:35.089627: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 15:02:35.464520: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 15:02:35.464617: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00029: early stopping
Length split part:  1398
Labels in this part of split:  [272, 276, 289, 288, 273]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 35s - loss: 1.6559 - accuracy: 0.4657 - val_loss: 1.3009 - val_accuracy: 0.5140
Epoch 2/500
44/44 - 36s - loss: 0.2305 - accuracy: 0.9227 - val_loss: 1.2842 - val_accuracy: 0.6592
Epoch 3/500
44/44 - 39s - loss: 0.0439 - accuracy: 0.9921 - val_loss: 1.1704 - val_accuracy: 0.6592
Epoch 4/500
44/44 - 17s - loss: 0.0274 - accuracy: 0.9950 - val_loss: 1.4914 - val_accuracy: 0.6760
Epoch 5/500
44/44 - 17s - loss: 0.0162 - accuracy: 0.9957 - val_loss: 1.2445 - val_accuracy: 0.6872
Epoch 6/500
44/44 - 17s - loss: 0.0116 - accuracy: 0.9964 - val_loss: 1.2862 - val_accuracy: 0.7039
Epoch 7/500
44/44 - 17s - loss: 0.0045 - accuracy: 0.9979 - val_loss: 1.3681 - val_accuracy: 0.6927
Epoch 8/500
44/44 - 36s - loss: 0.0041 - accuracy: 0.9979 - val_loss: 1.0378 - val_accuracy: 0.6816
Epoch 9/500
44/44 - 17s - loss: 0.0020 - accuracy: 0.9993 - val_loss: 1.0886 - val_accuracy: 0.6927
Epoch 10/500
44/44 - 17s - loss: 7.7251e-04 - accuracy: 1.0000 - val_loss: 1.0872 - val_accuracy: 0.7095
Epoch 11/500
44/44 - 17s - loss: 5.3521e-04 - accuracy: 1.0000 - val_loss: 1.0900 - val_accuracy: 0.6983
Epoch 12/500
44/44 - 17s - loss: 4.7044e-04 - accuracy: 1.0000 - val_loss: 1.0915 - val_accuracy: 0.7095
Epoch 13/500
44/44 - 17s - loss: 4.1767e-04 - accuracy: 1.0000 - val_loss: 1.1051 - val_accuracy: 0.6983
Epoch 14/500
44/44 - 17s - loss: 3.7616e-04 - accuracy: 1.0000 - val_loss: 1.1078 - val_accuracy: 0.7039
Epoch 15/500
44/44 - 17s - loss: 3.4149e-04 - accuracy: 1.0000 - val_loss: 1.1131 - val_accuracy: 0.7095
Epoch 16/500
44/44 - 17s - loss: 3.1231e-04 - accuracy: 1.0000 - val_loss: 1.1217 - val_accuracy: 0.7039
Epoch 17/500
44/44 - 17s - loss: 2.8802e-04 - accuracy: 1.0000 - val_loss: 1.1285 - val_accuracy: 0.7039
Epoch 18/500
44/44 - 17s - loss: 2.6533e-04 - accuracy: 1.0000 - val_loss: 1.1364 - val_accuracy: 0.7039
Epoch 19/500
44/44 - 17s - loss: 2.4649e-04 - accuracy: 1.0000 - val_loss: 1.1432 - val_accuracy: 0.6983
Epoch 20/500
44/44 - 17s - loss: 2.2954e-04 - accuracy: 1.0000 - val_loss: 1.1498 - val_accuracy: 0.6983
Epoch 21/500
44/44 - 17s - loss: 2.1444e-04 - accuracy: 1.0000 - val_loss: 1.1556 - val_accuracy: 0.6983
Epoch 22/500
44/44 - 17s - loss: 2.0090e-04 - accuracy: 1.0000 - val_loss: 1.1625 - val_accuracy: 0.6983
Epoch 23/500
44/44 - 17s - loss: 1.8899e-04 - accuracy: 1.0000 - val_loss: 1.1666 - val_accuracy: 0.6927
Epoch 24/500
44/44 - 17s - loss: 1.7787e-04 - accuracy: 1.0000 - val_loss: 1.1714 - val_accuracy: 0.6927
Epoch 25/500
44/44 - 17s - loss: 1.6794e-04 - accuracy: 1.0000 - val_loss: 1.1770 - val_accuracy: 0.6927
Epoch 26/500
44/44 - 17s - loss: 1.5843e-04 - accuracy: 1.0000 - val_loss: 1.1822 - val_accuracy: 0.6927
Epoch 27/500
44/44 - 17s - loss: 1.5011e-04 - accuracy: 1.0000 - val_loss: 1.1867 - val_accuracy: 0.6927
Epoch 28/500
44/44 - 17s - loss: 1.4235e-04 - accuracy: 1.0000 - val_loss: 1.1916 - val_accuracy: 0.6927
Epoch 29/500
44/44 - 17s - loss: 1.3509e-04 - accuracy: 1.0000 - val_loss: 1.1963 - val_accuracy: 0.6927
Epoch 30/500
44/44 - 17s - loss: 1.2846e-04 - accuracy: 1.0000 - val_loss: 1.2004 - val_accuracy: 0.6927
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 15:13:20.162175: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 15:13:20.162356: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 15:13:20.162392: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 15:13:20.538069: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 15:13:20.538164: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00030: early stopping
Length split part:  1397
Labels in this part of split:  [290, 289, 288, 246, 284]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 33s - loss: 1.5001 - accuracy: 0.4932 - val_loss: 1.5105 - val_accuracy: 0.3352
Epoch 2/500
44/44 - 36s - loss: 0.2767 - accuracy: 0.9091 - val_loss: 1.3541 - val_accuracy: 0.6648
Epoch 3/500
44/44 - 37s - loss: 0.0591 - accuracy: 0.9900 - val_loss: 1.1660 - val_accuracy: 0.5866
Epoch 4/500
44/44 - 17s - loss: 0.0186 - accuracy: 0.9964 - val_loss: 1.2286 - val_accuracy: 0.6313
Epoch 5/500
44/44 - 17s - loss: 0.0076 - accuracy: 0.9979 - val_loss: 1.2186 - val_accuracy: 0.6369
Epoch 6/500
44/44 - 17s - loss: 0.0048 - accuracy: 0.9993 - val_loss: 1.2962 - val_accuracy: 0.6704
Epoch 7/500
44/44 - 17s - loss: 0.0026 - accuracy: 0.9986 - val_loss: 1.3278 - val_accuracy: 0.6592
Epoch 8/500
44/44 - 17s - loss: 7.9565e-04 - accuracy: 1.0000 - val_loss: 1.4016 - val_accuracy: 0.6648
Epoch 9/500
44/44 - 17s - loss: 5.2705e-04 - accuracy: 1.0000 - val_loss: 1.4849 - val_accuracy: 0.6201
Epoch 10/500
44/44 - 17s - loss: 4.5061e-04 - accuracy: 1.0000 - val_loss: 1.5340 - val_accuracy: 0.5922
Epoch 11/500
44/44 - 17s - loss: 3.9561e-04 - accuracy: 1.0000 - val_loss: 1.5673 - val_accuracy: 0.6201
Epoch 12/500
44/44 - 17s - loss: 3.5363e-04 - accuracy: 1.0000 - val_loss: 1.5785 - val_accuracy: 0.6201
Epoch 13/500
44/44 - 17s - loss: 3.1869e-04 - accuracy: 1.0000 - val_loss: 1.5921 - val_accuracy: 0.6313
Epoch 14/500
44/44 - 17s - loss: 2.8973e-04 - accuracy: 1.0000 - val_loss: 1.6011 - val_accuracy: 0.6313
Epoch 15/500
44/44 - 17s - loss: 2.6543e-04 - accuracy: 1.0000 - val_loss: 1.6114 - val_accuracy: 0.6257
Epoch 16/500
44/44 - 17s - loss: 2.4384e-04 - accuracy: 1.0000 - val_loss: 1.6187 - val_accuracy: 0.6369
Epoch 17/500
44/44 - 17s - loss: 2.2546e-04 - accuracy: 1.0000 - val_loss: 1.6202 - val_accuracy: 0.6425
Epoch 18/500
44/44 - 17s - loss: 2.0964e-04 - accuracy: 1.0000 - val_loss: 1.6244 - val_accuracy: 0.6369
Epoch 19/500
44/44 - 17s - loss: 1.9541e-04 - accuracy: 1.0000 - val_loss: 1.6291 - val_accuracy: 0.6313
Epoch 20/500
44/44 - 17s - loss: 1.8276e-04 - accuracy: 1.0000 - val_loss: 1.6351 - val_accuracy: 0.6313
Epoch 21/500
44/44 - 17s - loss: 1.7132e-04 - accuracy: 1.0000 - val_loss: 1.6423 - val_accuracy: 0.6369
Epoch 22/500
44/44 - 17s - loss: 1.6103e-04 - accuracy: 1.0000 - val_loss: 1.6489 - val_accuracy: 0.6313
Epoch 23/500
44/44 - 17s - loss: 1.5168e-04 - accuracy: 1.0000 - val_loss: 1.6548 - val_accuracy: 0.6313
Epoch 24/500
44/44 - 17s - loss: 1.4341e-04 - accuracy: 1.0000 - val_loss: 1.6614 - val_accuracy: 0.6313
Epoch 25/500
44/44 - 17s - loss: 1.3556e-04 - accuracy: 1.0000 - val_loss: 1.6675 - val_accuracy: 0.6313
Epoch 26/500
44/44 - 17s - loss: 1.2836e-04 - accuracy: 1.0000 - val_loss: 1.6733 - val_accuracy: 0.6313
Epoch 00026: early stopping
InceptionV3
Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5
    8192/87910968 [..............................] - ETA: 0s   24576/87910968 [..............................] - ETA: 5:42   57344/87910968 [..............................] - ETA: 4:56  122880/87910968 [..............................] - ETA: 3:28  303104/87910968 [..............................] - ETA: 1:52  614400/87910968 [..............................] - ETA: 1:09 1253376/87910968 [..............................] - ETA: 40s  2531328/87910968 [..............................] - ETA: 23s 5087232/87910968 [>.............................] - ETA: 12s 8216576/87910968 [=>............................] - ETA: 8s 11362304/87910968 [==>...........................] - ETA: 6s14491648/87910968 [===>..........................] - ETA: 5s17620992/87910968 [=====>........................] - ETA: 4s20766720/87910968 [======>.......................] - ETA: 4s23896064/87910968 [=======>......................] - ETA: 3s27041792/87910968 [========>.....................] - ETA: 3s30171136/87910968 [=========>....................] - ETA: 2s33300480/87910968 [==========>...................] - ETA: 2s35643392/87910968 [===========>..................] - ETA: 2s36446208/87910968 [===========>..................] - ETA: 2s39575552/87910968 [============>.................] - ETA: 2s41820160/87910968 [=============>................] - ETA: 2s42721280/87910968 [=============>................] - ETA: 2s45768704/87910968 [==============>...............] - ETA: 1s45965312/87910968 [==============>...............] - ETA: 1s48996352/87910968 [===============>..............] - ETA: 1s51994624/87910968 [================>.............] - ETA: 1s52240384/87910968 [================>.............] - ETA: 1s55255040/87910968 [=================>............] - ETA: 1s56942592/87910968 [==================>...........] - ETA: 1s58400768/87910968 [==================>...........] - ETA: 1s60891136/87910968 [===================>..........] - ETA: 1s61628416/87910968 [====================>.........] - ETA: 1s64282624/87910968 [====================>.........] - ETA: 0s64856064/87910968 [=====================>........] - ETA: 0s67805184/87910968 [======================>.......] - ETA: 0s70262784/87910968 [======================>.......] - ETA: 0s71147520/87910968 [=======================>......] - ETA: 0s73768960/87910968 [========================>.....] - ETA: 0s74309632/87910968 [========================>.....] - ETA: 0s77209600/87910968 [=========================>....] - ETA: 0s78364672/87910968 [=========================>....] - ETA: 0s80355328/87910968 [==========================>...] - ETA: 0s82599936/87910968 [===========================>..] - ETA: 0s83632128/87910968 [===========================>..] - ETA: 0s85942272/87910968 [============================>.] - ETA: 0s86810624/87910968 [============================>.] - ETA: 0s87916544/87910968 [==============================] - 3s 0us/step
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 15:23:03.699134: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 15:23:03.699314: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 15:23:03.699363: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 15:23:03.850779: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 15:23:03.850878: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 127, 127, 32) 864         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 127, 127, 32) 96          conv2d[0][0]                     
__________________________________________________________________________________________________
activation (Activation)         (None, 127, 127, 32) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 125, 125, 32) 9216        activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 125, 125, 32) 96          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 125, 125, 32) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 125, 125, 64) 18432       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 125, 125, 64) 192         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 125, 125, 64) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 62, 62, 64)   0           activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 62, 62, 80)   5120        max_pooling2d[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 62, 62, 80)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 62, 62, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 60, 60, 192)  138240      activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 60, 60, 192)  576         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 60, 60, 192)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 29, 29, 192)  0           activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 29, 29, 64)   192         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 29, 29, 64)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 29, 29, 48)   9216        max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 29, 29, 96)   55296       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 29, 29, 48)   144         conv2d_6[0][0]                   
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 29, 29, 96)   288         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 29, 29, 48)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 29, 29, 96)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 29, 29, 192)  0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 29, 29, 64)   76800       activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 29, 29, 96)   82944       activation_9[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 29, 29, 32)   6144        average_pooling2d[0][0]          
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 29, 29, 64)   192         conv2d_5[0][0]                   
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 29, 29, 64)   192         conv2d_7[0][0]                   
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 29, 29, 96)   288         conv2d_10[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 29, 29, 32)   96          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 29, 29, 64)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 29, 29, 64)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 29, 29, 96)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 29, 29, 32)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
mixed0 (Concatenate)            (None, 29, 29, 256)  0           activation_5[0][0]               
                                                                 activation_7[0][0]               
                                                                 activation_10[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 29, 29, 64)   16384       mixed0[0][0]                     
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 29, 29, 64)   192         conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 29, 29, 64)   0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 29, 29, 48)   12288       mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 29, 29, 96)   55296       activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 29, 29, 48)   144         conv2d_13[0][0]                  
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 29, 29, 96)   288         conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 29, 29, 48)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 29, 29, 96)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 29, 29, 256)  0           mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 29, 29, 64)   16384       mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 29, 29, 64)   76800       activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 29, 29, 96)   82944       activation_16[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 29, 29, 64)   16384       average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 29, 29, 64)   192         conv2d_12[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 29, 29, 64)   192         conv2d_14[0][0]                  
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 29, 29, 96)   288         conv2d_17[0][0]                  
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 29, 29, 64)   192         conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 29, 29, 64)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 29, 29, 64)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 29, 29, 96)   0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 29, 29, 64)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
mixed1 (Concatenate)            (None, 29, 29, 288)  0           activation_12[0][0]              
                                                                 activation_14[0][0]              
                                                                 activation_17[0][0]              
                                                                 activation_18[0][0]              
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 29, 29, 64)   18432       mixed1[0][0]                     
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 29, 29, 64)   192         conv2d_22[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 29, 29, 64)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 29, 29, 48)   13824       mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 29, 29, 96)   55296       activation_22[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 29, 29, 48)   144         conv2d_20[0][0]                  
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 29, 29, 96)   288         conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 29, 29, 48)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 29, 29, 96)   0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 29, 29, 288)  0           mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 29, 29, 64)   18432       mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 29, 29, 64)   76800       activation_20[0][0]              
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 29, 29, 96)   82944       activation_23[0][0]              
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 29, 29, 64)   18432       average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 29, 29, 64)   192         conv2d_19[0][0]                  
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 29, 29, 64)   192         conv2d_21[0][0]                  
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 29, 29, 96)   288         conv2d_24[0][0]                  
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 29, 29, 64)   192         conv2d_25[0][0]                  
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 29, 29, 64)   0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 29, 29, 64)   0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 29, 29, 96)   0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 29, 29, 64)   0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
mixed2 (Concatenate)            (None, 29, 29, 288)  0           activation_19[0][0]              
                                                                 activation_21[0][0]              
                                                                 activation_24[0][0]              
                                                                 activation_25[0][0]              
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 29, 29, 64)   18432       mixed2[0][0]                     
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 29, 29, 64)   192         conv2d_27[0][0]                  
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 29, 29, 64)   0           batch_normalization_27[0][0]     
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 29, 29, 96)   55296       activation_27[0][0]              
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 29, 29, 96)   288         conv2d_28[0][0]                  
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 29, 29, 96)   0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 14, 14, 384)  995328      mixed2[0][0]                     
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 14, 14, 96)   82944       activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 14, 14, 384)  1152        conv2d_26[0][0]                  
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 14, 14, 96)   288         conv2d_29[0][0]                  
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 14, 14, 384)  0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 14, 14, 96)   0           batch_normalization_29[0][0]     
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 288)  0           mixed2[0][0]                     
__________________________________________________________________________________________________
mixed3 (Concatenate)            (None, 14, 14, 768)  0           activation_26[0][0]              
                                                                 activation_29[0][0]              
                                                                 max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 14, 14, 128)  98304       mixed3[0][0]                     
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 14, 14, 128)  384         conv2d_34[0][0]                  
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 14, 14, 128)  0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 14, 14, 128)  114688      activation_34[0][0]              
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 14, 14, 128)  384         conv2d_35[0][0]                  
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 14, 14, 128)  0           batch_normalization_35[0][0]     
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 14, 14, 128)  98304       mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 14, 14, 128)  114688      activation_35[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 14, 14, 128)  384         conv2d_31[0][0]                  
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 14, 14, 128)  384         conv2d_36[0][0]                  
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 14, 14, 128)  0           batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 14, 14, 128)  0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 14, 14, 128)  114688      activation_31[0][0]              
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 14, 14, 128)  114688      activation_36[0][0]              
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 14, 14, 128)  384         conv2d_32[0][0]                  
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 14, 14, 128)  384         conv2d_37[0][0]                  
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 14, 14, 128)  0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 14, 14, 128)  0           batch_normalization_37[0][0]     
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 14, 14, 768)  0           mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 14, 14, 192)  147456      mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 14, 14, 192)  172032      activation_32[0][0]              
__________________________________________________________________________________________________
conv2d_38 (Conv2D)              (None, 14, 14, 192)  172032      activation_37[0][0]              
__________________________________________________________________________________________________
conv2d_39 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 14, 14, 192)  576         conv2d_30[0][0]                  
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 14, 14, 192)  576         conv2d_33[0][0]                  
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 14, 14, 192)  576         conv2d_38[0][0]                  
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 14, 14, 192)  576         conv2d_39[0][0]                  
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 14, 14, 192)  0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 14, 14, 192)  0           batch_normalization_33[0][0]     
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 14, 14, 192)  0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 14, 14, 192)  0           batch_normalization_39[0][0]     
__________________________________________________________________________________________________
mixed4 (Concatenate)            (None, 14, 14, 768)  0           activation_30[0][0]              
                                                                 activation_33[0][0]              
                                                                 activation_38[0][0]              
                                                                 activation_39[0][0]              
__________________________________________________________________________________________________
conv2d_44 (Conv2D)              (None, 14, 14, 160)  122880      mixed4[0][0]                     
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 14, 14, 160)  480         conv2d_44[0][0]                  
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 14, 14, 160)  0           batch_normalization_44[0][0]     
__________________________________________________________________________________________________
conv2d_45 (Conv2D)              (None, 14, 14, 160)  179200      activation_44[0][0]              
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 14, 14, 160)  480         conv2d_45[0][0]                  
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 14, 14, 160)  0           batch_normalization_45[0][0]     
__________________________________________________________________________________________________
conv2d_41 (Conv2D)              (None, 14, 14, 160)  122880      mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_46 (Conv2D)              (None, 14, 14, 160)  179200      activation_45[0][0]              
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 14, 14, 160)  480         conv2d_41[0][0]                  
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 14, 14, 160)  480         conv2d_46[0][0]                  
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 14, 14, 160)  0           batch_normalization_41[0][0]     
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 14, 14, 160)  0           batch_normalization_46[0][0]     
__________________________________________________________________________________________________
conv2d_42 (Conv2D)              (None, 14, 14, 160)  179200      activation_41[0][0]              
__________________________________________________________________________________________________
conv2d_47 (Conv2D)              (None, 14, 14, 160)  179200      activation_46[0][0]              
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 14, 14, 160)  480         conv2d_42[0][0]                  
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 14, 14, 160)  480         conv2d_47[0][0]                  
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 14, 14, 160)  0           batch_normalization_42[0][0]     
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 14, 14, 160)  0           batch_normalization_47[0][0]     
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 14, 14, 768)  0           mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_40 (Conv2D)              (None, 14, 14, 192)  147456      mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_43 (Conv2D)              (None, 14, 14, 192)  215040      activation_42[0][0]              
__________________________________________________________________________________________________
conv2d_48 (Conv2D)              (None, 14, 14, 192)  215040      activation_47[0][0]              
__________________________________________________________________________________________________
conv2d_49 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 14, 14, 192)  576         conv2d_40[0][0]                  
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 14, 14, 192)  576         conv2d_43[0][0]                  
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 14, 14, 192)  576         conv2d_48[0][0]                  
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 14, 14, 192)  576         conv2d_49[0][0]                  
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 14, 14, 192)  0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 14, 14, 192)  0           batch_normalization_43[0][0]     
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 14, 14, 192)  0           batch_normalization_48[0][0]     
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 14, 14, 192)  0           batch_normalization_49[0][0]     
__________________________________________________________________________________________________
mixed5 (Concatenate)            (None, 14, 14, 768)  0           activation_40[0][0]              
                                                                 activation_43[0][0]              
                                                                 activation_48[0][0]              
                                                                 activation_49[0][0]              
__________________________________________________________________________________________________
conv2d_54 (Conv2D)              (None, 14, 14, 160)  122880      mixed5[0][0]                     
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 14, 14, 160)  480         conv2d_54[0][0]                  
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 14, 14, 160)  0           batch_normalization_54[0][0]     
__________________________________________________________________________________________________
conv2d_55 (Conv2D)              (None, 14, 14, 160)  179200      activation_54[0][0]              
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 14, 14, 160)  480         conv2d_55[0][0]                  
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 14, 14, 160)  0           batch_normalization_55[0][0]     
__________________________________________________________________________________________________
conv2d_51 (Conv2D)              (None, 14, 14, 160)  122880      mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_56 (Conv2D)              (None, 14, 14, 160)  179200      activation_55[0][0]              
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 14, 14, 160)  480         conv2d_51[0][0]                  
__________________________________________________________________________________________________
batch_normalization_56 (BatchNo (None, 14, 14, 160)  480         conv2d_56[0][0]                  
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 14, 14, 160)  0           batch_normalization_51[0][0]     
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 14, 14, 160)  0           batch_normalization_56[0][0]     
__________________________________________________________________________________________________
conv2d_52 (Conv2D)              (None, 14, 14, 160)  179200      activation_51[0][0]              
__________________________________________________________________________________________________
conv2d_57 (Conv2D)              (None, 14, 14, 160)  179200      activation_56[0][0]              
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 14, 14, 160)  480         conv2d_52[0][0]                  
__________________________________________________________________________________________________
batch_normalization_57 (BatchNo (None, 14, 14, 160)  480         conv2d_57[0][0]                  
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 14, 14, 160)  0           batch_normalization_52[0][0]     
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 14, 14, 160)  0           batch_normalization_57[0][0]     
__________________________________________________________________________________________________
average_pooling2d_5 (AveragePoo (None, 14, 14, 768)  0           mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_50 (Conv2D)              (None, 14, 14, 192)  147456      mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_53 (Conv2D)              (None, 14, 14, 192)  215040      activation_52[0][0]              
__________________________________________________________________________________________________
conv2d_58 (Conv2D)              (None, 14, 14, 192)  215040      activation_57[0][0]              
__________________________________________________________________________________________________
conv2d_59 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 14, 14, 192)  576         conv2d_50[0][0]                  
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 14, 14, 192)  576         conv2d_53[0][0]                  
__________________________________________________________________________________________________
batch_normalization_58 (BatchNo (None, 14, 14, 192)  576         conv2d_58[0][0]                  
__________________________________________________________________________________________________
batch_normalization_59 (BatchNo (None, 14, 14, 192)  576         conv2d_59[0][0]                  
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 14, 14, 192)  0           batch_normalization_50[0][0]     
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 14, 14, 192)  0           batch_normalization_53[0][0]     
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 14, 14, 192)  0           batch_normalization_58[0][0]     
__________________________________________________________________________________________________
activation_59 (Activation)      (None, 14, 14, 192)  0           batch_normalization_59[0][0]     
__________________________________________________________________________________________________
mixed6 (Concatenate)            (None, 14, 14, 768)  0           activation_50[0][0]              
                                                                 activation_53[0][0]              
                                                                 activation_58[0][0]              
                                                                 activation_59[0][0]              
__________________________________________________________________________________________________
conv2d_64 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
batch_normalization_64 (BatchNo (None, 14, 14, 192)  576         conv2d_64[0][0]                  
__________________________________________________________________________________________________
activation_64 (Activation)      (None, 14, 14, 192)  0           batch_normalization_64[0][0]     
__________________________________________________________________________________________________
conv2d_65 (Conv2D)              (None, 14, 14, 192)  258048      activation_64[0][0]              
__________________________________________________________________________________________________
batch_normalization_65 (BatchNo (None, 14, 14, 192)  576         conv2d_65[0][0]                  
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 14, 14, 192)  0           batch_normalization_65[0][0]     
__________________________________________________________________________________________________
conv2d_61 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_66 (Conv2D)              (None, 14, 14, 192)  258048      activation_65[0][0]              
__________________________________________________________________________________________________
batch_normalization_61 (BatchNo (None, 14, 14, 192)  576         conv2d_61[0][0]                  
__________________________________________________________________________________________________
batch_normalization_66 (BatchNo (None, 14, 14, 192)  576         conv2d_66[0][0]                  
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 14, 14, 192)  0           batch_normalization_61[0][0]     
__________________________________________________________________________________________________
activation_66 (Activation)      (None, 14, 14, 192)  0           batch_normalization_66[0][0]     
__________________________________________________________________________________________________
conv2d_62 (Conv2D)              (None, 14, 14, 192)  258048      activation_61[0][0]              
__________________________________________________________________________________________________
conv2d_67 (Conv2D)              (None, 14, 14, 192)  258048      activation_66[0][0]              
__________________________________________________________________________________________________
batch_normalization_62 (BatchNo (None, 14, 14, 192)  576         conv2d_62[0][0]                  
__________________________________________________________________________________________________
batch_normalization_67 (BatchNo (None, 14, 14, 192)  576         conv2d_67[0][0]                  
__________________________________________________________________________________________________
activation_62 (Activation)      (None, 14, 14, 192)  0           batch_normalization_62[0][0]     
__________________________________________________________________________________________________
activation_67 (Activation)      (None, 14, 14, 192)  0           batch_normalization_67[0][0]     
__________________________________________________________________________________________________
average_pooling2d_6 (AveragePoo (None, 14, 14, 768)  0           mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_60 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_63 (Conv2D)              (None, 14, 14, 192)  258048      activation_62[0][0]              
__________________________________________________________________________________________________
conv2d_68 (Conv2D)              (None, 14, 14, 192)  258048      activation_67[0][0]              
__________________________________________________________________________________________________
conv2d_69 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_6[0][0]        
__________________________________________________________________________________________________
batch_normalization_60 (BatchNo (None, 14, 14, 192)  576         conv2d_60[0][0]                  
__________________________________________________________________________________________________
batch_normalization_63 (BatchNo (None, 14, 14, 192)  576         conv2d_63[0][0]                  
__________________________________________________________________________________________________
batch_normalization_68 (BatchNo (None, 14, 14, 192)  576         conv2d_68[0][0]                  
__________________________________________________________________________________________________
batch_normalization_69 (BatchNo (None, 14, 14, 192)  576         conv2d_69[0][0]                  
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 14, 14, 192)  0           batch_normalization_60[0][0]     
__________________________________________________________________________________________________
activation_63 (Activation)      (None, 14, 14, 192)  0           batch_normalization_63[0][0]     
__________________________________________________________________________________________________
activation_68 (Activation)      (None, 14, 14, 192)  0           batch_normalization_68[0][0]     
__________________________________________________________________________________________________
activation_69 (Activation)      (None, 14, 14, 192)  0           batch_normalization_69[0][0]     
__________________________________________________________________________________________________
mixed7 (Concatenate)            (None, 14, 14, 768)  0           activation_60[0][0]              
                                                                 activation_63[0][0]              
                                                                 activation_68[0][0]              
                                                                 activation_69[0][0]              
__________________________________________________________________________________________________
conv2d_72 (Conv2D)              (None, 14, 14, 192)  147456      mixed7[0][0]                     
__________________________________________________________________________________________________
batch_normalization_72 (BatchNo (None, 14, 14, 192)  576         conv2d_72[0][0]                  
__________________________________________________________________________________________________
activation_72 (Activation)      (None, 14, 14, 192)  0           batch_normalization_72[0][0]     
__________________________________________________________________________________________________
conv2d_73 (Conv2D)              (None, 14, 14, 192)  258048      activation_72[0][0]              
__________________________________________________________________________________________________
batch_normalization_73 (BatchNo (None, 14, 14, 192)  576         conv2d_73[0][0]                  
__________________________________________________________________________________________________
activation_73 (Activation)      (None, 14, 14, 192)  0           batch_normalization_73[0][0]     
__________________________________________________________________________________________________
conv2d_70 (Conv2D)              (None, 14, 14, 192)  147456      mixed7[0][0]                     
__________________________________________________________________________________________________
conv2d_74 (Conv2D)              (None, 14, 14, 192)  258048      activation_73[0][0]              
__________________________________________________________________________________________________
batch_normalization_70 (BatchNo (None, 14, 14, 192)  576         conv2d_70[0][0]                  
__________________________________________________________________________________________________
batch_normalization_74 (BatchNo (None, 14, 14, 192)  576         conv2d_74[0][0]                  
__________________________________________________________________________________________________
activation_70 (Activation)      (None, 14, 14, 192)  0           batch_normalization_70[0][0]     
__________________________________________________________________________________________________
activation_74 (Activation)      (None, 14, 14, 192)  0           batch_normalization_74[0][0]     
__________________________________________________________________________________________________
conv2d_71 (Conv2D)              (None, 6, 6, 320)    552960      activation_70[0][0]              
__________________________________________________________________________________________________
conv2d_75 (Conv2D)              (None, 6, 6, 192)    331776      activation_74[0][0]              
__________________________________________________________________________________________________
batch_normalization_71 (BatchNo (None, 6, 6, 320)    960         conv2d_71[0][0]                  
__________________________________________________________________________________________________
batch_normalization_75 (BatchNo (None, 6, 6, 192)    576         conv2d_75[0][0]                  
__________________________________________________________________________________________________
activation_71 (Activation)      (None, 6, 6, 320)    0           batch_normalization_71[0][0]     
__________________________________________________________________________________________________
activation_75 (Activation)      (None, 6, 6, 192)    0           batch_normalization_75[0][0]     
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 6, 6, 768)    0           mixed7[0][0]                     
__________________________________________________________________________________________________
mixed8 (Concatenate)            (None, 6, 6, 1280)   0           activation_71[0][0]              
                                                                 activation_75[0][0]              
                                                                 max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_80 (Conv2D)              (None, 6, 6, 448)    573440      mixed8[0][0]                     
__________________________________________________________________________________________________
batch_normalization_80 (BatchNo (None, 6, 6, 448)    1344        conv2d_80[0][0]                  
__________________________________________________________________________________________________
activation_80 (Activation)      (None, 6, 6, 448)    0           batch_normalization_80[0][0]     
__________________________________________________________________________________________________
conv2d_77 (Conv2D)              (None, 6, 6, 384)    491520      mixed8[0][0]                     
__________________________________________________________________________________________________
conv2d_81 (Conv2D)              (None, 6, 6, 384)    1548288     activation_80[0][0]              
__________________________________________________________________________________________________
batch_normalization_77 (BatchNo (None, 6, 6, 384)    1152        conv2d_77[0][0]                  
__________________________________________________________________________________________________
batch_normalization_81 (BatchNo (None, 6, 6, 384)    1152        conv2d_81[0][0]                  
__________________________________________________________________________________________________
activation_77 (Activation)      (None, 6, 6, 384)    0           batch_normalization_77[0][0]     
__________________________________________________________________________________________________
activation_81 (Activation)      (None, 6, 6, 384)    0           batch_normalization_81[0][0]     
__________________________________________________________________________________________________
conv2d_78 (Conv2D)              (None, 6, 6, 384)    442368      activation_77[0][0]              
__________________________________________________________________________________________________
conv2d_79 (Conv2D)              (None, 6, 6, 384)    442368      activation_77[0][0]              
__________________________________________________________________________________________________
conv2d_82 (Conv2D)              (None, 6, 6, 384)    442368      activation_81[0][0]              
__________________________________________________________________________________________________
conv2d_83 (Conv2D)              (None, 6, 6, 384)    442368      activation_81[0][0]              
__________________________________________________________________________________________________
average_pooling2d_7 (AveragePoo (None, 6, 6, 1280)   0           mixed8[0][0]                     
__________________________________________________________________________________________________
conv2d_76 (Conv2D)              (None, 6, 6, 320)    409600      mixed8[0][0]                     
__________________________________________________________________________________________________
batch_normalization_78 (BatchNo (None, 6, 6, 384)    1152        conv2d_78[0][0]                  
__________________________________________________________________________________________________
batch_normalization_79 (BatchNo (None, 6, 6, 384)    1152        conv2d_79[0][0]                  
__________________________________________________________________________________________________
batch_normalization_82 (BatchNo (None, 6, 6, 384)    1152        conv2d_82[0][0]                  
__________________________________________________________________________________________________
batch_normalization_83 (BatchNo (None, 6, 6, 384)    1152        conv2d_83[0][0]                  
__________________________________________________________________________________________________
conv2d_84 (Conv2D)              (None, 6, 6, 192)    245760      average_pooling2d_7[0][0]        
__________________________________________________________________________________________________
batch_normalization_76 (BatchNo (None, 6, 6, 320)    960         conv2d_76[0][0]                  
__________________________________________________________________________________________________
activation_78 (Activation)      (None, 6, 6, 384)    0           batch_normalization_78[0][0]     
__________________________________________________________________________________________________
activation_79 (Activation)      (None, 6, 6, 384)    0           batch_normalization_79[0][0]     
__________________________________________________________________________________________________
activation_82 (Activation)      (None, 6, 6, 384)    0           batch_normalization_82[0][0]     
__________________________________________________________________________________________________
activation_83 (Activation)      (None, 6, 6, 384)    0           batch_normalization_83[0][0]     
__________________________________________________________________________________________________
batch_normalization_84 (BatchNo (None, 6, 6, 192)    576         conv2d_84[0][0]                  
__________________________________________________________________________________________________
activation_76 (Activation)      (None, 6, 6, 320)    0           batch_normalization_76[0][0]     
__________________________________________________________________________________________________
mixed9_0 (Concatenate)          (None, 6, 6, 768)    0           activation_78[0][0]              
                                                                 activation_79[0][0]              
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 6, 6, 768)    0           activation_82[0][0]              
                                                                 activation_83[0][0]              
__________________________________________________________________________________________________
activation_84 (Activation)      (None, 6, 6, 192)    0           batch_normalization_84[0][0]     
__________________________________________________________________________________________________
mixed9 (Concatenate)            (None, 6, 6, 2048)   0           activation_76[0][0]              
                                                                 mixed9_0[0][0]                   
                                                                 concatenate[0][0]                
                                                                 activation_84[0][0]              
__________________________________________________________________________________________________
conv2d_89 (Conv2D)              (None, 6, 6, 448)    917504      mixed9[0][0]                     
__________________________________________________________________________________________________
batch_normalization_89 (BatchNo (None, 6, 6, 448)    1344        conv2d_89[0][0]                  
__________________________________________________________________________________________________
activation_89 (Activation)      (None, 6, 6, 448)    0           batch_normalization_89[0][0]     
__________________________________________________________________________________________________
conv2d_86 (Conv2D)              (None, 6, 6, 384)    786432      mixed9[0][0]                     
__________________________________________________________________________________________________
conv2d_90 (Conv2D)              (None, 6, 6, 384)    1548288     activation_89[0][0]              
__________________________________________________________________________________________________
batch_normalization_86 (BatchNo (None, 6, 6, 384)    1152        conv2d_86[0][0]                  
__________________________________________________________________________________________________
batch_normalization_90 (BatchNo (None, 6, 6, 384)    1152        conv2d_90[0][0]                  
__________________________________________________________________________________________________
activation_86 (Activation)      (None, 6, 6, 384)    0           batch_normalization_86[0][0]     
__________________________________________________________________________________________________
activation_90 (Activation)      (None, 6, 6, 384)    0           batch_normalization_90[0][0]     
__________________________________________________________________________________________________
conv2d_87 (Conv2D)              (None, 6, 6, 384)    442368      activation_86[0][0]              
__________________________________________________________________________________________________
conv2d_88 (Conv2D)              (None, 6, 6, 384)    442368      activation_86[0][0]              
__________________________________________________________________________________________________
conv2d_91 (Conv2D)              (None, 6, 6, 384)    442368      activation_90[0][0]              
__________________________________________________________________________________________________
conv2d_92 (Conv2D)              (None, 6, 6, 384)    442368      activation_90[0][0]              
__________________________________________________________________________________________________
average_pooling2d_8 (AveragePoo (None, 6, 6, 2048)   0           mixed9[0][0]                     
__________________________________________________________________________________________________
conv2d_85 (Conv2D)              (None, 6, 6, 320)    655360      mixed9[0][0]                     
__________________________________________________________________________________________________
batch_normalization_87 (BatchNo (None, 6, 6, 384)    1152        conv2d_87[0][0]                  
__________________________________________________________________________________________________
batch_normalization_88 (BatchNo (None, 6, 6, 384)    1152        conv2d_88[0][0]                  
__________________________________________________________________________________________________
batch_normalization_91 (BatchNo (None, 6, 6, 384)    1152        conv2d_91[0][0]                  
__________________________________________________________________________________________________
batch_normalization_92 (BatchNo (None, 6, 6, 384)    1152        conv2d_92[0][0]                  
__________________________________________________________________________________________________
conv2d_93 (Conv2D)              (None, 6, 6, 192)    393216      average_pooling2d_8[0][0]        
__________________________________________________________________________________________________
batch_normalization_85 (BatchNo (None, 6, 6, 320)    960         conv2d_85[0][0]                  
__________________________________________________________________________________________________
activation_87 (Activation)      (None, 6, 6, 384)    0           batch_normalization_87[0][0]     
__________________________________________________________________________________________________
activation_88 (Activation)      (None, 6, 6, 384)    0           batch_normalization_88[0][0]     
__________________________________________________________________________________________________
activation_91 (Activation)      (None, 6, 6, 384)    0           batch_normalization_91[0][0]     
__________________________________________________________________________________________________
activation_92 (Activation)      (None, 6, 6, 384)    0           batch_normalization_92[0][0]     
__________________________________________________________________________________________________
batch_normalization_93 (BatchNo (None, 6, 6, 192)    576         conv2d_93[0][0]                  
__________________________________________________________________________________________________
activation_85 (Activation)      (None, 6, 6, 320)    0           batch_normalization_85[0][0]     
__________________________________________________________________________________________________
mixed9_1 (Concatenate)          (None, 6, 6, 768)    0           activation_87[0][0]              
                                                                 activation_88[0][0]              
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 6, 6, 768)    0           activation_91[0][0]              
                                                                 activation_92[0][0]              
__________________________________________________________________________________________________
activation_93 (Activation)      (None, 6, 6, 192)    0           batch_normalization_93[0][0]     
__________________________________________________________________________________________________
mixed10 (Concatenate)           (None, 6, 6, 2048)   0           activation_85[0][0]              
                                                                 mixed9_1[0][0]                   
                                                                 concatenate_1[0][0]              
                                                                 activation_93[0][0]              
__________________________________________________________________________________________________
flatten (Flatten)               (None, 73728)        0           mixed10[0][0]                    
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         301993984   flatten[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
predictions (Dense)             (None, 5)            20485       fc2[0][0]                        
==================================================================================================
Total params: 340,598,565
Trainable params: 340,564,133
Non-trainable params: 34,432
__________________________________________________________________________________________________
Start fitting ensemble models
Random seed for replication: 124
Length split part:  1398
Labels in this part of split:  [272, 285, 300, 255, 286]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 42s - loss: 1.2201 - accuracy: 0.4979 - val_loss: 2.1771 - val_accuracy: 0.1061
Epoch 2/500
44/44 - 18s - loss: 0.1419 - accuracy: 0.9900 - val_loss: 1.9694 - val_accuracy: 0.1732
Epoch 3/500
44/44 - 18s - loss: 0.0261 - accuracy: 0.9993 - val_loss: 1.5807 - val_accuracy: 0.3464
Epoch 4/500
44/44 - 20s - loss: 0.0128 - accuracy: 0.9993 - val_loss: 1.3468 - val_accuracy: 0.5754
Epoch 5/500
44/44 - 18s - loss: 0.0101 - accuracy: 0.9993 - val_loss: 1.3157 - val_accuracy: 0.5642
Epoch 6/500
44/44 - 18s - loss: 0.0068 - accuracy: 0.9993 - val_loss: 1.2690 - val_accuracy: 0.5698
Epoch 7/500
44/44 - 7s - loss: 0.0059 - accuracy: 0.9993 - val_loss: 1.4222 - val_accuracy: 0.4693
Epoch 8/500
44/44 - 7s - loss: 0.0066 - accuracy: 0.9993 - val_loss: 1.3138 - val_accuracy: 0.5196
Epoch 9/500
44/44 - 7s - loss: 0.0099 - accuracy: 0.9986 - val_loss: 1.2826 - val_accuracy: 0.6257
Epoch 10/500
44/44 - 7s - loss: 0.0051 - accuracy: 0.9993 - val_loss: 1.3099 - val_accuracy: 0.5810
Epoch 11/500
44/44 - 7s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3133 - val_accuracy: 0.6034
Epoch 12/500
44/44 - 7s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3426 - val_accuracy: 0.6480
Epoch 13/500
44/44 - 7s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3581 - val_accuracy: 0.6536
Epoch 14/500
44/44 - 7s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.3690 - val_accuracy: 0.6648
Epoch 15/500
44/44 - 7s - loss: 9.2228e-04 - accuracy: 1.0000 - val_loss: 1.3848 - val_accuracy: 0.6536
Epoch 16/500
44/44 - 7s - loss: 8.1861e-04 - accuracy: 1.0000 - val_loss: 1.3976 - val_accuracy: 0.6480
Epoch 17/500
44/44 - 7s - loss: 7.2661e-04 - accuracy: 1.0000 - val_loss: 1.4096 - val_accuracy: 0.6536
Epoch 18/500
44/44 - 7s - loss: 6.5484e-04 - accuracy: 1.0000 - val_loss: 1.4197 - val_accuracy: 0.6536
Epoch 19/500
44/44 - 7s - loss: 5.9030e-04 - accuracy: 1.0000 - val_loss: 1.4334 - val_accuracy: 0.6536
Epoch 20/500
44/44 - 7s - loss: 5.3686e-04 - accuracy: 1.0000 - val_loss: 1.4454 - val_accuracy: 0.6592
Epoch 21/500
44/44 - 7s - loss: 4.9023e-04 - accuracy: 1.0000 - val_loss: 1.4547 - val_accuracy: 0.6536
Epoch 22/500
44/44 - 7s - loss: 4.4824e-04 - accuracy: 1.0000 - val_loss: 1.4655 - val_accuracy: 0.6536
Epoch 23/500
44/44 - 7s - loss: 4.1177e-04 - accuracy: 1.0000 - val_loss: 1.4769 - val_accuracy: 0.6592
Epoch 24/500
44/44 - 7s - loss: 3.7950e-04 - accuracy: 1.0000 - val_loss: 1.4868 - val_accuracy: 0.6592
Epoch 25/500
44/44 - 7s - loss: 3.5101e-04 - accuracy: 1.0000 - val_loss: 1.4958 - val_accuracy: 0.6592
Epoch 26/500
44/44 - 7s - loss: 3.2515e-04 - accuracy: 1.0000 - val_loss: 1.5054 - val_accuracy: 0.6592
Epoch 27/500
44/44 - 7s - loss: 3.0256e-04 - accuracy: 1.0000 - val_loss: 1.5145 - val_accuracy: 0.6592
Epoch 28/500
44/44 - 7s - loss: 2.8125e-04 - accuracy: 1.0000 - val_loss: 1.5229 - val_accuracy: 0.6592
Epoch 29/500
44/44 - 7s - loss: 2.6264e-04 - accuracy: 1.0000 - val_loss: 1.5319 - val_accuracy: 0.6592
Epoch 30/500
44/44 - 7s - loss: 2.4550e-04 - accuracy: 1.0000 - val_loss: 1.5411 - val_accuracy: 0.6592
Epoch 31/500
44/44 - 7s - loss: 2.2930e-04 - accuracy: 1.0000 - val_loss: 1.5486 - val_accuracy: 0.6592
Epoch 32/500
44/44 - 7s - loss: 2.1518e-04 - accuracy: 1.0000 - val_loss: 1.5568 - val_accuracy: 0.6592
Epoch 33/500
44/44 - 7s - loss: 2.0223e-04 - accuracy: 1.0000 - val_loss: 1.5648 - val_accuracy: 0.6592
Epoch 34/500
44/44 - 7s - loss: 1.9028e-04 - accuracy: 1.0000 - val_loss: 1.5731 - val_accuracy: 0.6592
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 15:28:37.319995: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 15:28:37.320148: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 15:28:37.320181: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 15:28:37.470893: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 15:28:37.470995: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00034: early stopping
Length split part:  1398
Labels in this part of split:  [273, 282, 250, 312, 281]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 17s - loss: 1.4492 - accuracy: 0.4671 - val_loss: 1.5867 - val_accuracy: 0.2067
Epoch 2/500
44/44 - 7s - loss: 0.2370 - accuracy: 0.9285 - val_loss: 1.8923 - val_accuracy: 0.2682
Epoch 3/500
44/44 - 7s - loss: 0.0237 - accuracy: 0.9964 - val_loss: 1.5977 - val_accuracy: 0.4022
Epoch 4/500
44/44 - 7s - loss: 0.0076 - accuracy: 0.9993 - val_loss: 2.0773 - val_accuracy: 0.3296
Epoch 5/500
44/44 - 17s - loss: 0.0037 - accuracy: 0.9993 - val_loss: 1.4289 - val_accuracy: 0.5642
Epoch 6/500
44/44 - 7s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6220 - val_accuracy: 0.5028
Epoch 7/500
44/44 - 7s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.5946 - val_accuracy: 0.5475
Epoch 8/500
44/44 - 7s - loss: 9.2335e-04 - accuracy: 1.0000 - val_loss: 1.5923 - val_accuracy: 0.5642
Epoch 9/500
44/44 - 7s - loss: 7.9253e-04 - accuracy: 1.0000 - val_loss: 1.5848 - val_accuracy: 0.5587
Epoch 10/500
44/44 - 7s - loss: 6.9008e-04 - accuracy: 1.0000 - val_loss: 1.5416 - val_accuracy: 0.5866
Epoch 11/500
44/44 - 7s - loss: 6.0813e-04 - accuracy: 1.0000 - val_loss: 1.5042 - val_accuracy: 0.6257
Epoch 12/500
44/44 - 7s - loss: 5.4301e-04 - accuracy: 1.0000 - val_loss: 1.4965 - val_accuracy: 0.6313
Epoch 13/500
44/44 - 7s - loss: 4.9072e-04 - accuracy: 1.0000 - val_loss: 1.5115 - val_accuracy: 0.6425
Epoch 14/500
44/44 - 7s - loss: 4.4445e-04 - accuracy: 1.0000 - val_loss: 1.5297 - val_accuracy: 0.6480
Epoch 15/500
44/44 - 7s - loss: 4.0509e-04 - accuracy: 1.0000 - val_loss: 1.5536 - val_accuracy: 0.6592
Epoch 16/500
44/44 - 7s - loss: 3.7224e-04 - accuracy: 1.0000 - val_loss: 1.5683 - val_accuracy: 0.6704
Epoch 17/500
44/44 - 7s - loss: 3.4340e-04 - accuracy: 1.0000 - val_loss: 1.5833 - val_accuracy: 0.6648
Epoch 18/500
44/44 - 7s - loss: 3.1707e-04 - accuracy: 1.0000 - val_loss: 1.5980 - val_accuracy: 0.6872
Epoch 19/500
44/44 - 7s - loss: 2.9433e-04 - accuracy: 1.0000 - val_loss: 1.6100 - val_accuracy: 0.6760
Epoch 20/500
44/44 - 7s - loss: 2.7372e-04 - accuracy: 1.0000 - val_loss: 1.6221 - val_accuracy: 0.6760
Epoch 21/500
44/44 - 7s - loss: 2.5590e-04 - accuracy: 1.0000 - val_loss: 1.6322 - val_accuracy: 0.6760
Epoch 22/500
44/44 - 7s - loss: 2.3902e-04 - accuracy: 1.0000 - val_loss: 1.6392 - val_accuracy: 0.6760
Epoch 23/500
44/44 - 7s - loss: 2.2469e-04 - accuracy: 1.0000 - val_loss: 1.6464 - val_accuracy: 0.6704
Epoch 24/500
44/44 - 7s - loss: 2.1093e-04 - accuracy: 1.0000 - val_loss: 1.6536 - val_accuracy: 0.6760
Epoch 25/500
44/44 - 7s - loss: 1.9874e-04 - accuracy: 1.0000 - val_loss: 1.6612 - val_accuracy: 0.6760
Epoch 26/500
44/44 - 7s - loss: 1.8756e-04 - accuracy: 1.0000 - val_loss: 1.6665 - val_accuracy: 0.6704
Epoch 27/500
44/44 - 7s - loss: 1.7772e-04 - accuracy: 1.0000 - val_loss: 1.6748 - val_accuracy: 0.6760
Epoch 28/500
44/44 - 7s - loss: 1.6803e-04 - accuracy: 1.0000 - val_loss: 1.6838 - val_accuracy: 0.6704
Epoch 29/500
44/44 - 7s - loss: 1.5885e-04 - accuracy: 1.0000 - val_loss: 1.6890 - val_accuracy: 0.6704
Epoch 30/500
44/44 - 7s - loss: 1.5074e-04 - accuracy: 1.0000 - val_loss: 1.6958 - val_accuracy: 0.6704
Epoch 31/500
44/44 - 7s - loss: 1.4324e-04 - accuracy: 1.0000 - val_loss: 1.7011 - val_accuracy: 0.6648
Epoch 32/500
44/44 - 7s - loss: 1.3643e-04 - accuracy: 1.0000 - val_loss: 1.7084 - val_accuracy: 0.6648
Epoch 33/500
44/44 - 7s - loss: 1.2979e-04 - accuracy: 1.0000 - val_loss: 1.7128 - val_accuracy: 0.6704
Epoch 34/500
44/44 - 7s - loss: 1.2378e-04 - accuracy: 1.0000 - val_loss: 1.7175 - val_accuracy: 0.6648
Epoch 35/500
44/44 - 7s - loss: 1.1789e-04 - accuracy: 1.0000 - val_loss: 1.7253 - val_accuracy: 0.6648
Epoch 36/500
44/44 - 7s - loss: 1.1254e-04 - accuracy: 1.0000 - val_loss: 1.7297 - val_accuracy: 0.6648
Epoch 37/500
44/44 - 7s - loss: 1.0750e-04 - accuracy: 1.0000 - val_loss: 1.7358 - val_accuracy: 0.6648
Epoch 38/500
44/44 - 7s - loss: 1.0275e-04 - accuracy: 1.0000 - val_loss: 1.7414 - val_accuracy: 0.6648
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 15:33:46.546675: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 15:33:46.546822: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 15:33:46.546855: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 15:33:46.697677: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 15:33:46.697783: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00038: early stopping
Length split part:  1397
Labels in this part of split:  [295, 273, 289, 271, 269]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 19s - loss: 1.4160 - accuracy: 0.4789 - val_loss: 2.0746 - val_accuracy: 0.1508
Epoch 2/500
44/44 - 20s - loss: 0.2104 - accuracy: 0.9356 - val_loss: 1.6867 - val_accuracy: 0.3799
Epoch 3/500
44/44 - 7s - loss: 0.0221 - accuracy: 0.9957 - val_loss: 2.3495 - val_accuracy: 0.2626
Epoch 4/500
44/44 - 19s - loss: 0.0079 - accuracy: 0.9979 - val_loss: 1.6428 - val_accuracy: 0.4190
Epoch 5/500
44/44 - 19s - loss: 0.0036 - accuracy: 0.9993 - val_loss: 1.4286 - val_accuracy: 0.5028
Epoch 6/500
44/44 - 7s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.5880 - val_accuracy: 0.4693
Epoch 7/500
44/44 - 7s - loss: 9.7216e-04 - accuracy: 1.0000 - val_loss: 1.5114 - val_accuracy: 0.4916
Epoch 8/500
44/44 - 7s - loss: 8.0628e-04 - accuracy: 1.0000 - val_loss: 1.5024 - val_accuracy: 0.5140
Epoch 9/500
44/44 - 7s - loss: 6.8662e-04 - accuracy: 1.0000 - val_loss: 1.4933 - val_accuracy: 0.5531
Epoch 10/500
44/44 - 7s - loss: 5.9707e-04 - accuracy: 1.0000 - val_loss: 1.4921 - val_accuracy: 0.6089
Epoch 11/500
44/44 - 7s - loss: 5.2690e-04 - accuracy: 1.0000 - val_loss: 1.4915 - val_accuracy: 0.6145
Epoch 12/500
44/44 - 7s - loss: 4.7218e-04 - accuracy: 1.0000 - val_loss: 1.4894 - val_accuracy: 0.6201
Epoch 13/500
44/44 - 7s - loss: 4.2707e-04 - accuracy: 1.0000 - val_loss: 1.4988 - val_accuracy: 0.6369
Epoch 14/500
44/44 - 7s - loss: 3.8749e-04 - accuracy: 1.0000 - val_loss: 1.5086 - val_accuracy: 0.6257
Epoch 15/500
44/44 - 7s - loss: 3.5429e-04 - accuracy: 1.0000 - val_loss: 1.5059 - val_accuracy: 0.6257
Epoch 16/500
44/44 - 7s - loss: 3.2633e-04 - accuracy: 1.0000 - val_loss: 1.5134 - val_accuracy: 0.6480
Epoch 17/500
44/44 - 7s - loss: 3.0140e-04 - accuracy: 1.0000 - val_loss: 1.5271 - val_accuracy: 0.6536
Epoch 18/500
44/44 - 7s - loss: 2.7957e-04 - accuracy: 1.0000 - val_loss: 1.5395 - val_accuracy: 0.6536
Epoch 19/500
44/44 - 7s - loss: 2.6021e-04 - accuracy: 1.0000 - val_loss: 1.5501 - val_accuracy: 0.6536
Epoch 20/500
44/44 - 7s - loss: 2.4265e-04 - accuracy: 1.0000 - val_loss: 1.5591 - val_accuracy: 0.6536
Epoch 21/500
44/44 - 7s - loss: 2.2710e-04 - accuracy: 1.0000 - val_loss: 1.5690 - val_accuracy: 0.6536
Epoch 22/500
44/44 - 7s - loss: 2.1313e-04 - accuracy: 1.0000 - val_loss: 1.5780 - val_accuracy: 0.6536
Epoch 23/500
44/44 - 7s - loss: 2.0032e-04 - accuracy: 1.0000 - val_loss: 1.5831 - val_accuracy: 0.6536
Epoch 24/500
44/44 - 7s - loss: 1.8860e-04 - accuracy: 1.0000 - val_loss: 1.5910 - val_accuracy: 0.6536
Epoch 25/500
44/44 - 7s - loss: 1.7802e-04 - accuracy: 1.0000 - val_loss: 1.5979 - val_accuracy: 0.6536
Epoch 26/500
44/44 - 7s - loss: 1.6849e-04 - accuracy: 1.0000 - val_loss: 1.6031 - val_accuracy: 0.6536
Epoch 27/500
44/44 - 7s - loss: 1.5939e-04 - accuracy: 1.0000 - val_loss: 1.6100 - val_accuracy: 0.6536
Epoch 28/500
44/44 - 7s - loss: 1.5121e-04 - accuracy: 1.0000 - val_loss: 1.6160 - val_accuracy: 0.6536
Epoch 29/500
44/44 - 7s - loss: 1.4339e-04 - accuracy: 1.0000 - val_loss: 1.6235 - val_accuracy: 0.6536
Epoch 30/500
44/44 - 7s - loss: 1.3632e-04 - accuracy: 1.0000 - val_loss: 1.6280 - val_accuracy: 0.6536
Epoch 31/500
44/44 - 7s - loss: 1.2983e-04 - accuracy: 1.0000 - val_loss: 1.6347 - val_accuracy: 0.6536
Epoch 32/500
44/44 - 7s - loss: 1.2367e-04 - accuracy: 1.0000 - val_loss: 1.6372 - val_accuracy: 0.6536
Epoch 33/500
44/44 - 7s - loss: 1.1785e-04 - accuracy: 1.0000 - val_loss: 1.6451 - val_accuracy: 0.6536
Epoch 34/500
44/44 - 7s - loss: 1.1243e-04 - accuracy: 1.0000 - val_loss: 1.6498 - val_accuracy: 0.6536
Epoch 35/500
44/44 - 7s - loss: 1.0740e-04 - accuracy: 1.0000 - val_loss: 1.6562 - val_accuracy: 0.6536
Epoch 36/500
44/44 - 7s - loss: 1.0274e-04 - accuracy: 1.0000 - val_loss: 1.6608 - val_accuracy: 0.6536
Epoch 37/500
44/44 - 7s - loss: 9.8296e-05 - accuracy: 1.0000 - val_loss: 1.6659 - val_accuracy: 0.6536
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 15:40:19.709502: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 15:40:19.709661: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 15:40:19.709711: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 15:40:20.022130: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 15:40:20.022232: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00037: early stopping
InceptionResNetV2
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 127, 127, 32) 864         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 127, 127, 32) 96          conv2d[0][0]                     
__________________________________________________________________________________________________
activation (Activation)         (None, 127, 127, 32) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 125, 125, 32) 9216        activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 125, 125, 32) 96          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 125, 125, 32) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 125, 125, 64) 18432       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 125, 125, 64) 192         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 125, 125, 64) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 62, 62, 64)   0           activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 62, 62, 80)   5120        max_pooling2d[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 62, 62, 80)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 62, 62, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 60, 60, 192)  138240      activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 60, 60, 192)  576         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 60, 60, 192)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 29, 29, 192)  0           activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 29, 29, 64)   192         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 29, 29, 64)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 29, 29, 48)   9216        max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 29, 29, 96)   55296       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 29, 29, 48)   144         conv2d_6[0][0]                   
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 29, 29, 96)   288         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 29, 29, 48)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 29, 29, 96)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 29, 29, 192)  0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 29, 29, 96)   18432       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 29, 29, 64)   76800       activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 29, 29, 96)   82944       activation_9[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 29, 29, 64)   12288       average_pooling2d[0][0]          
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 29, 29, 96)   288         conv2d_5[0][0]                   
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 29, 29, 64)   192         conv2d_7[0][0]                   
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 29, 29, 96)   288         conv2d_10[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 29, 29, 64)   192         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 29, 29, 96)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 29, 29, 64)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 29, 29, 96)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 29, 29, 64)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
mixed_5b (Concatenate)          (None, 29, 29, 320)  0           activation_5[0][0]               
                                                                 activation_7[0][0]               
                                                                 activation_10[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 29, 29, 32)   10240       mixed_5b[0][0]                   
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 29, 29, 32)   96          conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 29, 29, 32)   0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 29, 29, 32)   10240       mixed_5b[0][0]                   
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 29, 29, 48)   13824       activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 29, 29, 32)   96          conv2d_13[0][0]                  
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 29, 29, 48)   144         conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 29, 29, 32)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 29, 29, 48)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 29, 29, 32)   10240       mixed_5b[0][0]                   
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 29, 29, 32)   9216        activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 29, 29, 64)   27648       activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 29, 29, 32)   96          conv2d_12[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 29, 29, 32)   96          conv2d_14[0][0]                  
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 29, 29, 64)   192         conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 29, 29, 32)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 29, 29, 32)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 29, 29, 64)   0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
block35_1_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_12[0][0]              
                                                                 activation_14[0][0]              
                                                                 activation_17[0][0]              
__________________________________________________________________________________________________
block35_1_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_1_mixed[0][0]            
__________________________________________________________________________________________________
block35_1 (Lambda)              (None, 29, 29, 320)  0           mixed_5b[0][0]                   
                                                                 block35_1_conv[0][0]             
__________________________________________________________________________________________________
block35_1_ac (Activation)       (None, 29, 29, 320)  0           block35_1[0][0]                  
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 29, 29, 32)   10240       block35_1_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 29, 29, 32)   96          conv2d_21[0][0]                  
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 29, 29, 32)   0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 29, 29, 32)   10240       block35_1_ac[0][0]               
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 29, 29, 48)   13824       activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 29, 29, 32)   96          conv2d_19[0][0]                  
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 29, 29, 48)   144         conv2d_22[0][0]                  
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 29, 29, 32)   0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 29, 29, 48)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 29, 29, 32)   10240       block35_1_ac[0][0]               
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 29, 29, 32)   9216        activation_19[0][0]              
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 29, 29, 64)   27648       activation_22[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 29, 29, 32)   96          conv2d_18[0][0]                  
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 29, 29, 32)   96          conv2d_20[0][0]                  
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 29, 29, 64)   192         conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 29, 29, 32)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 29, 29, 32)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 29, 29, 64)   0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
block35_2_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_18[0][0]              
                                                                 activation_20[0][0]              
                                                                 activation_23[0][0]              
__________________________________________________________________________________________________
block35_2_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_2_mixed[0][0]            
__________________________________________________________________________________________________
block35_2 (Lambda)              (None, 29, 29, 320)  0           block35_1_ac[0][0]               
                                                                 block35_2_conv[0][0]             
__________________________________________________________________________________________________
block35_2_ac (Activation)       (None, 29, 29, 320)  0           block35_2[0][0]                  
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 29, 29, 32)   10240       block35_2_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 29, 29, 32)   96          conv2d_27[0][0]                  
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 29, 29, 32)   0           batch_normalization_27[0][0]     
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 29, 29, 32)   10240       block35_2_ac[0][0]               
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 29, 29, 48)   13824       activation_27[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 29, 29, 32)   96          conv2d_25[0][0]                  
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 29, 29, 48)   144         conv2d_28[0][0]                  
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 29, 29, 32)   0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 29, 29, 48)   0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 29, 29, 32)   10240       block35_2_ac[0][0]               
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 29, 29, 32)   9216        activation_25[0][0]              
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 29, 29, 64)   27648       activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 29, 29, 32)   96          conv2d_24[0][0]                  
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 29, 29, 32)   96          conv2d_26[0][0]                  
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 29, 29, 64)   192         conv2d_29[0][0]                  
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 29, 29, 32)   0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 29, 29, 32)   0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 29, 29, 64)   0           batch_normalization_29[0][0]     
__________________________________________________________________________________________________
block35_3_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_24[0][0]              
                                                                 activation_26[0][0]              
                                                                 activation_29[0][0]              
__________________________________________________________________________________________________
block35_3_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_3_mixed[0][0]            
__________________________________________________________________________________________________
block35_3 (Lambda)              (None, 29, 29, 320)  0           block35_2_ac[0][0]               
                                                                 block35_3_conv[0][0]             
__________________________________________________________________________________________________
block35_3_ac (Activation)       (None, 29, 29, 320)  0           block35_3[0][0]                  
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 29, 29, 32)   10240       block35_3_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 29, 29, 32)   96          conv2d_33[0][0]                  
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 29, 29, 32)   0           batch_normalization_33[0][0]     
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 29, 29, 32)   10240       block35_3_ac[0][0]               
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 29, 29, 48)   13824       activation_33[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 29, 29, 32)   96          conv2d_31[0][0]                  
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 29, 29, 48)   144         conv2d_34[0][0]                  
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 29, 29, 32)   0           batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 29, 29, 48)   0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 29, 29, 32)   10240       block35_3_ac[0][0]               
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 29, 29, 32)   9216        activation_31[0][0]              
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 29, 29, 64)   27648       activation_34[0][0]              
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 29, 29, 32)   96          conv2d_30[0][0]                  
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 29, 29, 32)   96          conv2d_32[0][0]                  
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 29, 29, 64)   192         conv2d_35[0][0]                  
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 29, 29, 32)   0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 29, 29, 32)   0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 29, 29, 64)   0           batch_normalization_35[0][0]     
__________________________________________________________________________________________________
block35_4_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_30[0][0]              
                                                                 activation_32[0][0]              
                                                                 activation_35[0][0]              
__________________________________________________________________________________________________
block35_4_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_4_mixed[0][0]            
__________________________________________________________________________________________________
block35_4 (Lambda)              (None, 29, 29, 320)  0           block35_3_ac[0][0]               
                                                                 block35_4_conv[0][0]             
__________________________________________________________________________________________________
block35_4_ac (Activation)       (None, 29, 29, 320)  0           block35_4[0][0]                  
__________________________________________________________________________________________________
conv2d_39 (Conv2D)              (None, 29, 29, 32)   10240       block35_4_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 29, 29, 32)   96          conv2d_39[0][0]                  
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 29, 29, 32)   0           batch_normalization_39[0][0]     
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 29, 29, 32)   10240       block35_4_ac[0][0]               
__________________________________________________________________________________________________
conv2d_40 (Conv2D)              (None, 29, 29, 48)   13824       activation_39[0][0]              
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 29, 29, 32)   96          conv2d_37[0][0]                  
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 29, 29, 48)   144         conv2d_40[0][0]                  
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 29, 29, 32)   0           batch_normalization_37[0][0]     
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 29, 29, 48)   0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 29, 29, 32)   10240       block35_4_ac[0][0]               
__________________________________________________________________________________________________
conv2d_38 (Conv2D)              (None, 29, 29, 32)   9216        activation_37[0][0]              
__________________________________________________________________________________________________
conv2d_41 (Conv2D)              (None, 29, 29, 64)   27648       activation_40[0][0]              
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 29, 29, 32)   96          conv2d_36[0][0]                  
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 29, 29, 32)   96          conv2d_38[0][0]                  
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 29, 29, 64)   192         conv2d_41[0][0]                  
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 29, 29, 32)   0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 29, 29, 32)   0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 29, 29, 64)   0           batch_normalization_41[0][0]     
__________________________________________________________________________________________________
block35_5_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_36[0][0]              
                                                                 activation_38[0][0]              
                                                                 activation_41[0][0]              
__________________________________________________________________________________________________
block35_5_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_5_mixed[0][0]            
__________________________________________________________________________________________________
block35_5 (Lambda)              (None, 29, 29, 320)  0           block35_4_ac[0][0]               
                                                                 block35_5_conv[0][0]             
__________________________________________________________________________________________________
block35_5_ac (Activation)       (None, 29, 29, 320)  0           block35_5[0][0]                  
__________________________________________________________________________________________________
conv2d_45 (Conv2D)              (None, 29, 29, 32)   10240       block35_5_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 29, 29, 32)   96          conv2d_45[0][0]                  
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 29, 29, 32)   0           batch_normalization_45[0][0]     
__________________________________________________________________________________________________
conv2d_43 (Conv2D)              (None, 29, 29, 32)   10240       block35_5_ac[0][0]               
__________________________________________________________________________________________________
conv2d_46 (Conv2D)              (None, 29, 29, 48)   13824       activation_45[0][0]              
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 29, 29, 32)   96          conv2d_43[0][0]                  
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 29, 29, 48)   144         conv2d_46[0][0]                  
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 29, 29, 32)   0           batch_normalization_43[0][0]     
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 29, 29, 48)   0           batch_normalization_46[0][0]     
__________________________________________________________________________________________________
conv2d_42 (Conv2D)              (None, 29, 29, 32)   10240       block35_5_ac[0][0]               
__________________________________________________________________________________________________
conv2d_44 (Conv2D)              (None, 29, 29, 32)   9216        activation_43[0][0]              
__________________________________________________________________________________________________
conv2d_47 (Conv2D)              (None, 29, 29, 64)   27648       activation_46[0][0]              
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 29, 29, 32)   96          conv2d_42[0][0]                  
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 29, 29, 32)   96          conv2d_44[0][0]                  
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 29, 29, 64)   192         conv2d_47[0][0]                  
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 29, 29, 32)   0           batch_normalization_42[0][0]     
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 29, 29, 32)   0           batch_normalization_44[0][0]     
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 29, 29, 64)   0           batch_normalization_47[0][0]     
__________________________________________________________________________________________________
block35_6_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_42[0][0]              
                                                                 activation_44[0][0]              
                                                                 activation_47[0][0]              
__________________________________________________________________________________________________
block35_6_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_6_mixed[0][0]            
__________________________________________________________________________________________________
block35_6 (Lambda)              (None, 29, 29, 320)  0           block35_5_ac[0][0]               
                                                                 block35_6_conv[0][0]             
__________________________________________________________________________________________________
block35_6_ac (Activation)       (None, 29, 29, 320)  0           block35_6[0][0]                  
__________________________________________________________________________________________________
conv2d_51 (Conv2D)              (None, 29, 29, 32)   10240       block35_6_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 29, 29, 32)   96          conv2d_51[0][0]                  
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 29, 29, 32)   0           batch_normalization_51[0][0]     
__________________________________________________________________________________________________
conv2d_49 (Conv2D)              (None, 29, 29, 32)   10240       block35_6_ac[0][0]               
__________________________________________________________________________________________________
conv2d_52 (Conv2D)              (None, 29, 29, 48)   13824       activation_51[0][0]              
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 29, 29, 32)   96          conv2d_49[0][0]                  
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 29, 29, 48)   144         conv2d_52[0][0]                  
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 29, 29, 32)   0           batch_normalization_49[0][0]     
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 29, 29, 48)   0           batch_normalization_52[0][0]     
__________________________________________________________________________________________________
conv2d_48 (Conv2D)              (None, 29, 29, 32)   10240       block35_6_ac[0][0]               
__________________________________________________________________________________________________
conv2d_50 (Conv2D)              (None, 29, 29, 32)   9216        activation_49[0][0]              
__________________________________________________________________________________________________
conv2d_53 (Conv2D)              (None, 29, 29, 64)   27648       activation_52[0][0]              
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 29, 29, 32)   96          conv2d_48[0][0]                  
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 29, 29, 32)   96          conv2d_50[0][0]                  
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 29, 29, 64)   192         conv2d_53[0][0]                  
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 29, 29, 32)   0           batch_normalization_48[0][0]     
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 29, 29, 32)   0           batch_normalization_50[0][0]     
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 29, 29, 64)   0           batch_normalization_53[0][0]     
__________________________________________________________________________________________________
block35_7_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_48[0][0]              
                                                                 activation_50[0][0]              
                                                                 activation_53[0][0]              
__________________________________________________________________________________________________
block35_7_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_7_mixed[0][0]            
__________________________________________________________________________________________________
block35_7 (Lambda)              (None, 29, 29, 320)  0           block35_6_ac[0][0]               
                                                                 block35_7_conv[0][0]             
__________________________________________________________________________________________________
block35_7_ac (Activation)       (None, 29, 29, 320)  0           block35_7[0][0]                  
__________________________________________________________________________________________________
conv2d_57 (Conv2D)              (None, 29, 29, 32)   10240       block35_7_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_57 (BatchNo (None, 29, 29, 32)   96          conv2d_57[0][0]                  
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 29, 29, 32)   0           batch_normalization_57[0][0]     
__________________________________________________________________________________________________
conv2d_55 (Conv2D)              (None, 29, 29, 32)   10240       block35_7_ac[0][0]               
__________________________________________________________________________________________________
conv2d_58 (Conv2D)              (None, 29, 29, 48)   13824       activation_57[0][0]              
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 29, 29, 32)   96          conv2d_55[0][0]                  
__________________________________________________________________________________________________
batch_normalization_58 (BatchNo (None, 29, 29, 48)   144         conv2d_58[0][0]                  
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 29, 29, 32)   0           batch_normalization_55[0][0]     
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 29, 29, 48)   0           batch_normalization_58[0][0]     
__________________________________________________________________________________________________
conv2d_54 (Conv2D)              (None, 29, 29, 32)   10240       block35_7_ac[0][0]               
__________________________________________________________________________________________________
conv2d_56 (Conv2D)              (None, 29, 29, 32)   9216        activation_55[0][0]              
__________________________________________________________________________________________________
conv2d_59 (Conv2D)              (None, 29, 29, 64)   27648       activation_58[0][0]              
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 29, 29, 32)   96          conv2d_54[0][0]                  
__________________________________________________________________________________________________
batch_normalization_56 (BatchNo (None, 29, 29, 32)   96          conv2d_56[0][0]                  
__________________________________________________________________________________________________
batch_normalization_59 (BatchNo (None, 29, 29, 64)   192         conv2d_59[0][0]                  
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 29, 29, 32)   0           batch_normalization_54[0][0]     
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 29, 29, 32)   0           batch_normalization_56[0][0]     
__________________________________________________________________________________________________
activation_59 (Activation)      (None, 29, 29, 64)   0           batch_normalization_59[0][0]     
__________________________________________________________________________________________________
block35_8_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_54[0][0]              
                                                                 activation_56[0][0]              
                                                                 activation_59[0][0]              
__________________________________________________________________________________________________
block35_8_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_8_mixed[0][0]            
__________________________________________________________________________________________________
block35_8 (Lambda)              (None, 29, 29, 320)  0           block35_7_ac[0][0]               
                                                                 block35_8_conv[0][0]             
__________________________________________________________________________________________________
block35_8_ac (Activation)       (None, 29, 29, 320)  0           block35_8[0][0]                  
__________________________________________________________________________________________________
conv2d_63 (Conv2D)              (None, 29, 29, 32)   10240       block35_8_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_63 (BatchNo (None, 29, 29, 32)   96          conv2d_63[0][0]                  
__________________________________________________________________________________________________
activation_63 (Activation)      (None, 29, 29, 32)   0           batch_normalization_63[0][0]     
__________________________________________________________________________________________________
conv2d_61 (Conv2D)              (None, 29, 29, 32)   10240       block35_8_ac[0][0]               
__________________________________________________________________________________________________
conv2d_64 (Conv2D)              (None, 29, 29, 48)   13824       activation_63[0][0]              
__________________________________________________________________________________________________
batch_normalization_61 (BatchNo (None, 29, 29, 32)   96          conv2d_61[0][0]                  
__________________________________________________________________________________________________
batch_normalization_64 (BatchNo (None, 29, 29, 48)   144         conv2d_64[0][0]                  
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 29, 29, 32)   0           batch_normalization_61[0][0]     
__________________________________________________________________________________________________
activation_64 (Activation)      (None, 29, 29, 48)   0           batch_normalization_64[0][0]     
__________________________________________________________________________________________________
conv2d_60 (Conv2D)              (None, 29, 29, 32)   10240       block35_8_ac[0][0]               
__________________________________________________________________________________________________
conv2d_62 (Conv2D)              (None, 29, 29, 32)   9216        activation_61[0][0]              
__________________________________________________________________________________________________
conv2d_65 (Conv2D)              (None, 29, 29, 64)   27648       activation_64[0][0]              
__________________________________________________________________________________________________
batch_normalization_60 (BatchNo (None, 29, 29, 32)   96          conv2d_60[0][0]                  
__________________________________________________________________________________________________
batch_normalization_62 (BatchNo (None, 29, 29, 32)   96          conv2d_62[0][0]                  
__________________________________________________________________________________________________
batch_normalization_65 (BatchNo (None, 29, 29, 64)   192         conv2d_65[0][0]                  
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 29, 29, 32)   0           batch_normalization_60[0][0]     
__________________________________________________________________________________________________
activation_62 (Activation)      (None, 29, 29, 32)   0           batch_normalization_62[0][0]     
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 29, 29, 64)   0           batch_normalization_65[0][0]     
__________________________________________________________________________________________________
block35_9_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_60[0][0]              
                                                                 activation_62[0][0]              
                                                                 activation_65[0][0]              
__________________________________________________________________________________________________
block35_9_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_9_mixed[0][0]            
__________________________________________________________________________________________________
block35_9 (Lambda)              (None, 29, 29, 320)  0           block35_8_ac[0][0]               
                                                                 block35_9_conv[0][0]             
__________________________________________________________________________________________________
block35_9_ac (Activation)       (None, 29, 29, 320)  0           block35_9[0][0]                  
__________________________________________________________________________________________________
conv2d_69 (Conv2D)              (None, 29, 29, 32)   10240       block35_9_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_69 (BatchNo (None, 29, 29, 32)   96          conv2d_69[0][0]                  
__________________________________________________________________________________________________
activation_69 (Activation)      (None, 29, 29, 32)   0           batch_normalization_69[0][0]     
__________________________________________________________________________________________________
conv2d_67 (Conv2D)              (None, 29, 29, 32)   10240       block35_9_ac[0][0]               
__________________________________________________________________________________________________
conv2d_70 (Conv2D)              (None, 29, 29, 48)   13824       activation_69[0][0]              
__________________________________________________________________________________________________
batch_normalization_67 (BatchNo (None, 29, 29, 32)   96          conv2d_67[0][0]                  
__________________________________________________________________________________________________
batch_normalization_70 (BatchNo (None, 29, 29, 48)   144         conv2d_70[0][0]                  
__________________________________________________________________________________________________
activation_67 (Activation)      (None, 29, 29, 32)   0           batch_normalization_67[0][0]     
__________________________________________________________________________________________________
activation_70 (Activation)      (None, 29, 29, 48)   0           batch_normalization_70[0][0]     
__________________________________________________________________________________________________
conv2d_66 (Conv2D)              (None, 29, 29, 32)   10240       block35_9_ac[0][0]               
__________________________________________________________________________________________________
conv2d_68 (Conv2D)              (None, 29, 29, 32)   9216        activation_67[0][0]              
__________________________________________________________________________________________________
conv2d_71 (Conv2D)              (None, 29, 29, 64)   27648       activation_70[0][0]              
__________________________________________________________________________________________________
batch_normalization_66 (BatchNo (None, 29, 29, 32)   96          conv2d_66[0][0]                  
__________________________________________________________________________________________________
batch_normalization_68 (BatchNo (None, 29, 29, 32)   96          conv2d_68[0][0]                  
__________________________________________________________________________________________________
batch_normalization_71 (BatchNo (None, 29, 29, 64)   192         conv2d_71[0][0]                  
__________________________________________________________________________________________________
activation_66 (Activation)      (None, 29, 29, 32)   0           batch_normalization_66[0][0]     
__________________________________________________________________________________________________
activation_68 (Activation)      (None, 29, 29, 32)   0           batch_normalization_68[0][0]     
__________________________________________________________________________________________________
activation_71 (Activation)      (None, 29, 29, 64)   0           batch_normalization_71[0][0]     
__________________________________________________________________________________________________
block35_10_mixed (Concatenate)  (None, 29, 29, 128)  0           activation_66[0][0]              
                                                                 activation_68[0][0]              
                                                                 activation_71[0][0]              
__________________________________________________________________________________________________
block35_10_conv (Conv2D)        (None, 29, 29, 320)  41280       block35_10_mixed[0][0]           
__________________________________________________________________________________________________
block35_10 (Lambda)             (None, 29, 29, 320)  0           block35_9_ac[0][0]               
                                                                 block35_10_conv[0][0]            
__________________________________________________________________________________________________
block35_10_ac (Activation)      (None, 29, 29, 320)  0           block35_10[0][0]                 
__________________________________________________________________________________________________
conv2d_73 (Conv2D)              (None, 29, 29, 256)  81920       block35_10_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_73 (BatchNo (None, 29, 29, 256)  768         conv2d_73[0][0]                  
__________________________________________________________________________________________________
activation_73 (Activation)      (None, 29, 29, 256)  0           batch_normalization_73[0][0]     
__________________________________________________________________________________________________
conv2d_74 (Conv2D)              (None, 29, 29, 256)  589824      activation_73[0][0]              
__________________________________________________________________________________________________
batch_normalization_74 (BatchNo (None, 29, 29, 256)  768         conv2d_74[0][0]                  
__________________________________________________________________________________________________
activation_74 (Activation)      (None, 29, 29, 256)  0           batch_normalization_74[0][0]     
__________________________________________________________________________________________________
conv2d_72 (Conv2D)              (None, 14, 14, 384)  1105920     block35_10_ac[0][0]              
__________________________________________________________________________________________________
conv2d_75 (Conv2D)              (None, 14, 14, 384)  884736      activation_74[0][0]              
__________________________________________________________________________________________________
batch_normalization_72 (BatchNo (None, 14, 14, 384)  1152        conv2d_72[0][0]                  
__________________________________________________________________________________________________
batch_normalization_75 (BatchNo (None, 14, 14, 384)  1152        conv2d_75[0][0]                  
__________________________________________________________________________________________________
activation_72 (Activation)      (None, 14, 14, 384)  0           batch_normalization_72[0][0]     
__________________________________________________________________________________________________
activation_75 (Activation)      (None, 14, 14, 384)  0           batch_normalization_75[0][0]     
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 320)  0           block35_10_ac[0][0]              
__________________________________________________________________________________________________
mixed_6a (Concatenate)          (None, 14, 14, 1088) 0           activation_72[0][0]              
                                                                 activation_75[0][0]              
                                                                 max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_77 (Conv2D)              (None, 14, 14, 128)  139264      mixed_6a[0][0]                   
__________________________________________________________________________________________________
batch_normalization_77 (BatchNo (None, 14, 14, 128)  384         conv2d_77[0][0]                  
__________________________________________________________________________________________________
activation_77 (Activation)      (None, 14, 14, 128)  0           batch_normalization_77[0][0]     
__________________________________________________________________________________________________
conv2d_78 (Conv2D)              (None, 14, 14, 160)  143360      activation_77[0][0]              
__________________________________________________________________________________________________
batch_normalization_78 (BatchNo (None, 14, 14, 160)  480         conv2d_78[0][0]                  
__________________________________________________________________________________________________
activation_78 (Activation)      (None, 14, 14, 160)  0           batch_normalization_78[0][0]     
__________________________________________________________________________________________________
conv2d_76 (Conv2D)              (None, 14, 14, 192)  208896      mixed_6a[0][0]                   
__________________________________________________________________________________________________
conv2d_79 (Conv2D)              (None, 14, 14, 192)  215040      activation_78[0][0]              
__________________________________________________________________________________________________
batch_normalization_76 (BatchNo (None, 14, 14, 192)  576         conv2d_76[0][0]                  
__________________________________________________________________________________________________
batch_normalization_79 (BatchNo (None, 14, 14, 192)  576         conv2d_79[0][0]                  
__________________________________________________________________________________________________
activation_76 (Activation)      (None, 14, 14, 192)  0           batch_normalization_76[0][0]     
__________________________________________________________________________________________________
activation_79 (Activation)      (None, 14, 14, 192)  0           batch_normalization_79[0][0]     
__________________________________________________________________________________________________
block17_1_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_76[0][0]              
                                                                 activation_79[0][0]              
__________________________________________________________________________________________________
block17_1_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_1_mixed[0][0]            
__________________________________________________________________________________________________
block17_1 (Lambda)              (None, 14, 14, 1088) 0           mixed_6a[0][0]                   
                                                                 block17_1_conv[0][0]             
__________________________________________________________________________________________________
block17_1_ac (Activation)       (None, 14, 14, 1088) 0           block17_1[0][0]                  
__________________________________________________________________________________________________
conv2d_81 (Conv2D)              (None, 14, 14, 128)  139264      block17_1_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_81 (BatchNo (None, 14, 14, 128)  384         conv2d_81[0][0]                  
__________________________________________________________________________________________________
activation_81 (Activation)      (None, 14, 14, 128)  0           batch_normalization_81[0][0]     
__________________________________________________________________________________________________
conv2d_82 (Conv2D)              (None, 14, 14, 160)  143360      activation_81[0][0]              
__________________________________________________________________________________________________
batch_normalization_82 (BatchNo (None, 14, 14, 160)  480         conv2d_82[0][0]                  
__________________________________________________________________________________________________
activation_82 (Activation)      (None, 14, 14, 160)  0           batch_normalization_82[0][0]     
__________________________________________________________________________________________________
conv2d_80 (Conv2D)              (None, 14, 14, 192)  208896      block17_1_ac[0][0]               
__________________________________________________________________________________________________
conv2d_83 (Conv2D)              (None, 14, 14, 192)  215040      activation_82[0][0]              
__________________________________________________________________________________________________
batch_normalization_80 (BatchNo (None, 14, 14, 192)  576         conv2d_80[0][0]                  
__________________________________________________________________________________________________
batch_normalization_83 (BatchNo (None, 14, 14, 192)  576         conv2d_83[0][0]                  
__________________________________________________________________________________________________
activation_80 (Activation)      (None, 14, 14, 192)  0           batch_normalization_80[0][0]     
__________________________________________________________________________________________________
activation_83 (Activation)      (None, 14, 14, 192)  0           batch_normalization_83[0][0]     
__________________________________________________________________________________________________
block17_2_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_80[0][0]              
                                                                 activation_83[0][0]              
__________________________________________________________________________________________________
block17_2_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_2_mixed[0][0]            
__________________________________________________________________________________________________
block17_2 (Lambda)              (None, 14, 14, 1088) 0           block17_1_ac[0][0]               
                                                                 block17_2_conv[0][0]             
__________________________________________________________________________________________________
block17_2_ac (Activation)       (None, 14, 14, 1088) 0           block17_2[0][0]                  
__________________________________________________________________________________________________
conv2d_85 (Conv2D)              (None, 14, 14, 128)  139264      block17_2_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_85 (BatchNo (None, 14, 14, 128)  384         conv2d_85[0][0]                  
__________________________________________________________________________________________________
activation_85 (Activation)      (None, 14, 14, 128)  0           batch_normalization_85[0][0]     
__________________________________________________________________________________________________
conv2d_86 (Conv2D)              (None, 14, 14, 160)  143360      activation_85[0][0]              
__________________________________________________________________________________________________
batch_normalization_86 (BatchNo (None, 14, 14, 160)  480         conv2d_86[0][0]                  
__________________________________________________________________________________________________
activation_86 (Activation)      (None, 14, 14, 160)  0           batch_normalization_86[0][0]     
__________________________________________________________________________________________________
conv2d_84 (Conv2D)              (None, 14, 14, 192)  208896      block17_2_ac[0][0]               
__________________________________________________________________________________________________
conv2d_87 (Conv2D)              (None, 14, 14, 192)  215040      activation_86[0][0]              
__________________________________________________________________________________________________
batch_normalization_84 (BatchNo (None, 14, 14, 192)  576         conv2d_84[0][0]                  
__________________________________________________________________________________________________
batch_normalization_87 (BatchNo (None, 14, 14, 192)  576         conv2d_87[0][0]                  
__________________________________________________________________________________________________
activation_84 (Activation)      (None, 14, 14, 192)  0           batch_normalization_84[0][0]     
__________________________________________________________________________________________________
activation_87 (Activation)      (None, 14, 14, 192)  0           batch_normalization_87[0][0]     
__________________________________________________________________________________________________
block17_3_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_84[0][0]              
                                                                 activation_87[0][0]              
__________________________________________________________________________________________________
block17_3_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_3_mixed[0][0]            
__________________________________________________________________________________________________
block17_3 (Lambda)              (None, 14, 14, 1088) 0           block17_2_ac[0][0]               
                                                                 block17_3_conv[0][0]             
__________________________________________________________________________________________________
block17_3_ac (Activation)       (None, 14, 14, 1088) 0           block17_3[0][0]                  
__________________________________________________________________________________________________
conv2d_89 (Conv2D)              (None, 14, 14, 128)  139264      block17_3_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_89 (BatchNo (None, 14, 14, 128)  384         conv2d_89[0][0]                  
__________________________________________________________________________________________________
activation_89 (Activation)      (None, 14, 14, 128)  0           batch_normalization_89[0][0]     
__________________________________________________________________________________________________
conv2d_90 (Conv2D)              (None, 14, 14, 160)  143360      activation_89[0][0]              
__________________________________________________________________________________________________
batch_normalization_90 (BatchNo (None, 14, 14, 160)  480         conv2d_90[0][0]                  
__________________________________________________________________________________________________
activation_90 (Activation)      (None, 14, 14, 160)  0           batch_normalization_90[0][0]     
__________________________________________________________________________________________________
conv2d_88 (Conv2D)              (None, 14, 14, 192)  208896      block17_3_ac[0][0]               
__________________________________________________________________________________________________
conv2d_91 (Conv2D)              (None, 14, 14, 192)  215040      activation_90[0][0]              
__________________________________________________________________________________________________
batch_normalization_88 (BatchNo (None, 14, 14, 192)  576         conv2d_88[0][0]                  
__________________________________________________________________________________________________
batch_normalization_91 (BatchNo (None, 14, 14, 192)  576         conv2d_91[0][0]                  
__________________________________________________________________________________________________
activation_88 (Activation)      (None, 14, 14, 192)  0           batch_normalization_88[0][0]     
__________________________________________________________________________________________________
activation_91 (Activation)      (None, 14, 14, 192)  0           batch_normalization_91[0][0]     
__________________________________________________________________________________________________
block17_4_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_88[0][0]              
                                                                 activation_91[0][0]              
__________________________________________________________________________________________________
block17_4_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_4_mixed[0][0]            
__________________________________________________________________________________________________
block17_4 (Lambda)              (None, 14, 14, 1088) 0           block17_3_ac[0][0]               
                                                                 block17_4_conv[0][0]             
__________________________________________________________________________________________________
block17_4_ac (Activation)       (None, 14, 14, 1088) 0           block17_4[0][0]                  
__________________________________________________________________________________________________
conv2d_93 (Conv2D)              (None, 14, 14, 128)  139264      block17_4_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_93 (BatchNo (None, 14, 14, 128)  384         conv2d_93[0][0]                  
__________________________________________________________________________________________________
activation_93 (Activation)      (None, 14, 14, 128)  0           batch_normalization_93[0][0]     
__________________________________________________________________________________________________
conv2d_94 (Conv2D)              (None, 14, 14, 160)  143360      activation_93[0][0]              
__________________________________________________________________________________________________
batch_normalization_94 (BatchNo (None, 14, 14, 160)  480         conv2d_94[0][0]                  
__________________________________________________________________________________________________
activation_94 (Activation)      (None, 14, 14, 160)  0           batch_normalization_94[0][0]     
__________________________________________________________________________________________________
conv2d_92 (Conv2D)              (None, 14, 14, 192)  208896      block17_4_ac[0][0]               
__________________________________________________________________________________________________
conv2d_95 (Conv2D)              (None, 14, 14, 192)  215040      activation_94[0][0]              
__________________________________________________________________________________________________
batch_normalization_92 (BatchNo (None, 14, 14, 192)  576         conv2d_92[0][0]                  
__________________________________________________________________________________________________
batch_normalization_95 (BatchNo (None, 14, 14, 192)  576         conv2d_95[0][0]                  
__________________________________________________________________________________________________
activation_92 (Activation)      (None, 14, 14, 192)  0           batch_normalization_92[0][0]     
__________________________________________________________________________________________________
activation_95 (Activation)      (None, 14, 14, 192)  0           batch_normalization_95[0][0]     
__________________________________________________________________________________________________
block17_5_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_92[0][0]              
                                                                 activation_95[0][0]              
__________________________________________________________________________________________________
block17_5_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_5_mixed[0][0]            
__________________________________________________________________________________________________
block17_5 (Lambda)              (None, 14, 14, 1088) 0           block17_4_ac[0][0]               
                                                                 block17_5_conv[0][0]             
__________________________________________________________________________________________________
block17_5_ac (Activation)       (None, 14, 14, 1088) 0           block17_5[0][0]                  
__________________________________________________________________________________________________
conv2d_97 (Conv2D)              (None, 14, 14, 128)  139264      block17_5_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_97 (BatchNo (None, 14, 14, 128)  384         conv2d_97[0][0]                  
__________________________________________________________________________________________________
activation_97 (Activation)      (None, 14, 14, 128)  0           batch_normalization_97[0][0]     
__________________________________________________________________________________________________
conv2d_98 (Conv2D)              (None, 14, 14, 160)  143360      activation_97[0][0]              
__________________________________________________________________________________________________
batch_normalization_98 (BatchNo (None, 14, 14, 160)  480         conv2d_98[0][0]                  
__________________________________________________________________________________________________
activation_98 (Activation)      (None, 14, 14, 160)  0           batch_normalization_98[0][0]     
__________________________________________________________________________________________________
conv2d_96 (Conv2D)              (None, 14, 14, 192)  208896      block17_5_ac[0][0]               
__________________________________________________________________________________________________
conv2d_99 (Conv2D)              (None, 14, 14, 192)  215040      activation_98[0][0]              
__________________________________________________________________________________________________
batch_normalization_96 (BatchNo (None, 14, 14, 192)  576         conv2d_96[0][0]                  
__________________________________________________________________________________________________
batch_normalization_99 (BatchNo (None, 14, 14, 192)  576         conv2d_99[0][0]                  
__________________________________________________________________________________________________
activation_96 (Activation)      (None, 14, 14, 192)  0           batch_normalization_96[0][0]     
__________________________________________________________________________________________________
activation_99 (Activation)      (None, 14, 14, 192)  0           batch_normalization_99[0][0]     
__________________________________________________________________________________________________
block17_6_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_96[0][0]              
                                                                 activation_99[0][0]              
__________________________________________________________________________________________________
block17_6_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_6_mixed[0][0]            
__________________________________________________________________________________________________
block17_6 (Lambda)              (None, 14, 14, 1088) 0           block17_5_ac[0][0]               
                                                                 block17_6_conv[0][0]             
__________________________________________________________________________________________________
block17_6_ac (Activation)       (None, 14, 14, 1088) 0           block17_6[0][0]                  
__________________________________________________________________________________________________
conv2d_101 (Conv2D)             (None, 14, 14, 128)  139264      block17_6_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_101 (BatchN (None, 14, 14, 128)  384         conv2d_101[0][0]                 
__________________________________________________________________________________________________
activation_101 (Activation)     (None, 14, 14, 128)  0           batch_normalization_101[0][0]    
__________________________________________________________________________________________________
conv2d_102 (Conv2D)             (None, 14, 14, 160)  143360      activation_101[0][0]             
__________________________________________________________________________________________________
batch_normalization_102 (BatchN (None, 14, 14, 160)  480         conv2d_102[0][0]                 
__________________________________________________________________________________________________
activation_102 (Activation)     (None, 14, 14, 160)  0           batch_normalization_102[0][0]    
__________________________________________________________________________________________________
conv2d_100 (Conv2D)             (None, 14, 14, 192)  208896      block17_6_ac[0][0]               
__________________________________________________________________________________________________
conv2d_103 (Conv2D)             (None, 14, 14, 192)  215040      activation_102[0][0]             
__________________________________________________________________________________________________
batch_normalization_100 (BatchN (None, 14, 14, 192)  576         conv2d_100[0][0]                 
__________________________________________________________________________________________________
batch_normalization_103 (BatchN (None, 14, 14, 192)  576         conv2d_103[0][0]                 
__________________________________________________________________________________________________
activation_100 (Activation)     (None, 14, 14, 192)  0           batch_normalization_100[0][0]    
__________________________________________________________________________________________________
activation_103 (Activation)     (None, 14, 14, 192)  0           batch_normalization_103[0][0]    
__________________________________________________________________________________________________
block17_7_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_100[0][0]             
                                                                 activation_103[0][0]             
__________________________________________________________________________________________________
block17_7_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_7_mixed[0][0]            
__________________________________________________________________________________________________
block17_7 (Lambda)              (None, 14, 14, 1088) 0           block17_6_ac[0][0]               
                                                                 block17_7_conv[0][0]             
__________________________________________________________________________________________________
block17_7_ac (Activation)       (None, 14, 14, 1088) 0           block17_7[0][0]                  
__________________________________________________________________________________________________
conv2d_105 (Conv2D)             (None, 14, 14, 128)  139264      block17_7_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_105 (BatchN (None, 14, 14, 128)  384         conv2d_105[0][0]                 
__________________________________________________________________________________________________
activation_105 (Activation)     (None, 14, 14, 128)  0           batch_normalization_105[0][0]    
__________________________________________________________________________________________________
conv2d_106 (Conv2D)             (None, 14, 14, 160)  143360      activation_105[0][0]             
__________________________________________________________________________________________________
batch_normalization_106 (BatchN (None, 14, 14, 160)  480         conv2d_106[0][0]                 
__________________________________________________________________________________________________
activation_106 (Activation)     (None, 14, 14, 160)  0           batch_normalization_106[0][0]    
__________________________________________________________________________________________________
conv2d_104 (Conv2D)             (None, 14, 14, 192)  208896      block17_7_ac[0][0]               
__________________________________________________________________________________________________
conv2d_107 (Conv2D)             (None, 14, 14, 192)  215040      activation_106[0][0]             
__________________________________________________________________________________________________
batch_normalization_104 (BatchN (None, 14, 14, 192)  576         conv2d_104[0][0]                 
__________________________________________________________________________________________________
batch_normalization_107 (BatchN (None, 14, 14, 192)  576         conv2d_107[0][0]                 
__________________________________________________________________________________________________
activation_104 (Activation)     (None, 14, 14, 192)  0           batch_normalization_104[0][0]    
__________________________________________________________________________________________________
activation_107 (Activation)     (None, 14, 14, 192)  0           batch_normalization_107[0][0]    
__________________________________________________________________________________________________
block17_8_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_104[0][0]             
                                                                 activation_107[0][0]             
__________________________________________________________________________________________________
block17_8_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_8_mixed[0][0]            
__________________________________________________________________________________________________
block17_8 (Lambda)              (None, 14, 14, 1088) 0           block17_7_ac[0][0]               
                                                                 block17_8_conv[0][0]             
__________________________________________________________________________________________________
block17_8_ac (Activation)       (None, 14, 14, 1088) 0           block17_8[0][0]                  
__________________________________________________________________________________________________
conv2d_109 (Conv2D)             (None, 14, 14, 128)  139264      block17_8_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_109 (BatchN (None, 14, 14, 128)  384         conv2d_109[0][0]                 
__________________________________________________________________________________________________
activation_109 (Activation)     (None, 14, 14, 128)  0           batch_normalization_109[0][0]    
__________________________________________________________________________________________________
conv2d_110 (Conv2D)             (None, 14, 14, 160)  143360      activation_109[0][0]             
__________________________________________________________________________________________________
batch_normalization_110 (BatchN (None, 14, 14, 160)  480         conv2d_110[0][0]                 
__________________________________________________________________________________________________
activation_110 (Activation)     (None, 14, 14, 160)  0           batch_normalization_110[0][0]    
__________________________________________________________________________________________________
conv2d_108 (Conv2D)             (None, 14, 14, 192)  208896      block17_8_ac[0][0]               
__________________________________________________________________________________________________
conv2d_111 (Conv2D)             (None, 14, 14, 192)  215040      activation_110[0][0]             
__________________________________________________________________________________________________
batch_normalization_108 (BatchN (None, 14, 14, 192)  576         conv2d_108[0][0]                 
__________________________________________________________________________________________________
batch_normalization_111 (BatchN (None, 14, 14, 192)  576         conv2d_111[0][0]                 
__________________________________________________________________________________________________
activation_108 (Activation)     (None, 14, 14, 192)  0           batch_normalization_108[0][0]    
__________________________________________________________________________________________________
activation_111 (Activation)     (None, 14, 14, 192)  0           batch_normalization_111[0][0]    
__________________________________________________________________________________________________
block17_9_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_108[0][0]             
                                                                 activation_111[0][0]             
__________________________________________________________________________________________________
block17_9_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_9_mixed[0][0]            
__________________________________________________________________________________________________
block17_9 (Lambda)              (None, 14, 14, 1088) 0           block17_8_ac[0][0]               
                                                                 block17_9_conv[0][0]             
__________________________________________________________________________________________________
block17_9_ac (Activation)       (None, 14, 14, 1088) 0           block17_9[0][0]                  
__________________________________________________________________________________________________
conv2d_113 (Conv2D)             (None, 14, 14, 128)  139264      block17_9_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_113 (BatchN (None, 14, 14, 128)  384         conv2d_113[0][0]                 
__________________________________________________________________________________________________
activation_113 (Activation)     (None, 14, 14, 128)  0           batch_normalization_113[0][0]    
__________________________________________________________________________________________________
conv2d_114 (Conv2D)             (None, 14, 14, 160)  143360      activation_113[0][0]             
__________________________________________________________________________________________________
batch_normalization_114 (BatchN (None, 14, 14, 160)  480         conv2d_114[0][0]                 
__________________________________________________________________________________________________
activation_114 (Activation)     (None, 14, 14, 160)  0           batch_normalization_114[0][0]    
__________________________________________________________________________________________________
conv2d_112 (Conv2D)             (None, 14, 14, 192)  208896      block17_9_ac[0][0]               
__________________________________________________________________________________________________
conv2d_115 (Conv2D)             (None, 14, 14, 192)  215040      activation_114[0][0]             
__________________________________________________________________________________________________
batch_normalization_112 (BatchN (None, 14, 14, 192)  576         conv2d_112[0][0]                 
__________________________________________________________________________________________________
batch_normalization_115 (BatchN (None, 14, 14, 192)  576         conv2d_115[0][0]                 
__________________________________________________________________________________________________
activation_112 (Activation)     (None, 14, 14, 192)  0           batch_normalization_112[0][0]    
__________________________________________________________________________________________________
activation_115 (Activation)     (None, 14, 14, 192)  0           batch_normalization_115[0][0]    
__________________________________________________________________________________________________
block17_10_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_112[0][0]             
                                                                 activation_115[0][0]             
__________________________________________________________________________________________________
block17_10_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_10_mixed[0][0]           
__________________________________________________________________________________________________
block17_10 (Lambda)             (None, 14, 14, 1088) 0           block17_9_ac[0][0]               
                                                                 block17_10_conv[0][0]            
__________________________________________________________________________________________________
block17_10_ac (Activation)      (None, 14, 14, 1088) 0           block17_10[0][0]                 
__________________________________________________________________________________________________
conv2d_117 (Conv2D)             (None, 14, 14, 128)  139264      block17_10_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_117 (BatchN (None, 14, 14, 128)  384         conv2d_117[0][0]                 
__________________________________________________________________________________________________
activation_117 (Activation)     (None, 14, 14, 128)  0           batch_normalization_117[0][0]    
__________________________________________________________________________________________________
conv2d_118 (Conv2D)             (None, 14, 14, 160)  143360      activation_117[0][0]             
__________________________________________________________________________________________________
batch_normalization_118 (BatchN (None, 14, 14, 160)  480         conv2d_118[0][0]                 
__________________________________________________________________________________________________
activation_118 (Activation)     (None, 14, 14, 160)  0           batch_normalization_118[0][0]    
__________________________________________________________________________________________________
conv2d_116 (Conv2D)             (None, 14, 14, 192)  208896      block17_10_ac[0][0]              
__________________________________________________________________________________________________
conv2d_119 (Conv2D)             (None, 14, 14, 192)  215040      activation_118[0][0]             
__________________________________________________________________________________________________
batch_normalization_116 (BatchN (None, 14, 14, 192)  576         conv2d_116[0][0]                 
__________________________________________________________________________________________________
batch_normalization_119 (BatchN (None, 14, 14, 192)  576         conv2d_119[0][0]                 
__________________________________________________________________________________________________
activation_116 (Activation)     (None, 14, 14, 192)  0           batch_normalization_116[0][0]    
__________________________________________________________________________________________________
activation_119 (Activation)     (None, 14, 14, 192)  0           batch_normalization_119[0][0]    
__________________________________________________________________________________________________
block17_11_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_116[0][0]             
                                                                 activation_119[0][0]             
__________________________________________________________________________________________________
block17_11_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_11_mixed[0][0]           
__________________________________________________________________________________________________
block17_11 (Lambda)             (None, 14, 14, 1088) 0           block17_10_ac[0][0]              
                                                                 block17_11_conv[0][0]            
__________________________________________________________________________________________________
block17_11_ac (Activation)      (None, 14, 14, 1088) 0           block17_11[0][0]                 
__________________________________________________________________________________________________
conv2d_121 (Conv2D)             (None, 14, 14, 128)  139264      block17_11_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_121 (BatchN (None, 14, 14, 128)  384         conv2d_121[0][0]                 
__________________________________________________________________________________________________
activation_121 (Activation)     (None, 14, 14, 128)  0           batch_normalization_121[0][0]    
__________________________________________________________________________________________________
conv2d_122 (Conv2D)             (None, 14, 14, 160)  143360      activation_121[0][0]             
__________________________________________________________________________________________________
batch_normalization_122 (BatchN (None, 14, 14, 160)  480         conv2d_122[0][0]                 
__________________________________________________________________________________________________
activation_122 (Activation)     (None, 14, 14, 160)  0           batch_normalization_122[0][0]    
__________________________________________________________________________________________________
conv2d_120 (Conv2D)             (None, 14, 14, 192)  208896      block17_11_ac[0][0]              
__________________________________________________________________________________________________
conv2d_123 (Conv2D)             (None, 14, 14, 192)  215040      activation_122[0][0]             
__________________________________________________________________________________________________
batch_normalization_120 (BatchN (None, 14, 14, 192)  576         conv2d_120[0][0]                 
__________________________________________________________________________________________________
batch_normalization_123 (BatchN (None, 14, 14, 192)  576         conv2d_123[0][0]                 
__________________________________________________________________________________________________
activation_120 (Activation)     (None, 14, 14, 192)  0           batch_normalization_120[0][0]    
__________________________________________________________________________________________________
activation_123 (Activation)     (None, 14, 14, 192)  0           batch_normalization_123[0][0]    
__________________________________________________________________________________________________
block17_12_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_120[0][0]             
                                                                 activation_123[0][0]             
__________________________________________________________________________________________________
block17_12_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_12_mixed[0][0]           
__________________________________________________________________________________________________
block17_12 (Lambda)             (None, 14, 14, 1088) 0           block17_11_ac[0][0]              
                                                                 block17_12_conv[0][0]            
__________________________________________________________________________________________________
block17_12_ac (Activation)      (None, 14, 14, 1088) 0           block17_12[0][0]                 
__________________________________________________________________________________________________
conv2d_125 (Conv2D)             (None, 14, 14, 128)  139264      block17_12_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_125 (BatchN (None, 14, 14, 128)  384         conv2d_125[0][0]                 
__________________________________________________________________________________________________
activation_125 (Activation)     (None, 14, 14, 128)  0           batch_normalization_125[0][0]    
__________________________________________________________________________________________________
conv2d_126 (Conv2D)             (None, 14, 14, 160)  143360      activation_125[0][0]             
__________________________________________________________________________________________________
batch_normalization_126 (BatchN (None, 14, 14, 160)  480         conv2d_126[0][0]                 
__________________________________________________________________________________________________
activation_126 (Activation)     (None, 14, 14, 160)  0           batch_normalization_126[0][0]    
__________________________________________________________________________________________________
conv2d_124 (Conv2D)             (None, 14, 14, 192)  208896      block17_12_ac[0][0]              
__________________________________________________________________________________________________
conv2d_127 (Conv2D)             (None, 14, 14, 192)  215040      activation_126[0][0]             
__________________________________________________________________________________________________
batch_normalization_124 (BatchN (None, 14, 14, 192)  576         conv2d_124[0][0]                 
__________________________________________________________________________________________________
batch_normalization_127 (BatchN (None, 14, 14, 192)  576         conv2d_127[0][0]                 
__________________________________________________________________________________________________
activation_124 (Activation)     (None, 14, 14, 192)  0           batch_normalization_124[0][0]    
__________________________________________________________________________________________________
activation_127 (Activation)     (None, 14, 14, 192)  0           batch_normalization_127[0][0]    
__________________________________________________________________________________________________
block17_13_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_124[0][0]             
                                                                 activation_127[0][0]             
__________________________________________________________________________________________________
block17_13_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_13_mixed[0][0]           
__________________________________________________________________________________________________
block17_13 (Lambda)             (None, 14, 14, 1088) 0           block17_12_ac[0][0]              
                                                                 block17_13_conv[0][0]            
__________________________________________________________________________________________________
block17_13_ac (Activation)      (None, 14, 14, 1088) 0           block17_13[0][0]                 
__________________________________________________________________________________________________
conv2d_129 (Conv2D)             (None, 14, 14, 128)  139264      block17_13_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_129 (BatchN (None, 14, 14, 128)  384         conv2d_129[0][0]                 
__________________________________________________________________________________________________
activation_129 (Activation)     (None, 14, 14, 128)  0           batch_normalization_129[0][0]    
__________________________________________________________________________________________________
conv2d_130 (Conv2D)             (None, 14, 14, 160)  143360      activation_129[0][0]             
__________________________________________________________________________________________________
batch_normalization_130 (BatchN (None, 14, 14, 160)  480         conv2d_130[0][0]                 
__________________________________________________________________________________________________
activation_130 (Activation)     (None, 14, 14, 160)  0           batch_normalization_130[0][0]    
__________________________________________________________________________________________________
conv2d_128 (Conv2D)             (None, 14, 14, 192)  208896      block17_13_ac[0][0]              
__________________________________________________________________________________________________
conv2d_131 (Conv2D)             (None, 14, 14, 192)  215040      activation_130[0][0]             
__________________________________________________________________________________________________
batch_normalization_128 (BatchN (None, 14, 14, 192)  576         conv2d_128[0][0]                 
__________________________________________________________________________________________________
batch_normalization_131 (BatchN (None, 14, 14, 192)  576         conv2d_131[0][0]                 
__________________________________________________________________________________________________
activation_128 (Activation)     (None, 14, 14, 192)  0           batch_normalization_128[0][0]    
__________________________________________________________________________________________________
activation_131 (Activation)     (None, 14, 14, 192)  0           batch_normalization_131[0][0]    
__________________________________________________________________________________________________
block17_14_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_128[0][0]             
                                                                 activation_131[0][0]             
__________________________________________________________________________________________________
block17_14_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_14_mixed[0][0]           
__________________________________________________________________________________________________
block17_14 (Lambda)             (None, 14, 14, 1088) 0           block17_13_ac[0][0]              
                                                                 block17_14_conv[0][0]            
__________________________________________________________________________________________________
block17_14_ac (Activation)      (None, 14, 14, 1088) 0           block17_14[0][0]                 
__________________________________________________________________________________________________
conv2d_133 (Conv2D)             (None, 14, 14, 128)  139264      block17_14_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_133 (BatchN (None, 14, 14, 128)  384         conv2d_133[0][0]                 
__________________________________________________________________________________________________
activation_133 (Activation)     (None, 14, 14, 128)  0           batch_normalization_133[0][0]    
__________________________________________________________________________________________________
conv2d_134 (Conv2D)             (None, 14, 14, 160)  143360      activation_133[0][0]             
__________________________________________________________________________________________________
batch_normalization_134 (BatchN (None, 14, 14, 160)  480         conv2d_134[0][0]                 
__________________________________________________________________________________________________
activation_134 (Activation)     (None, 14, 14, 160)  0           batch_normalization_134[0][0]    
__________________________________________________________________________________________________
conv2d_132 (Conv2D)             (None, 14, 14, 192)  208896      block17_14_ac[0][0]              
__________________________________________________________________________________________________
conv2d_135 (Conv2D)             (None, 14, 14, 192)  215040      activation_134[0][0]             
__________________________________________________________________________________________________
batch_normalization_132 (BatchN (None, 14, 14, 192)  576         conv2d_132[0][0]                 
__________________________________________________________________________________________________
batch_normalization_135 (BatchN (None, 14, 14, 192)  576         conv2d_135[0][0]                 
__________________________________________________________________________________________________
activation_132 (Activation)     (None, 14, 14, 192)  0           batch_normalization_132[0][0]    
__________________________________________________________________________________________________
activation_135 (Activation)     (None, 14, 14, 192)  0           batch_normalization_135[0][0]    
__________________________________________________________________________________________________
block17_15_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_132[0][0]             
                                                                 activation_135[0][0]             
__________________________________________________________________________________________________
block17_15_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_15_mixed[0][0]           
__________________________________________________________________________________________________
block17_15 (Lambda)             (None, 14, 14, 1088) 0           block17_14_ac[0][0]              
                                                                 block17_15_conv[0][0]            
__________________________________________________________________________________________________
block17_15_ac (Activation)      (None, 14, 14, 1088) 0           block17_15[0][0]                 
__________________________________________________________________________________________________
conv2d_137 (Conv2D)             (None, 14, 14, 128)  139264      block17_15_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_137 (BatchN (None, 14, 14, 128)  384         conv2d_137[0][0]                 
__________________________________________________________________________________________________
activation_137 (Activation)     (None, 14, 14, 128)  0           batch_normalization_137[0][0]    
__________________________________________________________________________________________________
conv2d_138 (Conv2D)             (None, 14, 14, 160)  143360      activation_137[0][0]             
__________________________________________________________________________________________________
batch_normalization_138 (BatchN (None, 14, 14, 160)  480         conv2d_138[0][0]                 
__________________________________________________________________________________________________
activation_138 (Activation)     (None, 14, 14, 160)  0           batch_normalization_138[0][0]    
__________________________________________________________________________________________________
conv2d_136 (Conv2D)             (None, 14, 14, 192)  208896      block17_15_ac[0][0]              
__________________________________________________________________________________________________
conv2d_139 (Conv2D)             (None, 14, 14, 192)  215040      activation_138[0][0]             
__________________________________________________________________________________________________
batch_normalization_136 (BatchN (None, 14, 14, 192)  576         conv2d_136[0][0]                 
__________________________________________________________________________________________________
batch_normalization_139 (BatchN (None, 14, 14, 192)  576         conv2d_139[0][0]                 
__________________________________________________________________________________________________
activation_136 (Activation)     (None, 14, 14, 192)  0           batch_normalization_136[0][0]    
__________________________________________________________________________________________________
activation_139 (Activation)     (None, 14, 14, 192)  0           batch_normalization_139[0][0]    
__________________________________________________________________________________________________
block17_16_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_136[0][0]             
                                                                 activation_139[0][0]             
__________________________________________________________________________________________________
block17_16_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_16_mixed[0][0]           
__________________________________________________________________________________________________
block17_16 (Lambda)             (None, 14, 14, 1088) 0           block17_15_ac[0][0]              
                                                                 block17_16_conv[0][0]            
__________________________________________________________________________________________________
block17_16_ac (Activation)      (None, 14, 14, 1088) 0           block17_16[0][0]                 
__________________________________________________________________________________________________
conv2d_141 (Conv2D)             (None, 14, 14, 128)  139264      block17_16_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_141 (BatchN (None, 14, 14, 128)  384         conv2d_141[0][0]                 
__________________________________________________________________________________________________
activation_141 (Activation)     (None, 14, 14, 128)  0           batch_normalization_141[0][0]    
__________________________________________________________________________________________________
conv2d_142 (Conv2D)             (None, 14, 14, 160)  143360      activation_141[0][0]             
__________________________________________________________________________________________________
batch_normalization_142 (BatchN (None, 14, 14, 160)  480         conv2d_142[0][0]                 
__________________________________________________________________________________________________
activation_142 (Activation)     (None, 14, 14, 160)  0           batch_normalization_142[0][0]    
__________________________________________________________________________________________________
conv2d_140 (Conv2D)             (None, 14, 14, 192)  208896      block17_16_ac[0][0]              
__________________________________________________________________________________________________
conv2d_143 (Conv2D)             (None, 14, 14, 192)  215040      activation_142[0][0]             
__________________________________________________________________________________________________
batch_normalization_140 (BatchN (None, 14, 14, 192)  576         conv2d_140[0][0]                 
__________________________________________________________________________________________________
batch_normalization_143 (BatchN (None, 14, 14, 192)  576         conv2d_143[0][0]                 
__________________________________________________________________________________________________
activation_140 (Activation)     (None, 14, 14, 192)  0           batch_normalization_140[0][0]    
__________________________________________________________________________________________________
activation_143 (Activation)     (None, 14, 14, 192)  0           batch_normalization_143[0][0]    
__________________________________________________________________________________________________
block17_17_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_140[0][0]             
                                                                 activation_143[0][0]             
__________________________________________________________________________________________________
block17_17_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_17_mixed[0][0]           
__________________________________________________________________________________________________
block17_17 (Lambda)             (None, 14, 14, 1088) 0           block17_16_ac[0][0]              
                                                                 block17_17_conv[0][0]            
__________________________________________________________________________________________________
block17_17_ac (Activation)      (None, 14, 14, 1088) 0           block17_17[0][0]                 
__________________________________________________________________________________________________
conv2d_145 (Conv2D)             (None, 14, 14, 128)  139264      block17_17_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_145 (BatchN (None, 14, 14, 128)  384         conv2d_145[0][0]                 
__________________________________________________________________________________________________
activation_145 (Activation)     (None, 14, 14, 128)  0           batch_normalization_145[0][0]    
__________________________________________________________________________________________________
conv2d_146 (Conv2D)             (None, 14, 14, 160)  143360      activation_145[0][0]             
__________________________________________________________________________________________________
batch_normalization_146 (BatchN (None, 14, 14, 160)  480         conv2d_146[0][0]                 
__________________________________________________________________________________________________
activation_146 (Activation)     (None, 14, 14, 160)  0           batch_normalization_146[0][0]    
__________________________________________________________________________________________________
conv2d_144 (Conv2D)             (None, 14, 14, 192)  208896      block17_17_ac[0][0]              
__________________________________________________________________________________________________
conv2d_147 (Conv2D)             (None, 14, 14, 192)  215040      activation_146[0][0]             
__________________________________________________________________________________________________
batch_normalization_144 (BatchN (None, 14, 14, 192)  576         conv2d_144[0][0]                 
__________________________________________________________________________________________________
batch_normalization_147 (BatchN (None, 14, 14, 192)  576         conv2d_147[0][0]                 
__________________________________________________________________________________________________
activation_144 (Activation)     (None, 14, 14, 192)  0           batch_normalization_144[0][0]    
__________________________________________________________________________________________________
activation_147 (Activation)     (None, 14, 14, 192)  0           batch_normalization_147[0][0]    
__________________________________________________________________________________________________
block17_18_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_144[0][0]             
                                                                 activation_147[0][0]             
__________________________________________________________________________________________________
block17_18_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_18_mixed[0][0]           
__________________________________________________________________________________________________
block17_18 (Lambda)             (None, 14, 14, 1088) 0           block17_17_ac[0][0]              
                                                                 block17_18_conv[0][0]            
__________________________________________________________________________________________________
block17_18_ac (Activation)      (None, 14, 14, 1088) 0           block17_18[0][0]                 
__________________________________________________________________________________________________
conv2d_149 (Conv2D)             (None, 14, 14, 128)  139264      block17_18_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_149 (BatchN (None, 14, 14, 128)  384         conv2d_149[0][0]                 
__________________________________________________________________________________________________
activation_149 (Activation)     (None, 14, 14, 128)  0           batch_normalization_149[0][0]    
__________________________________________________________________________________________________
conv2d_150 (Conv2D)             (None, 14, 14, 160)  143360      activation_149[0][0]             
__________________________________________________________________________________________________
batch_normalization_150 (BatchN (None, 14, 14, 160)  480         conv2d_150[0][0]                 
__________________________________________________________________________________________________
activation_150 (Activation)     (None, 14, 14, 160)  0           batch_normalization_150[0][0]    
__________________________________________________________________________________________________
conv2d_148 (Conv2D)             (None, 14, 14, 192)  208896      block17_18_ac[0][0]              
__________________________________________________________________________________________________
conv2d_151 (Conv2D)             (None, 14, 14, 192)  215040      activation_150[0][0]             
__________________________________________________________________________________________________
batch_normalization_148 (BatchN (None, 14, 14, 192)  576         conv2d_148[0][0]                 
__________________________________________________________________________________________________
batch_normalization_151 (BatchN (None, 14, 14, 192)  576         conv2d_151[0][0]                 
__________________________________________________________________________________________________
activation_148 (Activation)     (None, 14, 14, 192)  0           batch_normalization_148[0][0]    
__________________________________________________________________________________________________
activation_151 (Activation)     (None, 14, 14, 192)  0           batch_normalization_151[0][0]    
__________________________________________________________________________________________________
block17_19_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_148[0][0]             
                                                                 activation_151[0][0]             
__________________________________________________________________________________________________
block17_19_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_19_mixed[0][0]           
__________________________________________________________________________________________________
block17_19 (Lambda)             (None, 14, 14, 1088) 0           block17_18_ac[0][0]              
                                                                 block17_19_conv[0][0]            
__________________________________________________________________________________________________
block17_19_ac (Activation)      (None, 14, 14, 1088) 0           block17_19[0][0]                 
__________________________________________________________________________________________________
conv2d_153 (Conv2D)             (None, 14, 14, 128)  139264      block17_19_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_153 (BatchN (None, 14, 14, 128)  384         conv2d_153[0][0]                 
__________________________________________________________________________________________________
activation_153 (Activation)     (None, 14, 14, 128)  0           batch_normalization_153[0][0]    
__________________________________________________________________________________________________
conv2d_154 (Conv2D)             (None, 14, 14, 160)  143360      activation_153[0][0]             
__________________________________________________________________________________________________
batch_normalization_154 (BatchN (None, 14, 14, 160)  480         conv2d_154[0][0]                 
__________________________________________________________________________________________________
activation_154 (Activation)     (None, 14, 14, 160)  0           batch_normalization_154[0][0]    
__________________________________________________________________________________________________
conv2d_152 (Conv2D)             (None, 14, 14, 192)  208896      block17_19_ac[0][0]              
__________________________________________________________________________________________________
conv2d_155 (Conv2D)             (None, 14, 14, 192)  215040      activation_154[0][0]             
__________________________________________________________________________________________________
batch_normalization_152 (BatchN (None, 14, 14, 192)  576         conv2d_152[0][0]                 
__________________________________________________________________________________________________
batch_normalization_155 (BatchN (None, 14, 14, 192)  576         conv2d_155[0][0]                 
__________________________________________________________________________________________________
activation_152 (Activation)     (None, 14, 14, 192)  0           batch_normalization_152[0][0]    
__________________________________________________________________________________________________
activation_155 (Activation)     (None, 14, 14, 192)  0           batch_normalization_155[0][0]    
__________________________________________________________________________________________________
block17_20_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_152[0][0]             
                                                                 activation_155[0][0]             
__________________________________________________________________________________________________
block17_20_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_20_mixed[0][0]           
__________________________________________________________________________________________________
block17_20 (Lambda)             (None, 14, 14, 1088) 0           block17_19_ac[0][0]              
                                                                 block17_20_conv[0][0]            
__________________________________________________________________________________________________
block17_20_ac (Activation)      (None, 14, 14, 1088) 0           block17_20[0][0]                 
__________________________________________________________________________________________________
conv2d_160 (Conv2D)             (None, 14, 14, 256)  278528      block17_20_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_160 (BatchN (None, 14, 14, 256)  768         conv2d_160[0][0]                 
__________________________________________________________________________________________________
activation_160 (Activation)     (None, 14, 14, 256)  0           batch_normalization_160[0][0]    
__________________________________________________________________________________________________
conv2d_156 (Conv2D)             (None, 14, 14, 256)  278528      block17_20_ac[0][0]              
__________________________________________________________________________________________________
conv2d_158 (Conv2D)             (None, 14, 14, 256)  278528      block17_20_ac[0][0]              
__________________________________________________________________________________________________
conv2d_161 (Conv2D)             (None, 14, 14, 288)  663552      activation_160[0][0]             
__________________________________________________________________________________________________
batch_normalization_156 (BatchN (None, 14, 14, 256)  768         conv2d_156[0][0]                 
__________________________________________________________________________________________________
batch_normalization_158 (BatchN (None, 14, 14, 256)  768         conv2d_158[0][0]                 
__________________________________________________________________________________________________
batch_normalization_161 (BatchN (None, 14, 14, 288)  864         conv2d_161[0][0]                 
__________________________________________________________________________________________________
activation_156 (Activation)     (None, 14, 14, 256)  0           batch_normalization_156[0][0]    
__________________________________________________________________________________________________
activation_158 (Activation)     (None, 14, 14, 256)  0           batch_normalization_158[0][0]    
__________________________________________________________________________________________________
activation_161 (Activation)     (None, 14, 14, 288)  0           batch_normalization_161[0][0]    
__________________________________________________________________________________________________
conv2d_157 (Conv2D)             (None, 6, 6, 384)    884736      activation_156[0][0]             
__________________________________________________________________________________________________
conv2d_159 (Conv2D)             (None, 6, 6, 288)    663552      activation_158[0][0]             
__________________________________________________________________________________________________
conv2d_162 (Conv2D)             (None, 6, 6, 320)    829440      activation_161[0][0]             
__________________________________________________________________________________________________
batch_normalization_157 (BatchN (None, 6, 6, 384)    1152        conv2d_157[0][0]                 
__________________________________________________________________________________________________
batch_normalization_159 (BatchN (None, 6, 6, 288)    864         conv2d_159[0][0]                 
__________________________________________________________________________________________________
batch_normalization_162 (BatchN (None, 6, 6, 320)    960         conv2d_162[0][0]                 
__________________________________________________________________________________________________
activation_157 (Activation)     (None, 6, 6, 384)    0           batch_normalization_157[0][0]    
__________________________________________________________________________________________________
activation_159 (Activation)     (None, 6, 6, 288)    0           batch_normalization_159[0][0]    
__________________________________________________________________________________________________
activation_162 (Activation)     (None, 6, 6, 320)    0           batch_normalization_162[0][0]    
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 6, 6, 1088)   0           block17_20_ac[0][0]              
__________________________________________________________________________________________________
mixed_7a (Concatenate)          (None, 6, 6, 2080)   0           activation_157[0][0]             
                                                                 activation_159[0][0]             
                                                                 activation_162[0][0]             
                                                                 max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_164 (Conv2D)             (None, 6, 6, 192)    399360      mixed_7a[0][0]                   
__________________________________________________________________________________________________
batch_normalization_164 (BatchN (None, 6, 6, 192)    576         conv2d_164[0][0]                 
__________________________________________________________________________________________________
activation_164 (Activation)     (None, 6, 6, 192)    0           batch_normalization_164[0][0]    
__________________________________________________________________________________________________
conv2d_165 (Conv2D)             (None, 6, 6, 224)    129024      activation_164[0][0]             
__________________________________________________________________________________________________
batch_normalization_165 (BatchN (None, 6, 6, 224)    672         conv2d_165[0][0]                 
__________________________________________________________________________________________________
activation_165 (Activation)     (None, 6, 6, 224)    0           batch_normalization_165[0][0]    
__________________________________________________________________________________________________
conv2d_163 (Conv2D)             (None, 6, 6, 192)    399360      mixed_7a[0][0]                   
__________________________________________________________________________________________________
conv2d_166 (Conv2D)             (None, 6, 6, 256)    172032      activation_165[0][0]             
__________________________________________________________________________________________________
batch_normalization_163 (BatchN (None, 6, 6, 192)    576         conv2d_163[0][0]                 
__________________________________________________________________________________________________
batch_normalization_166 (BatchN (None, 6, 6, 256)    768         conv2d_166[0][0]                 
__________________________________________________________________________________________________
activation_163 (Activation)     (None, 6, 6, 192)    0           batch_normalization_163[0][0]    
__________________________________________________________________________________________________
activation_166 (Activation)     (None, 6, 6, 256)    0           batch_normalization_166[0][0]    
__________________________________________________________________________________________________
block8_1_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_163[0][0]             
                                                                 activation_166[0][0]             
__________________________________________________________________________________________________
block8_1_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_1_mixed[0][0]             
__________________________________________________________________________________________________
block8_1 (Lambda)               (None, 6, 6, 2080)   0           mixed_7a[0][0]                   
                                                                 block8_1_conv[0][0]              
__________________________________________________________________________________________________
block8_1_ac (Activation)        (None, 6, 6, 2080)   0           block8_1[0][0]                   
__________________________________________________________________________________________________
conv2d_168 (Conv2D)             (None, 6, 6, 192)    399360      block8_1_ac[0][0]                
__________________________________________________________________________________________________
batch_normalization_168 (BatchN (None, 6, 6, 192)    576         conv2d_168[0][0]                 
__________________________________________________________________________________________________
activation_168 (Activation)     (None, 6, 6, 192)    0           batch_normalization_168[0][0]    
__________________________________________________________________________________________________
conv2d_169 (Conv2D)             (None, 6, 6, 224)    129024      activation_168[0][0]             
__________________________________________________________________________________________________
batch_normalization_169 (BatchN (None, 6, 6, 224)    672         conv2d_169[0][0]                 
__________________________________________________________________________________________________
activation_169 (Activation)     (None, 6, 6, 224)    0           batch_normalization_169[0][0]    
__________________________________________________________________________________________________
conv2d_167 (Conv2D)             (None, 6, 6, 192)    399360      block8_1_ac[0][0]                
__________________________________________________________________________________________________
conv2d_170 (Conv2D)             (None, 6, 6, 256)    172032      activation_169[0][0]             
__________________________________________________________________________________________________
batch_normalization_167 (BatchN (None, 6, 6, 192)    576         conv2d_167[0][0]                 
__________________________________________________________________________________________________
batch_normalization_170 (BatchN (None, 6, 6, 256)    768         conv2d_170[0][0]                 
__________________________________________________________________________________________________
activation_167 (Activation)     (None, 6, 6, 192)    0           batch_normalization_167[0][0]    
__________________________________________________________________________________________________
activation_170 (Activation)     (None, 6, 6, 256)    0           batch_normalization_170[0][0]    
__________________________________________________________________________________________________
block8_2_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_167[0][0]             
                                                                 activation_170[0][0]             
__________________________________________________________________________________________________
block8_2_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_2_mixed[0][0]             
__________________________________________________________________________________________________
block8_2 (Lambda)               (None, 6, 6, 2080)   0           block8_1_ac[0][0]                
                                                                 block8_2_conv[0][0]              
__________________________________________________________________________________________________
block8_2_ac (Activation)        (None, 6, 6, 2080)   0           block8_2[0][0]                   
__________________________________________________________________________________________________
conv2d_172 (Conv2D)             (None, 6, 6, 192)    399360      block8_2_ac[0][0]                
__________________________________________________________________________________________________
batch_normalization_172 (BatchN (None, 6, 6, 192)    576         conv2d_172[0][0]                 
__________________________________________________________________________________________________
activation_172 (Activation)     (None, 6, 6, 192)    0           batch_normalization_172[0][0]    
__________________________________________________________________________________________________
conv2d_173 (Conv2D)             (None, 6, 6, 224)    129024      activation_172[0][0]             
__________________________________________________________________________________________________
batch_normalization_173 (BatchN (None, 6, 6, 224)    672         conv2d_173[0][0]                 
__________________________________________________________________________________________________
activation_173 (Activation)     (None, 6, 6, 224)    0           batch_normalization_173[0][0]    
__________________________________________________________________________________________________
conv2d_171 (Conv2D)             (None, 6, 6, 192)    399360      block8_2_ac[0][0]                
__________________________________________________________________________________________________
conv2d_174 (Conv2D)             (None, 6, 6, 256)    172032      activation_173[0][0]             
__________________________________________________________________________________________________
batch_normalization_171 (BatchN (None, 6, 6, 192)    576         conv2d_171[0][0]                 
__________________________________________________________________________________________________
batch_normalization_174 (BatchN (None, 6, 6, 256)    768         conv2d_174[0][0]                 
__________________________________________________________________________________________________
activation_171 (Activation)     (None, 6, 6, 192)    0           batch_normalization_171[0][0]    
__________________________________________________________________________________________________
activation_174 (Activation)     (None, 6, 6, 256)    0           batch_normalization_174[0][0]    
__________________________________________________________________________________________________
block8_3_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_171[0][0]             
                                                                 activation_174[0][0]             
__________________________________________________________________________________________________
block8_3_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_3_mixed[0][0]             
__________________________________________________________________________________________________
block8_3 (Lambda)               (None, 6, 6, 2080)   0           block8_2_ac[0][0]                
                                                                 block8_3_conv[0][0]              
__________________________________________________________________________________________________
block8_3_ac (Activation)        (None, 6, 6, 2080)   0           block8_3[0][0]                   
__________________________________________________________________________________________________
conv2d_176 (Conv2D)             (None, 6, 6, 192)    399360      block8_3_ac[0][0]                
__________________________________________________________________________________________________
batch_normalization_176 (BatchN (None, 6, 6, 192)    576         conv2d_176[0][0]                 
__________________________________________________________________________________________________
activation_176 (Activation)     (None, 6, 6, 192)    0           batch_normalization_176[0][0]    
__________________________________________________________________________________________________
conv2d_177 (Conv2D)             (None, 6, 6, 224)    129024      activation_176[0][0]             
__________________________________________________________________________________________________
batch_normalization_177 (BatchN (None, 6, 6, 224)    672         conv2d_177[0][0]                 
__________________________________________________________________________________________________
activation_177 (Activation)     (None, 6, 6, 224)    0           batch_normalization_177[0][0]    
__________________________________________________________________________________________________
conv2d_175 (Conv2D)             (None, 6, 6, 192)    399360      block8_3_ac[0][0]                
__________________________________________________________________________________________________
conv2d_178 (Conv2D)             (None, 6, 6, 256)    172032      activation_177[0][0]             
__________________________________________________________________________________________________
batch_normalization_175 (BatchN (None, 6, 6, 192)    576         conv2d_175[0][0]                 
__________________________________________________________________________________________________
batch_normalization_178 (BatchN (None, 6, 6, 256)    768         conv2d_178[0][0]                 
__________________________________________________________________________________________________
activation_175 (Activation)     (None, 6, 6, 192)    0           batch_normalization_175[0][0]    
__________________________________________________________________________________________________
activation_178 (Activation)     (None, 6, 6, 256)    0           batch_normalization_178[0][0]    
__________________________________________________________________________________________________
block8_4_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_175[0][0]             
                                                                 activation_178[0][0]             
__________________________________________________________________________________________________
block8_4_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_4_mixed[0][0]             
__________________________________________________________________________________________________
block8_4 (Lambda)               (None, 6, 6, 2080)   0           block8_3_ac[0][0]                
                                                                 block8_4_conv[0][0]              
__________________________________________________________________________________________________
block8_4_ac (Activation)        (None, 6, 6, 2080)   0           block8_4[0][0]                   
__________________________________________________________________________________________________
conv2d_180 (Conv2D)             (None, 6, 6, 192)    399360      block8_4_ac[0][0]                
__________________________________________________________________________________________________
batch_normalization_180 (BatchN (None, 6, 6, 192)    576         conv2d_180[0][0]                 
__________________________________________________________________________________________________
activation_180 (Activation)     (None, 6, 6, 192)    0           batch_normalization_180[0][0]    
__________________________________________________________________________________________________
conv2d_181 (Conv2D)             (None, 6, 6, 224)    129024      activation_180[0][0]             
__________________________________________________________________________________________________
batch_normalization_181 (BatchN (None, 6, 6, 224)    672         conv2d_181[0][0]                 
__________________________________________________________________________________________________
activation_181 (Activation)     (None, 6, 6, 224)    0           batch_normalization_181[0][0]    
__________________________________________________________________________________________________
conv2d_179 (Conv2D)             (None, 6, 6, 192)    399360      block8_4_ac[0][0]                
__________________________________________________________________________________________________
conv2d_182 (Conv2D)             (None, 6, 6, 256)    172032      activation_181[0][0]             
__________________________________________________________________________________________________
batch_normalization_179 (BatchN (None, 6, 6, 192)    576         conv2d_179[0][0]                 
__________________________________________________________________________________________________
batch_normalization_182 (BatchN (None, 6, 6, 256)    768         conv2d_182[0][0]                 
__________________________________________________________________________________________________
activation_179 (Activation)     (None, 6, 6, 192)    0           batch_normalization_179[0][0]    
__________________________________________________________________________________________________
activation_182 (Activation)     (None, 6, 6, 256)    0           batch_normalization_182[0][0]    
__________________________________________________________________________________________________
block8_5_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_179[0][0]             
                                                                 activation_182[0][0]             
__________________________________________________________________________________________________
block8_5_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_5_mixed[0][0]             
__________________________________________________________________________________________________
block8_5 (Lambda)               (None, 6, 6, 2080)   0           block8_4_ac[0][0]                
                                                                 block8_5_conv[0][0]              
__________________________________________________________________________________________________
block8_5_ac (Activation)        (None, 6, 6, 2080)   0           block8_5[0][0]                   
__________________________________________________________________________________________________
conv2d_184 (Conv2D)             (None, 6, 6, 192)    399360      block8_5_ac[0][0]                
__________________________________________________________________________________________________
batch_normalization_184 (BatchN (None, 6, 6, 192)    576         conv2d_184[0][0]                 
__________________________________________________________________________________________________
activation_184 (Activation)     (None, 6, 6, 192)    0           batch_normalization_184[0][0]    
__________________________________________________________________________________________________
conv2d_185 (Conv2D)             (None, 6, 6, 224)    129024      activation_184[0][0]             
__________________________________________________________________________________________________
batch_normalization_185 (BatchN (None, 6, 6, 224)    672         conv2d_185[0][0]                 
__________________________________________________________________________________________________
activation_185 (Activation)     (None, 6, 6, 224)    0           batch_normalization_185[0][0]    
__________________________________________________________________________________________________
conv2d_183 (Conv2D)             (None, 6, 6, 192)    399360      block8_5_ac[0][0]                
__________________________________________________________________________________________________
conv2d_186 (Conv2D)             (None, 6, 6, 256)    172032      activation_185[0][0]             
__________________________________________________________________________________________________
batch_normalization_183 (BatchN (None, 6, 6, 192)    576         conv2d_183[0][0]                 
__________________________________________________________________________________________________
batch_normalization_186 (BatchN (None, 6, 6, 256)    768         conv2d_186[0][0]                 
__________________________________________________________________________________________________
activation_183 (Activation)     (None, 6, 6, 192)    0           batch_normalization_183[0][0]    
__________________________________________________________________________________________________
activation_186 (Activation)     (None, 6, 6, 256)    0           batch_normalization_186[0][0]    
__________________________________________________________________________________________________
block8_6_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_183[0][0]             
                                                                 activation_186[0][0]             
__________________________________________________________________________________________________
block8_6_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_6_mixed[0][0]             
__________________________________________________________________________________________________
block8_6 (Lambda)               (None, 6, 6, 2080)   0           block8_5_ac[0][0]                
                                                                 block8_6_conv[0][0]              
__________________________________________________________________________________________________
block8_6_ac (Activation)        (None, 6, 6, 2080)   0           block8_6[0][0]                   
__________________________________________________________________________________________________
conv2d_188 (Conv2D)             (None, 6, 6, 192)    399360      block8_6_ac[0][0]                
__________________________________________________________________________________________________
batch_normalization_188 (BatchN (None, 6, 6, 192)    576         conv2d_188[0][0]                 
__________________________________________________________________________________________________
activation_188 (Activation)     (None, 6, 6, 192)    0           batch_normalization_188[0][0]    
__________________________________________________________________________________________________
conv2d_189 (Conv2D)             (None, 6, 6, 224)    129024      activation_188[0][0]             
__________________________________________________________________________________________________
batch_normalization_189 (BatchN (None, 6, 6, 224)    672         conv2d_189[0][0]                 
__________________________________________________________________________________________________
activation_189 (Activation)     (None, 6, 6, 224)    0           batch_normalization_189[0][0]    
__________________________________________________________________________________________________
conv2d_187 (Conv2D)             (None, 6, 6, 192)    399360      block8_6_ac[0][0]                
__________________________________________________________________________________________________
conv2d_190 (Conv2D)             (None, 6, 6, 256)    172032      activation_189[0][0]             
__________________________________________________________________________________________________
batch_normalization_187 (BatchN (None, 6, 6, 192)    576         conv2d_187[0][0]                 
__________________________________________________________________________________________________
batch_normalization_190 (BatchN (None, 6, 6, 256)    768         conv2d_190[0][0]                 
__________________________________________________________________________________________________
activation_187 (Activation)     (None, 6, 6, 192)    0           batch_normalization_187[0][0]    
__________________________________________________________________________________________________
activation_190 (Activation)     (None, 6, 6, 256)    0           batch_normalization_190[0][0]    
__________________________________________________________________________________________________
block8_7_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_187[0][0]             
                                                                 activation_190[0][0]             
__________________________________________________________________________________________________
block8_7_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_7_mixed[0][0]             
__________________________________________________________________________________________________
block8_7 (Lambda)               (None, 6, 6, 2080)   0           block8_6_ac[0][0]                
                                                                 block8_7_conv[0][0]              
__________________________________________________________________________________________________
block8_7_ac (Activation)        (None, 6, 6, 2080)   0           block8_7[0][0]                   
__________________________________________________________________________________________________
conv2d_192 (Conv2D)             (None, 6, 6, 192)    399360      block8_7_ac[0][0]                
__________________________________________________________________________________________________
batch_normalization_192 (BatchN (None, 6, 6, 192)    576         conv2d_192[0][0]                 
__________________________________________________________________________________________________
activation_192 (Activation)     (None, 6, 6, 192)    0           batch_normalization_192[0][0]    
__________________________________________________________________________________________________
conv2d_193 (Conv2D)             (None, 6, 6, 224)    129024      activation_192[0][0]             
__________________________________________________________________________________________________
batch_normalization_193 (BatchN (None, 6, 6, 224)    672         conv2d_193[0][0]                 
__________________________________________________________________________________________________
activation_193 (Activation)     (None, 6, 6, 224)    0           batch_normalization_193[0][0]    
__________________________________________________________________________________________________
conv2d_191 (Conv2D)             (None, 6, 6, 192)    399360      block8_7_ac[0][0]                
__________________________________________________________________________________________________
conv2d_194 (Conv2D)             (None, 6, 6, 256)    172032      activation_193[0][0]             
__________________________________________________________________________________________________
batch_normalization_191 (BatchN (None, 6, 6, 192)    576         conv2d_191[0][0]                 
__________________________________________________________________________________________________
batch_normalization_194 (BatchN (None, 6, 6, 256)    768         conv2d_194[0][0]                 
__________________________________________________________________________________________________
activation_191 (Activation)     (None, 6, 6, 192)    0           batch_normalization_191[0][0]    
__________________________________________________________________________________________________
activation_194 (Activation)     (None, 6, 6, 256)    0           batch_normalization_194[0][0]    
__________________________________________________________________________________________________
block8_8_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_191[0][0]             
                                                                 activation_194[0][0]             
__________________________________________________________________________________________________
block8_8_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_8_mixed[0][0]             
__________________________________________________________________________________________________
block8_8 (Lambda)               (None, 6, 6, 2080)   0           block8_7_ac[0][0]                
                                                                 block8_8_conv[0][0]              
__________________________________________________________________________________________________
block8_8_ac (Activation)        (None, 6, 6, 2080)   0           block8_8[0][0]                   
__________________________________________________________________________________________________
conv2d_196 (Conv2D)             (None, 6, 6, 192)    399360      block8_8_ac[0][0]                
__________________________________________________________________________________________________
batch_normalization_196 (BatchN (None, 6, 6, 192)    576         conv2d_196[0][0]                 
__________________________________________________________________________________________________
activation_196 (Activation)     (None, 6, 6, 192)    0           batch_normalization_196[0][0]    
__________________________________________________________________________________________________
conv2d_197 (Conv2D)             (None, 6, 6, 224)    129024      activation_196[0][0]             
__________________________________________________________________________________________________
batch_normalization_197 (BatchN (None, 6, 6, 224)    672         conv2d_197[0][0]                 
__________________________________________________________________________________________________
activation_197 (Activation)     (None, 6, 6, 224)    0           batch_normalization_197[0][0]    
__________________________________________________________________________________________________
conv2d_195 (Conv2D)             (None, 6, 6, 192)    399360      block8_8_ac[0][0]                
__________________________________________________________________________________________________
conv2d_198 (Conv2D)             (None, 6, 6, 256)    172032      activation_197[0][0]             
__________________________________________________________________________________________________
batch_normalization_195 (BatchN (None, 6, 6, 192)    576         conv2d_195[0][0]                 
__________________________________________________________________________________________________
batch_normalization_198 (BatchN (None, 6, 6, 256)    768         conv2d_198[0][0]                 
__________________________________________________________________________________________________
activation_195 (Activation)     (None, 6, 6, 192)    0           batch_normalization_195[0][0]    
__________________________________________________________________________________________________
activation_198 (Activation)     (None, 6, 6, 256)    0           batch_normalization_198[0][0]    
__________________________________________________________________________________________________
block8_9_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_195[0][0]             
                                                                 activation_198[0][0]             
__________________________________________________________________________________________________
block8_9_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_9_mixed[0][0]             
__________________________________________________________________________________________________
block8_9 (Lambda)               (None, 6, 6, 2080)   0           block8_8_ac[0][0]                
                                                                 block8_9_conv[0][0]              
__________________________________________________________________________________________________
block8_9_ac (Activation)        (None, 6, 6, 2080)   0           block8_9[0][0]                   
__________________________________________________________________________________________________
conv2d_200 (Conv2D)             (None, 6, 6, 192)    399360      block8_9_ac[0][0]                
__________________________________________________________________________________________________
batch_normalization_200 (BatchN (None, 6, 6, 192)    576         conv2d_200[0][0]                 
__________________________________________________________________________________________________
activation_200 (Activation)     (None, 6, 6, 192)    0           batch_normalization_200[0][0]    
__________________________________________________________________________________________________
conv2d_201 (Conv2D)             (None, 6, 6, 224)    129024      activation_200[0][0]             
__________________________________________________________________________________________________
batch_normalization_201 (BatchN (None, 6, 6, 224)    672         conv2d_201[0][0]                 
__________________________________________________________________________________________________
activation_201 (Activation)     (None, 6, 6, 224)    0           batch_normalization_201[0][0]    
__________________________________________________________________________________________________
conv2d_199 (Conv2D)             (None, 6, 6, 192)    399360      block8_9_ac[0][0]                
__________________________________________________________________________________________________
conv2d_202 (Conv2D)             (None, 6, 6, 256)    172032      activation_201[0][0]             
__________________________________________________________________________________________________
batch_normalization_199 (BatchN (None, 6, 6, 192)    576         conv2d_199[0][0]                 
__________________________________________________________________________________________________
batch_normalization_202 (BatchN (None, 6, 6, 256)    768         conv2d_202[0][0]                 
__________________________________________________________________________________________________
activation_199 (Activation)     (None, 6, 6, 192)    0           batch_normalization_199[0][0]    
__________________________________________________________________________________________________
activation_202 (Activation)     (None, 6, 6, 256)    0           batch_normalization_202[0][0]    
__________________________________________________________________________________________________
block8_10_mixed (Concatenate)   (None, 6, 6, 448)    0           activation_199[0][0]             
                                                                 activation_202[0][0]             
__________________________________________________________________________________________________
block8_10_conv (Conv2D)         (None, 6, 6, 2080)   933920      block8_10_mixed[0][0]            
__________________________________________________________________________________________________
block8_10 (Lambda)              (None, 6, 6, 2080)   0           block8_9_ac[0][0]                
                                                                 block8_10_conv[0][0]             
__________________________________________________________________________________________________
conv_7b (Conv2D)                (None, 6, 6, 1536)   3194880     block8_10[0][0]                  
__________________________________________________________________________________________________
conv_7b_bn (BatchNormalization) (None, 6, 6, 1536)   4608        conv_7b[0][0]                    
__________________________________________________________________________________________________
conv_7b_ac (Activation)         (None, 6, 6, 1536)   0           conv_7b_bn[0][0]                 
__________________________________________________________________________________________________
flatten (Flatten)               (None, 55296)        0           conv_7b_ac[0][0]                 
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         226496512   flatten[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
predictions (Dense)             (None, 5)            20485       fc2[0][0]                        
==================================================================================================
Total params: 297,635,045
Trainable params: 297,574,501
Non-trainable params: 60,544
__________________________________________________________________________________________________
Start fitting ensemble models
Random seed for replication: 292
Length split part:  1398
Labels in this part of split:  [291, 256, 300, 277, 274]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 66s - loss: 1.4076 - accuracy: 0.4270 - val_loss: 1.4401 - val_accuracy: 0.4190
Epoch 2/500
44/44 - 14s - loss: 0.5273 - accuracy: 0.8670 - val_loss: 1.7466 - val_accuracy: 0.2458
Epoch 3/500
44/44 - 14s - loss: 0.1944 - accuracy: 0.9671 - val_loss: 1.6004 - val_accuracy: 0.3911
Epoch 4/500
44/44 - 26s - loss: 0.0839 - accuracy: 0.9835 - val_loss: 1.4367 - val_accuracy: 0.4469
Epoch 5/500
44/44 - 28s - loss: 0.0433 - accuracy: 0.9907 - val_loss: 1.3387 - val_accuracy: 0.5028
Epoch 6/500
44/44 - 14s - loss: 0.0290 - accuracy: 0.9936 - val_loss: 1.5147 - val_accuracy: 0.4246
Epoch 7/500
44/44 - 14s - loss: 0.0196 - accuracy: 0.9964 - val_loss: 1.5802 - val_accuracy: 0.4413
Epoch 8/500
44/44 - 14s - loss: 0.0126 - accuracy: 0.9986 - val_loss: 1.5268 - val_accuracy: 0.4637
Epoch 9/500
44/44 - 14s - loss: 0.0071 - accuracy: 0.9993 - val_loss: 1.5843 - val_accuracy: 0.5084
Epoch 10/500
44/44 - 14s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4786 - val_accuracy: 0.5363
Epoch 11/500
44/44 - 14s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.5065 - val_accuracy: 0.5587
Epoch 12/500
44/44 - 14s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6030 - val_accuracy: 0.5475
Epoch 13/500
44/44 - 14s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6734 - val_accuracy: 0.5419
Epoch 14/500
44/44 - 14s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7250 - val_accuracy: 0.5587
Epoch 15/500
44/44 - 14s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7766 - val_accuracy: 0.5698
Epoch 16/500
44/44 - 14s - loss: 9.8344e-04 - accuracy: 1.0000 - val_loss: 1.8252 - val_accuracy: 0.5754
Epoch 17/500
44/44 - 14s - loss: 8.6392e-04 - accuracy: 1.0000 - val_loss: 1.8599 - val_accuracy: 0.5698
Epoch 18/500
44/44 - 14s - loss: 7.6669e-04 - accuracy: 1.0000 - val_loss: 1.8912 - val_accuracy: 0.5642
Epoch 19/500
44/44 - 14s - loss: 6.8465e-04 - accuracy: 1.0000 - val_loss: 1.9273 - val_accuracy: 0.5698
Epoch 20/500
44/44 - 14s - loss: 6.1573e-04 - accuracy: 1.0000 - val_loss: 1.9605 - val_accuracy: 0.5642
Epoch 21/500
44/44 - 14s - loss: 5.5412e-04 - accuracy: 1.0000 - val_loss: 1.9854 - val_accuracy: 0.5587
Epoch 22/500
44/44 - 14s - loss: 5.0173e-04 - accuracy: 1.0000 - val_loss: 2.0081 - val_accuracy: 0.5587
Epoch 23/500
44/44 - 14s - loss: 4.5772e-04 - accuracy: 1.0000 - val_loss: 2.0325 - val_accuracy: 0.5587
Epoch 24/500
44/44 - 14s - loss: 4.1837e-04 - accuracy: 1.0000 - val_loss: 2.0492 - val_accuracy: 0.5587
Epoch 25/500
44/44 - 14s - loss: 3.8421e-04 - accuracy: 1.0000 - val_loss: 2.0711 - val_accuracy: 0.5531
Epoch 26/500
44/44 - 14s - loss: 3.5305e-04 - accuracy: 1.0000 - val_loss: 2.0924 - val_accuracy: 0.5587
Epoch 27/500
44/44 - 14s - loss: 3.2535e-04 - accuracy: 1.0000 - val_loss: 2.1106 - val_accuracy: 0.5642
Epoch 28/500
44/44 - 14s - loss: 3.0075e-04 - accuracy: 1.0000 - val_loss: 2.1261 - val_accuracy: 0.5587
Epoch 29/500
44/44 - 14s - loss: 2.7875e-04 - accuracy: 1.0000 - val_loss: 2.1392 - val_accuracy: 0.5531
Epoch 30/500
44/44 - 14s - loss: 2.5920e-04 - accuracy: 1.0000 - val_loss: 2.1589 - val_accuracy: 0.5587
Epoch 31/500
44/44 - 14s - loss: 2.4160e-04 - accuracy: 1.0000 - val_loss: 2.1709 - val_accuracy: 0.5587
Epoch 32/500
44/44 - 14s - loss: 2.2547e-04 - accuracy: 1.0000 - val_loss: 2.1860 - val_accuracy: 0.5587
Epoch 33/500
44/44 - 14s - loss: 2.0989e-04 - accuracy: 1.0000 - val_loss: 2.2029 - val_accuracy: 0.5587
Epoch 34/500
44/44 - 14s - loss: 1.9680e-04 - accuracy: 1.0000 - val_loss: 2.2169 - val_accuracy: 0.5587
Epoch 35/500
44/44 - 14s - loss: 1.8432e-04 - accuracy: 1.0000 - val_loss: 2.2300 - val_accuracy: 0.5587
Epoch 36/500
44/44 - 14s - loss: 1.7322e-04 - accuracy: 1.0000 - val_loss: 2.2411 - val_accuracy: 0.5587
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 15:50:28.366183: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 15:50:28.366339: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 15:50:28.366373: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 15:50:28.679178: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 15:50:28.679278: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00036: early stopping
Length split part:  1398
Labels in this part of split:  [259, 293, 277, 273, 296]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 24s - loss: 1.4688 - accuracy: 0.4242 - val_loss: 4.0159 - val_accuracy: 0.1564
Epoch 2/500
44/44 - 25s - loss: 0.5827 - accuracy: 0.7876 - val_loss: 2.4835 - val_accuracy: 0.2458
Epoch 3/500
44/44 - 23s - loss: 0.1737 - accuracy: 0.9406 - val_loss: 2.3237 - val_accuracy: 0.3408
Epoch 4/500
44/44 - 25s - loss: 0.0624 - accuracy: 0.9785 - val_loss: 2.0770 - val_accuracy: 0.4134
Epoch 5/500
44/44 - 14s - loss: 0.0617 - accuracy: 0.9807 - val_loss: 2.5557 - val_accuracy: 0.3352
Epoch 6/500
44/44 - 24s - loss: 0.0323 - accuracy: 0.9907 - val_loss: 1.9123 - val_accuracy: 0.4581
Epoch 7/500
44/44 - 26s - loss: 0.0166 - accuracy: 0.9964 - val_loss: 1.7331 - val_accuracy: 0.5698
Epoch 8/500
44/44 - 14s - loss: 0.0103 - accuracy: 0.9979 - val_loss: 1.7373 - val_accuracy: 0.5419
Epoch 9/500
44/44 - 24s - loss: 0.0058 - accuracy: 0.9986 - val_loss: 1.7027 - val_accuracy: 0.5754
Epoch 10/500
44/44 - 24s - loss: 0.0047 - accuracy: 0.9986 - val_loss: 1.6106 - val_accuracy: 0.5698
Epoch 11/500
44/44 - 30s - loss: 0.0065 - accuracy: 0.9986 - val_loss: 1.5708 - val_accuracy: 0.6034
Epoch 12/500
44/44 - 14s - loss: 0.0043 - accuracy: 0.9986 - val_loss: 1.6815 - val_accuracy: 0.5642
Epoch 13/500
44/44 - 14s - loss: 0.0049 - accuracy: 0.9986 - val_loss: 1.6979 - val_accuracy: 0.5531
Epoch 14/500
44/44 - 14s - loss: 0.0039 - accuracy: 0.9986 - val_loss: 1.7566 - val_accuracy: 0.5475
Epoch 15/500
44/44 - 14s - loss: 0.0044 - accuracy: 0.9986 - val_loss: 1.7169 - val_accuracy: 0.5140
Epoch 16/500
44/44 - 14s - loss: 0.0032 - accuracy: 0.9986 - val_loss: 1.7151 - val_accuracy: 0.5587
Epoch 17/500
44/44 - 14s - loss: 0.0031 - accuracy: 0.9986 - val_loss: 1.7098 - val_accuracy: 0.5531
Epoch 18/500
44/44 - 14s - loss: 0.0031 - accuracy: 0.9986 - val_loss: 1.7333 - val_accuracy: 0.5698
Epoch 19/500
44/44 - 14s - loss: 0.0032 - accuracy: 0.9986 - val_loss: 1.7280 - val_accuracy: 0.5587
Epoch 20/500
44/44 - 14s - loss: 0.0029 - accuracy: 0.9986 - val_loss: 1.7505 - val_accuracy: 0.5587
Epoch 21/500
44/44 - 14s - loss: 0.0028 - accuracy: 0.9986 - val_loss: 1.7517 - val_accuracy: 0.5587
Epoch 22/500
44/44 - 14s - loss: 0.0026 - accuracy: 0.9986 - val_loss: 1.7770 - val_accuracy: 0.5698
Epoch 23/500
44/44 - 14s - loss: 0.0026 - accuracy: 0.9986 - val_loss: 1.7766 - val_accuracy: 0.5587
Epoch 24/500
44/44 - 14s - loss: 0.0026 - accuracy: 0.9986 - val_loss: 1.7992 - val_accuracy: 0.5698
Epoch 25/500
44/44 - 14s - loss: 0.0026 - accuracy: 0.9986 - val_loss: 1.7974 - val_accuracy: 0.5307
Epoch 26/500
44/44 - 14s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 1.8080 - val_accuracy: 0.5531
Epoch 27/500
44/44 - 14s - loss: 0.0026 - accuracy: 0.9986 - val_loss: 1.8092 - val_accuracy: 0.5531
Epoch 28/500
44/44 - 14s - loss: 0.0026 - accuracy: 0.9986 - val_loss: 1.8476 - val_accuracy: 0.5698
Epoch 29/500
44/44 - 14s - loss: 0.0030 - accuracy: 0.9986 - val_loss: 1.8301 - val_accuracy: 0.5419
Epoch 30/500
44/44 - 14s - loss: 0.0027 - accuracy: 0.9986 - val_loss: 1.8595 - val_accuracy: 0.5531
Epoch 31/500
44/44 - 14s - loss: 0.0032 - accuracy: 0.9986 - val_loss: 1.8288 - val_accuracy: 0.5307
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 16:00:18.148397: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 16:00:18.148554: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 16:00:18.148603: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 16:00:18.462531: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 16:00:18.462627: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00031: early stopping
Length split part:  1397
Labels in this part of split:  [290, 291, 262, 288, 266]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 26s - loss: 1.4704 - accuracy: 0.4488 - val_loss: 1.8407 - val_accuracy: 0.2458
Epoch 2/500
44/44 - 14s - loss: 0.5545 - accuracy: 0.7903 - val_loss: 3.8278 - val_accuracy: 0.1732
Epoch 3/500
44/44 - 24s - loss: 0.1661 - accuracy: 0.9506 - val_loss: 1.7758 - val_accuracy: 0.4022
Epoch 4/500
44/44 - 14s - loss: 0.0479 - accuracy: 0.9907 - val_loss: 3.1554 - val_accuracy: 0.2291
Epoch 5/500
44/44 - 14s - loss: 0.0229 - accuracy: 0.9943 - val_loss: 1.8639 - val_accuracy: 0.4525
Epoch 6/500
44/44 - 14s - loss: 0.0066 - accuracy: 0.9993 - val_loss: 2.1765 - val_accuracy: 0.3743
Epoch 7/500
44/44 - 26s - loss: 0.0037 - accuracy: 0.9993 - val_loss: 1.7020 - val_accuracy: 0.5140
Epoch 8/500
44/44 - 24s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6103 - val_accuracy: 0.5587
Epoch 9/500
44/44 - 26s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5171 - val_accuracy: 0.5866
Epoch 10/500
44/44 - 14s - loss: 9.6900e-04 - accuracy: 1.0000 - val_loss: 1.5171 - val_accuracy: 0.6145
Epoch 11/500
44/44 - 25s - loss: 8.1540e-04 - accuracy: 1.0000 - val_loss: 1.5125 - val_accuracy: 0.6536
Epoch 12/500
44/44 - 14s - loss: 7.0484e-04 - accuracy: 1.0000 - val_loss: 1.5652 - val_accuracy: 0.6313
Epoch 13/500
44/44 - 14s - loss: 6.1717e-04 - accuracy: 1.0000 - val_loss: 1.5754 - val_accuracy: 0.6480
Epoch 14/500
44/44 - 14s - loss: 5.4829e-04 - accuracy: 1.0000 - val_loss: 1.6161 - val_accuracy: 0.6369
Epoch 15/500
44/44 - 14s - loss: 4.9139e-04 - accuracy: 1.0000 - val_loss: 1.6327 - val_accuracy: 0.6313
Epoch 16/500
44/44 - 14s - loss: 4.4474e-04 - accuracy: 1.0000 - val_loss: 1.6501 - val_accuracy: 0.6369
Epoch 17/500
44/44 - 14s - loss: 4.0468e-04 - accuracy: 1.0000 - val_loss: 1.6730 - val_accuracy: 0.6313
Epoch 18/500
44/44 - 14s - loss: 3.7185e-04 - accuracy: 1.0000 - val_loss: 1.6842 - val_accuracy: 0.6425
Epoch 19/500
44/44 - 14s - loss: 3.4097e-04 - accuracy: 1.0000 - val_loss: 1.6970 - val_accuracy: 0.6480
Epoch 20/500
44/44 - 14s - loss: 3.1500e-04 - accuracy: 1.0000 - val_loss: 1.7095 - val_accuracy: 0.6480
Epoch 21/500
44/44 - 14s - loss: 2.9229e-04 - accuracy: 1.0000 - val_loss: 1.7209 - val_accuracy: 0.6480
Epoch 22/500
44/44 - 14s - loss: 2.7202e-04 - accuracy: 1.0000 - val_loss: 1.7324 - val_accuracy: 0.6480
Epoch 23/500
44/44 - 14s - loss: 2.5406e-04 - accuracy: 1.0000 - val_loss: 1.7407 - val_accuracy: 0.6480
Epoch 24/500
44/44 - 14s - loss: 2.3754e-04 - accuracy: 1.0000 - val_loss: 1.7479 - val_accuracy: 0.6480
Epoch 25/500
44/44 - 14s - loss: 2.2292e-04 - accuracy: 1.0000 - val_loss: 1.7552 - val_accuracy: 0.6480
Epoch 26/500
44/44 - 14s - loss: 2.0951e-04 - accuracy: 1.0000 - val_loss: 1.7623 - val_accuracy: 0.6480
Epoch 27/500
44/44 - 14s - loss: 1.9701e-04 - accuracy: 1.0000 - val_loss: 1.7699 - val_accuracy: 0.6480
Epoch 28/500
44/44 - 14s - loss: 1.8618e-04 - accuracy: 1.0000 - val_loss: 1.7789 - val_accuracy: 0.6480
Epoch 29/500
44/44 - 14s - loss: 1.7594e-04 - accuracy: 1.0000 - val_loss: 1.7867 - val_accuracy: 0.6480
Epoch 30/500
44/44 - 14s - loss: 1.6637e-04 - accuracy: 1.0000 - val_loss: 1.7972 - val_accuracy: 0.6480
Epoch 31/500
44/44 - 14s - loss: 1.5769e-04 - accuracy: 1.0000 - val_loss: 1.8056 - val_accuracy: 0.6480
Epoch 00031: early stopping
DenseNet121
Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5
    8192/29084464 [..............................] - ETA: 0s   24576/29084464 [..............................] - ETA: 1:48   57344/29084464 [..............................] - ETA: 1:34  139264/29084464 [..............................] - ETA: 58s   303104/29084464 [..............................] - ETA: 35s  614400/29084464 [..............................] - ETA: 21s 1253376/29084464 [>.............................] - ETA: 12s 2523136/29084464 [=>............................] - ETA: 6s  5095424/29084464 [====>.........................] - ETA: 3s 8208384/29084464 [=======>......................] - ETA: 2s11337728/29084464 [==========>...................] - ETA: 1s14450688/29084464 [=============>................] - ETA: 1s17563648/29084464 [=================>............] - ETA: 0s20692992/29084464 [====================>.........] - ETA: 0s23805952/29084464 [=======================>......] - ETA: 0s26918912/29084464 [==========================>...] - ETA: 0s29089792/29084464 [==============================] - 1s 0us/step
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 16:10:21.451754: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 16:10:21.451908: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 16:10:21.451942: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 16:10:21.630214: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 16:10:21.630311: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            
__________________________________________________________________________________________________
zero_padding2d (ZeroPadding2D)  (None, 262, 262, 3)  0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1/conv (Conv2D)             (None, 128, 128, 64) 9408        zero_padding2d[0][0]             
__________________________________________________________________________________________________
conv1/bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1/conv[0][0]                 
__________________________________________________________________________________________________
conv1/relu (Activation)         (None, 128, 128, 64) 0           conv1/bn[0][0]                   
__________________________________________________________________________________________________
zero_padding2d_1 (ZeroPadding2D (None, 130, 130, 64) 0           conv1/relu[0][0]                 
__________________________________________________________________________________________________
pool1 (MaxPooling2D)            (None, 64, 64, 64)   0           zero_padding2d_1[0][0]           
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 64, 64, 64)   256         pool1[0][0]                      
__________________________________________________________________________________________________
conv2_block1_0_relu (Activation (None, 64, 64, 64)   0           conv2_block1_0_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 64, 64, 128)  8192        conv2_block1_0_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 64, 64, 128)  0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_concat (Concatenat (None, 64, 64, 96)   0           pool1[0][0]                      
                                                                 conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_0_bn (BatchNormali (None, 64, 64, 96)   384         conv2_block1_concat[0][0]        
__________________________________________________________________________________________________
conv2_block2_0_relu (Activation (None, 64, 64, 96)   0           conv2_block2_0_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 64, 64, 128)  12288       conv2_block2_0_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 64, 64, 128)  0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_concat (Concatenat (None, 64, 64, 128)  0           conv2_block1_concat[0][0]        
                                                                 conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_0_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block2_concat[0][0]        
__________________________________________________________________________________________________
conv2_block3_0_relu (Activation (None, 64, 64, 128)  0           conv2_block3_0_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 64, 64, 128)  16384       conv2_block3_0_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 64, 64, 128)  0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_concat (Concatenat (None, 64, 64, 160)  0           conv2_block2_concat[0][0]        
                                                                 conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block4_0_bn (BatchNormali (None, 64, 64, 160)  640         conv2_block3_concat[0][0]        
__________________________________________________________________________________________________
conv2_block4_0_relu (Activation (None, 64, 64, 160)  0           conv2_block4_0_bn[0][0]          
__________________________________________________________________________________________________
conv2_block4_1_conv (Conv2D)    (None, 64, 64, 128)  20480       conv2_block4_0_relu[0][0]        
__________________________________________________________________________________________________
conv2_block4_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block4_1_relu (Activation (None, 64, 64, 128)  0           conv2_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block4_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block4_concat (Concatenat (None, 64, 64, 192)  0           conv2_block3_concat[0][0]        
                                                                 conv2_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block5_0_bn (BatchNormali (None, 64, 64, 192)  768         conv2_block4_concat[0][0]        
__________________________________________________________________________________________________
conv2_block5_0_relu (Activation (None, 64, 64, 192)  0           conv2_block5_0_bn[0][0]          
__________________________________________________________________________________________________
conv2_block5_1_conv (Conv2D)    (None, 64, 64, 128)  24576       conv2_block5_0_relu[0][0]        
__________________________________________________________________________________________________
conv2_block5_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block5_1_relu (Activation (None, 64, 64, 128)  0           conv2_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block5_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block5_concat (Concatenat (None, 64, 64, 224)  0           conv2_block4_concat[0][0]        
                                                                 conv2_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block6_0_bn (BatchNormali (None, 64, 64, 224)  896         conv2_block5_concat[0][0]        
__________________________________________________________________________________________________
conv2_block6_0_relu (Activation (None, 64, 64, 224)  0           conv2_block6_0_bn[0][0]          
__________________________________________________________________________________________________
conv2_block6_1_conv (Conv2D)    (None, 64, 64, 128)  28672       conv2_block6_0_relu[0][0]        
__________________________________________________________________________________________________
conv2_block6_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block6_1_relu (Activation (None, 64, 64, 128)  0           conv2_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block6_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block6_concat (Concatenat (None, 64, 64, 256)  0           conv2_block5_concat[0][0]        
                                                                 conv2_block6_2_conv[0][0]        
__________________________________________________________________________________________________
pool2_bn (BatchNormalization)   (None, 64, 64, 256)  1024        conv2_block6_concat[0][0]        
__________________________________________________________________________________________________
pool2_relu (Activation)         (None, 64, 64, 256)  0           pool2_bn[0][0]                   
__________________________________________________________________________________________________
pool2_conv (Conv2D)             (None, 64, 64, 128)  32768       pool2_relu[0][0]                 
__________________________________________________________________________________________________
pool2_pool (AveragePooling2D)   (None, 32, 32, 128)  0           pool2_conv[0][0]                 
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 32, 32, 128)  512         pool2_pool[0][0]                 
__________________________________________________________________________________________________
conv3_block1_0_relu (Activation (None, 32, 32, 128)  0           conv3_block1_0_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  16384       conv3_block1_0_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_concat (Concatenat (None, 32, 32, 160)  0           pool2_pool[0][0]                 
                                                                 conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_0_bn (BatchNormali (None, 32, 32, 160)  640         conv3_block1_concat[0][0]        
__________________________________________________________________________________________________
conv3_block2_0_relu (Activation (None, 32, 32, 160)  0           conv3_block2_0_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  20480       conv3_block2_0_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_concat (Concatenat (None, 32, 32, 192)  0           conv3_block1_concat[0][0]        
                                                                 conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_0_bn (BatchNormali (None, 32, 32, 192)  768         conv3_block2_concat[0][0]        
__________________________________________________________________________________________________
conv3_block3_0_relu (Activation (None, 32, 32, 192)  0           conv3_block3_0_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  24576       conv3_block3_0_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_concat (Concatenat (None, 32, 32, 224)  0           conv3_block2_concat[0][0]        
                                                                 conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_0_bn (BatchNormali (None, 32, 32, 224)  896         conv3_block3_concat[0][0]        
__________________________________________________________________________________________________
conv3_block4_0_relu (Activation (None, 32, 32, 224)  0           conv3_block4_0_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  28672       conv3_block4_0_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_concat (Concatenat (None, 32, 32, 256)  0           conv3_block3_concat[0][0]        
                                                                 conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block5_0_bn (BatchNormali (None, 32, 32, 256)  1024        conv3_block4_concat[0][0]        
__________________________________________________________________________________________________
conv3_block5_0_relu (Activation (None, 32, 32, 256)  0           conv3_block5_0_bn[0][0]          
__________________________________________________________________________________________________
conv3_block5_1_conv (Conv2D)    (None, 32, 32, 128)  32768       conv3_block5_0_relu[0][0]        
__________________________________________________________________________________________________
conv3_block5_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block5_1_relu (Activation (None, 32, 32, 128)  0           conv3_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block5_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block5_concat (Concatenat (None, 32, 32, 288)  0           conv3_block4_concat[0][0]        
                                                                 conv3_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block6_0_bn (BatchNormali (None, 32, 32, 288)  1152        conv3_block5_concat[0][0]        
__________________________________________________________________________________________________
conv3_block6_0_relu (Activation (None, 32, 32, 288)  0           conv3_block6_0_bn[0][0]          
__________________________________________________________________________________________________
conv3_block6_1_conv (Conv2D)    (None, 32, 32, 128)  36864       conv3_block6_0_relu[0][0]        
__________________________________________________________________________________________________
conv3_block6_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block6_1_relu (Activation (None, 32, 32, 128)  0           conv3_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block6_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block6_concat (Concatenat (None, 32, 32, 320)  0           conv3_block5_concat[0][0]        
                                                                 conv3_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block7_0_bn (BatchNormali (None, 32, 32, 320)  1280        conv3_block6_concat[0][0]        
__________________________________________________________________________________________________
conv3_block7_0_relu (Activation (None, 32, 32, 320)  0           conv3_block7_0_bn[0][0]          
__________________________________________________________________________________________________
conv3_block7_1_conv (Conv2D)    (None, 32, 32, 128)  40960       conv3_block7_0_relu[0][0]        
__________________________________________________________________________________________________
conv3_block7_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block7_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block7_1_relu (Activation (None, 32, 32, 128)  0           conv3_block7_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block7_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block7_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block7_concat (Concatenat (None, 32, 32, 352)  0           conv3_block6_concat[0][0]        
                                                                 conv3_block7_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block8_0_bn (BatchNormali (None, 32, 32, 352)  1408        conv3_block7_concat[0][0]        
__________________________________________________________________________________________________
conv3_block8_0_relu (Activation (None, 32, 32, 352)  0           conv3_block8_0_bn[0][0]          
__________________________________________________________________________________________________
conv3_block8_1_conv (Conv2D)    (None, 32, 32, 128)  45056       conv3_block8_0_relu[0][0]        
__________________________________________________________________________________________________
conv3_block8_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block8_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block8_1_relu (Activation (None, 32, 32, 128)  0           conv3_block8_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block8_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block8_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block8_concat (Concatenat (None, 32, 32, 384)  0           conv3_block7_concat[0][0]        
                                                                 conv3_block8_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block9_0_bn (BatchNormali (None, 32, 32, 384)  1536        conv3_block8_concat[0][0]        
__________________________________________________________________________________________________
conv3_block9_0_relu (Activation (None, 32, 32, 384)  0           conv3_block9_0_bn[0][0]          
__________________________________________________________________________________________________
conv3_block9_1_conv (Conv2D)    (None, 32, 32, 128)  49152       conv3_block9_0_relu[0][0]        
__________________________________________________________________________________________________
conv3_block9_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block9_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block9_1_relu (Activation (None, 32, 32, 128)  0           conv3_block9_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block9_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block9_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block9_concat (Concatenat (None, 32, 32, 416)  0           conv3_block8_concat[0][0]        
                                                                 conv3_block9_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block10_0_bn (BatchNormal (None, 32, 32, 416)  1664        conv3_block9_concat[0][0]        
__________________________________________________________________________________________________
conv3_block10_0_relu (Activatio (None, 32, 32, 416)  0           conv3_block10_0_bn[0][0]         
__________________________________________________________________________________________________
conv3_block10_1_conv (Conv2D)   (None, 32, 32, 128)  53248       conv3_block10_0_relu[0][0]       
__________________________________________________________________________________________________
conv3_block10_1_bn (BatchNormal (None, 32, 32, 128)  512         conv3_block10_1_conv[0][0]       
__________________________________________________________________________________________________
conv3_block10_1_relu (Activatio (None, 32, 32, 128)  0           conv3_block10_1_bn[0][0]         
__________________________________________________________________________________________________
conv3_block10_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv3_block10_1_relu[0][0]       
__________________________________________________________________________________________________
conv3_block10_concat (Concatena (None, 32, 32, 448)  0           conv3_block9_concat[0][0]        
                                                                 conv3_block10_2_conv[0][0]       
__________________________________________________________________________________________________
conv3_block11_0_bn (BatchNormal (None, 32, 32, 448)  1792        conv3_block10_concat[0][0]       
__________________________________________________________________________________________________
conv3_block11_0_relu (Activatio (None, 32, 32, 448)  0           conv3_block11_0_bn[0][0]         
__________________________________________________________________________________________________
conv3_block11_1_conv (Conv2D)   (None, 32, 32, 128)  57344       conv3_block11_0_relu[0][0]       
__________________________________________________________________________________________________
conv3_block11_1_bn (BatchNormal (None, 32, 32, 128)  512         conv3_block11_1_conv[0][0]       
__________________________________________________________________________________________________
conv3_block11_1_relu (Activatio (None, 32, 32, 128)  0           conv3_block11_1_bn[0][0]         
__________________________________________________________________________________________________
conv3_block11_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv3_block11_1_relu[0][0]       
__________________________________________________________________________________________________
conv3_block11_concat (Concatena (None, 32, 32, 480)  0           conv3_block10_concat[0][0]       
                                                                 conv3_block11_2_conv[0][0]       
__________________________________________________________________________________________________
conv3_block12_0_bn (BatchNormal (None, 32, 32, 480)  1920        conv3_block11_concat[0][0]       
__________________________________________________________________________________________________
conv3_block12_0_relu (Activatio (None, 32, 32, 480)  0           conv3_block12_0_bn[0][0]         
__________________________________________________________________________________________________
conv3_block12_1_conv (Conv2D)   (None, 32, 32, 128)  61440       conv3_block12_0_relu[0][0]       
__________________________________________________________________________________________________
conv3_block12_1_bn (BatchNormal (None, 32, 32, 128)  512         conv3_block12_1_conv[0][0]       
__________________________________________________________________________________________________
conv3_block12_1_relu (Activatio (None, 32, 32, 128)  0           conv3_block12_1_bn[0][0]         
__________________________________________________________________________________________________
conv3_block12_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv3_block12_1_relu[0][0]       
__________________________________________________________________________________________________
conv3_block12_concat (Concatena (None, 32, 32, 512)  0           conv3_block11_concat[0][0]       
                                                                 conv3_block12_2_conv[0][0]       
__________________________________________________________________________________________________
pool3_bn (BatchNormalization)   (None, 32, 32, 512)  2048        conv3_block12_concat[0][0]       
__________________________________________________________________________________________________
pool3_relu (Activation)         (None, 32, 32, 512)  0           pool3_bn[0][0]                   
__________________________________________________________________________________________________
pool3_conv (Conv2D)             (None, 32, 32, 256)  131072      pool3_relu[0][0]                 
__________________________________________________________________________________________________
pool3_pool (AveragePooling2D)   (None, 16, 16, 256)  0           pool3_conv[0][0]                 
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 16, 16, 256)  1024        pool3_pool[0][0]                 
__________________________________________________________________________________________________
conv4_block1_0_relu (Activation (None, 16, 16, 256)  0           conv4_block1_0_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 16, 16, 128)  32768       conv4_block1_0_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 16, 16, 128)  0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_concat (Concatenat (None, 16, 16, 288)  0           pool3_pool[0][0]                 
                                                                 conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_0_bn (BatchNormali (None, 16, 16, 288)  1152        conv4_block1_concat[0][0]        
__________________________________________________________________________________________________
conv4_block2_0_relu (Activation (None, 16, 16, 288)  0           conv4_block2_0_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 16, 16, 128)  36864       conv4_block2_0_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 16, 16, 128)  0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_concat (Concatenat (None, 16, 16, 320)  0           conv4_block1_concat[0][0]        
                                                                 conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_0_bn (BatchNormali (None, 16, 16, 320)  1280        conv4_block2_concat[0][0]        
__________________________________________________________________________________________________
conv4_block3_0_relu (Activation (None, 16, 16, 320)  0           conv4_block3_0_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 16, 16, 128)  40960       conv4_block3_0_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 16, 16, 128)  0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_concat (Concatenat (None, 16, 16, 352)  0           conv4_block2_concat[0][0]        
                                                                 conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_0_bn (BatchNormali (None, 16, 16, 352)  1408        conv4_block3_concat[0][0]        
__________________________________________________________________________________________________
conv4_block4_0_relu (Activation (None, 16, 16, 352)  0           conv4_block4_0_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 16, 16, 128)  45056       conv4_block4_0_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 16, 16, 128)  0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_concat (Concatenat (None, 16, 16, 384)  0           conv4_block3_concat[0][0]        
                                                                 conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_0_bn (BatchNormali (None, 16, 16, 384)  1536        conv4_block4_concat[0][0]        
__________________________________________________________________________________________________
conv4_block5_0_relu (Activation (None, 16, 16, 384)  0           conv4_block5_0_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 16, 16, 128)  49152       conv4_block5_0_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 16, 16, 128)  0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_concat (Concatenat (None, 16, 16, 416)  0           conv4_block4_concat[0][0]        
                                                                 conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_0_bn (BatchNormali (None, 16, 16, 416)  1664        conv4_block5_concat[0][0]        
__________________________________________________________________________________________________
conv4_block6_0_relu (Activation (None, 16, 16, 416)  0           conv4_block6_0_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 16, 16, 128)  53248       conv4_block6_0_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 16, 16, 128)  0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_concat (Concatenat (None, 16, 16, 448)  0           conv4_block5_concat[0][0]        
                                                                 conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_0_bn (BatchNormali (None, 16, 16, 448)  1792        conv4_block6_concat[0][0]        
__________________________________________________________________________________________________
conv4_block7_0_relu (Activation (None, 16, 16, 448)  0           conv4_block7_0_bn[0][0]          
__________________________________________________________________________________________________
conv4_block7_1_conv (Conv2D)    (None, 16, 16, 128)  57344       conv4_block7_0_relu[0][0]        
__________________________________________________________________________________________________
conv4_block7_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block7_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block7_1_relu (Activation (None, 16, 16, 128)  0           conv4_block7_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block7_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block7_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block7_concat (Concatenat (None, 16, 16, 480)  0           conv4_block6_concat[0][0]        
                                                                 conv4_block7_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_0_bn (BatchNormali (None, 16, 16, 480)  1920        conv4_block7_concat[0][0]        
__________________________________________________________________________________________________
conv4_block8_0_relu (Activation (None, 16, 16, 480)  0           conv4_block8_0_bn[0][0]          
__________________________________________________________________________________________________
conv4_block8_1_conv (Conv2D)    (None, 16, 16, 128)  61440       conv4_block8_0_relu[0][0]        
__________________________________________________________________________________________________
conv4_block8_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block8_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block8_1_relu (Activation (None, 16, 16, 128)  0           conv4_block8_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block8_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block8_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block8_concat (Concatenat (None, 16, 16, 512)  0           conv4_block7_concat[0][0]        
                                                                 conv4_block8_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_0_bn (BatchNormali (None, 16, 16, 512)  2048        conv4_block8_concat[0][0]        
__________________________________________________________________________________________________
conv4_block9_0_relu (Activation (None, 16, 16, 512)  0           conv4_block9_0_bn[0][0]          
__________________________________________________________________________________________________
conv4_block9_1_conv (Conv2D)    (None, 16, 16, 128)  65536       conv4_block9_0_relu[0][0]        
__________________________________________________________________________________________________
conv4_block9_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block9_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block9_1_relu (Activation (None, 16, 16, 128)  0           conv4_block9_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block9_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block9_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block9_concat (Concatenat (None, 16, 16, 544)  0           conv4_block8_concat[0][0]        
                                                                 conv4_block9_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block10_0_bn (BatchNormal (None, 16, 16, 544)  2176        conv4_block9_concat[0][0]        
__________________________________________________________________________________________________
conv4_block10_0_relu (Activatio (None, 16, 16, 544)  0           conv4_block10_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block10_1_conv (Conv2D)   (None, 16, 16, 128)  69632       conv4_block10_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block10_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block10_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block10_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block10_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block10_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block10_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block10_concat (Concatena (None, 16, 16, 576)  0           conv4_block9_concat[0][0]        
                                                                 conv4_block10_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_0_bn (BatchNormal (None, 16, 16, 576)  2304        conv4_block10_concat[0][0]       
__________________________________________________________________________________________________
conv4_block11_0_relu (Activatio (None, 16, 16, 576)  0           conv4_block11_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block11_1_conv (Conv2D)   (None, 16, 16, 128)  73728       conv4_block11_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block11_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block11_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block11_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block11_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block11_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block11_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block11_concat (Concatena (None, 16, 16, 608)  0           conv4_block10_concat[0][0]       
                                                                 conv4_block11_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_0_bn (BatchNormal (None, 16, 16, 608)  2432        conv4_block11_concat[0][0]       
__________________________________________________________________________________________________
conv4_block12_0_relu (Activatio (None, 16, 16, 608)  0           conv4_block12_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block12_1_conv (Conv2D)   (None, 16, 16, 128)  77824       conv4_block12_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block12_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block12_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block12_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block12_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block12_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block12_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block12_concat (Concatena (None, 16, 16, 640)  0           conv4_block11_concat[0][0]       
                                                                 conv4_block12_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_0_bn (BatchNormal (None, 16, 16, 640)  2560        conv4_block12_concat[0][0]       
__________________________________________________________________________________________________
conv4_block13_0_relu (Activatio (None, 16, 16, 640)  0           conv4_block13_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block13_1_conv (Conv2D)   (None, 16, 16, 128)  81920       conv4_block13_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block13_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block13_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block13_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block13_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block13_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block13_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block13_concat (Concatena (None, 16, 16, 672)  0           conv4_block12_concat[0][0]       
                                                                 conv4_block13_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_0_bn (BatchNormal (None, 16, 16, 672)  2688        conv4_block13_concat[0][0]       
__________________________________________________________________________________________________
conv4_block14_0_relu (Activatio (None, 16, 16, 672)  0           conv4_block14_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block14_1_conv (Conv2D)   (None, 16, 16, 128)  86016       conv4_block14_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block14_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block14_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block14_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block14_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block14_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block14_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block14_concat (Concatena (None, 16, 16, 704)  0           conv4_block13_concat[0][0]       
                                                                 conv4_block14_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_0_bn (BatchNormal (None, 16, 16, 704)  2816        conv4_block14_concat[0][0]       
__________________________________________________________________________________________________
conv4_block15_0_relu (Activatio (None, 16, 16, 704)  0           conv4_block15_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block15_1_conv (Conv2D)   (None, 16, 16, 128)  90112       conv4_block15_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block15_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block15_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block15_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block15_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block15_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block15_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block15_concat (Concatena (None, 16, 16, 736)  0           conv4_block14_concat[0][0]       
                                                                 conv4_block15_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_0_bn (BatchNormal (None, 16, 16, 736)  2944        conv4_block15_concat[0][0]       
__________________________________________________________________________________________________
conv4_block16_0_relu (Activatio (None, 16, 16, 736)  0           conv4_block16_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block16_1_conv (Conv2D)   (None, 16, 16, 128)  94208       conv4_block16_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block16_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block16_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block16_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block16_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block16_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block16_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block16_concat (Concatena (None, 16, 16, 768)  0           conv4_block15_concat[0][0]       
                                                                 conv4_block16_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_0_bn (BatchNormal (None, 16, 16, 768)  3072        conv4_block16_concat[0][0]       
__________________________________________________________________________________________________
conv4_block17_0_relu (Activatio (None, 16, 16, 768)  0           conv4_block17_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block17_1_conv (Conv2D)   (None, 16, 16, 128)  98304       conv4_block17_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block17_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block17_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block17_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block17_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block17_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block17_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block17_concat (Concatena (None, 16, 16, 800)  0           conv4_block16_concat[0][0]       
                                                                 conv4_block17_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_0_bn (BatchNormal (None, 16, 16, 800)  3200        conv4_block17_concat[0][0]       
__________________________________________________________________________________________________
conv4_block18_0_relu (Activatio (None, 16, 16, 800)  0           conv4_block18_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block18_1_conv (Conv2D)   (None, 16, 16, 128)  102400      conv4_block18_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block18_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block18_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block18_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block18_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block18_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block18_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block18_concat (Concatena (None, 16, 16, 832)  0           conv4_block17_concat[0][0]       
                                                                 conv4_block18_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_0_bn (BatchNormal (None, 16, 16, 832)  3328        conv4_block18_concat[0][0]       
__________________________________________________________________________________________________
conv4_block19_0_relu (Activatio (None, 16, 16, 832)  0           conv4_block19_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block19_1_conv (Conv2D)   (None, 16, 16, 128)  106496      conv4_block19_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block19_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block19_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block19_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block19_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block19_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block19_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block19_concat (Concatena (None, 16, 16, 864)  0           conv4_block18_concat[0][0]       
                                                                 conv4_block19_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_0_bn (BatchNormal (None, 16, 16, 864)  3456        conv4_block19_concat[0][0]       
__________________________________________________________________________________________________
conv4_block20_0_relu (Activatio (None, 16, 16, 864)  0           conv4_block20_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block20_1_conv (Conv2D)   (None, 16, 16, 128)  110592      conv4_block20_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block20_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block20_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block20_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block20_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block20_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block20_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block20_concat (Concatena (None, 16, 16, 896)  0           conv4_block19_concat[0][0]       
                                                                 conv4_block20_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_0_bn (BatchNormal (None, 16, 16, 896)  3584        conv4_block20_concat[0][0]       
__________________________________________________________________________________________________
conv4_block21_0_relu (Activatio (None, 16, 16, 896)  0           conv4_block21_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block21_1_conv (Conv2D)   (None, 16, 16, 128)  114688      conv4_block21_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block21_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block21_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block21_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block21_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block21_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block21_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block21_concat (Concatena (None, 16, 16, 928)  0           conv4_block20_concat[0][0]       
                                                                 conv4_block21_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_0_bn (BatchNormal (None, 16, 16, 928)  3712        conv4_block21_concat[0][0]       
__________________________________________________________________________________________________
conv4_block22_0_relu (Activatio (None, 16, 16, 928)  0           conv4_block22_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block22_1_conv (Conv2D)   (None, 16, 16, 128)  118784      conv4_block22_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block22_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block22_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block22_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block22_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block22_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block22_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block22_concat (Concatena (None, 16, 16, 960)  0           conv4_block21_concat[0][0]       
                                                                 conv4_block22_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_0_bn (BatchNormal (None, 16, 16, 960)  3840        conv4_block22_concat[0][0]       
__________________________________________________________________________________________________
conv4_block23_0_relu (Activatio (None, 16, 16, 960)  0           conv4_block23_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block23_1_conv (Conv2D)   (None, 16, 16, 128)  122880      conv4_block23_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block23_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block23_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block23_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block23_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block23_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block23_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block23_concat (Concatena (None, 16, 16, 992)  0           conv4_block22_concat[0][0]       
                                                                 conv4_block23_2_conv[0][0]       
__________________________________________________________________________________________________
conv4_block24_0_bn (BatchNormal (None, 16, 16, 992)  3968        conv4_block23_concat[0][0]       
__________________________________________________________________________________________________
conv4_block24_0_relu (Activatio (None, 16, 16, 992)  0           conv4_block24_0_bn[0][0]         
__________________________________________________________________________________________________
conv4_block24_1_conv (Conv2D)   (None, 16, 16, 128)  126976      conv4_block24_0_relu[0][0]       
__________________________________________________________________________________________________
conv4_block24_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block24_1_conv[0][0]       
__________________________________________________________________________________________________
conv4_block24_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block24_1_bn[0][0]         
__________________________________________________________________________________________________
conv4_block24_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block24_1_relu[0][0]       
__________________________________________________________________________________________________
conv4_block24_concat (Concatena (None, 16, 16, 1024) 0           conv4_block23_concat[0][0]       
                                                                 conv4_block24_2_conv[0][0]       
__________________________________________________________________________________________________
pool4_bn (BatchNormalization)   (None, 16, 16, 1024) 4096        conv4_block24_concat[0][0]       
__________________________________________________________________________________________________
pool4_relu (Activation)         (None, 16, 16, 1024) 0           pool4_bn[0][0]                   
__________________________________________________________________________________________________
pool4_conv (Conv2D)             (None, 16, 16, 512)  524288      pool4_relu[0][0]                 
__________________________________________________________________________________________________
pool4_pool (AveragePooling2D)   (None, 8, 8, 512)    0           pool4_conv[0][0]                 
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 8, 8, 512)    2048        pool4_pool[0][0]                 
__________________________________________________________________________________________________
conv5_block1_0_relu (Activation (None, 8, 8, 512)    0           conv5_block1_0_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 8, 8, 128)    65536       conv5_block1_0_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 8, 8, 128)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_concat (Concatenat (None, 8, 8, 544)    0           pool4_pool[0][0]                 
                                                                 conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_0_bn (BatchNormali (None, 8, 8, 544)    2176        conv5_block1_concat[0][0]        
__________________________________________________________________________________________________
conv5_block2_0_relu (Activation (None, 8, 8, 544)    0           conv5_block2_0_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 8, 8, 128)    69632       conv5_block2_0_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 8, 8, 128)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_concat (Concatenat (None, 8, 8, 576)    0           conv5_block1_concat[0][0]        
                                                                 conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_0_bn (BatchNormali (None, 8, 8, 576)    2304        conv5_block2_concat[0][0]        
__________________________________________________________________________________________________
conv5_block3_0_relu (Activation (None, 8, 8, 576)    0           conv5_block3_0_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 8, 8, 128)    73728       conv5_block3_0_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 8, 8, 128)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_concat (Concatenat (None, 8, 8, 608)    0           conv5_block2_concat[0][0]        
                                                                 conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block4_0_bn (BatchNormali (None, 8, 8, 608)    2432        conv5_block3_concat[0][0]        
__________________________________________________________________________________________________
conv5_block4_0_relu (Activation (None, 8, 8, 608)    0           conv5_block4_0_bn[0][0]          
__________________________________________________________________________________________________
conv5_block4_1_conv (Conv2D)    (None, 8, 8, 128)    77824       conv5_block4_0_relu[0][0]        
__________________________________________________________________________________________________
conv5_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv5_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block4_1_relu (Activation (None, 8, 8, 128)    0           conv5_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block4_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv5_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block4_concat (Concatenat (None, 8, 8, 640)    0           conv5_block3_concat[0][0]        
                                                                 conv5_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block5_0_bn (BatchNormali (None, 8, 8, 640)    2560        conv5_block4_concat[0][0]        
__________________________________________________________________________________________________
conv5_block5_0_relu (Activation (None, 8, 8, 640)    0           conv5_block5_0_bn[0][0]          
__________________________________________________________________________________________________
conv5_block5_1_conv (Conv2D)    (None, 8, 8, 128)    81920       conv5_block5_0_relu[0][0]        
__________________________________________________________________________________________________
conv5_block5_1_bn (BatchNormali (None, 8, 8, 128)    512         conv5_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block5_1_relu (Activation (None, 8, 8, 128)    0           conv5_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block5_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv5_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block5_concat (Concatenat (None, 8, 8, 672)    0           conv5_block4_concat[0][0]        
                                                                 conv5_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block6_0_bn (BatchNormali (None, 8, 8, 672)    2688        conv5_block5_concat[0][0]        
__________________________________________________________________________________________________
conv5_block6_0_relu (Activation (None, 8, 8, 672)    0           conv5_block6_0_bn[0][0]          
__________________________________________________________________________________________________
conv5_block6_1_conv (Conv2D)    (None, 8, 8, 128)    86016       conv5_block6_0_relu[0][0]        
__________________________________________________________________________________________________
conv5_block6_1_bn (BatchNormali (None, 8, 8, 128)    512         conv5_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block6_1_relu (Activation (None, 8, 8, 128)    0           conv5_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block6_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv5_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block6_concat (Concatenat (None, 8, 8, 704)    0           conv5_block5_concat[0][0]        
                                                                 conv5_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block7_0_bn (BatchNormali (None, 8, 8, 704)    2816        conv5_block6_concat[0][0]        
__________________________________________________________________________________________________
conv5_block7_0_relu (Activation (None, 8, 8, 704)    0           conv5_block7_0_bn[0][0]          
__________________________________________________________________________________________________
conv5_block7_1_conv (Conv2D)    (None, 8, 8, 128)    90112       conv5_block7_0_relu[0][0]        
__________________________________________________________________________________________________
conv5_block7_1_bn (BatchNormali (None, 8, 8, 128)    512         conv5_block7_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block7_1_relu (Activation (None, 8, 8, 128)    0           conv5_block7_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block7_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv5_block7_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block7_concat (Concatenat (None, 8, 8, 736)    0           conv5_block6_concat[0][0]        
                                                                 conv5_block7_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block8_0_bn (BatchNormali (None, 8, 8, 736)    2944        conv5_block7_concat[0][0]        
__________________________________________________________________________________________________
conv5_block8_0_relu (Activation (None, 8, 8, 736)    0           conv5_block8_0_bn[0][0]          
__________________________________________________________________________________________________
conv5_block8_1_conv (Conv2D)    (None, 8, 8, 128)    94208       conv5_block8_0_relu[0][0]        
__________________________________________________________________________________________________
conv5_block8_1_bn (BatchNormali (None, 8, 8, 128)    512         conv5_block8_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block8_1_relu (Activation (None, 8, 8, 128)    0           conv5_block8_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block8_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv5_block8_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block8_concat (Concatenat (None, 8, 8, 768)    0           conv5_block7_concat[0][0]        
                                                                 conv5_block8_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block9_0_bn (BatchNormali (None, 8, 8, 768)    3072        conv5_block8_concat[0][0]        
__________________________________________________________________________________________________
conv5_block9_0_relu (Activation (None, 8, 8, 768)    0           conv5_block9_0_bn[0][0]          
__________________________________________________________________________________________________
conv5_block9_1_conv (Conv2D)    (None, 8, 8, 128)    98304       conv5_block9_0_relu[0][0]        
__________________________________________________________________________________________________
conv5_block9_1_bn (BatchNormali (None, 8, 8, 128)    512         conv5_block9_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block9_1_relu (Activation (None, 8, 8, 128)    0           conv5_block9_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block9_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv5_block9_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block9_concat (Concatenat (None, 8, 8, 800)    0           conv5_block8_concat[0][0]        
                                                                 conv5_block9_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block10_0_bn (BatchNormal (None, 8, 8, 800)    3200        conv5_block9_concat[0][0]        
__________________________________________________________________________________________________
conv5_block10_0_relu (Activatio (None, 8, 8, 800)    0           conv5_block10_0_bn[0][0]         
__________________________________________________________________________________________________
conv5_block10_1_conv (Conv2D)   (None, 8, 8, 128)    102400      conv5_block10_0_relu[0][0]       
__________________________________________________________________________________________________
conv5_block10_1_bn (BatchNormal (None, 8, 8, 128)    512         conv5_block10_1_conv[0][0]       
__________________________________________________________________________________________________
conv5_block10_1_relu (Activatio (None, 8, 8, 128)    0           conv5_block10_1_bn[0][0]         
__________________________________________________________________________________________________
conv5_block10_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv5_block10_1_relu[0][0]       
__________________________________________________________________________________________________
conv5_block10_concat (Concatena (None, 8, 8, 832)    0           conv5_block9_concat[0][0]        
                                                                 conv5_block10_2_conv[0][0]       
__________________________________________________________________________________________________
conv5_block11_0_bn (BatchNormal (None, 8, 8, 832)    3328        conv5_block10_concat[0][0]       
__________________________________________________________________________________________________
conv5_block11_0_relu (Activatio (None, 8, 8, 832)    0           conv5_block11_0_bn[0][0]         
__________________________________________________________________________________________________
conv5_block11_1_conv (Conv2D)   (None, 8, 8, 128)    106496      conv5_block11_0_relu[0][0]       
__________________________________________________________________________________________________
conv5_block11_1_bn (BatchNormal (None, 8, 8, 128)    512         conv5_block11_1_conv[0][0]       
__________________________________________________________________________________________________
conv5_block11_1_relu (Activatio (None, 8, 8, 128)    0           conv5_block11_1_bn[0][0]         
__________________________________________________________________________________________________
conv5_block11_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv5_block11_1_relu[0][0]       
__________________________________________________________________________________________________
conv5_block11_concat (Concatena (None, 8, 8, 864)    0           conv5_block10_concat[0][0]       
                                                                 conv5_block11_2_conv[0][0]       
__________________________________________________________________________________________________
conv5_block12_0_bn (BatchNormal (None, 8, 8, 864)    3456        conv5_block11_concat[0][0]       
__________________________________________________________________________________________________
conv5_block12_0_relu (Activatio (None, 8, 8, 864)    0           conv5_block12_0_bn[0][0]         
__________________________________________________________________________________________________
conv5_block12_1_conv (Conv2D)   (None, 8, 8, 128)    110592      conv5_block12_0_relu[0][0]       
__________________________________________________________________________________________________
conv5_block12_1_bn (BatchNormal (None, 8, 8, 128)    512         conv5_block12_1_conv[0][0]       
__________________________________________________________________________________________________
conv5_block12_1_relu (Activatio (None, 8, 8, 128)    0           conv5_block12_1_bn[0][0]         
__________________________________________________________________________________________________
conv5_block12_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv5_block12_1_relu[0][0]       
__________________________________________________________________________________________________
conv5_block12_concat (Concatena (None, 8, 8, 896)    0           conv5_block11_concat[0][0]       
                                                                 conv5_block12_2_conv[0][0]       
__________________________________________________________________________________________________
conv5_block13_0_bn (BatchNormal (None, 8, 8, 896)    3584        conv5_block12_concat[0][0]       
__________________________________________________________________________________________________
conv5_block13_0_relu (Activatio (None, 8, 8, 896)    0           conv5_block13_0_bn[0][0]         
__________________________________________________________________________________________________
conv5_block13_1_conv (Conv2D)   (None, 8, 8, 128)    114688      conv5_block13_0_relu[0][0]       
__________________________________________________________________________________________________
conv5_block13_1_bn (BatchNormal (None, 8, 8, 128)    512         conv5_block13_1_conv[0][0]       
__________________________________________________________________________________________________
conv5_block13_1_relu (Activatio (None, 8, 8, 128)    0           conv5_block13_1_bn[0][0]         
__________________________________________________________________________________________________
conv5_block13_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv5_block13_1_relu[0][0]       
__________________________________________________________________________________________________
conv5_block13_concat (Concatena (None, 8, 8, 928)    0           conv5_block12_concat[0][0]       
                                                                 conv5_block13_2_conv[0][0]       
__________________________________________________________________________________________________
conv5_block14_0_bn (BatchNormal (None, 8, 8, 928)    3712        conv5_block13_concat[0][0]       
__________________________________________________________________________________________________
conv5_block14_0_relu (Activatio (None, 8, 8, 928)    0           conv5_block14_0_bn[0][0]         
__________________________________________________________________________________________________
conv5_block14_1_conv (Conv2D)   (None, 8, 8, 128)    118784      conv5_block14_0_relu[0][0]       
__________________________________________________________________________________________________
conv5_block14_1_bn (BatchNormal (None, 8, 8, 128)    512         conv5_block14_1_conv[0][0]       
__________________________________________________________________________________________________
conv5_block14_1_relu (Activatio (None, 8, 8, 128)    0           conv5_block14_1_bn[0][0]         
__________________________________________________________________________________________________
conv5_block14_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv5_block14_1_relu[0][0]       
__________________________________________________________________________________________________
conv5_block14_concat (Concatena (None, 8, 8, 960)    0           conv5_block13_concat[0][0]       
                                                                 conv5_block14_2_conv[0][0]       
__________________________________________________________________________________________________
conv5_block15_0_bn (BatchNormal (None, 8, 8, 960)    3840        conv5_block14_concat[0][0]       
__________________________________________________________________________________________________
conv5_block15_0_relu (Activatio (None, 8, 8, 960)    0           conv5_block15_0_bn[0][0]         
__________________________________________________________________________________________________
conv5_block15_1_conv (Conv2D)   (None, 8, 8, 128)    122880      conv5_block15_0_relu[0][0]       
__________________________________________________________________________________________________
conv5_block15_1_bn (BatchNormal (None, 8, 8, 128)    512         conv5_block15_1_conv[0][0]       
__________________________________________________________________________________________________
conv5_block15_1_relu (Activatio (None, 8, 8, 128)    0           conv5_block15_1_bn[0][0]         
__________________________________________________________________________________________________
conv5_block15_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv5_block15_1_relu[0][0]       
__________________________________________________________________________________________________
conv5_block15_concat (Concatena (None, 8, 8, 992)    0           conv5_block14_concat[0][0]       
                                                                 conv5_block15_2_conv[0][0]       
__________________________________________________________________________________________________
conv5_block16_0_bn (BatchNormal (None, 8, 8, 992)    3968        conv5_block15_concat[0][0]       
__________________________________________________________________________________________________
conv5_block16_0_relu (Activatio (None, 8, 8, 992)    0           conv5_block16_0_bn[0][0]         
__________________________________________________________________________________________________
conv5_block16_1_conv (Conv2D)   (None, 8, 8, 128)    126976      conv5_block16_0_relu[0][0]       
__________________________________________________________________________________________________
conv5_block16_1_bn (BatchNormal (None, 8, 8, 128)    512         conv5_block16_1_conv[0][0]       
__________________________________________________________________________________________________
conv5_block16_1_relu (Activatio (None, 8, 8, 128)    0           conv5_block16_1_bn[0][0]         
__________________________________________________________________________________________________
conv5_block16_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv5_block16_1_relu[0][0]       
__________________________________________________________________________________________________
conv5_block16_concat (Concatena (None, 8, 8, 1024)   0           conv5_block15_concat[0][0]       
                                                                 conv5_block16_2_conv[0][0]       
__________________________________________________________________________________________________
bn (BatchNormalization)         (None, 8, 8, 1024)   4096        conv5_block16_concat[0][0]       
__________________________________________________________________________________________________
relu (Activation)               (None, 8, 8, 1024)   0           bn[0][0]                         
__________________________________________________________________________________________________
flatten (Flatten)               (None, 65536)        0           relu[0][0]                       
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         268439552   flatten[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
predictions (Dense)             (None, 5)            20485       fc2[0][0]                        
==================================================================================================
Total params: 292,278,853
Trainable params: 292,195,205
Non-trainable params: 83,648
__________________________________________________________________________________________________
Start fitting ensemble models
Random seed for replication: 375
Length split part:  1398
Labels in this part of split:  [279, 271, 288, 274, 286]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 53s - loss: 1.3760 - accuracy: 0.4971 - val_loss: 1.6991 - val_accuracy: 0.1844
Epoch 2/500
44/44 - 8s - loss: 0.2455 - accuracy: 0.9363 - val_loss: 2.4064 - val_accuracy: 0.1564
Epoch 3/500
44/44 - 8s - loss: 0.0707 - accuracy: 0.9943 - val_loss: 1.9805 - val_accuracy: 0.1508
Epoch 4/500
44/44 - 8s - loss: 0.0368 - accuracy: 0.9971 - val_loss: 2.4283 - val_accuracy: 0.1453
Epoch 5/500
44/44 - 8s - loss: 0.0251 - accuracy: 0.9971 - val_loss: 2.1092 - val_accuracy: 0.1732
Epoch 6/500
44/44 - 8s - loss: 0.0161 - accuracy: 0.9986 - val_loss: 1.8600 - val_accuracy: 0.2514
Epoch 7/500
44/44 - 8s - loss: 0.0158 - accuracy: 0.9986 - val_loss: 2.0670 - val_accuracy: 0.1955
Epoch 8/500
44/44 - 8s - loss: 0.0119 - accuracy: 0.9986 - val_loss: 1.8361 - val_accuracy: 0.2905
Epoch 9/500
44/44 - 8s - loss: 0.0105 - accuracy: 0.9993 - val_loss: 1.8919 - val_accuracy: 0.2849
Epoch 10/500
44/44 - 19s - loss: 0.0056 - accuracy: 0.9993 - val_loss: 1.3829 - val_accuracy: 0.4804
Epoch 11/500
44/44 - 8s - loss: 0.0065 - accuracy: 0.9993 - val_loss: 1.3882 - val_accuracy: 0.5307
Epoch 12/500
44/44 - 18s - loss: 0.0098 - accuracy: 0.9993 - val_loss: 1.1624 - val_accuracy: 0.5866
Epoch 13/500
44/44 - 8s - loss: 0.0074 - accuracy: 0.9993 - val_loss: 1.2443 - val_accuracy: 0.5475
Epoch 14/500
44/44 - 17s - loss: 0.0083 - accuracy: 0.9993 - val_loss: 1.1494 - val_accuracy: 0.5810
Epoch 15/500
44/44 - 18s - loss: 0.0055 - accuracy: 0.9993 - val_loss: 1.1408 - val_accuracy: 0.6201
Epoch 16/500
44/44 - 19s - loss: 0.0075 - accuracy: 0.9993 - val_loss: 1.1241 - val_accuracy: 0.6592
Epoch 17/500
44/44 - 8s - loss: 0.0053 - accuracy: 0.9993 - val_loss: 1.2643 - val_accuracy: 0.6927
Epoch 18/500
44/44 - 8s - loss: 0.0069 - accuracy: 0.9993 - val_loss: 1.1923 - val_accuracy: 0.7039
Epoch 19/500
44/44 - 19s - loss: 0.0047 - accuracy: 0.9993 - val_loss: 1.1201 - val_accuracy: 0.6704
Epoch 20/500
44/44 - 8s - loss: 0.0064 - accuracy: 0.9993 - val_loss: 1.2405 - val_accuracy: 0.7207
Epoch 21/500
44/44 - 8s - loss: 0.0043 - accuracy: 0.9993 - val_loss: 1.1621 - val_accuracy: 0.6872
Epoch 22/500
44/44 - 8s - loss: 0.0057 - accuracy: 0.9993 - val_loss: 1.2176 - val_accuracy: 0.6089
Epoch 23/500
44/44 - 8s - loss: 0.0049 - accuracy: 0.9993 - val_loss: 1.3709 - val_accuracy: 0.7263
Epoch 24/500
44/44 - 8s - loss: 0.0055 - accuracy: 0.9993 - val_loss: 1.2313 - val_accuracy: 0.6983
Epoch 25/500
44/44 - 8s - loss: 0.0039 - accuracy: 0.9993 - val_loss: 1.2464 - val_accuracy: 0.6983
Epoch 26/500
44/44 - 8s - loss: 0.0048 - accuracy: 0.9993 - val_loss: 1.3347 - val_accuracy: 0.7207
Epoch 27/500
44/44 - 8s - loss: 0.0040 - accuracy: 0.9993 - val_loss: 1.2118 - val_accuracy: 0.6983
Epoch 28/500
44/44 - 8s - loss: 0.0045 - accuracy: 0.9993 - val_loss: 1.3175 - val_accuracy: 0.6927
Epoch 29/500
44/44 - 8s - loss: 0.0035 - accuracy: 0.9993 - val_loss: 1.3431 - val_accuracy: 0.7039
Epoch 30/500
44/44 - 8s - loss: 0.0047 - accuracy: 0.9993 - val_loss: 1.2737 - val_accuracy: 0.6145
Epoch 31/500
44/44 - 8s - loss: 0.0030 - accuracy: 0.9993 - val_loss: 1.2570 - val_accuracy: 0.7095
Epoch 32/500
44/44 - 8s - loss: 0.0038 - accuracy: 0.9993 - val_loss: 1.3578 - val_accuracy: 0.7151
Epoch 33/500
44/44 - 8s - loss: 0.0035 - accuracy: 0.9993 - val_loss: 1.5433 - val_accuracy: 0.7095
Epoch 34/500
44/44 - 8s - loss: 0.0037 - accuracy: 0.9993 - val_loss: 1.2435 - val_accuracy: 0.6369
Epoch 35/500
44/44 - 8s - loss: 0.0035 - accuracy: 0.9993 - val_loss: 1.7001 - val_accuracy: 0.6983
Epoch 36/500
44/44 - 8s - loss: 0.0025 - accuracy: 0.9993 - val_loss: 1.2970 - val_accuracy: 0.7039
Epoch 37/500
44/44 - 8s - loss: 0.0025 - accuracy: 0.9993 - val_loss: 1.2925 - val_accuracy: 0.6927
Epoch 38/500
44/44 - 8s - loss: 0.0037 - accuracy: 0.9993 - val_loss: 1.2712 - val_accuracy: 0.6760
Epoch 39/500
44/44 - 8s - loss: 0.0030 - accuracy: 0.9993 - val_loss: 1.6256 - val_accuracy: 0.7151
Epoch 40/500
44/44 - 8s - loss: 0.0033 - accuracy: 0.9993 - val_loss: 1.3257 - val_accuracy: 0.6145
Epoch 41/500
44/44 - 8s - loss: 0.0030 - accuracy: 0.9993 - val_loss: 1.4393 - val_accuracy: 0.7039
Epoch 42/500
44/44 - 8s - loss: 0.0029 - accuracy: 0.9993 - val_loss: 1.2831 - val_accuracy: 0.6480
Epoch 43/500
44/44 - 8s - loss: 0.0020 - accuracy: 0.9993 - val_loss: 1.4323 - val_accuracy: 0.7039
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 16:18:00.796521: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 16:18:00.796679: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 16:18:00.796712: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 16:18:00.974581: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 16:18:00.974679: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00043: early stopping
Length split part:  1398
Labels in this part of split:  [273, 293, 284, 274, 274]
Train for 44 steps, validate for 6 steps
Epoch 1/500
44/44 - 17s - loss: 2.0106 - accuracy: 0.4363 - val_loss: 1.5411 - val_accuracy: 0.2905
Epoch 2/500
44/44 - 8s - loss: 0.3878 - accuracy: 0.8677 - val_loss: 2.0539 - val_accuracy: 0.1397
Epoch 3/500
44/44 - 8s - loss: 0.1000 - accuracy: 0.9728 - val_loss: 2.1645 - val_accuracy: 0.1397
Epoch 4/500
44/44 - 8s - loss: 0.0252 - accuracy: 0.9971 - val_loss: 2.3040 - val_accuracy: 0.1732
Epoch 5/500
44/44 - 8s - loss: 0.0137 - accuracy: 0.9979 - val_loss: 2.5127 - val_accuracy: 0.1620
Epoch 6/500
44/44 - 8s - loss: 0.0106 - accuracy: 0.9979 - val_loss: 2.2132 - val_accuracy: 0.2011
Epoch 7/500
44/44 - 8s - loss: 0.0092 - accuracy: 0.9979 - val_loss: 1.9489 - val_accuracy: 0.2793
Epoch 8/500
44/44 - 8s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.9126 - val_accuracy: 0.3240
Epoch 9/500
44/44 - 8s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.7296 - val_accuracy: 0.3855
Epoch 10/500
44/44 - 20s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.5092 - val_accuracy: 0.5028
Epoch 11/500
44/44 - 18s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4469 - val_accuracy: 0.5140
Epoch 12/500
44/44 - 19s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3724 - val_accuracy: 0.5810
Epoch 13/500
44/44 - 19s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3392 - val_accuracy: 0.6034
Epoch 14/500
44/44 - 17s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3257 - val_accuracy: 0.6425
Epoch 15/500
44/44 - 8s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3499 - val_accuracy: 0.6480
Epoch 16/500
44/44 - 8s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3801 - val_accuracy: 0.6536
Epoch 17/500
44/44 - 8s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4026 - val_accuracy: 0.6648
Epoch 18/500
44/44 - 8s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4125 - val_accuracy: 0.6592
Epoch 19/500
44/44 - 8s - loss: 9.8117e-04 - accuracy: 1.0000 - val_loss: 1.4241 - val_accuracy: 0.6480
Epoch 20/500
44/44 - 8s - loss: 9.0578e-04 - accuracy: 1.0000 - val_loss: 1.4337 - val_accuracy: 0.6480
Epoch 21/500
44/44 - 8s - loss: 8.3740e-04 - accuracy: 1.0000 - val_loss: 1.4401 - val_accuracy: 0.6536
Epoch 22/500
44/44 - 8s - loss: 7.8000e-04 - accuracy: 1.0000 - val_loss: 1.4482 - val_accuracy: 0.6592
Epoch 23/500
44/44 - 8s - loss: 7.3040e-04 - accuracy: 1.0000 - val_loss: 1.4542 - val_accuracy: 0.6536
Epoch 24/500
44/44 - 8s - loss: 6.8142e-04 - accuracy: 1.0000 - val_loss: 1.4622 - val_accuracy: 0.6648
Epoch 25/500
44/44 - 8s - loss: 6.3995e-04 - accuracy: 1.0000 - val_loss: 1.4734 - val_accuracy: 0.6704
Epoch 26/500
44/44 - 8s - loss: 5.9813e-04 - accuracy: 1.0000 - val_loss: 1.4794 - val_accuracy: 0.6704
Epoch 27/500
44/44 - 8s - loss: 5.6559e-04 - accuracy: 1.0000 - val_loss: 1.4905 - val_accuracy: 0.6648
Epoch 28/500
44/44 - 8s - loss: 5.2872e-04 - accuracy: 1.0000 - val_loss: 1.4979 - val_accuracy: 0.6648
Epoch 29/500
44/44 - 8s - loss: 4.9860e-04 - accuracy: 1.0000 - val_loss: 1.5096 - val_accuracy: 0.6704
Epoch 30/500
44/44 - 8s - loss: 4.7124e-04 - accuracy: 1.0000 - val_loss: 1.5132 - val_accuracy: 0.6704
Epoch 31/500
44/44 - 8s - loss: 4.4579e-04 - accuracy: 1.0000 - val_loss: 1.5213 - val_accuracy: 0.6648
Epoch 32/500
44/44 - 8s - loss: 4.2080e-04 - accuracy: 1.0000 - val_loss: 1.5290 - val_accuracy: 0.6704
Epoch 33/500
44/44 - 8s - loss: 3.9849e-04 - accuracy: 1.0000 - val_loss: 1.5402 - val_accuracy: 0.6704
Epoch 34/500
44/44 - 8s - loss: 3.7704e-04 - accuracy: 1.0000 - val_loss: 1.5451 - val_accuracy: 0.6760
Epoch 35/500
44/44 - 8s - loss: 3.5843e-04 - accuracy: 1.0000 - val_loss: 1.5531 - val_accuracy: 0.6648
Epoch 36/500
44/44 - 8s - loss: 3.4156e-04 - accuracy: 1.0000 - val_loss: 1.5614 - val_accuracy: 0.6760
Epoch 37/500
44/44 - 8s - loss: 3.2435e-04 - accuracy: 1.0000 - val_loss: 1.5678 - val_accuracy: 0.6648
Epoch 38/500
44/44 - 8s - loss: 3.0857e-04 - accuracy: 1.0000 - val_loss: 1.5751 - val_accuracy: 0.6648
Epoch 39/500
44/44 - 8s - loss: 2.9523e-04 - accuracy: 1.0000 - val_loss: 1.5821 - val_accuracy: 0.6704
Epoch 40/500
44/44 - 8s - loss: 2.8205e-04 - accuracy: 1.0000 - val_loss: 1.5909 - val_accuracy: 0.6704
Epoch 41/500
44/44 - 8s - loss: 2.6791e-04 - accuracy: 1.0000 - val_loss: 1.5966 - val_accuracy: 0.6648
Epoch 42/500
44/44 - 8s - loss: 2.5557e-04 - accuracy: 1.0000 - val_loss: 1.6048 - val_accuracy: 0.6704
Epoch 43/500
44/44 - 8s - loss: 2.4443e-04 - accuracy: 1.0000 - val_loss: 1.6094 - val_accuracy: 0.6592
Epoch 44/500
44/44 - 8s - loss: 2.3291e-04 - accuracy: 1.0000 - val_loss: 1.6187 - val_accuracy: 0.6704
Epoch 45/500
44/44 - 8s - loss: 2.2285e-04 - accuracy: 1.0000 - val_loss: 1.6261 - val_accuracy: 0.6704
Epoch 46/500
44/44 - 8s - loss: 2.1322e-04 - accuracy: 1.0000 - val_loss: 1.6284 - val_accuracy: 0.6648
Epoch 47/500
44/44 - 8s - loss: 2.0475e-04 - accuracy: 1.0000 - val_loss: 1.6384 - val_accuracy: 0.6648
Epoch 48/500
44/44 - 8s - loss: 1.9585e-04 - accuracy: 1.0000 - val_loss: 1.6448 - val_accuracy: 0.6760
Epoch 49/500
44/44 - 8s - loss: 1.8726e-04 - accuracy: 1.0000 - val_loss: 1.6503 - val_accuracy: 0.6760
Epoch 50/500
44/44 - 8s - loss: 1.7964e-04 - accuracy: 1.0000 - val_loss: 1.6582 - val_accuracy: 0.6760
Epoch 51/500
44/44 - 8s - loss: 1.7220e-04 - accuracy: 1.0000 - val_loss: 1.6623 - val_accuracy: 0.6704
Epoch 52/500
44/44 - 8s - loss: 1.6496e-04 - accuracy: 1.0000 - val_loss: 1.6684 - val_accuracy: 0.6648
Epoch 53/500
44/44 - 8s - loss: 1.5853e-04 - accuracy: 1.0000 - val_loss: 1.6784 - val_accuracy: 0.6704
Epoch 54/500
44/44 - 8s - loss: 1.5237e-04 - accuracy: 1.0000 - val_loss: 1.6820 - val_accuracy: 0.6704
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-25 16:26:52.205330: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-25 16:26:52.205488: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 16:26:52.205524: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-25 16:26:52.384392: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-25 16:26:52.384507: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00054: early stopping
Length split part:  1397
Labels in this part of split:  [288, 276, 267, 290, 276]
Train for 44 steps, validate for 6 steps
Epoch 1/500
Traceback (most recent call last):
  File "/software/software/TensorFlow/2.1.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 115, in save_model_to_hdf5
    save_optimizer_weights_to_hdf5_group(f, model.optimizer)
  File "/software/software/TensorFlow/2.1.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 592, in save_optimizer_weights_to_hdf5_group
    param_dset[:] = val
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "/software/software/h5py/2.10.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/h5py-2.10.0-py3.7-linux-x86_64.egg/h5py/_hl/dataset.py", line 708, in __setitem__
    self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
  File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
  File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
OSError: Can't write data (file write failed: time = Mon May 25 16:27:11 2020
, filename = 'best_model.h5', file descriptor = 47, errno = 122, error message = 'Disk quota exceeded', buf = 0x7f95dee89248, total write size = 452984264, bytes this sub-write = 452984264, bytes actually written = 18446744073709551615, offset = 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "MES_Multi_Ensemble.py", line 383, in <module>
    main()
  File "MES_Multi_Ensemble.py", line 377, in main
    ensemble = [fit_model(x_train_splits, y_train_splits, x_val, y_val, ensemble_model, log_dir, i, archi_name[ind]) for i in range(N_ENSEMBLE_MEMBERS)]
  File "MES_Multi_Ensemble.py", line 377, in <listcomp>
    ensemble = [fit_model(x_train_splits, y_train_splits, x_val, y_val, ensemble_model, log_dir, i, archi_name[ind]) for i in range(N_ENSEMBLE_MEMBERS)]
  File "MES_Multi_Ensemble.py", line 277, in fit_model
    callbacks=[tensorboard_callback, early_stopping, mc])
  File "/software/software/TensorFlow/2.1.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File "/software/software/TensorFlow/2.1.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py", line 397, in fit
    prefix='val_')
  File "/software/software/Python/3.7.4-GCCcore-8.3.0/lib/python3.7/contextlib.py", line 119, in __exit__
    next(self.gen)
  File "/software/software/TensorFlow/2.1.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py", line 771, in on_epoch
    self.callbacks.on_epoch_end(epoch, epoch_logs)
  File "/software/software/TensorFlow/2.1.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py", line 302, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/software/software/TensorFlow/2.1.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py", line 992, in on_epoch_end
    self._save_model(epoch=epoch, logs=logs)
  File "/software/software/TensorFlow/2.1.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py", line 1029, in _save_model
    self.model.save(filepath, overwrite=True)
  File "/software/software/TensorFlow/2.1.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py", line 1008, in save
    signatures, options)
  File "/software/software/TensorFlow/2.1.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py", line 112, in save_model
    model, filepath, overwrite, include_optimizer)
  File "/software/software/TensorFlow/2.1.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 120, in save_model_to_hdf5
    f.close()
  File "/software/software/h5py/2.10.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/h5py-2.10.0-py3.7-linux-x86_64.egg/h5py/_hl/files.py", line 443, in close
    h5i.dec_ref(id_)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
RuntimeError: Can't decrement id ref count (unable to close file, errno = 5, error message = 'Input/output error')
[pg-gpu30:19787] *** Process received signal ***
[pg-gpu30:19787] Signal: Segmentation fault (11)
[pg-gpu30:19787] Signal code: Address not mapped (1)
[pg-gpu30:19787] Failing at address: 0x558
[pg-gpu30:19787] [ 0] /lib64/libpthread.so.0(+0xf5f0)[0x7f9a459f25f0]
[pg-gpu30:19787] [ 1] /software/software/HDF5/1.10.5-gompic-2019b/lib/libhdf5.so.103(H5F__close_cb+0x29)[0x7f9a3c56a349]
[pg-gpu30:19787] [ 2] /software/software/HDF5/1.10.5-gompic-2019b/lib/libhdf5.so.103(H5I_dec_ref+0xbe)[0x7f9a3c5d86de]
[pg-gpu30:19787] [ 3] /software/software/HDF5/1.10.5-gompic-2019b/lib/libhdf5.so.103(H5I_dec_app_ref+0x3c)[0x7f9a3c5d885c]
[pg-gpu30:19787] [ 4] /software/software/HDF5/1.10.5-gompic-2019b/lib/libhdf5.so.103(H5Idec_ref+0x41)[0x7f9a3c5d8991]
[pg-gpu30:19787] [ 5] /software/software/h5py/2.10.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/h5py-2.10.0-py3.7-linux-x86_64.egg/h5py/defs.cpython-37m-x86_64-linux-gnu.so(+0x24d73)[0x7f9a39270d73]
[pg-gpu30:19787] [ 6] /software/software/h5py/2.10.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/h5py-2.10.0-py3.7-linux-x86_64.egg/h5py/_objects.cpython-37m-x86_64-linux-gnu.so(+0x11eb0)[0x7f9a3923ceb0]
[pg-gpu30:19787] [ 7] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(+0x8679b)[0x7f9a463c279b]
[pg-gpu30:19787] [ 8] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(+0x1974b9)[0x7f9a464d34b9]
[pg-gpu30:19787] [ 9] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(+0x1974a4)[0x7f9a464d34a4]
[pg-gpu30:19787] [10] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(+0x1974a4)[0x7f9a464d34a4]
[pg-gpu30:19787] [11] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(+0x1974a4)[0x7f9a464d34a4]
[pg-gpu30:19787] [12] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(+0x1974a4)[0x7f9a464d34a4]
[pg-gpu30:19787] [13] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(+0x1974a4)[0x7f9a464d34a4]
[pg-gpu30:19787] [14] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(+0x1974a4)[0x7f9a464d34a4]
[pg-gpu30:19787] [15] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(+0x1974a4)[0x7f9a464d34a4]
[pg-gpu30:19787] [16] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(+0x1974a4)[0x7f9a464d34a4]
[pg-gpu30:19787] [17] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(+0x1974a4)[0x7f9a464d34a4]
[pg-gpu30:19787] [18] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(+0x1974a4)[0x7f9a464d34a4]
[pg-gpu30:19787] [19] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(+0x1974a4)[0x7f9a464d34a4]
[pg-gpu30:19787] [20] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(+0x1974a4)[0x7f9a464d34a4]
[pg-gpu30:19787] [21] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(+0x1974a4)[0x7f9a464d34a4]
[pg-gpu30:19787] [22] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(+0x1974a4)[0x7f9a464d34a4]
[pg-gpu30:19787] [23] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(+0xd5c2e)[0x7f9a46411c2e]
[pg-gpu30:19787] [24] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(PyDict_SetItemString+0x38)[0x7f9a46416778]
[pg-gpu30:19787] [25] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(PyImport_Cleanup+0x8f)[0x7f9a464b4b4f]
[pg-gpu30:19787] [26] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(Py_FinalizeEx+0x76)[0x7f9a464c0da6]
[pg-gpu30:19787] [27] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(+0x1a81e5)[0x7f9a464e41e5]
[pg-gpu30:19787] [28] /software/software/Python/3.7.4-GCCcore-8.3.0/lib/libpython3.7m.so.1.0(_Py_UnixMain+0x3e)[0x7f9a464e492e]
[pg-gpu30:19787] [29] /lib64/libc.so.6(__libc_start_main+0xf5)[0x7f9a45434505]
[pg-gpu30:19787] *** End of error message ***
/var/spool/slurmd/job11724849/slurm_script: line 14: 19787 Segmentation fault      python MES_Multi_Ensemble.py


###############################################################################
Peregrine Cluster
Job 11724849 for user 's2934833'
Finished at: Mon May 25 16:27:22 CEST 2020

Job details:
============

Name                : MESEN
User                : s2934833
Partition           : gpu
Nodes               : pg-gpu30
Cores               : 12
State               : FAILED
Submit              : 2020-05-25T11:24:56
Start               : 2020-05-25T11:24:58
End                 : 2020-05-25T16:27:22
Reserved walltime   : 1-00:00:00
Used walltime       :   05:02:24
Used CPU time       :   04:30:07 (efficiency:  7.44%)
% User (Computation): 66.29%
% System (I/O)      : 33.71%
Mem reserved        : 125G/node
Max Mem used        : 16.15G (pg-gpu30)
Max Disk Write      : 153.60K (pg-gpu30)
Max Disk Read       : 5.83M (pg-gpu30)
Average GPU usage   : 72.7% (pg-gpu30)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/additional_information/scientific_output

################################################################################
