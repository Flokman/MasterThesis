
The following have been reloaded with a version change:
  1) FFTW/3.3.8-gompic-2019b => FFTW/3.3.8-gompi-2019b
  2) OpenMPI/3.1.4-gcccuda-2019b => OpenMPI/3.1.4-GCC-8.3.0
  3) ScaLAPACK/2.0.2-gompic-2019b => ScaLAPACK/2.0.2-gompi-2019b
  4) SciPy-bundle/2019.10-fosscuda-2019b-Python-3.7.4 => SciPy-bundle/2019.10-foss-2019b-Python-3.7.4

2020-05-11 12:01:42.940099: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-11 12:01:49.940185: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-05-11 12:01:49.947322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-11 12:01:49.947878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-11 12:01:49.947971: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-11 12:01:49.952523: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-11 12:01:49.955735: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-11 12:01:49.957150: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-11 12:01:49.960364: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-11 12:01:49.962249: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-11 12:01:49.967223: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-11 12:01:49.967425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-11 12:01:49.968018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-11 12:01:49.968460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-05-11 12:01:49.970993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-11 12:01:49.971451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-11 12:01:49.971537: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-11 12:01:49.971626: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-11 12:01:49.971691: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-11 12:01:49.971753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-11 12:01:49.971813: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-11 12:01:49.971874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-11 12:01:49.971935: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-11 12:01:49.972075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-11 12:01:49.972581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-11 12:01:49.972999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-05-11 12:01:49.973092: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-11 12:01:50.594718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-11 12:01:50.594853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-05-11 12:01:50.594909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-05-11 12:01:50.595212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-11 12:01:50.595851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-11 12:01:50.596391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-11 12:01:50.596863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28652 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2020-05-11 12:01:50.597239: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-11 12:01:53.272476: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-11 12:01:53.505313: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-11 12:01:55.320732: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-11 12:01:55.320886: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1259] Profiler found 1 GPUs
2020-05-11 12:01:55.323252: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1
2020-05-11 12:01:55.423837: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-05-11 12:01:55.424422: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-05-11 12:01:55.444158: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-11 12:01:55.444270: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
dataset_name = /CIFAR10, batch_size = 64, num_classes = 10, epochs_1 = 150,
        epochts_2 = 30, test_img_idx = 6954,
        train_test_split = 0.8
        learn rate = 1e-05,
        train_all_layers = True, weights_to_use = imagenet,
        es_patience_1 = 20, es_patience_2 = 5, train_val_split = 0.9
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 test samples
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
block1_conv1 (Conv2D)           (None, 32, 32, 64)   1792        input_1[0][0]                    
__________________________________________________________________________________________________
block1_conv2 (Conv2D)           (None, 32, 32, 64)   36928       block1_conv1[1][0]               
__________________________________________________________________________________________________
block1_pool (MaxPooling2D)      (None, 16, 16, 64)   0           block1_conv2[1][0]               
__________________________________________________________________________________________________
block2_conv1 (Conv2D)           (None, 16, 16, 128)  73856       block1_pool[1][0]                
__________________________________________________________________________________________________
block2_conv2 (Conv2D)           (None, 16, 16, 128)  147584      block2_conv1[1][0]               
__________________________________________________________________________________________________
block2_pool (MaxPooling2D)      (None, 8, 8, 128)    0           block2_conv2[1][0]               
__________________________________________________________________________________________________
block3_conv1 (Conv2D)           (None, 8, 8, 256)    295168      block2_pool[1][0]                
__________________________________________________________________________________________________
block3_conv2 (Conv2D)           (None, 8, 8, 256)    590080      block3_conv1[1][0]               
__________________________________________________________________________________________________
block3_conv3 (Conv2D)           (None, 8, 8, 256)    590080      block3_conv2[1][0]               
__________________________________________________________________________________________________
block3_pool (MaxPooling2D)      (None, 4, 4, 256)    0           block3_conv3[1][0]               
__________________________________________________________________________________________________
block4_conv1 (Conv2D)           (None, 4, 4, 512)    1180160     block3_pool[1][0]                
__________________________________________________________________________________________________
block4_conv2 (Conv2D)           (None, 4, 4, 512)    2359808     block4_conv1[1][0]               
__________________________________________________________________________________________________
block4_conv3 (Conv2D)           (None, 4, 4, 512)    2359808     block4_conv2[1][0]               
__________________________________________________________________________________________________
block4_pool (MaxPooling2D)      (None, 2, 2, 512)    0           block4_conv3[1][0]               
__________________________________________________________________________________________________
block5_conv1 (Conv2D)           (None, 2, 2, 512)    2359808     block4_pool[1][0]                
__________________________________________________________________________________________________
block5_conv2 (Conv2D)           (None, 2, 2, 512)    2359808     block5_conv1[1][0]               
__________________________________________________________________________________________________
block5_conv3 (Conv2D)           (None, 2, 2, 512)    2359808     block5_conv2[1][0]               
__________________________________________________________________________________________________
block5_pool (MaxPooling2D)      (None, 1, 1, 512)    0           block5_conv3[1][0]               
__________________________________________________________________________________________________
flatten (Flatten)               (None, 512)          0           block5_pool[1][0]                
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         2101248     flatten[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
dense (Dense)                   (None, 10)           40970       fc2[0][0]                        
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           40970       fc2[0][0]                        
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 20)           0           dense[0][0]                      
                                                                 dense_1[0][0]                    
==================================================================================================
Total params: 33,679,188
Trainable params: 33,679,188
Non-trainable params: 0
__________________________________________________________________________________________________
Start fitting
Train for 704 steps, validate for 79 steps
Epoch 1/150
704/704 - 17s - loss: 0.0226 - acc: 0.3166 - val_loss: 0.0118 - val_acc: 0.6372
Epoch 2/150
704/704 - 13s - loss: 0.0102 - acc: 0.6855 - val_loss: 0.0091 - val_acc: 0.7120
Epoch 3/150
704/704 - 14s - loss: 0.0076 - acc: 0.7405 - val_loss: 0.0081 - val_acc: 0.7436
Epoch 4/150
704/704 - 13s - loss: 0.0062 - acc: 0.7684 - val_loss: 0.0078 - val_acc: 0.7568
Epoch 5/150
704/704 - 13s - loss: 0.0050 - acc: 0.7873 - val_loss: 0.0071 - val_acc: 0.7610
Epoch 6/150
704/704 - 13s - loss: 0.0040 - acc: 0.8027 - val_loss: 0.0062 - val_acc: 0.7694
Epoch 7/150
704/704 - 13s - loss: 0.0032 - acc: 0.8116 - val_loss: 0.0062 - val_acc: 0.7616
Epoch 8/150
704/704 - 13s - loss: 0.0025 - acc: 0.8177 - val_loss: 0.0063 - val_acc: 0.7566
Epoch 9/150
704/704 - 13s - loss: 0.0020 - acc: 0.8221 - val_loss: 0.0059 - val_acc: 0.7280
Epoch 10/150
704/704 - 13s - loss: 0.0015 - acc: 0.8266 - val_loss: 0.0055 - val_acc: 0.7424
Epoch 11/150
704/704 - 13s - loss: 0.0012 - acc: 0.8275 - val_loss: 0.0055 - val_acc: 0.7446
Epoch 12/150
704/704 - 13s - loss: 9.8537e-04 - acc: 0.8325 - val_loss: 0.0057 - val_acc: 0.7516
Epoch 13/150
704/704 - 13s - loss: 8.0504e-04 - acc: 0.8332 - val_loss: 0.0058 - val_acc: 0.7360
Epoch 14/150
704/704 - 13s - loss: 6.2919e-04 - acc: 0.8334 - val_loss: 0.0056 - val_acc: 0.7276
Epoch 15/150
704/704 - 13s - loss: 6.0678e-04 - acc: 0.8313 - val_loss: 0.0056 - val_acc: 0.7320
Epoch 16/150
704/704 - 13s - loss: 4.6117e-04 - acc: 0.8371 - val_loss: 0.0058 - val_acc: 0.6962
Epoch 17/150
704/704 - 12s - loss: 5.4850e-04 - acc: 0.8226 - val_loss: 0.0060 - val_acc: 0.7540
Epoch 18/150
704/704 - 13s - loss: 4.0417e-04 - acc: 0.8322 - val_loss: 0.0058 - val_acc: 0.7320
Epoch 19/150
704/704 - 12s - loss: 4.8082e-04 - acc: 0.8272 - val_loss: 0.0061 - val_acc: 0.7332
Epoch 20/150
704/704 - 13s - loss: 3.2129e-04 - acc: 0.8358 - val_loss: 0.0058 - val_acc: 0.7284
Epoch 21/150
704/704 - 12s - loss: 3.4233e-04 - acc: 0.8369 - val_loss: 0.0058 - val_acc: 0.7160
Epoch 22/150
704/704 - 12s - loss: 4.4756e-04 - acc: 0.8209 - val_loss: 0.0055 - val_acc: 0.7320
Epoch 23/150
704/704 - 13s - loss: 1.9368e-04 - acc: 0.8454 - val_loss: 0.0058 - val_acc: 0.7288
Epoch 24/150
704/704 - 12s - loss: 3.5360e-04 - acc: 0.8236 - val_loss: 0.0071 - val_acc: 0.6626
Epoch 25/150
704/704 - 12s - loss: 2.0604e-04 - acc: 0.8293 - val_loss: 0.0056 - val_acc: 0.7550
Epoch 26/150
704/704 - 12s - loss: 2.8988e-04 - acc: 0.8276 - val_loss: 0.0055 - val_acc: 0.7434
Epoch 27/150
704/704 - 14s - loss: 1.7791e-04 - acc: 0.8524 - val_loss: 0.0068 - val_acc: 0.7068
Epoch 28/150
704/704 - 12s - loss: 3.7683e-04 - acc: 0.8097 - val_loss: 0.0058 - val_acc: 0.7134
Epoch 29/150
704/704 - 14s - loss: 1.6563e-04 - acc: 0.8331 - val_loss: 0.0058 - val_acc: 0.7328
Epoch 30/150
704/704 - 13s - loss: 1.0846e-04 - acc: 0.8479 - val_loss: 0.0055 - val_acc: 0.7518
Epoch 31/150
704/704 - 12s - loss: 2.6217e-04 - acc: 0.8383 - val_loss: 0.0066 - val_acc: 0.6890
Epoch 32/150
704/704 - 12s - loss: 2.8060e-04 - acc: 0.8186 - val_loss: 0.0056 - val_acc: 0.7346
Epoch 33/150
704/704 - 14s - loss: 7.7192e-05 - acc: 0.8514 - val_loss: 0.0056 - val_acc: 0.7360
Epoch 34/150
704/704 - 12s - loss: 1.2067e-04 - acc: 0.8492 - val_loss: 0.0071 - val_acc: 0.7132
Epoch 35/150
704/704 - 12s - loss: 3.5490e-04 - acc: 0.8064 - val_loss: 0.0056 - val_acc: 0.7286
Epoch 36/150
704/704 - 13s - loss: 6.0983e-05 - acc: 0.8497 - val_loss: 0.0059 - val_acc: 0.7332
Epoch 37/150
704/704 - 12s - loss: 2.9144e-04 - acc: 0.8078 - val_loss: 0.0057 - val_acc: 0.7200
Epoch 38/150
704/704 - 12s - loss: 7.5864e-05 - acc: 0.8320 - val_loss: 0.0056 - val_acc: 0.7368
Epoch 39/150
704/704 - 12s - loss: 1.3730e-04 - acc: 0.8402 - val_loss: 0.0071 - val_acc: 0.6354
Epoch 40/150
704/704 - 12s - loss: 2.2489e-04 - acc: 0.8003 - val_loss: 0.0057 - val_acc: 0.7078
Epoch 41/150
704/704 - 12s - loss: 1.0622e-04 - acc: 0.8229 - val_loss: 0.0061 - val_acc: 0.7102
Epoch 42/150
704/704 - 12s - loss: 2.2096e-04 - acc: 0.7959 - val_loss: 0.0058 - val_acc: 0.7046
Epoch 43/150
704/704 - 12s - loss: 8.9045e-05 - acc: 0.8137 - val_loss: 0.0055 - val_acc: 0.7340
Epoch 44/150
704/704 - 13s - loss: 3.0235e-05 - acc: 0.8374 - val_loss: 0.0055 - val_acc: 0.7432
Epoch 45/150
704/704 - 13s - loss: 2.5909e-05 - acc: 0.8430 - val_loss: 0.0055 - val_acc: 0.7416
Epoch 46/150
704/704 - 13s - loss: 2.5227e-05 - acc: 0.8450 - val_loss: 0.0056 - val_acc: 0.7434
Epoch 47/150
704/704 - 12s - loss: 4.4233e-04 - acc: 0.8077 - val_loss: 0.0053 - val_acc: 0.7032
Epoch 48/150
704/704 - 12s - loss: 1.2012e-04 - acc: 0.8001 - val_loss: 0.0056 - val_acc: 0.7274
Epoch 49/150
704/704 - 12s - loss: 2.7245e-05 - acc: 0.8274 - val_loss: 0.0053 - val_acc: 0.7454
Epoch 50/150
704/704 - 13s - loss: 1.7530e-05 - acc: 0.8372 - val_loss: 0.0053 - val_acc: 0.7508
Epoch 51/150
704/704 - 13s - loss: 1.5275e-05 - acc: 0.8466 - val_loss: 0.0054 - val_acc: 0.7446
Epoch 52/150
704/704 - 12s - loss: 1.5812e-05 - acc: 0.8460 - val_loss: 0.0054 - val_acc: 0.7472
Epoch 53/150
704/704 - 12s - loss: 2.9610e-04 - acc: 0.8290 - val_loss: 0.0060 - val_acc: 0.7114
Epoch 54/150
704/704 - 12s - loss: 2.0487e-04 - acc: 0.7957 - val_loss: 0.0054 - val_acc: 0.7286
Epoch 55/150
704/704 - 12s - loss: 2.0657e-05 - acc: 0.8356 - val_loss: 0.0051 - val_acc: 0.7488
Epoch 56/150
704/704 - 13s - loss: 1.2787e-05 - acc: 0.8435 - val_loss: 0.0052 - val_acc: 0.7498
Epoch 57/150
704/704 - 13s - loss: 1.1266e-05 - acc: 0.8420 - val_loss: 0.0052 - val_acc: 0.7524
Epoch 58/150
704/704 - 13s - loss: 1.0950e-05 - acc: 0.8478 - val_loss: 0.0052 - val_acc: 0.7546
Epoch 59/150
704/704 - 12s - loss: 1.1081e-05 - acc: 0.8476 - val_loss: 0.0053 - val_acc: 0.7358
Epoch 60/150
704/704 - 12s - loss: 3.4654e-04 - acc: 0.8052 - val_loss: 0.0058 - val_acc: 0.7234
Epoch 61/150
704/704 - 12s - loss: 1.6933e-04 - acc: 0.7851 - val_loss: 0.0055 - val_acc: 0.6678
Epoch 62/150
704/704 - 12s - loss: 1.0291e-04 - acc: 0.7890 - val_loss: 0.0054 - val_acc: 0.7272
Epoch 63/150
704/704 - 12s - loss: 4.7704e-05 - acc: 0.8097 - val_loss: 0.0055 - val_acc: 0.7090
Epoch 64/150
704/704 - 12s - loss: 1.2078e-05 - acc: 0.8272 - val_loss: 0.0053 - val_acc: 0.7452
Epoch 65/150
704/704 - 13s - loss: 9.8520e-06 - acc: 0.8396 - val_loss: 0.0054 - val_acc: 0.7374
Epoch 66/150
704/704 - 12s - loss: 1.0262e-05 - acc: 0.8458 - val_loss: 0.0054 - val_acc: 0.7500
Epoch 67/150
704/704 - 12s - loss: 2.5861e-04 - acc: 0.8251 - val_loss: 0.0060 - val_acc: 0.6708
Epoch 68/150
704/704 - 12s - loss: 1.6250e-04 - acc: 0.7950 - val_loss: 0.0058 - val_acc: 0.7026
Epoch 69/150
704/704 - 12s - loss: 2.1486e-05 - acc: 0.8170 - val_loss: 0.0056 - val_acc: 0.7116
Epoch 70/150
704/704 - 12s - loss: 1.6796e-04 - acc: 0.7900 - val_loss: 0.0056 - val_acc: 0.7342
Epoch 71/150
704/704 - 12s - loss: 3.9465e-05 - acc: 0.8168 - val_loss: 0.0055 - val_acc: 0.7278
Epoch 72/150
704/704 - 13s - loss: 9.0751e-06 - acc: 0.8288 - val_loss: 0.0054 - val_acc: 0.7362
Epoch 73/150
704/704 - 13s - loss: 8.1465e-06 - acc: 0.8320 - val_loss: 0.0054 - val_acc: 0.7382
Epoch 74/150
704/704 - 12s - loss: 8.3131e-06 - acc: 0.8352 - val_loss: 0.0055 - val_acc: 0.7344
Epoch 75/150
704/704 - 12s - loss: 9.0888e-06 - acc: 0.8369 - val_loss: 0.0056 - val_acc: 0.7484
Epoch 76/150
704/704 - 12s - loss: 3.2642e-04 - acc: 0.8050 - val_loss: 0.0058 - val_acc: 0.6680
Epoch 77/150
704/704 - 12s - loss: 9.0873e-05 - acc: 0.7879 - val_loss: 0.0060 - val_acc: 0.7264
Epoch 78/150
704/704 - 12s - loss: 2.0513e-05 - acc: 0.8111 - val_loss: 0.0055 - val_acc: 0.7376
Epoch 79/150
704/704 - 13s - loss: 8.0401e-06 - acc: 0.8295 - val_loss: 0.0054 - val_acc: 0.7562
Epoch 80/150
704/704 - 13s - loss: 7.3486e-06 - acc: 0.8333 - val_loss: 0.0054 - val_acc: 0.7446
Epoch 81/150
704/704 - 12s - loss: 7.8888e-06 - acc: 0.8342 - val_loss: 0.0054 - val_acc: 0.7498
Epoch 82/150
704/704 - 12s - loss: 9.3380e-06 - acc: 0.8288 - val_loss: 0.0055 - val_acc: 0.7382
Epoch 83/150
704/704 - 12s - loss: 3.0164e-04 - acc: 0.7826 - val_loss: 0.0067 - val_acc: 0.6660
Epoch 84/150
704/704 - 12s - loss: 5.4206e-05 - acc: 0.7961 - val_loss: 0.0055 - val_acc: 0.7302
Epoch 85/150
704/704 - 12s - loss: 1.0211e-05 - acc: 0.8263 - val_loss: 0.0054 - val_acc: 0.7466
Epoch 86/150
704/704 - 12s - loss: 7.3808e-06 - acc: 0.8328 - val_loss: 0.0054 - val_acc: 0.7544
Epoch 87/150
704/704 - 12s - loss: 9.1982e-06 - acc: 0.8341 - val_loss: 0.0055 - val_acc: 0.7492
Epoch 88/150
704/704 - 12s - loss: 8.6868e-06 - acc: 0.8409 - val_loss: 0.0055 - val_acc: 0.7542
Epoch 89/150
704/704 - 12s - loss: 1.1354e-05 - acc: 0.8406 - val_loss: 0.0054 - val_acc: 0.7558
Epoch 90/150
704/704 - 12s - loss: 3.6309e-04 - acc: 0.7838 - val_loss: 0.0054 - val_acc: 0.7306
Epoch 91/150
704/704 - 12s - loss: 4.7379e-05 - acc: 0.8022 - val_loss: 0.0057 - val_acc: 0.7356
Epoch 92/150
704/704 - 12s - loss: 1.9367e-05 - acc: 0.8205 - val_loss: 0.0060 - val_acc: 0.7130
Epoch 93/150
704/704 - 12s - loss: 9.6696e-05 - acc: 0.7838 - val_loss: 0.0053 - val_acc: 0.7308
Epoch 94/150
704/704 - 12s - loss: 1.2144e-05 - acc: 0.8181 - val_loss: 0.0052 - val_acc: 0.7284
Epoch 95/150
704/704 - 13s - loss: 5.9674e-06 - acc: 0.8149 - val_loss: 0.0052 - val_acc: 0.7296
Epoch 96/150
704/704 - 13s - loss: 5.9362e-06 - acc: 0.8198 - val_loss: 0.0052 - val_acc: 0.7232
Epoch 97/150
704/704 - 12s - loss: 6.1090e-06 - acc: 0.8177 - val_loss: 0.0052 - val_acc: 0.7332
Epoch 98/150
704/704 - 12s - loss: 8.3638e-06 - acc: 0.8205 - val_loss: 0.0058 - val_acc: 0.7216
Epoch 99/150
704/704 - 12s - loss: 3.5393e-04 - acc: 0.7648 - val_loss: 0.0054 - val_acc: 0.6946
Epoch 100/150
704/704 - 12s - loss: 8.1014e-05 - acc: 0.7719 - val_loss: 0.0053 - val_acc: 0.7228
Epoch 101/150
704/704 - 12s - loss: 1.1644e-05 - acc: 0.8107 - val_loss: 0.0054 - val_acc: 0.7420
Epoch 102/150
704/704 - 12s - loss: 6.0390e-06 - acc: 0.8130 - val_loss: 0.0053 - val_acc: 0.7250
Epoch 103/150
704/704 - 13s - loss: 5.0513e-06 - acc: 0.8210 - val_loss: 0.0053 - val_acc: 0.7304
Epoch 104/150
704/704 - 12s - loss: 5.2542e-06 - acc: 0.8203 - val_loss: 0.0053 - val_acc: 0.7372
Epoch 105/150
704/704 - 12s - loss: 6.4859e-06 - acc: 0.8224 - val_loss: 0.0054 - val_acc: 0.7572
Epoch 106/150
704/704 - 12s - loss: 7.7194e-06 - acc: 0.8310 - val_loss: 0.0053 - val_acc: 0.7568
Epoch 107/150
704/704 - 12s - loss: 2.6102e-04 - acc: 0.7822 - val_loss: 0.0053 - val_acc: 0.7024
Epoch 108/150
704/704 - 12s - loss: 9.2014e-05 - acc: 0.7788 - val_loss: 0.0057 - val_acc: 0.6548
Epoch 109/150
704/704 - 12s - loss: 2.3089e-05 - acc: 0.7780 - val_loss: 0.0052 - val_acc: 0.7204
Epoch 110/150
704/704 - 12s - loss: 5.4676e-06 - acc: 0.8062 - val_loss: 0.0052 - val_acc: 0.7456
Epoch 111/150
704/704 - 12s - loss: 5.0642e-06 - acc: 0.8155 - val_loss: 0.0053 - val_acc: 0.7488
Epoch 112/150
704/704 - 12s - loss: 5.8324e-06 - acc: 0.8215 - val_loss: 0.0052 - val_acc: 0.7318
Epoch 113/150
704/704 - 12s - loss: 7.3640e-06 - acc: 0.8220 - val_loss: 0.0054 - val_acc: 0.7320
Epoch 114/150
704/704 - 12s - loss: 2.1371e-04 - acc: 0.8023 - val_loss: 0.0058 - val_acc: 0.6810
Epoch 115/150
704/704 - 12s - loss: 1.2251e-04 - acc: 0.7630 - val_loss: 0.0054 - val_acc: 0.7180
Epoch 116/150
704/704 - 12s - loss: 7.6042e-05 - acc: 0.7896 - val_loss: 0.0053 - val_acc: 0.7336
Epoch 117/150
704/704 - 12s - loss: 4.6947e-05 - acc: 0.7947 - val_loss: 0.0053 - val_acc: 0.6932
Epoch 118/150
704/704 - 12s - loss: 1.9655e-05 - acc: 0.7920 - val_loss: 0.0060 - val_acc: 0.6830
Epoch 119/150
704/704 - 12s - loss: 7.5831e-05 - acc: 0.7918 - val_loss: 0.0064 - val_acc: 0.6412
Epoch 120/150
704/704 - 12s - loss: 9.7193e-05 - acc: 0.7400 - val_loss: 0.0058 - val_acc: 0.6484
Epoch 121/150
704/704 - 12s - loss: 9.9542e-06 - acc: 0.7603 - val_loss: 0.0056 - val_acc: 0.7140
Epoch 122/150
704/704 - 13s - loss: 4.5202e-06 - acc: 0.7869 - val_loss: 0.0057 - val_acc: 0.7116
Epoch 123/150
704/704 - 13s - loss: 4.2563e-06 - acc: 0.7926 - val_loss: 0.0057 - val_acc: 0.7110
Epoch 124/150
704/704 - 12s - loss: 4.7789e-06 - acc: 0.7976 - val_loss: 0.0057 - val_acc: 0.7208
Epoch 125/150
704/704 - 12s - loss: 5.6125e-06 - acc: 0.8030 - val_loss: 0.0057 - val_acc: 0.7194
Epoch 126/150
704/704 - 12s - loss: 2.2154e-04 - acc: 0.7753 - val_loss: 0.0057 - val_acc: 0.7254
Epoch 127/150
704/704 - 12s - loss: 9.5742e-05 - acc: 0.7731 - val_loss: 0.0055 - val_acc: 0.6790
Epoch 128/150
704/704 - 12s - loss: 1.9659e-05 - acc: 0.8022 - val_loss: 0.0054 - val_acc: 0.7410
Epoch 129/150
704/704 - 12s - loss: 6.7293e-05 - acc: 0.7831 - val_loss: 0.0055 - val_acc: 0.6842
Epoch 130/150
704/704 - 12s - loss: 6.2186e-05 - acc: 0.7623 - val_loss: 0.0058 - val_acc: 0.6874
Epoch 131/150
704/704 - 12s - loss: 8.4393e-05 - acc: 0.7577 - val_loss: 0.0054 - val_acc: 0.6852
Epoch 132/150
704/704 - 12s - loss: 2.2612e-05 - acc: 0.7761 - val_loss: 0.0054 - val_acc: 0.7260
Epoch 133/150
704/704 - 12s - loss: 4.4182e-06 - acc: 0.7937 - val_loss: 0.0055 - val_acc: 0.7254
Epoch 134/150
704/704 - 13s - loss: 3.9179e-06 - acc: 0.8027 - val_loss: 0.0054 - val_acc: 0.7340
Epoch 135/150
704/704 - 12s - loss: 3.9799e-06 - acc: 0.8127 - val_loss: 0.0055 - val_acc: 0.7382
Epoch 136/150
704/704 - 12s - loss: 4.5636e-06 - acc: 0.8181 - val_loss: 0.0054 - val_acc: 0.7524
Epoch 137/150
704/704 - 12s - loss: 2.3111e-04 - acc: 0.7717 - val_loss: 0.0060 - val_acc: 0.7118
Epoch 138/150
704/704 - 12s - loss: 4.7926e-05 - acc: 0.7936 - val_loss: 0.0055 - val_acc: 0.7210
Epoch 139/150
704/704 - 12s - loss: 1.9800e-05 - acc: 0.7711 - val_loss: 0.0057 - val_acc: 0.7086
Epoch 140/150
704/704 - 12s - loss: 7.6132e-05 - acc: 0.7681 - val_loss: 0.0057 - val_acc: 0.7144
Epoch 141/150
704/704 - 12s - loss: 1.1978e-04 - acc: 0.7644 - val_loss: 0.0053 - val_acc: 0.7072
Epoch 142/150
704/704 - 12s - loss: 5.8824e-05 - acc: 0.7792 - val_loss: 0.0055 - val_acc: 0.7366
Epoch 143/150
704/704 - 12s - loss: 3.3248e-05 - acc: 0.7954 - val_loss: 0.0052 - val_acc: 0.7354
Epoch 144/150
704/704 - 12s - loss: 4.3377e-06 - acc: 0.7943 - val_loss: 0.0051 - val_acc: 0.7296
Epoch 145/150
704/704 - 13s - loss: 3.6006e-06 - acc: 0.7986 - val_loss: 0.0052 - val_acc: 0.7100
Epoch 146/150
704/704 - 12s - loss: 3.6909e-06 - acc: 0.8025 - val_loss: 0.0052 - val_acc: 0.7404
Epoch 147/150
704/704 - 12s - loss: 3.7235e-06 - acc: 0.8072 - val_loss: 0.0053 - val_acc: 0.7384
Epoch 148/150
704/704 - 12s - loss: 4.5525e-06 - acc: 0.8097 - val_loss: 0.0052 - val_acc: 0.7350
Epoch 149/150
704/704 - 12s - loss: 6.1345e-06 - acc: 0.8125 - val_loss: 0.0055 - val_acc: 0.7258
Epoch 150/150
704/704 - 12s - loss: 1.9256e-04 - acc: 0.7495 - val_loss: 0.0056 - val_acc: 0.7104
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-11 12:33:11.717049: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-11 12:33:11.717236: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-11 12:33:11.717311: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-11 12:33:11.735675: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-11 12:33:11.735821: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Train for 704 steps, validate for 79 steps
Epoch 1/30
704/704 - 16s - loss: 0.1844 - acc: 0.9276 - val_loss: 0.6317 - val_acc: 0.8484
Epoch 2/30
704/704 - 12s - loss: 0.0857 - acc: 0.9666 - val_loss: 0.6764 - val_acc: 0.8492
Epoch 3/30
704/704 - 12s - loss: 0.0434 - acc: 0.9844 - val_loss: 0.7588 - val_acc: 0.8504
Epoch 4/30
704/704 - 12s - loss: 0.0211 - acc: 0.9918 - val_loss: 0.8608 - val_acc: 0.8478
Epoch 5/30
704/704 - 12s - loss: 0.0147 - acc: 0.9943 - val_loss: 0.8913 - val_acc: 0.8482
Epoch 6/30
704/704 - 12s - loss: 0.0103 - acc: 0.9956 - val_loss: 1.0108 - val_acc: 0.8450
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-11 12:34:29.909614: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-11 12:34:29.909820: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-11 12:34:29.909894: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-11 12:34:29.929567: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-11 12:34:29.929703: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00006: early stopping
Train for 704 steps, validate for 79 steps
Epoch 1/30
704/704 - 17s - loss: 0.1213 - acc: 0.9548 - val_loss: 0.6736 - val_acc: 0.8498
Epoch 2/30
704/704 - 15s - loss: 0.0451 - acc: 0.9836 - val_loss: 0.7563 - val_acc: 0.8538
Epoch 3/30
704/704 - 14s - loss: 0.0234 - acc: 0.9920 - val_loss: 0.8492 - val_acc: 0.8466
Epoch 4/30
704/704 - 14s - loss: 0.0147 - acc: 0.9948 - val_loss: 0.9133 - val_acc: 0.8506
Epoch 5/30
704/704 - 14s - loss: 0.0130 - acc: 0.9958 - val_loss: 0.9328 - val_acc: 0.8508
Epoch 6/30
704/704 - 14s - loss: 0.0071 - acc: 0.9974 - val_loss: 1.0084 - val_acc: 0.8476
Epoch 00006: early stopping
Accuracy on original test dataset: 62.9%
tf.Tensor(
[[895  17  49   0   0   0   0   6   5  28]
 [ 19 963   2   0   0   0   0   1   0  15]
 [ 95  13 815   1   0  29   6  16   3  22]
 [ 67  76 143  98   3 233  12 119   5 244]
 [ 96  35 265   1 105  67  15 231   2 183]
 [ 37  24 107   4   1 675   6  67   0  79]
 [ 28 121  91   2   0  34 592   7   4 121]
 [ 30   7  37   0   0  42   0 830   1  53]
 [231 143   6   0   0   2   0   1 561  56]
 [ 27 213   2   0   0   0   0   0   0 758]], shape=(10, 10), dtype=int32)
Correct: 6292, wrong: 3708, accuracy: 62.92%

Mean probability on true label of original test dataset when correctly predicted = 99.47%
Mean uncertainty on true label of original test dataset when correctly predicted = 74.34%
Mean probability on true label of original test dataset when wrongly predicted = 1.09%
Mean uncertainty on true label of original test dataset when wrongly predicted = 45.60%

Mean probability on highest predicted on original test dataset when wrong = 93.50%
Mean uncertainty on highest predicted on original test dataset when wrong = 47.53%

Mean probability on all not true label on original test dataset = 4.11%
Mean uncertainty on all not true label on original test dataset = 45.81%
creating scatterplot
0.6292


###############################################################################
Peregrine Cluster
Job 11368507 for user 's2934833'
Finished at: Mon May 11 12:40:33 CEST 2020

Job details:
============

Name                : CIFVAR
User                : s2934833
Partition           : gpu
Nodes               : pg-gpu39
Cores               : 12
State               : COMPLETED
Submit              : 2020-05-11T12:01:37
Start               : 2020-05-11T12:01:37
End                 : 2020-05-11T12:40:33
Reserved walltime   : 02:00:00
Used walltime       : 00:38:56
Used CPU time       : 00:37:40 (efficiency:  8.06%)
% User (Computation): 78.21%
% System (I/O)      : 21.79%
Mem reserved        : 32000M/node
Max Mem used        : 3.63G (pg-gpu39)
Max Disk Write      : 153.60K (pg-gpu39)
Max Disk Read       : 5.83M (pg-gpu39)
Average GPU usage   : 70.3% (pg-gpu39)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/additional_information/scientific_output

################################################################################
