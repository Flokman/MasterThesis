
The following have been reloaded with a version change:
  1) FFTW/3.3.8-gompic-2019b => FFTW/3.3.8-gompi-2019b
  2) OpenMPI/3.1.4-gcccuda-2019b => OpenMPI/3.1.4-GCC-8.3.0
  3) ScaLAPACK/2.0.2-gompic-2019b => ScaLAPACK/2.0.2-gompi-2019b
  4) SciPy-bundle/2019.10-fosscuda-2019b-Python-3.7.4 => SciPy-bundle/2019.10-foss-2019b-Python-3.7.4

2020-03-10 17:26:46.898492: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-10 17:26:55.502187: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-10 17:26:55.509354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-10 17:26:55.509863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.87GiB deviceMemoryBandwidth: 836.37GiB/s
2020-03-10 17:26:55.509921: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-10 17:26:55.513372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-10 17:26:55.516344: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-10 17:26:55.517192: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-10 17:26:55.520329: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-10 17:26:55.522019: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-10 17:26:55.527637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-10 17:26:55.527821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-10 17:26:55.528414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-10 17:26:55.528784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-10 17:26:55.531623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-10 17:26:55.532034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.87GiB deviceMemoryBandwidth: 836.37GiB/s
2020-03-10 17:26:55.532082: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-10 17:26:55.532116: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-10 17:26:55.532138: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-10 17:26:55.532157: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-10 17:26:55.532176: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-10 17:26:55.532196: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-10 17:26:55.532216: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-10 17:26:55.532317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-10 17:26:55.532804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-10 17:26:55.533170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-10 17:26:55.533223: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-10 17:26:56.288497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-10 17:26:56.288581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-10 17:26:56.288597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-10 17:26:56.288885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-10 17:26:56.289493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-10 17:26:56.290015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-10 17:26:56.290488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28652 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2020-03-10 17:26:56.290835: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-03-10 17:27:01.270476: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-10 17:27:01.634872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-10 17:27:06.359811: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-03-10 17:27:06.359926: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1259] Profiler found 1 GPUs
2020-03-10 17:27:06.362356: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1
2020-03-10 17:27:06.462906: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-03-10 17:27:06.463416: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-03-10 17:27:06.665739: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-03-10 17:27:06.665847: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Random seed for replication: 218
dataset_name = /Messidor2_PNG_AUG_256.hdf5, batch_size = 32, num_classes = 5, epochs_1 = 120,
        epochts_2 = 300, test_img_idx = 408,
        train_test_split = 0.8, to_shuffle = True, augmentation = False, label_count = [1261, 1416, 1397, 1455, 1463],
        label_normalizer = True, save_augmentation_to_hdf5 = True, learn rate = 1e-05,
        train_all_layers = True, weights_to_use = None,
        es_patience_1 = 30, es_patience_2 = 50, train_val_split = 0.9
x_train shape: (5593, 256, 256, 3)
5593 train samples
1399 test samples
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            
__________________________________________________________________________________________________
block1_conv1 (Conv2D)           (None, 256, 256, 64) 1792        input_1[0][0]                    
__________________________________________________________________________________________________
block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[1][0]               
__________________________________________________________________________________________________
block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[1][0]               
__________________________________________________________________________________________________
block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[1][0]                
__________________________________________________________________________________________________
block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[1][0]               
__________________________________________________________________________________________________
block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[1][0]               
__________________________________________________________________________________________________
block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[1][0]                
__________________________________________________________________________________________________
block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[1][0]               
__________________________________________________________________________________________________
block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[1][0]               
__________________________________________________________________________________________________
block3_pool (MaxPooling2D)      (None, 32, 32, 256)  0           block3_conv3[1][0]               
__________________________________________________________________________________________________
block4_conv1 (Conv2D)           (None, 32, 32, 512)  1180160     block3_pool[1][0]                
__________________________________________________________________________________________________
block4_conv2 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv1[1][0]               
__________________________________________________________________________________________________
block4_conv3 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv2[1][0]               
__________________________________________________________________________________________________
block4_pool (MaxPooling2D)      (None, 16, 16, 512)  0           block4_conv3[1][0]               
__________________________________________________________________________________________________
block5_conv1 (Conv2D)           (None, 16, 16, 512)  2359808     block4_pool[1][0]                
__________________________________________________________________________________________________
block5_conv2 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv1[1][0]               
__________________________________________________________________________________________________
block5_conv3 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv2[1][0]               
__________________________________________________________________________________________________
block5_pool (MaxPooling2D)      (None, 8, 8, 512)    0           block5_conv3[1][0]               
__________________________________________________________________________________________________
flatten (Flatten)               (None, 32768)        0           block5_pool[1][0]                
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         134221824   flatten[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
dense (Dense)                   (None, 5)            20485       fc2[0][0]                        
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 5)            20485       fc2[0][0]                        
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 10)           0           dense[0][0]                      
                                                                 dense_1[0][0]                    
==================================================================================================
Total params: 165,758,794
Trainable params: 165,758,794
Non-trainable params: 0
__________________________________________________________________________________________________
Start fitting
Train for 158 steps, validate for 18 steps
Epoch 1/120
158/158 - 41s - loss: 1.5841 - acc: 0.2325 - val_loss: 1.4782 - val_acc: 0.3161
Epoch 2/120
158/158 - 33s - loss: 1.4445 - acc: 0.3447 - val_loss: 1.3985 - val_acc: 0.3804
Epoch 3/120
158/158 - 33s - loss: 1.3871 - acc: 0.3876 - val_loss: 1.3794 - val_acc: 0.3857
Epoch 4/120
158/158 - 33s - loss: 1.3331 - acc: 0.4202 - val_loss: 1.3795 - val_acc: 0.4036
Epoch 5/120
158/158 - 33s - loss: 1.2966 - acc: 0.4407 - val_loss: 1.3530 - val_acc: 0.4143
Epoch 6/120
158/158 - 33s - loss: 1.2550 - acc: 0.4627 - val_loss: 1.2948 - val_acc: 0.4411
Epoch 7/120
158/158 - 33s - loss: 1.2128 - acc: 0.4812 - val_loss: 1.2644 - val_acc: 0.4643
Epoch 8/120
158/158 - 33s - loss: 1.1565 - acc: 0.5164 - val_loss: 1.2115 - val_acc: 0.4964
Epoch 9/120
158/158 - 33s - loss: 1.1038 - acc: 0.5349 - val_loss: 1.2489 - val_acc: 0.4429
Epoch 10/120
158/158 - 33s - loss: 1.0378 - acc: 0.5728 - val_loss: 1.1252 - val_acc: 0.5107
Epoch 11/120
158/158 - 33s - loss: 0.9686 - acc: 0.5806 - val_loss: 1.0836 - val_acc: 0.5232
Epoch 12/120
158/158 - 33s - loss: 0.8760 - acc: 0.5837 - val_loss: 1.0907 - val_acc: 0.4929
Epoch 13/120
158/158 - 33s - loss: 0.7749 - acc: 0.5583 - val_loss: 1.0264 - val_acc: 0.4893
Epoch 14/120
158/158 - 33s - loss: 0.7005 - acc: 0.5450 - val_loss: 0.9803 - val_acc: 0.4393
Epoch 15/120
158/158 - 33s - loss: 0.5944 - acc: 0.5198 - val_loss: 0.9437 - val_acc: 0.4321
Epoch 16/120
158/158 - 33s - loss: 0.5034 - acc: 0.4550 - val_loss: 0.9041 - val_acc: 0.3643
Epoch 17/120
158/158 - 33s - loss: 0.4022 - acc: 0.3535 - val_loss: 1.0906 - val_acc: 0.2750
Epoch 18/120
158/158 - 33s - loss: 0.3507 - acc: 0.2760 - val_loss: 1.0665 - val_acc: 0.2839
Epoch 19/120
158/158 - 33s - loss: 0.2955 - acc: 0.2647 - val_loss: 1.1053 - val_acc: 0.1661
Epoch 20/120
158/158 - 33s - loss: 0.2483 - acc: 0.2664 - val_loss: 1.3471 - val_acc: 0.1321
Epoch 21/120
158/158 - 33s - loss: 0.1867 - acc: 0.1989 - val_loss: 1.2191 - val_acc: 0.0911
Epoch 22/120
158/158 - 33s - loss: 0.2168 - acc: 0.1599 - val_loss: 1.1368 - val_acc: 0.1357
Epoch 23/120
158/158 - 33s - loss: 0.1619 - acc: 0.1860 - val_loss: 1.2636 - val_acc: 0.1089
Epoch 24/120
158/158 - 33s - loss: 0.1114 - acc: 0.1427 - val_loss: 1.4234 - val_acc: 0.0911
Epoch 25/120
158/158 - 33s - loss: 0.0877 - acc: 0.1162 - val_loss: 1.2754 - val_acc: 0.0750
Epoch 26/120
158/158 - 33s - loss: 0.0686 - acc: 0.0954 - val_loss: 1.5364 - val_acc: 0.0643
Epoch 27/120
158/158 - 33s - loss: 0.0969 - acc: 0.1484 - val_loss: 1.3213 - val_acc: 0.0750
Epoch 28/120
158/158 - 33s - loss: 0.1025 - acc: 0.1224 - val_loss: 1.2818 - val_acc: 0.0589
Epoch 29/120
158/158 - 33s - loss: 0.0874 - acc: 0.0942 - val_loss: 1.4585 - val_acc: 0.0821
Epoch 30/120
158/158 - 33s - loss: 0.0754 - acc: 0.1256 - val_loss: 1.4891 - val_acc: 0.0768
Epoch 31/120
158/158 - 33s - loss: 0.1027 - acc: 0.1442 - val_loss: 1.6019 - val_acc: 0.0768
Epoch 32/120
158/158 - 33s - loss: 0.0692 - acc: 0.1828 - val_loss: 1.3736 - val_acc: 0.0875
Epoch 33/120
158/158 - 33s - loss: 0.0596 - acc: 0.1272 - val_loss: 1.3960 - val_acc: 0.0679
Epoch 34/120
158/158 - 33s - loss: 0.0529 - acc: 0.1190 - val_loss: 1.3798 - val_acc: 0.0643
Epoch 35/120
158/158 - 33s - loss: 0.0438 - acc: 0.1001 - val_loss: 1.2932 - val_acc: 0.0429
Epoch 36/120
158/158 - 33s - loss: 0.0481 - acc: 0.0745 - val_loss: 1.2802 - val_acc: 0.0464
Epoch 37/120
158/158 - 33s - loss: 0.1133 - acc: 0.1309 - val_loss: 1.3533 - val_acc: 0.0768
Epoch 38/120
158/158 - 33s - loss: 0.0790 - acc: 0.1657 - val_loss: 1.4236 - val_acc: 0.0911
Epoch 39/120
158/158 - 33s - loss: 0.0398 - acc: 0.1333 - val_loss: 1.3714 - val_acc: 0.0911
Epoch 40/120
158/158 - 33s - loss: 0.0456 - acc: 0.1641 - val_loss: 1.2755 - val_acc: 0.1464
Epoch 41/120
158/158 - 33s - loss: 0.0384 - acc: 0.1872 - val_loss: 1.2735 - val_acc: 0.1107
Epoch 42/120
158/158 - 33s - loss: 0.0344 - acc: 0.1588 - val_loss: 1.2581 - val_acc: 0.1214
Epoch 43/120
158/158 - 33s - loss: 0.0278 - acc: 0.1568 - val_loss: 1.2591 - val_acc: 0.0893
Epoch 44/120
158/158 - 33s - loss: 0.0314 - acc: 0.1901 - val_loss: 1.3103 - val_acc: 0.1429
Epoch 45/120
158/158 - 33s - loss: 0.0331 - acc: 0.2118 - val_loss: 1.2205 - val_acc: 0.1446
Epoch 46/120
158/158 - 33s - loss: 0.0316 - acc: 0.2110 - val_loss: 1.2977 - val_acc: 0.1643
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-03-10 17:52:14.162542: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-03-10 17:52:14.162693: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-03-10 17:52:14.162725: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-03-10 17:52:14.364432: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-03-10 17:52:14.364538: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00046: early stopping
Train for 158 steps, validate for 18 steps
Epoch 1/300
158/158 - 34s - loss: 0.3743 - acc: 0.8951 - val_loss: 0.9155 - val_acc: 0.7321
Epoch 2/300
158/158 - 33s - loss: 0.1749 - acc: 0.9770 - val_loss: 0.8474 - val_acc: 0.7500
Epoch 3/300
158/158 - 33s - loss: 0.1566 - acc: 0.9827 - val_loss: 0.9510 - val_acc: 0.7411
Epoch 4/300
158/158 - 33s - loss: 0.0870 - acc: 0.9881 - val_loss: 0.9179 - val_acc: 0.7018
Epoch 5/300
158/158 - 33s - loss: 0.0714 - acc: 0.9899 - val_loss: 0.9820 - val_acc: 0.7518
Epoch 6/300
158/158 - 33s - loss: 0.0613 - acc: 0.9883 - val_loss: 0.9575 - val_acc: 0.7607
Epoch 7/300
158/158 - 33s - loss: 0.0539 - acc: 0.9891 - val_loss: 0.9024 - val_acc: 0.7679
Epoch 8/300
158/158 - 33s - loss: 0.0483 - acc: 0.9891 - val_loss: 1.0038 - val_acc: 0.7661
Epoch 9/300
158/158 - 33s - loss: 0.0441 - acc: 0.9907 - val_loss: 0.9814 - val_acc: 0.7554
Epoch 10/300
158/158 - 33s - loss: 0.0428 - acc: 0.9899 - val_loss: 0.9542 - val_acc: 0.7482
Epoch 11/300
158/158 - 33s - loss: 0.0429 - acc: 0.9909 - val_loss: 0.8544 - val_acc: 0.7696
Epoch 12/300
158/158 - 33s - loss: 0.0427 - acc: 0.9911 - val_loss: 0.9632 - val_acc: 0.7607
Epoch 13/300
158/158 - 33s - loss: 0.0401 - acc: 0.9905 - val_loss: 0.9315 - val_acc: 0.7714
Epoch 14/300
158/158 - 33s - loss: 0.0391 - acc: 0.9903 - val_loss: 0.9771 - val_acc: 0.7607
Epoch 15/300
158/158 - 33s - loss: 0.0374 - acc: 0.9905 - val_loss: 0.9430 - val_acc: 0.7518
Epoch 16/300
158/158 - 33s - loss: 0.0383 - acc: 0.9921 - val_loss: 0.9771 - val_acc: 0.7500
Epoch 17/300
158/158 - 33s - loss: 0.0402 - acc: 0.9895 - val_loss: 1.0158 - val_acc: 0.7643
Epoch 18/300
158/158 - 33s - loss: 0.0391 - acc: 0.9907 - val_loss: 1.0206 - val_acc: 0.7357
Epoch 19/300
158/158 - 33s - loss: 0.0400 - acc: 0.9911 - val_loss: 0.9731 - val_acc: 0.7661
Epoch 20/300
158/158 - 33s - loss: 0.0372 - acc: 0.9911 - val_loss: 0.9041 - val_acc: 0.7679
Epoch 21/300
158/158 - 33s - loss: 0.0345 - acc: 0.9901 - val_loss: 0.9587 - val_acc: 0.7714
Epoch 22/300
158/158 - 33s - loss: 0.0331 - acc: 0.9911 - val_loss: 0.9909 - val_acc: 0.7804
Epoch 23/300
158/158 - 33s - loss: 0.0346 - acc: 0.9903 - val_loss: 0.9952 - val_acc: 0.7607
Epoch 24/300
158/158 - 33s - loss: 0.0332 - acc: 0.9915 - val_loss: 1.0341 - val_acc: 0.7643
Epoch 25/300
158/158 - 33s - loss: 0.0326 - acc: 0.9903 - val_loss: 0.9188 - val_acc: 0.7750
Epoch 26/300
158/158 - 33s - loss: 0.0322 - acc: 0.9907 - val_loss: 1.0027 - val_acc: 0.7500
Epoch 27/300
158/158 - 33s - loss: 0.0343 - acc: 0.9891 - val_loss: 0.9933 - val_acc: 0.7714
Epoch 28/300
158/158 - 33s - loss: 0.0306 - acc: 0.9921 - val_loss: 0.9953 - val_acc: 0.7589
Epoch 29/300
158/158 - 33s - loss: 0.0299 - acc: 0.9915 - val_loss: 0.9534 - val_acc: 0.7679
Epoch 30/300
158/158 - 33s - loss: 0.0287 - acc: 0.9905 - val_loss: 1.0041 - val_acc: 0.7357
Epoch 31/300
158/158 - 33s - loss: 0.0305 - acc: 0.9907 - val_loss: 0.9429 - val_acc: 0.7679
Epoch 32/300
158/158 - 33s - loss: 0.0286 - acc: 0.9911 - val_loss: 0.9908 - val_acc: 0.7768
Epoch 33/300
158/158 - 33s - loss: 0.0274 - acc: 0.9909 - val_loss: 0.9878 - val_acc: 0.7643
Epoch 34/300
158/158 - 33s - loss: 0.0492 - acc: 0.9867 - val_loss: 1.1327 - val_acc: 0.7571
Epoch 35/300
158/158 - 33s - loss: 0.0809 - acc: 0.9797 - val_loss: 1.1186 - val_acc: 0.7589
Epoch 36/300
158/158 - 33s - loss: 0.0357 - acc: 0.9911 - val_loss: 0.9669 - val_acc: 0.7714
Epoch 37/300
158/158 - 33s - loss: 0.0265 - acc: 0.9911 - val_loss: 0.9844 - val_acc: 0.7679
Epoch 38/300
158/158 - 33s - loss: 0.0229 - acc: 0.9905 - val_loss: 0.9703 - val_acc: 0.7750
Epoch 39/300
158/158 - 33s - loss: 0.0214 - acc: 0.9911 - val_loss: 0.9964 - val_acc: 0.7679
Epoch 40/300
158/158 - 33s - loss: 0.0200 - acc: 0.9911 - val_loss: 1.0034 - val_acc: 0.7696
Epoch 41/300
158/158 - 33s - loss: 0.0196 - acc: 0.9915 - val_loss: 1.0032 - val_acc: 0.7589
Epoch 42/300
158/158 - 33s - loss: 0.0226 - acc: 0.9895 - val_loss: 0.9747 - val_acc: 0.7696
Epoch 43/300
158/158 - 33s - loss: 0.0198 - acc: 0.9921 - val_loss: 0.9792 - val_acc: 0.7643
Epoch 44/300
158/158 - 33s - loss: 0.0200 - acc: 0.9915 - val_loss: 0.9675 - val_acc: 0.7714
Epoch 45/300
158/158 - 33s - loss: 0.0206 - acc: 0.9907 - val_loss: 0.9693 - val_acc: 0.7804
Epoch 46/300
158/158 - 33s - loss: 0.0222 - acc: 0.9921 - val_loss: 0.9485 - val_acc: 0.7804
Epoch 47/300
158/158 - 33s - loss: 0.0207 - acc: 0.9915 - val_loss: 0.9149 - val_acc: 0.7857
Epoch 48/300
158/158 - 33s - loss: 0.0216 - acc: 0.9909 - val_loss: 0.9646 - val_acc: 0.7786
Epoch 49/300
158/158 - 33s - loss: 0.0193 - acc: 0.9915 - val_loss: 0.9307 - val_acc: 0.7714
Epoch 50/300
158/158 - 33s - loss: 0.0197 - acc: 0.9909 - val_loss: 0.9997 - val_acc: 0.7679
Epoch 51/300
158/158 - 33s - loss: 0.0199 - acc: 0.9917 - val_loss: 1.0571 - val_acc: 0.7625
Epoch 52/300
158/158 - 33s - loss: 0.0217 - acc: 0.9913 - val_loss: 0.9400 - val_acc: 0.7786
Epoch 00052: early stopping
Correct: 1051, wrong: 348, accuracy: 75.12508934953537%
Varcorrect: 258, varwrong: 1141, accuracy: 18.441744102930667%
Supercorrect: 173, superwrong: 302, accuracy: 12.365975696926377%
match: 219, notmatch: 1180, accuracy: 15.654038598999284%


###############################################################################
Peregrine Cluster
Job 10031599 for user 's2934833'
Finished at: Tue Mar 10 18:20:45 CET 2020

Job details:
============

Name                : varianceoutput
User                : s2934833
Partition           : gpu
Nodes               : pg-gpu20
Cores               : 12
State               : COMPLETED
Submit              : 2020-03-10T17:00:06
Start               : 2020-03-10T17:26:42
End                 : 2020-03-10T18:20:45
Reserved walltime   : 02:00:00
Used walltime       : 00:54:03
Used CPU time       : 00:45:41 (efficiency:  7.05%)
% User (Computation): 70.92%
% System (I/O)      : 29.08%
Mem reserved        : 32000M/node
Max Mem used        : 9.17G (pg-gpu20)
Max Disk Write      : 153.60K (pg-gpu20)
Max Disk Read       : 5.35M (pg-gpu20)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/additional_information/scientific_output

################################################################################
