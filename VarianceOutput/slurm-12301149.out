
The following have been reloaded with a version change:
  1) FFTW/3.3.8-gompic-2019b => FFTW/3.3.8-gompi-2019b
  2) OpenMPI/3.1.4-gcccuda-2019b => OpenMPI/3.1.4-GCC-8.3.0
  3) ScaLAPACK/2.0.2-gompic-2019b => ScaLAPACK/2.0.2-gompi-2019b
  4) SciPy-bundle/2019.10-fosscuda-2019b-Python-3.7.4 => SciPy-bundle/2019.10-foss-2019b-Python-3.7.4

2020-06-23 14:24:51.525424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-23 14:25:02.304683: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-06-23 14:25:02.312351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-23 14:25:02.312981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-06-23 14:25:02.313045: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-23 14:25:02.318273: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-23 14:25:02.322324: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-23 14:25:02.323890: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-23 14:25:02.327402: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-23 14:25:02.329354: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-23 14:25:02.335036: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-23 14:25:02.335317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-23 14:25:02.336104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-23 14:25:02.336596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-06-23 14:25:02.340322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-23 14:25:02.340898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-06-23 14:25:02.340958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-23 14:25:02.341014: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-23 14:25:02.341036: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-23 14:25:02.341056: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-23 14:25:02.341075: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-23 14:25:02.341095: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-23 14:25:02.341115: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-23 14:25:02.341248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-23 14:25:02.341771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-23 14:25:02.342200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-06-23 14:25:02.342253: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-23 14:25:03.073332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-23 14:25:03.073468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-06-23 14:25:03.073485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-06-23 14:25:03.073894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-23 14:25:03.074607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-23 14:25:03.075133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-23 14:25:03.075602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28652 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2020-06-23 14:25:03.075989: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-06-23 14:25:06.244171: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-23 14:25:06.504029: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-23 14:25:08.643839: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-06-23 14:25:08.643981: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1259] Profiler found 1 GPUs
2020-06-23 14:25:08.646601: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1
2020-06-23 14:25:08.747284: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-06-23 14:25:08.747979: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-06-23 14:25:08.776768: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-06-23 14:25:08.776893: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
dataset_name = /CIFAR10, batch_size = 128, num_classes = 10, epochs_1 = 150,
        epochts_2 = 30, test_img_idx = 1862,
        train_test_split = 0.8
        learn rate = 1e-05,
        train_all_layers = True, weights_to_use = imagenet,
        es_patience_1 = 10, es_patience_2 = 10, train_val_split = 0.875
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 test samples
Total labels in train set:  [5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]
Labels in validation set:  [139, 115, 122, 105, 118, 122, 127, 129, 131, 142]
Labels in test set:  [861, 885, 878, 895, 882, 878, 873, 871, 869, 858]
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
block1_conv1 (Conv2D)           (None, 32, 32, 64)   1792        input_1[0][0]                    
__________________________________________________________________________________________________
block1_conv2 (Conv2D)           (None, 32, 32, 64)   36928       block1_conv1[1][0]               
__________________________________________________________________________________________________
block1_pool (MaxPooling2D)      (None, 16, 16, 64)   0           block1_conv2[1][0]               
__________________________________________________________________________________________________
block2_conv1 (Conv2D)           (None, 16, 16, 128)  73856       block1_pool[1][0]                
__________________________________________________________________________________________________
block2_conv2 (Conv2D)           (None, 16, 16, 128)  147584      block2_conv1[1][0]               
__________________________________________________________________________________________________
block2_pool (MaxPooling2D)      (None, 8, 8, 128)    0           block2_conv2[1][0]               
__________________________________________________________________________________________________
block3_conv1 (Conv2D)           (None, 8, 8, 256)    295168      block2_pool[1][0]                
__________________________________________________________________________________________________
block3_conv2 (Conv2D)           (None, 8, 8, 256)    590080      block3_conv1[1][0]               
__________________________________________________________________________________________________
block3_conv3 (Conv2D)           (None, 8, 8, 256)    590080      block3_conv2[1][0]               
__________________________________________________________________________________________________
block3_pool (MaxPooling2D)      (None, 4, 4, 256)    0           block3_conv3[1][0]               
__________________________________________________________________________________________________
block4_conv1 (Conv2D)           (None, 4, 4, 512)    1180160     block3_pool[1][0]                
__________________________________________________________________________________________________
block4_conv2 (Conv2D)           (None, 4, 4, 512)    2359808     block4_conv1[1][0]               
__________________________________________________________________________________________________
block4_conv3 (Conv2D)           (None, 4, 4, 512)    2359808     block4_conv2[1][0]               
__________________________________________________________________________________________________
block4_pool (MaxPooling2D)      (None, 2, 2, 512)    0           block4_conv3[1][0]               
__________________________________________________________________________________________________
block5_conv1 (Conv2D)           (None, 2, 2, 512)    2359808     block4_pool[1][0]                
__________________________________________________________________________________________________
block5_conv2 (Conv2D)           (None, 2, 2, 512)    2359808     block5_conv1[1][0]               
__________________________________________________________________________________________________
block5_conv3 (Conv2D)           (None, 2, 2, 512)    2359808     block5_conv2[1][0]               
__________________________________________________________________________________________________
block5_pool (MaxPooling2D)      (None, 1, 1, 512)    0           block5_conv3[1][0]               
__________________________________________________________________________________________________
flatten (Flatten)               (None, 512)          0           block5_pool[1][0]                
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         2101248     flatten[0][0]                    
__________________________________________________________________________________________________
fc2_1 (Dense)                   (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
fc2_2 (Dense)                   (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
dense (Dense)                   (None, 10)           40970       fc2_1[0][0]                      
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           40970       fc2_2[0][0]                      
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 20)           0           dense[0][0]                      
                                                                 dense_1[0][0]                    
==================================================================================================
Total params: 50,460,500
Trainable params: 50,460,500
Non-trainable params: 0
__________________________________________________________________________________________________
Start fitting
Train for 391 steps, validate for 10 steps
Epoch 1/150
391/391 - 16s - loss: 0.0222 - acc: 0.4495 - val_loss: 0.0116 - val_acc: 0.6688
Epoch 2/150
391/391 - 13s - loss: 0.0097 - acc: 0.6962 - val_loss: 0.0086 - val_acc: 0.6880
Epoch 3/150
391/391 - 11s - loss: 0.0075 - acc: 0.7280 - val_loss: 0.0073 - val_acc: 0.7264
Epoch 4/150
391/391 - 11s - loss: 0.0061 - acc: 0.7434 - val_loss: 0.0068 - val_acc: 0.7096
Epoch 5/150
391/391 - 11s - loss: 0.0051 - acc: 0.7494 - val_loss: 0.0063 - val_acc: 0.7288
Epoch 6/150
391/391 - 11s - loss: 0.0043 - acc: 0.7661 - val_loss: 0.0064 - val_acc: 0.7472
Epoch 7/150
391/391 - 11s - loss: 0.0036 - acc: 0.7819 - val_loss: 0.0052 - val_acc: 0.7448
Epoch 8/150
391/391 - 11s - loss: 0.0029 - acc: 0.7880 - val_loss: 0.0055 - val_acc: 0.7336
Epoch 9/150
391/391 - 11s - loss: 0.0024 - acc: 0.7999 - val_loss: 0.0048 - val_acc: 0.7328
Epoch 10/150
391/391 - 11s - loss: 0.0020 - acc: 0.8084 - val_loss: 0.0050 - val_acc: 0.7376
Epoch 11/150
391/391 - 11s - loss: 0.0016 - acc: 0.8197 - val_loss: 0.0046 - val_acc: 0.7248
Epoch 12/150
391/391 - 11s - loss: 0.0013 - acc: 0.8301 - val_loss: 0.0048 - val_acc: 0.7424
Epoch 13/150
391/391 - 12s - loss: 0.0011 - acc: 0.8377 - val_loss: 0.0046 - val_acc: 0.7328
Epoch 14/150
391/391 - 11s - loss: 8.4727e-04 - acc: 0.8491 - val_loss: 0.0047 - val_acc: 0.7440
Epoch 15/150
391/391 - 11s - loss: 7.1828e-04 - acc: 0.8553 - val_loss: 0.0049 - val_acc: 0.7632
Epoch 16/150
391/391 - 11s - loss: 5.8826e-04 - acc: 0.8594 - val_loss: 0.0046 - val_acc: 0.7432
Epoch 17/150
391/391 - 14s - loss: 5.1617e-04 - acc: 0.8628 - val_loss: 0.0048 - val_acc: 0.7328
Epoch 18/150
391/391 - 11s - loss: 4.8461e-04 - acc: 0.8585 - val_loss: 0.0052 - val_acc: 0.7328
Epoch 19/150
391/391 - 10s - loss: 5.7567e-04 - acc: 0.8462 - val_loss: 0.0046 - val_acc: 0.7496
Epoch 20/150
391/391 - 11s - loss: 3.4221e-04 - acc: 0.8759 - val_loss: 0.0050 - val_acc: 0.7320
Epoch 21/150
391/391 - 11s - loss: 3.2687e-04 - acc: 0.8691 - val_loss: 0.0047 - val_acc: 0.7640
Epoch 22/150
391/391 - 11s - loss: 2.8820e-04 - acc: 0.8735 - val_loss: 0.0048 - val_acc: 0.7512
Epoch 23/150
391/391 - 10s - loss: 5.1514e-04 - acc: 0.8471 - val_loss: 0.0050 - val_acc: 0.7320
Epoch 24/150
391/391 - 10s - loss: 3.1241e-04 - acc: 0.8647 - val_loss: 0.0043 - val_acc: 0.7616
Epoch 25/150
391/391 - 11s - loss: 2.1849e-04 - acc: 0.8754 - val_loss: 0.0044 - val_acc: 0.7768
Epoch 26/150
391/391 - 11s - loss: 1.7036e-04 - acc: 0.8825 - val_loss: 0.0045 - val_acc: 0.7560
Epoch 27/150
391/391 - 11s - loss: 1.5531e-04 - acc: 0.8802 - val_loss: 0.0046 - val_acc: 0.7600
Epoch 28/150
391/391 - 11s - loss: 1.4176e-04 - acc: 0.8814 - val_loss: 0.0046 - val_acc: 0.7536
Epoch 29/150
391/391 - 11s - loss: 1.4097e-04 - acc: 0.8752 - val_loss: 0.0050 - val_acc: 0.7440
Epoch 30/150
391/391 - 10s - loss: 7.1809e-04 - acc: 0.8286 - val_loss: 0.0044 - val_acc: 0.7696
Epoch 31/150
391/391 - 10s - loss: 1.5899e-04 - acc: 0.8707 - val_loss: 0.0046 - val_acc: 0.7840
Epoch 32/150
391/391 - 12s - loss: 1.0829e-04 - acc: 0.8821 - val_loss: 0.0047 - val_acc: 0.7616
Epoch 33/150
391/391 - 11s - loss: 9.5109e-05 - acc: 0.8807 - val_loss: 0.0045 - val_acc: 0.7760
Epoch 34/150
391/391 - 11s - loss: 8.6220e-05 - acc: 0.8807 - val_loss: 0.0046 - val_acc: 0.7776
Epoch 35/150
391/391 - 11s - loss: 8.3062e-05 - acc: 0.8786 - val_loss: 0.0049 - val_acc: 0.7544
Epoch 36/150
391/391 - 10s - loss: 4.8848e-04 - acc: 0.8388 - val_loss: 0.0045 - val_acc: 0.7472
Epoch 37/150
391/391 - 10s - loss: 2.0838e-04 - acc: 0.8501 - val_loss: 0.0043 - val_acc: 0.7640
Epoch 38/150
391/391 - 11s - loss: 7.4279e-05 - acc: 0.8753 - val_loss: 0.0043 - val_acc: 0.7560
Epoch 39/150
391/391 - 11s - loss: 5.8110e-05 - acc: 0.8768 - val_loss: 0.0044 - val_acc: 0.7744
Epoch 40/150
391/391 - 11s - loss: 5.2415e-05 - acc: 0.8758 - val_loss: 0.0045 - val_acc: 0.7728
Epoch 41/150
391/391 - 11s - loss: 4.8791e-05 - acc: 0.8719 - val_loss: 0.0044 - val_acc: 0.7616
Epoch 42/150
391/391 - 14s - loss: 4.5514e-05 - acc: 0.8713 - val_loss: 0.0046 - val_acc: 0.7600
Epoch 43/150
391/391 - 11s - loss: 4.3433e-05 - acc: 0.8705 - val_loss: 0.0044 - val_acc: 0.7488
Epoch 44/150
391/391 - 10s - loss: 2.6778e-04 - acc: 0.8493 - val_loss: 0.0055 - val_acc: 0.6968
Epoch 45/150
391/391 - 10s - loss: 3.7327e-04 - acc: 0.8333 - val_loss: 0.0043 - val_acc: 0.7664
Epoch 46/150
391/391 - 10s - loss: 5.1015e-05 - acc: 0.8730 - val_loss: 0.0041 - val_acc: 0.7720
Epoch 47/150
391/391 - 11s - loss: 3.2960e-05 - acc: 0.8757 - val_loss: 0.0045 - val_acc: 0.7472
Epoch 48/150
391/391 - 11s - loss: 2.8228e-05 - acc: 0.8745 - val_loss: 0.0041 - val_acc: 0.7880
Epoch 49/150
391/391 - 11s - loss: 2.4171e-05 - acc: 0.8748 - val_loss: 0.0042 - val_acc: 0.7640
Epoch 50/150
391/391 - 12s - loss: 2.2545e-05 - acc: 0.8729 - val_loss: 0.0043 - val_acc: 0.7648
Epoch 51/150
391/391 - 11s - loss: 2.1425e-05 - acc: 0.8708 - val_loss: 0.0043 - val_acc: 0.7752
Epoch 52/150
391/391 - 12s - loss: 1.9414e-05 - acc: 0.8735 - val_loss: 0.0043 - val_acc: 0.7624
Epoch 53/150
391/391 - 11s - loss: 1.8719e-05 - acc: 0.8742 - val_loss: 0.0045 - val_acc: 0.7632
Epoch 54/150
391/391 - 10s - loss: 7.9894e-05 - acc: 0.8696 - val_loss: 0.0093 - val_acc: 0.6624
Epoch 55/150
391/391 - 10s - loss: 5.3520e-04 - acc: 0.8199 - val_loss: 0.0048 - val_acc: 0.7600
Epoch 56/150
391/391 - 10s - loss: 5.4847e-05 - acc: 0.8678 - val_loss: 0.0042 - val_acc: 0.7632
Epoch 57/150
391/391 - 10s - loss: 2.0725e-05 - acc: 0.8712 - val_loss: 0.0042 - val_acc: 0.7624
Epoch 58/150
391/391 - 11s - loss: 1.5437e-05 - acc: 0.8681 - val_loss: 0.0043 - val_acc: 0.7776
Epoch 59/150
391/391 - 11s - loss: 1.3450e-05 - acc: 0.8710 - val_loss: 0.0043 - val_acc: 0.7592
Epoch 60/150
391/391 - 11s - loss: 1.2516e-05 - acc: 0.8702 - val_loss: 0.0043 - val_acc: 0.7704
Epoch 61/150
391/391 - 13s - loss: 1.1855e-05 - acc: 0.8742 - val_loss: 0.0044 - val_acc: 0.7608
Epoch 62/150
391/391 - 13s - loss: 1.1363e-05 - acc: 0.8691 - val_loss: 0.0044 - val_acc: 0.7672
Epoch 63/150
391/391 - 11s - loss: 1.1201e-05 - acc: 0.8709 - val_loss: 0.0044 - val_acc: 0.7640
Epoch 64/150
391/391 - 11s - loss: 1.1130e-05 - acc: 0.8735 - val_loss: 0.0044 - val_acc: 0.7728
Epoch 65/150
391/391 - 10s - loss: 1.1935e-05 - acc: 0.8731 - val_loss: 0.0045 - val_acc: 0.7640
Epoch 66/150
391/391 - 10s - loss: 6.3195e-04 - acc: 0.8446 - val_loss: 0.0044 - val_acc: 0.7632
Epoch 67/150
391/391 - 10s - loss: 1.0968e-04 - acc: 0.8548 - val_loss: 0.0040 - val_acc: 0.7840
Epoch 68/150
391/391 - 10s - loss: 2.0352e-05 - acc: 0.8749 - val_loss: 0.0039 - val_acc: 0.7880
Epoch 69/150
391/391 - 10s - loss: 1.2646e-05 - acc: 0.8726 - val_loss: 0.0040 - val_acc: 0.7824
Epoch 70/150
391/391 - 11s - loss: 1.0314e-05 - acc: 0.8745 - val_loss: 0.0040 - val_acc: 0.7832
Epoch 71/150
391/391 - 11s - loss: 9.1446e-06 - acc: 0.8727 - val_loss: 0.0041 - val_acc: 0.7776
Epoch 72/150
391/391 - 11s - loss: 8.6730e-06 - acc: 0.8727 - val_loss: 0.0041 - val_acc: 0.7672
Epoch 73/150
391/391 - 11s - loss: 8.0320e-06 - acc: 0.8721 - val_loss: 0.0041 - val_acc: 0.7808
Epoch 74/150
391/391 - 11s - loss: 7.9392e-06 - acc: 0.8714 - val_loss: 0.0042 - val_acc: 0.7752
Epoch 75/150
391/391 - 10s - loss: 7.9836e-06 - acc: 0.8705 - val_loss: 0.0041 - val_acc: 0.7848
Epoch 76/150
391/391 - 10s - loss: 8.9313e-06 - acc: 0.8703 - val_loss: 0.0042 - val_acc: 0.7736
Epoch 77/150
391/391 - 10s - loss: 9.6410e-06 - acc: 0.8741 - val_loss: 0.0043 - val_acc: 0.7768
Epoch 78/150
391/391 - 10s - loss: 4.5132e-04 - acc: 0.8323 - val_loss: 0.0040 - val_acc: 0.7640
Epoch 79/150
391/391 - 10s - loss: 8.5511e-05 - acc: 0.8515 - val_loss: 0.0041 - val_acc: 0.7656
Epoch 80/150
391/391 - 10s - loss: 3.1686e-05 - acc: 0.8646 - val_loss: 0.0039 - val_acc: 0.7664
Epoch 81/150
391/391 - 10s - loss: 1.0421e-05 - acc: 0.8791 - val_loss: 0.0039 - val_acc: 0.7888
Epoch 82/150
391/391 - 10s - loss: 8.3645e-06 - acc: 0.8764 - val_loss: 0.0039 - val_acc: 0.7920
Epoch 83/150
391/391 - 11s - loss: 7.3978e-06 - acc: 0.8754 - val_loss: 0.0040 - val_acc: 0.7896
Epoch 84/150
391/391 - 11s - loss: 7.1297e-06 - acc: 0.8719 - val_loss: 0.0040 - val_acc: 0.7896
Epoch 85/150
391/391 - 13s - loss: 6.8708e-06 - acc: 0.8723 - val_loss: 0.0040 - val_acc: 0.7712
Epoch 86/150
391/391 - 10s - loss: 6.8764e-06 - acc: 0.8756 - val_loss: 0.0041 - val_acc: 0.7896
Epoch 87/150
391/391 - 10s - loss: 7.3891e-06 - acc: 0.8728 - val_loss: 0.0041 - val_acc: 0.7856
Epoch 88/150
391/391 - 10s - loss: 4.5942e-04 - acc: 0.8144 - val_loss: 0.0041 - val_acc: 0.7280
Epoch 89/150
391/391 - 10s - loss: 9.7817e-05 - acc: 0.8427 - val_loss: 0.0041 - val_acc: 0.7784
Epoch 90/150
391/391 - 10s - loss: 1.6290e-05 - acc: 0.8700 - val_loss: 0.0039 - val_acc: 0.7872
Epoch 91/150
391/391 - 10s - loss: 9.4753e-06 - acc: 0.8697 - val_loss: 0.0041 - val_acc: 0.7848
Epoch 92/150
391/391 - 10s - loss: 7.5154e-06 - acc: 0.8752 - val_loss: 0.0041 - val_acc: 0.7824
Epoch 93/150
391/391 - 11s - loss: 6.7759e-06 - acc: 0.8719 - val_loss: 0.0041 - val_acc: 0.8024
Epoch 94/150
391/391 - 13s - loss: 6.3472e-06 - acc: 0.8713 - val_loss: 0.0041 - val_acc: 0.7712
Epoch 95/150
391/391 - 11s - loss: 6.0823e-06 - acc: 0.8711 - val_loss: 0.0041 - val_acc: 0.7808
Epoch 96/150
391/391 - 10s - loss: 6.3864e-06 - acc: 0.8708 - val_loss: 0.0041 - val_acc: 0.7784
Epoch 97/150
391/391 - 10s - loss: 6.9242e-06 - acc: 0.8719 - val_loss: 0.0041 - val_acc: 0.7656
Epoch 98/150
391/391 - 10s - loss: 8.1455e-06 - acc: 0.8714 - val_loss: 0.0043 - val_acc: 0.7864
Epoch 99/150
391/391 - 10s - loss: 4.5534e-04 - acc: 0.8040 - val_loss: 0.0044 - val_acc: 0.7512
Epoch 100/150
391/391 - 10s - loss: 6.5747e-05 - acc: 0.8389 - val_loss: 0.0042 - val_acc: 0.7272
Epoch 101/150
391/391 - 10s - loss: 5.3853e-05 - acc: 0.8442 - val_loss: 0.0040 - val_acc: 0.7752
Epoch 102/150
391/391 - 10s - loss: 1.0143e-05 - acc: 0.8688 - val_loss: 0.0039 - val_acc: 0.7680
Epoch 103/150
391/391 - 10s - loss: 7.2513e-06 - acc: 0.8661 - val_loss: 0.0039 - val_acc: 0.7832
Epoch 104/150
391/391 - 10s - loss: 6.5472e-06 - acc: 0.8638 - val_loss: 0.0039 - val_acc: 0.7888
Epoch 105/150
391/391 - 12s - loss: 5.9101e-06 - acc: 0.8669 - val_loss: 0.0039 - val_acc: 0.7832
Epoch 106/150
391/391 - 11s - loss: 5.7804e-06 - acc: 0.8676 - val_loss: 0.0040 - val_acc: 0.7800
Epoch 107/150
391/391 - 10s - loss: 5.8917e-06 - acc: 0.8672 - val_loss: 0.0040 - val_acc: 0.7864
Epoch 108/150
391/391 - 10s - loss: 6.6302e-06 - acc: 0.8670 - val_loss: 0.0039 - val_acc: 0.7752
Epoch 109/150
391/391 - 10s - loss: 1.0500e-05 - acc: 0.8650 - val_loss: 0.0040 - val_acc: 0.7736
Epoch 110/150
391/391 - 10s - loss: 3.3953e-04 - acc: 0.8286 - val_loss: 0.0044 - val_acc: 0.7408
Epoch 111/150
391/391 - 10s - loss: 6.0339e-05 - acc: 0.8396 - val_loss: 0.0043 - val_acc: 0.7608
Epoch 112/150
391/391 - 10s - loss: 1.2056e-05 - acc: 0.8583 - val_loss: 0.0042 - val_acc: 0.7808
Epoch 113/150
391/391 - 10s - loss: 6.9844e-06 - acc: 0.8671 - val_loss: 0.0042 - val_acc: 0.7872
Epoch 114/150
391/391 - 11s - loss: 5.5583e-06 - acc: 0.8668 - val_loss: 0.0042 - val_acc: 0.7760
Epoch 115/150
391/391 - 12s - loss: 5.1203e-06 - acc: 0.8639 - val_loss: 0.0042 - val_acc: 0.7712
Epoch 116/150
391/391 - 10s - loss: 5.1237e-06 - acc: 0.8662 - val_loss: 0.0042 - val_acc: 0.7768
Epoch 117/150
391/391 - 10s - loss: 5.6825e-06 - acc: 0.8630 - val_loss: 0.0042 - val_acc: 0.7728
Epoch 118/150
391/391 - 10s - loss: 5.4539e-06 - acc: 0.8635 - val_loss: 0.0042 - val_acc: 0.8000
Epoch 119/150
391/391 - 10s - loss: 6.0761e-06 - acc: 0.8646 - val_loss: 0.0044 - val_acc: 0.7736
Epoch 120/150
391/391 - 10s - loss: 6.2247e-06 - acc: 0.8630 - val_loss: 0.0043 - val_acc: 0.7512
Epoch 121/150
391/391 - 10s - loss: 3.5610e-04 - acc: 0.8240 - val_loss: 0.0051 - val_acc: 0.7400
Epoch 122/150
391/391 - 10s - loss: 1.3823e-04 - acc: 0.8193 - val_loss: 0.0039 - val_acc: 0.7408
Epoch 123/150
391/391 - 10s - loss: 2.7334e-05 - acc: 0.8529 - val_loss: 0.0039 - val_acc: 0.7792
Epoch 124/150
391/391 - 10s - loss: 1.2350e-05 - acc: 0.8526 - val_loss: 0.0040 - val_acc: 0.7864
Epoch 125/150
391/391 - 10s - loss: 5.7941e-06 - acc: 0.8620 - val_loss: 0.0040 - val_acc: 0.7728
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-06-23 14:47:27.148136: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-06-23 14:47:27.148317: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-06-23 14:47:27.148353: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-06-23 14:47:27.175080: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-06-23 14:47:27.175199: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00125: early stopping
Train for 391 steps, validate for 10 steps
Epoch 1/30
391/391 - 18s - loss: 0.2247 - acc: 0.9117 - val_loss: 0.5653 - val_acc: 0.8368
Epoch 2/30
391/391 - 10s - loss: 0.1155 - acc: 0.9547 - val_loss: 0.5658 - val_acc: 0.8472
Epoch 3/30
391/391 - 10s - loss: 0.0704 - acc: 0.9739 - val_loss: 0.6381 - val_acc: 0.8472
Epoch 4/30
391/391 - 10s - loss: 0.0424 - acc: 0.9853 - val_loss: 0.6835 - val_acc: 0.8552
Epoch 5/30
391/391 - 10s - loss: 0.0223 - acc: 0.9925 - val_loss: 0.7406 - val_acc: 0.8520
Epoch 6/30
391/391 - 10s - loss: 0.0106 - acc: 0.9967 - val_loss: 0.8209 - val_acc: 0.8440
Epoch 7/30
391/391 - 10s - loss: 0.0199 - acc: 0.9928 - val_loss: 0.9019 - val_acc: 0.8440
Epoch 8/30
391/391 - 10s - loss: 0.0124 - acc: 0.9958 - val_loss: 0.8605 - val_acc: 0.8472
Epoch 9/30
391/391 - 10s - loss: 0.0013 - acc: 0.9995 - val_loss: 0.8553 - val_acc: 0.8560
Epoch 10/30
391/391 - 10s - loss: 3.9641e-04 - acc: 0.9995 - val_loss: 0.8966 - val_acc: 0.8536
Epoch 11/30
391/391 - 10s - loss: 2.0614e-04 - acc: 0.9995 - val_loss: 0.9216 - val_acc: 0.8552
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-06-23 14:49:24.992841: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-06-23 14:49:24.993010: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-06-23 14:49:24.993042: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-06-23 14:49:25.022107: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-06-23 14:49:25.022225: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00011: early stopping
Train for 391 steps, validate for 10 steps
Epoch 1/30
391/391 - 17s - loss: 0.1619 - acc: 0.9382 - val_loss: 0.5511 - val_acc: 0.8504
Epoch 2/30
391/391 - 15s - loss: 0.0783 - acc: 0.9717 - val_loss: 0.5895 - val_acc: 0.8592
Epoch 3/30
391/391 - 14s - loss: 0.0438 - acc: 0.9850 - val_loss: 0.6874 - val_acc: 0.8512
Epoch 4/30
391/391 - 14s - loss: 0.0230 - acc: 0.9931 - val_loss: 0.7220 - val_acc: 0.8584
Epoch 5/30
391/391 - 14s - loss: 0.0128 - acc: 0.9964 - val_loss: 0.7805 - val_acc: 0.8504
Epoch 6/30
391/391 - 10s - loss: 0.0154 - acc: 0.9947 - val_loss: 0.8404 - val_acc: 0.8560
Epoch 7/30
391/391 - 16s - loss: 0.0108 - acc: 0.9969 - val_loss: 0.8064 - val_acc: 0.8560
Epoch 8/30
391/391 - 14s - loss: 0.0059 - acc: 0.9983 - val_loss: 0.9178 - val_acc: 0.8464
Epoch 9/30
391/391 - 13s - loss: 0.0050 - acc: 0.9986 - val_loss: 0.9367 - val_acc: 0.8504
Epoch 10/30
391/391 - 10s - loss: 0.0128 - acc: 0.9959 - val_loss: 0.9480 - val_acc: 0.8432
Epoch 11/30
391/391 - 10s - loss: 0.0118 - acc: 0.9964 - val_loss: 0.8772 - val_acc: 0.8664
Epoch 00011: early stopping
Accuracy on original test dataset: 69.1%
tf.Tensor(
[[684  16 101   1   0   0   0  21   9  29]
 [  6 845   9   0   1   1   0   0   5  18]
 [ 25   6 729   9   5  47  17  32   3   5]
 [  8  33 137 296  12 225  13 120   0  51]
 [ 22  18 213  26 304  74  23 163   4  35]
 [  2  10  68  68   2 648   0  71   0   9]
 [  3  45 158  21  10  43 556  16   3  18]
 [  5   9  44  10   3  42   0 749   0   9]
 [133  87  25   0   2   1   1  15 566  39]
 [ 13 147  20   1   0   1   0   6   1 669]], shape=(10, 10), dtype=int32)
Correct: 6046, wrong: 2704, accuracy: 69.09714285714286%

Mean probability on true label of original test dataset when correctly predicted = 99.68%
Mean uncertainty on true label of original test dataset when correctly predicted = -36.08%
Mean probability on true label of original test dataset when wrongly predicted = 0.74%
Mean uncertainty on true label of original test dataset when wrongly predicted = -14.29%

Mean probability on highest predicted on original test dataset when wrong = 98.01%
Mean uncertainty on highest predicted on original test dataset when wrong = -22.42%

Mean probability on all not true label on original test dataset = 3.43%
Mean uncertainty on all not true label on original test dataset = -6.93%
creating scatterplot
Accuracy on original test dataset: 69.1%
tf.Tensor(
[[684  16 101   1   0   0   0  21   9  29]
 [  6 845   9   0   1   1   0   0   5  18]
 [ 25   6 729   9   5  47  17  32   3   5]
 [  8  33 137 296  12 225  13 120   0  51]
 [ 22  18 213  26 304  74  23 163   4  35]
 [  2  10  68  68   2 648   0  71   0   9]
 [  3  45 158  21  10  43 556  16   3  18]
 [  5   9  44  10   3  42   0 749   0   9]
 [133  87  25   0   2   1   1  15 566  39]
 [ 13 147  20   1   0   1   0   6   1 669]], shape=(10, 10), dtype=int32)
Correct: 6046, wrong: 2704, accuracy: 69.09714285714286%

Mean probability on true label of original test dataset when correctly predicted = 99.68%
Mean uncertainty on true label of original test dataset when correctly predicted = 69.29%
Mean probability on true label of original test dataset when wrongly predicted = 0.74%
Mean uncertainty on true label of original test dataset when wrongly predicted = 47.71%

Mean probability on highest predicted on original test dataset when wrong = 98.01%
Mean uncertainty on highest predicted on original test dataset when wrong = 56.77%

Mean probability on all not true label on original test dataset = 3.43%
Mean uncertainty on all not true label on original test dataset = 52.86%
creating scatterplot
0.6909714285714286


###############################################################################
Peregrine Cluster
Job 12301149 for user 's2934833'
Finished at: Tue Jun 23 14:51:56 CEST 2020

Job details:
============

Name                : CIFVAR
User                : s2934833
Partition           : gpu
Nodes               : pg-gpu40
Cores               : 12
State               : COMPLETED
Submit              : 2020-06-23T14:19:31
Start               : 2020-06-23T14:24:45
End                 : 2020-06-23T14:51:56
Reserved walltime   : 02:00:00
Used walltime       : 00:27:11
Used CPU time       : 00:29:05 (efficiency:  8.92%)
% User (Computation): 75.92%
% System (I/O)      : 24.08%
Mem reserved        : 32000M/node
Max Mem used        : 4.36G (pg-gpu40)
Max Disk Write      : 153.60K (pg-gpu40)
Max Disk Read       : 5.97M (pg-gpu40)
Average GPU usage   : 71.9% (pg-gpu40)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/additional_information/scientific_output

################################################################################
