
The following have been reloaded with a version change:
  1) FFTW/3.3.8-gompic-2019b => FFTW/3.3.8-gompi-2019b
  2) OpenMPI/3.1.4-gcccuda-2019b => OpenMPI/3.1.4-GCC-8.3.0
  3) ScaLAPACK/2.0.2-gompic-2019b => ScaLAPACK/2.0.2-gompi-2019b
  4) SciPy-bundle/2019.10-fosscuda-2019b-Python-3.7.4 => SciPy-bundle/2019.10-foss-2019b-Python-3.7.4

2020-05-10 16:32:05.155077: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-10 16:32:19.179585: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-05-10 16:32:19.186588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-10 16:32:19.187088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-10 16:32:19.187176: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-10 16:32:19.192154: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-10 16:32:19.195584: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-10 16:32:19.197385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-10 16:32:19.200766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-10 16:32:19.202772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-10 16:32:19.207793: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-10 16:32:19.208005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-10 16:32:19.208609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-10 16:32:19.209044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-05-10 16:32:19.211911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-10 16:32:19.212392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-10 16:32:19.212490: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-10 16:32:19.212568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-10 16:32:19.212631: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-10 16:32:19.212693: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-10 16:32:19.212754: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-10 16:32:19.212815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-10 16:32:19.212877: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-10 16:32:19.213015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-10 16:32:19.213571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-10 16:32:19.214001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-05-10 16:32:19.214093: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-10 16:32:19.835919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-10 16:32:19.836056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-05-10 16:32:19.836113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-05-10 16:32:19.836436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-10 16:32:19.837147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-10 16:32:19.837724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-10 16:32:19.838210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28652 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2020-05-10 16:32:19.838597: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-10 16:32:22.840905: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-10 16:32:23.089049: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-10 16:32:24.931619: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-10 16:32:24.931772: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1259] Profiler found 1 GPUs
2020-05-10 16:32:24.934214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1
2020-05-10 16:32:25.034850: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-05-10 16:32:25.035529: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-05-10 16:32:25.055769: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-10 16:32:25.055915: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
dataset_name = /CIFAR10, batch_size = 64, num_classes = 10, epochs_1 = 150,
        epochts_2 = 30, test_img_idx = 1658,
        train_test_split = 0.8
        learn rate = 1e-05,
        train_all_layers = False, weights_to_use = imagenet,
        es_patience_1 = 20, es_patience_2 = 5, train_val_split = 0.9
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 test samples
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
block1_conv1 (Conv2D)           (None, 32, 32, 64)   1792        input_1[0][0]                    
__________________________________________________________________________________________________
block1_conv2 (Conv2D)           (None, 32, 32, 64)   36928       block1_conv1[1][0]               
__________________________________________________________________________________________________
block1_pool (MaxPooling2D)      (None, 16, 16, 64)   0           block1_conv2[1][0]               
__________________________________________________________________________________________________
block2_conv1 (Conv2D)           (None, 16, 16, 128)  73856       block1_pool[1][0]                
__________________________________________________________________________________________________
block2_conv2 (Conv2D)           (None, 16, 16, 128)  147584      block2_conv1[1][0]               
__________________________________________________________________________________________________
block2_pool (MaxPooling2D)      (None, 8, 8, 128)    0           block2_conv2[1][0]               
__________________________________________________________________________________________________
block3_conv1 (Conv2D)           (None, 8, 8, 256)    295168      block2_pool[1][0]                
__________________________________________________________________________________________________
block3_conv2 (Conv2D)           (None, 8, 8, 256)    590080      block3_conv1[1][0]               
__________________________________________________________________________________________________
block3_conv3 (Conv2D)           (None, 8, 8, 256)    590080      block3_conv2[1][0]               
__________________________________________________________________________________________________
block3_pool (MaxPooling2D)      (None, 4, 4, 256)    0           block3_conv3[1][0]               
__________________________________________________________________________________________________
block4_conv1 (Conv2D)           (None, 4, 4, 512)    1180160     block3_pool[1][0]                
__________________________________________________________________________________________________
block4_conv2 (Conv2D)           (None, 4, 4, 512)    2359808     block4_conv1[1][0]               
__________________________________________________________________________________________________
block4_conv3 (Conv2D)           (None, 4, 4, 512)    2359808     block4_conv2[1][0]               
__________________________________________________________________________________________________
block4_pool (MaxPooling2D)      (None, 2, 2, 512)    0           block4_conv3[1][0]               
__________________________________________________________________________________________________
block5_conv1 (Conv2D)           (None, 2, 2, 512)    2359808     block4_pool[1][0]                
__________________________________________________________________________________________________
block5_conv2 (Conv2D)           (None, 2, 2, 512)    2359808     block5_conv1[1][0]               
__________________________________________________________________________________________________
block5_conv3 (Conv2D)           (None, 2, 2, 512)    2359808     block5_conv2[1][0]               
__________________________________________________________________________________________________
block5_pool (MaxPooling2D)      (None, 1, 1, 512)    0           block5_conv3[1][0]               
__________________________________________________________________________________________________
flatten (Flatten)               (None, 512)          0           block5_pool[1][0]                
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         2101248     flatten[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
dense (Dense)                   (None, 10)           40970       fc2[0][0]                        
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           40970       fc2[0][0]                        
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 20)           0           dense[0][0]                      
                                                                 dense_1[0][0]                    
==================================================================================================
Total params: 33,679,188
Trainable params: 33,679,188
Non-trainable params: 0
__________________________________________________________________________________________________
Start fitting
Train for 704 steps, validate for 79 steps
Epoch 1/150
704/704 - 18s - loss: 0.0233 - acc: 0.3128 - val_loss: 0.0123 - val_acc: 0.6330
Epoch 2/150
704/704 - 14s - loss: 0.0103 - acc: 0.6775 - val_loss: 0.0093 - val_acc: 0.7230
Epoch 3/150
704/704 - 13s - loss: 0.0078 - acc: 0.7328 - val_loss: 0.0081 - val_acc: 0.7386
Epoch 4/150
704/704 - 13s - loss: 0.0062 - acc: 0.7624 - val_loss: 0.0074 - val_acc: 0.7410
Epoch 5/150
704/704 - 13s - loss: 0.0051 - acc: 0.7776 - val_loss: 0.0067 - val_acc: 0.7614
Epoch 6/150
704/704 - 13s - loss: 0.0041 - acc: 0.7905 - val_loss: 0.0064 - val_acc: 0.7556
Epoch 7/150
704/704 - 13s - loss: 0.0033 - acc: 0.8042 - val_loss: 0.0059 - val_acc: 0.7596
Epoch 8/150
704/704 - 13s - loss: 0.0027 - acc: 0.8096 - val_loss: 0.0062 - val_acc: 0.7268
Epoch 9/150
704/704 - 13s - loss: 0.0021 - acc: 0.8157 - val_loss: 0.0063 - val_acc: 0.7332
Epoch 10/150
704/704 - 13s - loss: 0.0016 - acc: 0.8233 - val_loss: 0.0056 - val_acc: 0.7450
Epoch 11/150
704/704 - 14s - loss: 0.0013 - acc: 0.8266 - val_loss: 0.0057 - val_acc: 0.7492
Epoch 12/150
704/704 - 14s - loss: 0.0011 - acc: 0.8260 - val_loss: 0.0062 - val_acc: 0.7200
Epoch 13/150
704/704 - 14s - loss: 8.2636e-04 - acc: 0.8303 - val_loss: 0.0057 - val_acc: 0.7312
Epoch 14/150
704/704 - 13s - loss: 7.3100e-04 - acc: 0.8277 - val_loss: 0.0057 - val_acc: 0.7260
Epoch 15/150
704/704 - 14s - loss: 7.2463e-04 - acc: 0.8300 - val_loss: 0.0056 - val_acc: 0.6944
Epoch 16/150
704/704 - 13s - loss: 4.7643e-04 - acc: 0.8385 - val_loss: 0.0060 - val_acc: 0.7412
Epoch 17/150
704/704 - 13s - loss: 4.7502e-04 - acc: 0.8302 - val_loss: 0.0068 - val_acc: 0.6974
Epoch 18/150
704/704 - 13s - loss: 4.5242e-04 - acc: 0.8265 - val_loss: 0.0062 - val_acc: 0.7150
Epoch 19/150
704/704 - 12s - loss: 5.1574e-04 - acc: 0.8158 - val_loss: 0.0060 - val_acc: 0.7162
Epoch 20/150
704/704 - 14s - loss: 2.6343e-04 - acc: 0.8407 - val_loss: 0.0058 - val_acc: 0.7462
Epoch 21/150
704/704 - 12s - loss: 4.5775e-04 - acc: 0.8261 - val_loss: 0.0056 - val_acc: 0.7202
Epoch 22/150
704/704 - 12s - loss: 3.2392e-04 - acc: 0.8236 - val_loss: 0.0060 - val_acc: 0.6990
Epoch 23/150
704/704 - 13s - loss: 2.5151e-04 - acc: 0.8256 - val_loss: 0.0062 - val_acc: 0.6820
Epoch 24/150
704/704 - 13s - loss: 2.2997e-04 - acc: 0.8296 - val_loss: 0.0061 - val_acc: 0.6544
Epoch 25/150
704/704 - 13s - loss: 3.8991e-04 - acc: 0.8089 - val_loss: 0.0056 - val_acc: 0.7062
Epoch 26/150
704/704 - 14s - loss: 1.6733e-04 - acc: 0.8423 - val_loss: 0.0061 - val_acc: 0.6806
Epoch 27/150
704/704 - 13s - loss: 3.2077e-04 - acc: 0.8061 - val_loss: 0.0057 - val_acc: 0.7008
Epoch 28/150
704/704 - 13s - loss: 2.5841e-04 - acc: 0.8120 - val_loss: 0.0057 - val_acc: 0.7092
Epoch 29/150
704/704 - 13s - loss: 1.8162e-04 - acc: 0.8232 - val_loss: 0.0060 - val_acc: 0.7082
Epoch 30/150
704/704 - 13s - loss: 3.2154e-04 - acc: 0.8056 - val_loss: 0.0063 - val_acc: 0.6988
Epoch 31/150
704/704 - 13s - loss: 2.1457e-04 - acc: 0.8242 - val_loss: 0.0058 - val_acc: 0.7026
Epoch 32/150
704/704 - 13s - loss: 1.2911e-04 - acc: 0.8171 - val_loss: 0.0056 - val_acc: 0.7312
Epoch 33/150
704/704 - 12s - loss: 2.0706e-04 - acc: 0.8223 - val_loss: 0.0062 - val_acc: 0.6474
Epoch 34/150
704/704 - 13s - loss: 2.5155e-04 - acc: 0.7898 - val_loss: 0.0060 - val_acc: 0.6946
Epoch 35/150
704/704 - 13s - loss: 1.7786e-04 - acc: 0.8075 - val_loss: 0.0062 - val_acc: 0.6950
Epoch 36/150
704/704 - 13s - loss: 1.5772e-04 - acc: 0.8043 - val_loss: 0.0055 - val_acc: 0.6764
Epoch 37/150
704/704 - 13s - loss: 1.5913e-04 - acc: 0.8127 - val_loss: 0.0056 - val_acc: 0.7448
Epoch 38/150
704/704 - 13s - loss: 1.6803e-04 - acc: 0.8117 - val_loss: 0.0061 - val_acc: 0.6768
Epoch 39/150
704/704 - 14s - loss: 5.8695e-05 - acc: 0.8106 - val_loss: 0.0055 - val_acc: 0.7398
Epoch 40/150
704/704 - 13s - loss: 1.7719e-04 - acc: 0.8124 - val_loss: 0.0056 - val_acc: 0.6928
Epoch 41/150
704/704 - 12s - loss: 1.5563e-04 - acc: 0.7888 - val_loss: 0.0059 - val_acc: 0.6970
Epoch 42/150
704/704 - 13s - loss: 1.6984e-04 - acc: 0.7978 - val_loss: 0.0059 - val_acc: 0.6844
Epoch 43/150
704/704 - 12s - loss: 1.2905e-04 - acc: 0.7820 - val_loss: 0.0056 - val_acc: 0.6938
Epoch 44/150
704/704 - 12s - loss: 1.3560e-04 - acc: 0.7872 - val_loss: 0.0055 - val_acc: 0.7060
Epoch 45/150
704/704 - 13s - loss: 3.9932e-05 - acc: 0.8184 - val_loss: 0.0058 - val_acc: 0.7262
Epoch 46/150
704/704 - 13s - loss: 1.6826e-04 - acc: 0.7885 - val_loss: 0.0056 - val_acc: 0.7108
Epoch 47/150
704/704 - 13s - loss: 3.2793e-05 - acc: 0.8187 - val_loss: 0.0053 - val_acc: 0.7594
Epoch 48/150
704/704 - 13s - loss: 2.8231e-04 - acc: 0.7827 - val_loss: 0.0054 - val_acc: 0.6778
Epoch 49/150
704/704 - 13s - loss: 1.1299e-04 - acc: 0.7809 - val_loss: 0.0059 - val_acc: 0.6644
Epoch 50/150
704/704 - 13s - loss: 4.2520e-05 - acc: 0.7976 - val_loss: 0.0051 - val_acc: 0.7118
Epoch 51/150
704/704 - 12s - loss: 1.0875e-04 - acc: 0.8013 - val_loss: 0.0053 - val_acc: 0.7154
Epoch 52/150
704/704 - 13s - loss: 1.9723e-05 - acc: 0.8175 - val_loss: 0.0054 - val_acc: 0.7192
Epoch 53/150
704/704 - 13s - loss: 1.8813e-05 - acc: 0.8183 - val_loss: 0.0054 - val_acc: 0.7352
Epoch 54/150
704/704 - 13s - loss: 3.2365e-04 - acc: 0.7709 - val_loss: 0.0054 - val_acc: 0.6992
Epoch 55/150
704/704 - 12s - loss: 3.2341e-05 - acc: 0.8076 - val_loss: 0.0053 - val_acc: 0.7128
Epoch 56/150
704/704 - 12s - loss: 7.9141e-05 - acc: 0.7980 - val_loss: 0.0055 - val_acc: 0.7208
Epoch 57/150
704/704 - 13s - loss: 2.4500e-05 - acc: 0.8054 - val_loss: 0.0055 - val_acc: 0.7156
Epoch 58/150
704/704 - 13s - loss: 2.4071e-04 - acc: 0.7678 - val_loss: 0.0056 - val_acc: 0.7224
Epoch 59/150
704/704 - 13s - loss: 9.5434e-05 - acc: 0.7929 - val_loss: 0.0052 - val_acc: 0.7192
Epoch 60/150
704/704 - 13s - loss: 1.9019e-05 - acc: 0.8133 - val_loss: 0.0055 - val_acc: 0.7176
Epoch 61/150
704/704 - 13s - loss: 1.5106e-05 - acc: 0.8147 - val_loss: 0.0052 - val_acc: 0.7156
Epoch 62/150
704/704 - 14s - loss: 1.2849e-05 - acc: 0.8233 - val_loss: 0.0052 - val_acc: 0.7432
Epoch 63/150
704/704 - 14s - loss: 1.2779e-05 - acc: 0.8236 - val_loss: 0.0053 - val_acc: 0.7520
Epoch 64/150
704/704 - 13s - loss: 1.3799e-05 - acc: 0.8253 - val_loss: 0.0055 - val_acc: 0.7102
Epoch 65/150
704/704 - 13s - loss: 2.6225e-04 - acc: 0.8038 - val_loss: 0.0057 - val_acc: 0.6718
Epoch 66/150
704/704 - 13s - loss: 1.7770e-04 - acc: 0.7647 - val_loss: 0.0052 - val_acc: 0.7156
Epoch 67/150
704/704 - 13s - loss: 6.8236e-05 - acc: 0.7923 - val_loss: 0.0053 - val_acc: 0.7124
Epoch 68/150
704/704 - 14s - loss: 1.2497e-05 - acc: 0.8132 - val_loss: 0.0051 - val_acc: 0.7068
Epoch 69/150
704/704 - 14s - loss: 9.2229e-06 - acc: 0.8193 - val_loss: 0.0052 - val_acc: 0.7248
Epoch 70/150
704/704 - 13s - loss: 9.4570e-06 - acc: 0.8240 - val_loss: 0.0051 - val_acc: 0.7478
Epoch 71/150
704/704 - 13s - loss: 9.4278e-06 - acc: 0.8185 - val_loss: 0.0052 - val_acc: 0.7342
Epoch 72/150
704/704 - 13s - loss: 2.4155e-04 - acc: 0.8012 - val_loss: 0.0058 - val_acc: 0.6946
Epoch 73/150
704/704 - 13s - loss: 1.1529e-04 - acc: 0.7810 - val_loss: 0.0053 - val_acc: 0.7064
Epoch 74/150
704/704 - 13s - loss: 1.8731e-05 - acc: 0.8123 - val_loss: 0.0054 - val_acc: 0.7296
Epoch 75/150
704/704 - 13s - loss: 8.5766e-06 - acc: 0.8321 - val_loss: 0.0054 - val_acc: 0.7450
Epoch 76/150
704/704 - 14s - loss: 7.3910e-06 - acc: 0.8306 - val_loss: 0.0053 - val_acc: 0.7296
Epoch 77/150
704/704 - 13s - loss: 8.1413e-06 - acc: 0.8359 - val_loss: 0.0053 - val_acc: 0.7610
Epoch 78/150
704/704 - 13s - loss: 8.4839e-06 - acc: 0.8347 - val_loss: 0.0064 - val_acc: 0.7432
Epoch 79/150
704/704 - 13s - loss: 3.7120e-04 - acc: 0.7497 - val_loss: 0.0061 - val_acc: 0.6044
Epoch 80/150
704/704 - 13s - loss: 9.5070e-05 - acc: 0.7756 - val_loss: 0.0056 - val_acc: 0.7306
Epoch 81/150
704/704 - 13s - loss: 6.3087e-05 - acc: 0.7902 - val_loss: 0.0057 - val_acc: 0.7272
Epoch 82/150
704/704 - 13s - loss: 4.1551e-05 - acc: 0.7867 - val_loss: 0.0056 - val_acc: 0.7042
Epoch 83/150
704/704 - 13s - loss: 1.5328e-04 - acc: 0.7617 - val_loss: 0.0056 - val_acc: 0.6858
Epoch 84/150
704/704 - 12s - loss: 2.2222e-05 - acc: 0.7955 - val_loss: 0.0053 - val_acc: 0.7182
Epoch 85/150
704/704 - 13s - loss: 7.3936e-06 - acc: 0.8121 - val_loss: 0.0053 - val_acc: 0.7258
Epoch 86/150
704/704 - 14s - loss: 6.9757e-06 - acc: 0.8201 - val_loss: 0.0052 - val_acc: 0.7276
Epoch 87/150
704/704 - 13s - loss: 7.4473e-06 - acc: 0.8181 - val_loss: 0.0052 - val_acc: 0.7402
Epoch 88/150
704/704 - 13s - loss: 1.1371e-04 - acc: 0.8145 - val_loss: 0.0071 - val_acc: 0.6540
Epoch 89/150
704/704 - 12s - loss: 2.0527e-04 - acc: 0.7684 - val_loss: 0.0055 - val_acc: 0.7028
Epoch 90/150
704/704 - 13s - loss: 1.4036e-05 - acc: 0.8118 - val_loss: 0.0053 - val_acc: 0.7270
Epoch 91/150
704/704 - 13s - loss: 6.6139e-06 - acc: 0.8148 - val_loss: 0.0052 - val_acc: 0.7366
Epoch 92/150
704/704 - 14s - loss: 6.2754e-06 - acc: 0.8205 - val_loss: 0.0053 - val_acc: 0.7258
Epoch 93/150
704/704 - 12s - loss: 7.5216e-06 - acc: 0.8198 - val_loss: 0.0053 - val_acc: 0.7364
Epoch 94/150
704/704 - 12s - loss: 7.4776e-06 - acc: 0.8168 - val_loss: 0.0053 - val_acc: 0.7498
Epoch 95/150
704/704 - 13s - loss: 2.4011e-04 - acc: 0.7888 - val_loss: 0.0058 - val_acc: 0.6332
Epoch 96/150
704/704 - 13s - loss: 8.5776e-05 - acc: 0.7713 - val_loss: 0.0053 - val_acc: 0.6942
Epoch 97/150
704/704 - 13s - loss: 7.6601e-05 - acc: 0.7817 - val_loss: 0.0056 - val_acc: 0.7320
Epoch 98/150
704/704 - 13s - loss: 1.3545e-05 - acc: 0.8097 - val_loss: 0.0053 - val_acc: 0.7308
Epoch 99/150
704/704 - 13s - loss: 6.5302e-06 - acc: 0.8142 - val_loss: 0.0052 - val_acc: 0.7256
Epoch 100/150
704/704 - 14s - loss: 5.4978e-06 - acc: 0.8157 - val_loss: 0.0053 - val_acc: 0.7174
Epoch 101/150
704/704 - 12s - loss: 5.9062e-06 - acc: 0.8157 - val_loss: 0.0053 - val_acc: 0.7248
Epoch 102/150
704/704 - 13s - loss: 5.8956e-06 - acc: 0.8224 - val_loss: 0.0053 - val_acc: 0.7478
Epoch 103/150
704/704 - 13s - loss: 6.6748e-06 - acc: 0.8258 - val_loss: 0.0054 - val_acc: 0.7176
Epoch 104/150
704/704 - 13s - loss: 3.0246e-04 - acc: 0.7774 - val_loss: 0.0053 - val_acc: 0.7158
Epoch 105/150
704/704 - 12s - loss: 3.5626e-05 - acc: 0.7858 - val_loss: 0.0055 - val_acc: 0.7276
Epoch 106/150
704/704 - 13s - loss: 9.7042e-05 - acc: 0.7630 - val_loss: 0.0057 - val_acc: 0.6920
Epoch 107/150
704/704 - 13s - loss: 2.2788e-05 - acc: 0.7861 - val_loss: 0.0054 - val_acc: 0.7236
Epoch 108/150
704/704 - 12s - loss: 1.4288e-04 - acc: 0.7574 - val_loss: 0.0060 - val_acc: 0.6802
Epoch 109/150
704/704 - 12s - loss: 2.4577e-05 - acc: 0.7839 - val_loss: 0.0056 - val_acc: 0.6938
Epoch 110/150
704/704 - 12s - loss: 7.9470e-06 - acc: 0.8010 - val_loss: 0.0053 - val_acc: 0.7024
Epoch 111/150
704/704 - 13s - loss: 5.3547e-06 - acc: 0.8090 - val_loss: 0.0053 - val_acc: 0.7408
Epoch 112/150
704/704 - 13s - loss: 4.9224e-06 - acc: 0.8135 - val_loss: 0.0053 - val_acc: 0.7466
Epoch 113/150
704/704 - 12s - loss: 5.2752e-06 - acc: 0.8225 - val_loss: 0.0053 - val_acc: 0.7264
Epoch 114/150
704/704 - 13s - loss: 6.5130e-06 - acc: 0.8270 - val_loss: 0.0054 - val_acc: 0.7490
Epoch 115/150
704/704 - 13s - loss: 2.3835e-04 - acc: 0.7805 - val_loss: 0.0054 - val_acc: 0.7212
Epoch 116/150
704/704 - 12s - loss: 4.8004e-05 - acc: 0.7774 - val_loss: 0.0057 - val_acc: 0.7408
Epoch 117/150
704/704 - 13s - loss: 6.7560e-06 - acc: 0.8035 - val_loss: 0.0052 - val_acc: 0.7372
Epoch 118/150
704/704 - 14s - loss: 4.4157e-06 - acc: 0.8111 - val_loss: 0.0053 - val_acc: 0.7350
Epoch 119/150
704/704 - 14s - loss: 4.3454e-06 - acc: 0.8091 - val_loss: 0.0053 - val_acc: 0.7150
Epoch 120/150
704/704 - 13s - loss: 4.6169e-06 - acc: 0.8182 - val_loss: 0.0053 - val_acc: 0.7210
Epoch 121/150
704/704 - 13s - loss: 5.2936e-06 - acc: 0.8167 - val_loss: 0.0053 - val_acc: 0.7210
Epoch 122/150
704/704 - 13s - loss: 5.4155e-06 - acc: 0.8148 - val_loss: 0.0054 - val_acc: 0.7272
Epoch 123/150
704/704 - 12s - loss: 2.9435e-04 - acc: 0.7632 - val_loss: 0.0058 - val_acc: 0.6700
Epoch 124/150
704/704 - 12s - loss: 5.7081e-05 - acc: 0.7815 - val_loss: 0.0052 - val_acc: 0.7398
Epoch 125/150
704/704 - 13s - loss: 7.0781e-05 - acc: 0.7934 - val_loss: 0.0052 - val_acc: 0.7308
Epoch 126/150
704/704 - 12s - loss: 9.3420e-06 - acc: 0.7990 - val_loss: 0.0052 - val_acc: 0.7252
Epoch 127/150
704/704 - 12s - loss: 4.5485e-06 - acc: 0.8082 - val_loss: 0.0051 - val_acc: 0.7322
Epoch 128/150
704/704 - 14s - loss: 4.2926e-06 - acc: 0.8059 - val_loss: 0.0052 - val_acc: 0.7328
Epoch 129/150
704/704 - 12s - loss: 4.3641e-06 - acc: 0.8174 - val_loss: 0.0052 - val_acc: 0.7288
Epoch 130/150
704/704 - 13s - loss: 4.4238e-06 - acc: 0.8240 - val_loss: 0.0052 - val_acc: 0.7294
Epoch 131/150
704/704 - 12s - loss: 4.9879e-06 - acc: 0.8268 - val_loss: 0.0052 - val_acc: 0.7178
Epoch 132/150
704/704 - 12s - loss: 2.1428e-04 - acc: 0.7842 - val_loss: 0.0062 - val_acc: 0.6572
Epoch 133/150
704/704 - 13s - loss: 6.1068e-05 - acc: 0.7678 - val_loss: 0.0055 - val_acc: 0.7194
Epoch 134/150
704/704 - 12s - loss: 8.1195e-06 - acc: 0.7952 - val_loss: 0.0051 - val_acc: 0.7592
Epoch 135/150
704/704 - 13s - loss: 3.9602e-06 - acc: 0.8114 - val_loss: 0.0051 - val_acc: 0.7458
Epoch 136/150
704/704 - 13s - loss: 3.7250e-06 - acc: 0.8121 - val_loss: 0.0051 - val_acc: 0.7380
Epoch 137/150
704/704 - 13s - loss: 3.8053e-06 - acc: 0.8187 - val_loss: 0.0051 - val_acc: 0.7192
Epoch 138/150
704/704 - 13s - loss: 4.0511e-06 - acc: 0.8180 - val_loss: 0.0051 - val_acc: 0.7362
Epoch 139/150
704/704 - 12s - loss: 4.2918e-06 - acc: 0.8259 - val_loss: 0.0052 - val_acc: 0.7322
Epoch 140/150
704/704 - 13s - loss: 5.2491e-06 - acc: 0.8286 - val_loss: 0.0052 - val_acc: 0.7476
Epoch 141/150
704/704 - 12s - loss: 2.6580e-04 - acc: 0.7998 - val_loss: 0.0052 - val_acc: 0.7322
Epoch 142/150
704/704 - 13s - loss: 4.9415e-05 - acc: 0.8012 - val_loss: 0.0052 - val_acc: 0.7062
Epoch 143/150
704/704 - 13s - loss: 3.7219e-05 - acc: 0.7711 - val_loss: 0.0054 - val_acc: 0.6928
Epoch 144/150
704/704 - 13s - loss: 5.1550e-05 - acc: 0.7735 - val_loss: 0.0055 - val_acc: 0.7148
Epoch 145/150
704/704 - 13s - loss: 2.8510e-05 - acc: 0.7797 - val_loss: 0.0051 - val_acc: 0.7314
Epoch 146/150
704/704 - 13s - loss: 5.0408e-05 - acc: 0.7736 - val_loss: 0.0064 - val_acc: 0.6758
Epoch 147/150
704/704 - 13s - loss: 8.4627e-05 - acc: 0.7550 - val_loss: 0.0051 - val_acc: 0.6950
Epoch 148/150
704/704 - 13s - loss: 8.8805e-06 - acc: 0.7939 - val_loss: 0.0051 - val_acc: 0.7358
Epoch 149/150
704/704 - 13s - loss: 3.6349e-06 - acc: 0.8071 - val_loss: 0.0051 - val_acc: 0.7058
Epoch 150/150
704/704 - 14s - loss: 3.2995e-06 - acc: 0.8079 - val_loss: 0.0051 - val_acc: 0.7376
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-10 17:04:35.563600: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-10 17:04:35.563795: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-10 17:04:35.563870: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-10 17:04:35.583283: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-10 17:04:35.583432: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Train for 704 steps, validate for 79 steps
Epoch 1/30
704/704 - 16s - loss: 0.1823 - acc: 0.9274 - val_loss: 0.6287 - val_acc: 0.8456
Epoch 2/30
704/704 - 13s - loss: 0.0864 - acc: 0.9659 - val_loss: 0.6621 - val_acc: 0.8542
Epoch 3/30
704/704 - 13s - loss: 0.0447 - acc: 0.9836 - val_loss: 0.7576 - val_acc: 0.8464
Epoch 4/30
704/704 - 13s - loss: 0.0237 - acc: 0.9914 - val_loss: 0.8064 - val_acc: 0.8516
Epoch 5/30
704/704 - 13s - loss: 0.0129 - acc: 0.9953 - val_loss: 0.9372 - val_acc: 0.8460
Epoch 6/30
704/704 - 13s - loss: 0.0131 - acc: 0.9948 - val_loss: 0.9428 - val_acc: 0.8480
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-10 17:05:55.756586: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-10 17:05:55.756788: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-10 17:05:55.756862: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-10 17:05:55.776728: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-10 17:05:55.776870: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00006: early stopping
Train for 704 steps, validate for 79 steps
Epoch 1/30
704/704 - 17s - loss: 0.1228 - acc: 0.9528 - val_loss: 0.6536 - val_acc: 0.8524
Epoch 2/30
704/704 - 15s - loss: 0.0491 - acc: 0.9818 - val_loss: 0.7441 - val_acc: 0.8518
Epoch 3/30
704/704 - 15s - loss: 0.0233 - acc: 0.9916 - val_loss: 0.8157 - val_acc: 0.8534
Epoch 4/30
704/704 - 15s - loss: 0.0162 - acc: 0.9942 - val_loss: 0.8871 - val_acc: 0.8516
Epoch 5/30
704/704 - 16s - loss: 0.0096 - acc: 0.9969 - val_loss: 0.9673 - val_acc: 0.8462
Epoch 6/30
704/704 - 13s - loss: 0.0109 - acc: 0.9967 - val_loss: 0.9699 - val_acc: 0.8478
Epoch 00006: early stopping
Accuracy on original test dataset: 62.5%
tf.Tensor(
[[874  37  43   1   0   0   0   3  17  25]
 [ 13 968   1   0   0   0   0   0   2  16]
 [ 78  79 747   5   0  34  49   4   0   4]
 [ 72 297  86  82   1 304 108   7  10  33]
 [138 267  98  20 157  69 165  63   6  17]
 [ 34 215  61   8   1 619  29  16   3  14]
 [ 26 190  35   1   0   6 728   2   3   9]
 [ 66  77  26  11   5  74  20 678   2  41]
 [182 132   5   2   0   1   0   0 632  46]
 [ 26 213   0   0   0   0   0   0   1 760]], shape=(10, 10), dtype=int32)
Correct: 6245, wrong: 3755, accuracy: 62.45%

Mean probability on true label of original test dataset when correctly predicted = 98.15%
Mean uncertainty on true label of original test dataset when correctly predicted = 49.39%
Mean probability on true label of original test dataset when wrongly predicted = 2.61%
Mean uncertainty on true label of original test dataset when wrongly predicted = 23.01%

Mean probability on highest predicted on original test dataset when wrong = 87.35%
Mean uncertainty on highest predicted on original test dataset when wrong = 24.24%

Mean probability on all not true label on original test dataset = 4.19%
Mean uncertainty on all not true label on original test dataset = 35.34%
creating scatterplot
0.6245


###############################################################################
Peregrine Cluster
Job 11353527 for user 's2934833'
Finished at: Sun May 10 17:07:31 CEST 2020

Job details:
============

Name                : CIFVAR
User                : s2934833
Partition           : gpu
Nodes               : pg-gpu19
Cores               : 12
State               : COMPLETED
Submit              : 2020-05-10T16:31:59
Start               : 2020-05-10T16:31:59
End                 : 2020-05-10T17:07:31
Reserved walltime   : 02:00:00
Used walltime       : 00:35:32
Used CPU time       : 00:39:47 (efficiency:  9.33%)
% User (Computation): 79.05%
% System (I/O)      : 20.95%
Mem reserved        : 32000M/node
Max Mem used        : 3.85G (pg-gpu19)
Max Disk Write      : 153.60K (pg-gpu19)
Max Disk Read       : 5.83M (pg-gpu19)
Average GPU usage   : 72.6% (pg-gpu19)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/additional_information/scientific_output

################################################################################
