
The following have been reloaded with a version change:
  1) FFTW/3.3.8-gompic-2019b => FFTW/3.3.8-gompi-2019b
  2) OpenMPI/3.1.4-gcccuda-2019b => OpenMPI/3.1.4-GCC-8.3.0
  3) ScaLAPACK/2.0.2-gompic-2019b => ScaLAPACK/2.0.2-gompi-2019b
  4) SciPy-bundle/2019.10-fosscuda-2019b-Python-3.7.4 => SciPy-bundle/2019.10-foss-2019b-Python-3.7.4

2020-05-20 13:25:09.118361: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-20 13:25:20.407986: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-05-20 13:25:20.415035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 13:25:20.415550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-20 13:25:20.415601: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-20 13:25:20.420371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-20 13:25:20.424100: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-20 13:25:20.425601: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-20 13:25:20.429298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-20 13:25:20.431543: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-20 13:25:20.437383: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-20 13:25:20.437561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 13:25:20.438194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 13:25:20.438622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-05-20 13:25:20.441329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 13:25:20.441777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-20 13:25:20.441819: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-20 13:25:20.441853: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-20 13:25:20.441875: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-20 13:25:20.441895: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-20 13:25:20.441915: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-20 13:25:20.441936: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-20 13:25:20.441956: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-20 13:25:20.442062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 13:25:20.442524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 13:25:20.442876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-05-20 13:25:20.442925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-20 13:25:21.087437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-20 13:25:21.087520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-05-20 13:25:21.087536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-05-20 13:25:21.087800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 13:25:21.088452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 13:25:21.088956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 13:25:21.089393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28652 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2020-05-20 13:25:21.089755: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-20 13:25:24.915999: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-20 13:25:25.205105: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-20 13:25:31.128812: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-20 13:25:31.128917: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1259] Profiler found 1 GPUs
2020-05-20 13:25:31.131544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1
2020-05-20 13:25:31.232197: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-05-20 13:25:31.232779: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-05-20 13:25:31.618413: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-20 13:25:31.618513: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
loaded data
dataset_name = /Messidor2_PNG_AUG_256.hdf5, batch_size = 64, num_classes = 5, epochs_1 = 150,
        epochts_2 = 100, test_img_idx = 197,
        train_test_split = 0.7, to_shuffle = False, augmentation = False, label_count = [840, 840, 839, 838, 836],
        label_normalizer = False, save_augmentation_to_hdf5 = False, learn rate = 1e-05,
        train_all_layers = True, weights_to_use = imagenet,
        es_patience_1 = 20, es_patience_2 = 25, train_val_split = 0.875
x_train shape: (4193, 256, 256, 3)
4193 train samples
346 test samples
Total labels in train set:  [840, 840, 839, 838, 836]
Labels in validation set:  [119, 22, 28, 7, 3]
Labels in test set:  [202, 58, 70, 10, 6]
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            
__________________________________________________________________________________________________
block1_conv1 (Conv2D)           (None, 256, 256, 64) 1792        input_1[0][0]                    
__________________________________________________________________________________________________
block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[1][0]               
__________________________________________________________________________________________________
block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[1][0]               
__________________________________________________________________________________________________
block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[1][0]                
__________________________________________________________________________________________________
block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[1][0]               
__________________________________________________________________________________________________
block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[1][0]               
__________________________________________________________________________________________________
block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[1][0]                
__________________________________________________________________________________________________
block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[1][0]               
__________________________________________________________________________________________________
block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[1][0]               
__________________________________________________________________________________________________
block3_pool (MaxPooling2D)      (None, 32, 32, 256)  0           block3_conv3[1][0]               
__________________________________________________________________________________________________
block4_conv1 (Conv2D)           (None, 32, 32, 512)  1180160     block3_pool[1][0]                
__________________________________________________________________________________________________
block4_conv2 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv1[1][0]               
__________________________________________________________________________________________________
block4_conv3 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv2[1][0]               
__________________________________________________________________________________________________
block4_pool (MaxPooling2D)      (None, 16, 16, 512)  0           block4_conv3[1][0]               
__________________________________________________________________________________________________
block5_conv1 (Conv2D)           (None, 16, 16, 512)  2359808     block4_pool[1][0]                
__________________________________________________________________________________________________
block5_conv2 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv1[1][0]               
__________________________________________________________________________________________________
block5_conv3 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv2[1][0]               
__________________________________________________________________________________________________
block5_pool (MaxPooling2D)      (None, 8, 8, 512)    0           block5_conv3[1][0]               
__________________________________________________________________________________________________
flatten (Flatten)               (None, 32768)        0           block5_pool[1][0]                
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         134221824   flatten[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
dense (Dense)                   (None, 5)            20485       fc2[0][0]                        
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 5)            20485       fc2[0][0]                        
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 10)           0           dense[0][0]                      
                                                                 dense_1[0][0]                    
==================================================================================================
Total params: 165,758,794
Trainable params: 165,758,794
Non-trainable params: 0
__________________________________________________________________________________________________
Start fitting
Train for 66 steps, validate for 3 steps
Epoch 1/150
66/66 - 41s - loss: 1.5557 - acc: 0.0274 - val_loss: 1.2519 - val_acc: 0.4302
Epoch 2/150
66/66 - 31s - loss: 1.4511 - acc: 0.1145 - val_loss: 1.1316 - val_acc: 0.5754
Epoch 3/150
66/66 - 30s - loss: 1.3817 - acc: 0.2170 - val_loss: 1.1117 - val_acc: 0.4860
Epoch 4/150
66/66 - 30s - loss: 1.3302 - acc: 0.2814 - val_loss: 1.0486 - val_acc: 0.5978
Epoch 5/150
66/66 - 30s - loss: 1.2714 - acc: 0.3372 - val_loss: 1.0052 - val_acc: 0.6034
Epoch 6/150
66/66 - 30s - loss: 1.2201 - acc: 0.3921 - val_loss: 1.0193 - val_acc: 0.5251
Epoch 7/150
66/66 - 30s - loss: 1.1592 - acc: 0.4429 - val_loss: 0.9853 - val_acc: 0.5810
Epoch 8/150
66/66 - 30s - loss: 1.0952 - acc: 0.4846 - val_loss: 0.9322 - val_acc: 0.6425
Epoch 9/150
66/66 - 30s - loss: 1.0336 - acc: 0.5495 - val_loss: 0.9346 - val_acc: 0.6145
Epoch 10/150
66/66 - 30s - loss: 0.9697 - acc: 0.5750 - val_loss: 0.9270 - val_acc: 0.6536
Epoch 11/150
66/66 - 30s - loss: 0.9026 - acc: 0.6017 - val_loss: 0.9803 - val_acc: 0.5419
Epoch 12/150
66/66 - 30s - loss: 0.8371 - acc: 0.6294 - val_loss: 0.9668 - val_acc: 0.5419
Epoch 13/150
66/66 - 30s - loss: 0.7731 - acc: 0.6539 - val_loss: 0.9116 - val_acc: 0.5754
Epoch 14/150
66/66 - 30s - loss: 0.7152 - acc: 0.6692 - val_loss: 0.9507 - val_acc: 0.5531
Epoch 15/150
66/66 - 30s - loss: 0.6597 - acc: 0.6892 - val_loss: 0.9410 - val_acc: 0.5419
Epoch 16/150
66/66 - 30s - loss: 0.6085 - acc: 0.6976 - val_loss: 0.9270 - val_acc: 0.5587
Epoch 17/150
66/66 - 30s - loss: 0.5538 - acc: 0.7241 - val_loss: 1.1616 - val_acc: 0.3296
Epoch 18/150
66/66 - 30s - loss: 0.5172 - acc: 0.7307 - val_loss: 0.9572 - val_acc: 0.4525
Epoch 19/150
66/66 - 30s - loss: 0.4755 - acc: 0.7479 - val_loss: 0.9737 - val_acc: 0.4637
Epoch 20/150
66/66 - 30s - loss: 0.4390 - acc: 0.7644 - val_loss: 0.9575 - val_acc: 0.5196
Epoch 21/150
66/66 - 30s - loss: 0.4035 - acc: 0.7720 - val_loss: 0.9806 - val_acc: 0.4804
Epoch 22/150
66/66 - 32s - loss: 0.3749 - acc: 0.7808 - val_loss: 0.9361 - val_acc: 0.5475
Epoch 23/150
66/66 - 30s - loss: 0.3419 - acc: 0.7985 - val_loss: 0.9605 - val_acc: 0.4972
Epoch 24/150
66/66 - 30s - loss: 0.3239 - acc: 0.8030 - val_loss: 0.9583 - val_acc: 0.5196
Epoch 25/150
66/66 - 30s - loss: 0.2948 - acc: 0.8145 - val_loss: 0.9800 - val_acc: 0.4916
Epoch 26/150
66/66 - 31s - loss: 0.2709 - acc: 0.8235 - val_loss: 0.9710 - val_acc: 0.5531
Epoch 27/150
66/66 - 30s - loss: 0.2471 - acc: 0.8371 - val_loss: 0.9943 - val_acc: 0.4972
Epoch 28/150
66/66 - 30s - loss: 0.2364 - acc: 0.8404 - val_loss: 1.0092 - val_acc: 0.5698
Epoch 29/150
66/66 - 30s - loss: 0.2179 - acc: 0.8493 - val_loss: 1.0021 - val_acc: 0.5084
Epoch 30/150
66/66 - 30s - loss: 0.1957 - acc: 0.8586 - val_loss: 1.0100 - val_acc: 0.5251
Epoch 31/150
66/66 - 31s - loss: 0.1922 - acc: 0.8607 - val_loss: 1.1762 - val_acc: 0.3966
Epoch 32/150
66/66 - 33s - loss: 0.1685 - acc: 0.8786 - val_loss: 1.1066 - val_acc: 0.4469
Epoch 33/150
66/66 - 32s - loss: 0.1543 - acc: 0.8824 - val_loss: 1.0606 - val_acc: 0.4804
Epoch 34/150
66/66 - 31s - loss: 0.1429 - acc: 0.8877 - val_loss: 1.0354 - val_acc: 0.5196
Epoch 35/150
66/66 - 30s - loss: 0.1369 - acc: 0.8936 - val_loss: 1.0473 - val_acc: 0.5028
Epoch 36/150
66/66 - 30s - loss: 0.1223 - acc: 0.9046 - val_loss: 1.1253 - val_acc: 0.4637
Epoch 37/150
66/66 - 30s - loss: 0.1173 - acc: 0.8996 - val_loss: 1.0954 - val_acc: 0.5866
Epoch 38/150
66/66 - 30s - loss: 0.1135 - acc: 0.9039 - val_loss: 1.1672 - val_acc: 0.6145
Epoch 39/150
66/66 - 26s - loss: 0.1140 - acc: 0.8989 - val_loss: 1.1302 - val_acc: 0.4749
Epoch 40/150
66/66 - 30s - loss: 0.0923 - acc: 0.9234 - val_loss: 1.1186 - val_acc: 0.5084
Epoch 41/150
66/66 - 30s - loss: 0.0882 - acc: 0.9194 - val_loss: 1.1568 - val_acc: 0.4860
Epoch 42/150
66/66 - 30s - loss: 0.0853 - acc: 0.9208 - val_loss: 1.2621 - val_acc: 0.4525
Epoch 43/150
66/66 - 26s - loss: 0.0874 - acc: 0.9244 - val_loss: 1.3324 - val_acc: 0.4413
Epoch 44/150
66/66 - 30s - loss: 0.0818 - acc: 0.9246 - val_loss: 1.2106 - val_acc: 0.4525
Epoch 45/150
66/66 - 31s - loss: 0.0812 - acc: 0.9301 - val_loss: 1.1676 - val_acc: 0.5251
Epoch 46/150
66/66 - 30s - loss: 0.0677 - acc: 0.9358 - val_loss: 1.1514 - val_acc: 0.5363
Epoch 47/150
66/66 - 30s - loss: 0.0625 - acc: 0.9413 - val_loss: 1.1986 - val_acc: 0.4972
Epoch 48/150
66/66 - 30s - loss: 0.0616 - acc: 0.9406 - val_loss: 1.1630 - val_acc: 0.5028
Epoch 49/150
66/66 - 30s - loss: 0.0547 - acc: 0.9454 - val_loss: 1.2424 - val_acc: 0.4860
Epoch 50/150
66/66 - 30s - loss: 0.0521 - acc: 0.9437 - val_loss: 1.2222 - val_acc: 0.5196
Epoch 51/150
66/66 - 30s - loss: 0.0504 - acc: 0.9502 - val_loss: 1.2782 - val_acc: 0.4581
Epoch 52/150
66/66 - 26s - loss: 0.0523 - acc: 0.9482 - val_loss: 1.2791 - val_acc: 0.4693
Epoch 53/150
66/66 - 30s - loss: 0.0448 - acc: 0.9549 - val_loss: 1.3006 - val_acc: 0.4525
Epoch 54/150
66/66 - 26s - loss: 0.0523 - acc: 0.9409 - val_loss: 1.2784 - val_acc: 0.5140
Epoch 55/150
66/66 - 30s - loss: 0.0447 - acc: 0.9561 - val_loss: 1.2550 - val_acc: 0.5140
Epoch 56/150
66/66 - 26s - loss: 0.0455 - acc: 0.9504 - val_loss: 1.3371 - val_acc: 0.4581
Epoch 57/150
66/66 - 31s - loss: 0.0445 - acc: 0.9518 - val_loss: 1.2813 - val_acc: 0.5251
Epoch 58/150
66/66 - 30s - loss: 0.0440 - acc: 0.9542 - val_loss: 1.3267 - val_acc: 0.5084
Epoch 59/150
66/66 - 31s - loss: 0.0433 - acc: 0.9552 - val_loss: 1.4016 - val_acc: 0.4693
Epoch 60/150
66/66 - 31s - loss: 0.0420 - acc: 0.9583 - val_loss: 1.3372 - val_acc: 0.4860
Epoch 61/150
66/66 - 32s - loss: 0.0420 - acc: 0.9578 - val_loss: 1.2888 - val_acc: 0.5531
Epoch 62/150
66/66 - 32s - loss: 0.0396 - acc: 0.9623 - val_loss: 1.2720 - val_acc: 0.5419
Epoch 63/150
66/66 - 32s - loss: 0.0345 - acc: 0.9640 - val_loss: 1.3756 - val_acc: 0.5028
Epoch 64/150
66/66 - 26s - loss: 0.0430 - acc: 0.9533 - val_loss: 1.3826 - val_acc: 0.4916
Epoch 65/150
66/66 - 26s - loss: 0.0368 - acc: 0.9585 - val_loss: 1.3587 - val_acc: 0.5140
Epoch 66/150
66/66 - 26s - loss: 0.0458 - acc: 0.9504 - val_loss: 1.3621 - val_acc: 0.5587
Epoch 67/150
66/66 - 31s - loss: 0.0340 - acc: 0.9637 - val_loss: 1.3434 - val_acc: 0.5140
Epoch 68/150
66/66 - 26s - loss: 0.0340 - acc: 0.9649 - val_loss: 1.3429 - val_acc: 0.5196
Epoch 69/150
66/66 - 26s - loss: 0.0340 - acc: 0.9628 - val_loss: 1.4748 - val_acc: 0.4749
Epoch 70/150
66/66 - 26s - loss: 0.0341 - acc: 0.9652 - val_loss: 1.5259 - val_acc: 0.4860
Epoch 71/150
66/66 - 26s - loss: 0.0354 - acc: 0.9649 - val_loss: 1.4919 - val_acc: 0.4525
Epoch 72/150
66/66 - 31s - loss: 0.0326 - acc: 0.9671 - val_loss: 1.3858 - val_acc: 0.5698
Epoch 73/150
66/66 - 26s - loss: 0.0358 - acc: 0.9626 - val_loss: 1.4493 - val_acc: 0.5251
Epoch 74/150
66/66 - 26s - loss: 0.0373 - acc: 0.9637 - val_loss: 1.4429 - val_acc: 0.4693
Epoch 75/150
66/66 - 26s - loss: 0.0375 - acc: 0.9616 - val_loss: 1.5512 - val_acc: 0.4581
Epoch 76/150
66/66 - 26s - loss: 0.0367 - acc: 0.9664 - val_loss: 1.5383 - val_acc: 0.5084
Epoch 77/150
66/66 - 30s - loss: 0.0324 - acc: 0.9709 - val_loss: 1.4674 - val_acc: 0.5698
Epoch 78/150
66/66 - 26s - loss: 0.0389 - acc: 0.9580 - val_loss: 1.5708 - val_acc: 0.4749
Epoch 79/150
66/66 - 30s - loss: 0.0322 - acc: 0.9649 - val_loss: 1.4928 - val_acc: 0.5196
Epoch 80/150
66/66 - 30s - loss: 0.0313 - acc: 0.9692 - val_loss: 1.4520 - val_acc: 0.5531
Epoch 81/150
66/66 - 26s - loss: 0.0356 - acc: 0.9597 - val_loss: 1.5794 - val_acc: 0.5140
Epoch 82/150
66/66 - 26s - loss: 0.0329 - acc: 0.9666 - val_loss: 1.4148 - val_acc: 0.5754
Epoch 83/150
66/66 - 31s - loss: 0.0302 - acc: 0.9673 - val_loss: 1.4080 - val_acc: 0.5587
Epoch 84/150
66/66 - 31s - loss: 0.0268 - acc: 0.9773 - val_loss: 1.5495 - val_acc: 0.4804
Epoch 85/150
66/66 - 26s - loss: 0.0326 - acc: 0.9685 - val_loss: 1.5209 - val_acc: 0.4916
Epoch 86/150
66/66 - 26s - loss: 0.0300 - acc: 0.9702 - val_loss: 1.5754 - val_acc: 0.4860
Epoch 87/150
66/66 - 26s - loss: 0.0350 - acc: 0.9707 - val_loss: 1.4340 - val_acc: 0.5251
Epoch 88/150
66/66 - 30s - loss: 0.0265 - acc: 0.9723 - val_loss: 1.7270 - val_acc: 0.4246
Epoch 89/150
66/66 - 26s - loss: 0.0283 - acc: 0.9745 - val_loss: 1.4147 - val_acc: 0.5810
Epoch 90/150
66/66 - 26s - loss: 0.0303 - acc: 0.9668 - val_loss: 1.4604 - val_acc: 0.5251
Epoch 91/150
66/66 - 26s - loss: 0.0317 - acc: 0.9692 - val_loss: 1.5325 - val_acc: 0.4860
Epoch 92/150
66/66 - 26s - loss: 0.0282 - acc: 0.9752 - val_loss: 1.6168 - val_acc: 0.4804
Epoch 93/150
66/66 - 26s - loss: 0.0289 - acc: 0.9764 - val_loss: 1.5695 - val_acc: 0.4860
Epoch 94/150
66/66 - 26s - loss: 0.0342 - acc: 0.9721 - val_loss: 1.7633 - val_acc: 0.4246
Epoch 95/150
66/66 - 26s - loss: 0.0353 - acc: 0.9728 - val_loss: 1.4304 - val_acc: 0.5307
Epoch 96/150
66/66 - 26s - loss: 0.0304 - acc: 0.9707 - val_loss: 1.5920 - val_acc: 0.4916
Epoch 97/150
66/66 - 26s - loss: 0.0329 - acc: 0.9685 - val_loss: 1.4702 - val_acc: 0.5642
Epoch 98/150
66/66 - 30s - loss: 0.0247 - acc: 0.9764 - val_loss: 1.4892 - val_acc: 0.5251
Epoch 99/150
66/66 - 26s - loss: 0.0285 - acc: 0.9750 - val_loss: 1.6067 - val_acc: 0.4916
Epoch 100/150
66/66 - 26s - loss: 0.0318 - acc: 0.9731 - val_loss: 1.6441 - val_acc: 0.4693
Epoch 101/150
66/66 - 26s - loss: 0.0290 - acc: 0.9733 - val_loss: 1.6433 - val_acc: 0.4860
Epoch 102/150
66/66 - 26s - loss: 0.0258 - acc: 0.9728 - val_loss: 1.5133 - val_acc: 0.5084
Epoch 103/150
66/66 - 26s - loss: 0.0324 - acc: 0.9731 - val_loss: 1.5909 - val_acc: 0.4860
Epoch 104/150
66/66 - 26s - loss: 0.0309 - acc: 0.9714 - val_loss: 1.5262 - val_acc: 0.5642
Epoch 105/150
66/66 - 26s - loss: 0.0275 - acc: 0.9754 - val_loss: 1.5719 - val_acc: 0.6201
Epoch 106/150
66/66 - 26s - loss: 0.0276 - acc: 0.9771 - val_loss: 1.6380 - val_acc: 0.4525
Epoch 107/150
66/66 - 26s - loss: 0.0305 - acc: 0.9728 - val_loss: 1.5611 - val_acc: 0.5642
Epoch 108/150
66/66 - 26s - loss: 0.0254 - acc: 0.9742 - val_loss: 1.7233 - val_acc: 0.4525
Epoch 109/150
66/66 - 26s - loss: 0.0251 - acc: 0.9781 - val_loss: 1.6327 - val_acc: 0.4916
Epoch 110/150
66/66 - 26s - loss: 0.0345 - acc: 0.9704 - val_loss: 1.6941 - val_acc: 0.5419
Epoch 111/150
66/66 - 26s - loss: 0.0281 - acc: 0.9759 - val_loss: 1.5517 - val_acc: 0.5419
Epoch 112/150
66/66 - 26s - loss: 0.0317 - acc: 0.9800 - val_loss: 1.5207 - val_acc: 0.5587
Epoch 113/150
66/66 - 26s - loss: 0.0311 - acc: 0.9733 - val_loss: 1.6180 - val_acc: 0.5028
Epoch 114/150
66/66 - 26s - loss: 0.0305 - acc: 0.9757 - val_loss: 1.6696 - val_acc: 0.6145
Epoch 115/150
66/66 - 26s - loss: 0.0315 - acc: 0.9685 - val_loss: 1.5975 - val_acc: 0.4972
Epoch 116/150
66/66 - 26s - loss: 0.0306 - acc: 0.9731 - val_loss: 1.6481 - val_acc: 0.5196
Epoch 117/150
66/66 - 26s - loss: 0.0290 - acc: 0.9747 - val_loss: 1.6417 - val_acc: 0.5196
Epoch 118/150
66/66 - 26s - loss: 0.0288 - acc: 0.9757 - val_loss: 1.6564 - val_acc: 0.5028
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-20 14:21:26.111501: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-20 14:21:26.111645: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-20 14:21:26.111678: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-20 14:21:26.497642: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-20 14:21:26.497742: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00118: early stopping
Train for 66 steps, validate for 3 steps
Epoch 1/100
66/66 - 32s - loss: 0.6588 - acc: 0.7937 - val_loss: 1.0973 - val_acc: 0.5698
Epoch 2/100
66/66 - 26s - loss: 0.0734 - acc: 0.9482 - val_loss: 1.2749 - val_acc: 0.5642
Epoch 3/100
66/66 - 26s - loss: 0.0587 - acc: 0.9540 - val_loss: 1.5121 - val_acc: 0.5363
Epoch 4/100
66/66 - 26s - loss: 0.0886 - acc: 0.9430 - val_loss: 1.4366 - val_acc: 0.5642
Epoch 5/100
66/66 - 26s - loss: 0.0645 - acc: 0.9499 - val_loss: 1.4016 - val_acc: 0.5810
Epoch 6/100
66/66 - 26s - loss: 0.1187 - acc: 0.9234 - val_loss: 1.5140 - val_acc: 0.5475
Epoch 7/100
66/66 - 26s - loss: 0.0818 - acc: 0.9540 - val_loss: 1.8341 - val_acc: 0.4860
Epoch 8/100
66/66 - 26s - loss: 0.0878 - acc: 0.9513 - val_loss: 1.6203 - val_acc: 0.5251
Epoch 9/100
66/66 - 26s - loss: 0.1432 - acc: 0.9120 - val_loss: 1.2896 - val_acc: 0.5922
Epoch 10/100
66/66 - 26s - loss: 0.1028 - acc: 0.9361 - val_loss: 1.3721 - val_acc: 0.5810
Epoch 11/100
66/66 - 26s - loss: 0.0849 - acc: 0.9473 - val_loss: 1.3186 - val_acc: 0.5642
Epoch 12/100
66/66 - 26s - loss: 0.0742 - acc: 0.9630 - val_loss: 1.5367 - val_acc: 0.6369
Epoch 13/100
66/66 - 26s - loss: 0.0681 - acc: 0.9642 - val_loss: 1.4336 - val_acc: 0.6089
Epoch 14/100
66/66 - 26s - loss: 0.0517 - acc: 0.9759 - val_loss: 1.6053 - val_acc: 0.5251
Epoch 15/100
66/66 - 26s - loss: 0.0531 - acc: 0.9752 - val_loss: 1.5909 - val_acc: 0.6425
Epoch 16/100
66/66 - 26s - loss: 0.0585 - acc: 0.9685 - val_loss: 1.5375 - val_acc: 0.6369
Epoch 17/100
66/66 - 26s - loss: 0.0607 - acc: 0.9683 - val_loss: 1.4709 - val_acc: 0.6816
Epoch 18/100
66/66 - 26s - loss: 0.0595 - acc: 0.9771 - val_loss: 1.5247 - val_acc: 0.6648
Epoch 19/100
66/66 - 26s - loss: 0.0592 - acc: 0.9742 - val_loss: 1.4106 - val_acc: 0.6425
Epoch 20/100
66/66 - 26s - loss: 0.0567 - acc: 0.9711 - val_loss: 1.4687 - val_acc: 0.6034
Epoch 21/100
66/66 - 26s - loss: 0.0554 - acc: 0.9695 - val_loss: 1.8426 - val_acc: 0.4860
Epoch 22/100
66/66 - 26s - loss: 0.0465 - acc: 0.9769 - val_loss: 1.7631 - val_acc: 0.5531
Epoch 23/100
66/66 - 26s - loss: 0.0487 - acc: 0.9824 - val_loss: 1.7545 - val_acc: 0.4637
Epoch 24/100
66/66 - 26s - loss: 0.0492 - acc: 0.9814 - val_loss: 1.5545 - val_acc: 0.6145
Epoch 25/100
66/66 - 26s - loss: 0.0586 - acc: 0.9628 - val_loss: 1.5150 - val_acc: 0.5866
Epoch 26/100
66/66 - 26s - loss: 0.0430 - acc: 0.9778 - val_loss: 1.9682 - val_acc: 0.4581
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-20 14:32:44.471243: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-20 14:32:44.471428: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-20 14:32:44.471472: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-20 14:32:44.857002: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-20 14:32:44.857111: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00026: early stopping
Train for 66 steps, validate for 3 steps
Epoch 1/100
66/66 - 34s - loss: 2.1246 - acc: 0.2180 - val_loss: 1.2607 - val_acc: 0.6648
Epoch 2/100
66/66 - 34s - loss: 1.5091 - acc: 0.3625 - val_loss: 1.1637 - val_acc: 0.6369
Epoch 3/100
66/66 - 34s - loss: 1.4229 - acc: 0.4145 - val_loss: 1.1387 - val_acc: 0.5866
Epoch 4/100
66/66 - 34s - loss: 1.3458 - acc: 0.4612 - val_loss: 0.9907 - val_acc: 0.6760
Epoch 5/100
66/66 - 33s - loss: 1.2315 - acc: 0.5137 - val_loss: 1.0114 - val_acc: 0.6480
Epoch 6/100
66/66 - 33s - loss: 1.1424 - acc: 0.5531 - val_loss: 0.9672 - val_acc: 0.6648
Epoch 7/100
66/66 - 33s - loss: 1.0277 - acc: 0.6043 - val_loss: 1.0387 - val_acc: 0.5978
Epoch 8/100
66/66 - 33s - loss: 0.9369 - acc: 0.6370 - val_loss: 0.9793 - val_acc: 0.6480
Epoch 9/100
66/66 - 33s - loss: 0.8072 - acc: 0.6892 - val_loss: 0.9907 - val_acc: 0.6313
Epoch 10/100
66/66 - 35s - loss: 0.7191 - acc: 0.7267 - val_loss: 1.0284 - val_acc: 0.6425
Epoch 11/100
66/66 - 33s - loss: 0.6431 - acc: 0.7613 - val_loss: 1.1098 - val_acc: 0.5698
Epoch 12/100
66/66 - 33s - loss: 0.5659 - acc: 0.7963 - val_loss: 1.1399 - val_acc: 0.5866
Epoch 13/100
66/66 - 33s - loss: 0.5091 - acc: 0.8226 - val_loss: 1.0323 - val_acc: 0.6369
Epoch 14/100
66/66 - 34s - loss: 0.4567 - acc: 0.8459 - val_loss: 1.1024 - val_acc: 0.5698
Epoch 15/100
66/66 - 34s - loss: 0.4287 - acc: 0.8526 - val_loss: 1.0657 - val_acc: 0.6089
Epoch 16/100
66/66 - 33s - loss: 0.3792 - acc: 0.8729 - val_loss: 1.3171 - val_acc: 0.5754
Epoch 17/100
66/66 - 33s - loss: 0.3209 - acc: 0.8996 - val_loss: 1.3329 - val_acc: 0.5196
Epoch 18/100
66/66 - 33s - loss: 0.3159 - acc: 0.9008 - val_loss: 1.6332 - val_acc: 0.4469
Epoch 19/100
66/66 - 33s - loss: 0.3003 - acc: 0.9070 - val_loss: 1.3926 - val_acc: 0.5419
Epoch 20/100
66/66 - 34s - loss: 0.2449 - acc: 0.9313 - val_loss: 1.3299 - val_acc: 0.6145
Epoch 21/100
66/66 - 33s - loss: 0.2273 - acc: 0.9358 - val_loss: 1.2919 - val_acc: 0.5810
Epoch 22/100
66/66 - 33s - loss: 0.2183 - acc: 0.9399 - val_loss: 1.5776 - val_acc: 0.5642
Epoch 23/100
66/66 - 33s - loss: 0.1962 - acc: 0.9499 - val_loss: 1.3423 - val_acc: 0.6313
Epoch 24/100
66/66 - 33s - loss: 0.1717 - acc: 0.9580 - val_loss: 1.5706 - val_acc: 0.5866
Epoch 25/100
66/66 - 33s - loss: 0.1609 - acc: 0.9609 - val_loss: 1.3376 - val_acc: 0.6592
Epoch 26/100
66/66 - 33s - loss: 0.1531 - acc: 0.9661 - val_loss: 1.5686 - val_acc: 0.5866
Epoch 27/100
66/66 - 26s - loss: 0.1578 - acc: 0.9604 - val_loss: 1.5830 - val_acc: 0.6145
Epoch 28/100
66/66 - 33s - loss: 0.1331 - acc: 0.9735 - val_loss: 1.5680 - val_acc: 0.6313
Epoch 29/100
66/66 - 34s - loss: 0.1191 - acc: 0.9764 - val_loss: 1.6281 - val_acc: 0.6201
Epoch 30/100
66/66 - 26s - loss: 0.1226 - acc: 0.9762 - val_loss: 1.5642 - val_acc: 0.6480
Epoch 31/100
66/66 - 26s - loss: 0.1432 - acc: 0.9640 - val_loss: 1.5533 - val_acc: 0.6257
Epoch 00031: early stopping
Accuracy on original test dataset: 50.0%
tf.Tensor(
[[159  39   3   0   1]
 [ 44  13   1   0   0]
 [ 56   9   1   0   4]
 [  8   0   2   0   0]
 [  3   0   2   1   0]], shape=(5, 5), dtype=int32)
Correct: 173, wrong: 173, accuracy: 50.0%

Mean probability on true label of original test dataset when correctly predicted = 99.82%
Mean uncertainty on true label of original test dataset when correctly predicted = 6.87%
Mean probability on true label of original test dataset when wrongly predicted = 0.00%
Mean uncertainty on true label of original test dataset when wrongly predicted = 5.83%

Mean probability on highest predicted on original test dataset when wrong = 100.00%
Mean uncertainty on highest predicted on original test dataset when wrong = 10.00%

Mean probability on all not true label on original test dataset = 12.52%
Mean uncertainty on all not true label on original test dataset = 23.41%
creating scatterplot
Accuracy on original test dataset: 50.0%
tf.Tensor(
[[159  39   3   0   1]
 [ 44  13   1   0   0]
 [ 56   9   1   0   4]
 [  8   0   2   0   0]
 [  3   0   2   1   0]], shape=(5, 5), dtype=int32)
Correct: 173, wrong: 173, accuracy: 50.0%

Mean probability on true label of original test dataset when correctly predicted = 99.82%
Mean uncertainty on true label of original test dataset when correctly predicted = 6.82%
Mean probability on true label of original test dataset when wrongly predicted = 0.00%
Mean uncertainty on true label of original test dataset when wrongly predicted = 5.83%

Mean probability on highest predicted on original test dataset when wrong = 100.00%
Mean uncertainty on highest predicted on original test dataset when wrong = 10.00%

Mean probability on all not true label on original test dataset = 12.52%
Mean uncertainty on all not true label on original test dataset = 23.42%
creating scatterplot
0.5


###############################################################################
Peregrine Cluster
Job 11623293 for user 's2934833'
Finished at: Wed May 20 14:49:40 CEST 2020

Job details:
============

Name                : MESVAR
User                : s2934833
Partition           : gpu
Nodes               : pg-gpu37
Cores               : 12
State               : COMPLETED
Submit              : 2020-05-20T12:03:41
Start               : 2020-05-20T13:25:03
End                 : 2020-05-20T14:49:40
Reserved walltime   : 08:00:00
Used walltime       : 01:24:37
Used CPU time       : 01:09:45 (efficiency:  6.87%)
% User (Computation): 64.05%
% System (I/O)      : 35.95%
Mem reserved        : 32000M/node
Max Mem used        : 10.12G (pg-gpu37)
Max Disk Write      : 153.60K (pg-gpu37)
Max Disk Read       : 5.83M (pg-gpu37)
Average GPU usage   : 90.8% (pg-gpu37)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/additional_information/scientific_output

################################################################################
