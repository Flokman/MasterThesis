
The following have been reloaded with a version change:
  1) FFTW/3.3.8-gompic-2019b => FFTW/3.3.8-gompi-2019b
  2) OpenMPI/3.1.4-gcccuda-2019b => OpenMPI/3.1.4-GCC-8.3.0
  3) ScaLAPACK/2.0.2-gompic-2019b => ScaLAPACK/2.0.2-gompi-2019b
  4) SciPy-bundle/2019.10-fosscuda-2019b-Python-3.7.4 => SciPy-bundle/2019.10-foss-2019b-Python-3.7.4

2020-05-11 12:58:42.297818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-11 12:58:57.233540: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-05-11 12:58:57.240032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-11 12:58:57.240522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-11 12:58:57.240609: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-11 12:58:57.245303: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-11 12:58:57.248556: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-11 12:58:57.249991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-11 12:58:57.253198: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-11 12:58:57.255349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-11 12:58:57.260238: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-11 12:58:57.260456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-11 12:58:57.261028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-11 12:58:57.261964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-05-11 12:58:57.264552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-11 12:58:57.264980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-11 12:58:57.265075: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-11 12:58:57.265154: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-11 12:58:57.265217: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-11 12:58:57.265279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-11 12:58:57.265341: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-11 12:58:57.265402: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-11 12:58:57.265463: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-11 12:58:57.265602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-11 12:58:57.266083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-11 12:58:57.266474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-05-11 12:58:57.266562: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-11 12:58:57.890406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-11 12:58:57.890536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-05-11 12:58:57.890593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-05-11 12:58:57.890898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-11 12:58:57.891519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-11 12:58:57.892038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-11 12:58:57.892490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28652 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2020-05-11 12:58:57.892839: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-11 12:59:00.917149: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-11 12:59:01.166812: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-11 12:59:02.952685: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-11 12:59:02.952834: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1259] Profiler found 1 GPUs
2020-05-11 12:59:02.955259: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1
2020-05-11 12:59:03.055805: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-05-11 12:59:03.056386: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-05-11 12:59:03.076142: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-11 12:59:03.076262: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
dataset_name = /CIFAR10, batch_size = 64, num_classes = 10, epochs_1 = 150,
        epochts_2 = 30, test_img_idx = 4695,
        train_test_split = 0.8
        learn rate = 1e-05,
        train_all_layers = True, weights_to_use = imagenet,
        es_patience_1 = 20, es_patience_2 = 5, train_val_split = 0.9
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 test samples
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
block1_conv1 (Conv2D)           (None, 32, 32, 64)   1792        input_1[0][0]                    
__________________________________________________________________________________________________
block1_conv2 (Conv2D)           (None, 32, 32, 64)   36928       block1_conv1[1][0]               
__________________________________________________________________________________________________
block1_pool (MaxPooling2D)      (None, 16, 16, 64)   0           block1_conv2[1][0]               
__________________________________________________________________________________________________
block2_conv1 (Conv2D)           (None, 16, 16, 128)  73856       block1_pool[1][0]                
__________________________________________________________________________________________________
block2_conv2 (Conv2D)           (None, 16, 16, 128)  147584      block2_conv1[1][0]               
__________________________________________________________________________________________________
block2_pool (MaxPooling2D)      (None, 8, 8, 128)    0           block2_conv2[1][0]               
__________________________________________________________________________________________________
block3_conv1 (Conv2D)           (None, 8, 8, 256)    295168      block2_pool[1][0]                
__________________________________________________________________________________________________
block3_conv2 (Conv2D)           (None, 8, 8, 256)    590080      block3_conv1[1][0]               
__________________________________________________________________________________________________
block3_conv3 (Conv2D)           (None, 8, 8, 256)    590080      block3_conv2[1][0]               
__________________________________________________________________________________________________
block3_pool (MaxPooling2D)      (None, 4, 4, 256)    0           block3_conv3[1][0]               
__________________________________________________________________________________________________
block4_conv1 (Conv2D)           (None, 4, 4, 512)    1180160     block3_pool[1][0]                
__________________________________________________________________________________________________
block4_conv2 (Conv2D)           (None, 4, 4, 512)    2359808     block4_conv1[1][0]               
__________________________________________________________________________________________________
block4_conv3 (Conv2D)           (None, 4, 4, 512)    2359808     block4_conv2[1][0]               
__________________________________________________________________________________________________
block4_pool (MaxPooling2D)      (None, 2, 2, 512)    0           block4_conv3[1][0]               
__________________________________________________________________________________________________
block5_conv1 (Conv2D)           (None, 2, 2, 512)    2359808     block4_pool[1][0]                
__________________________________________________________________________________________________
block5_conv2 (Conv2D)           (None, 2, 2, 512)    2359808     block5_conv1[1][0]               
__________________________________________________________________________________________________
block5_conv3 (Conv2D)           (None, 2, 2, 512)    2359808     block5_conv2[1][0]               
__________________________________________________________________________________________________
block5_pool (MaxPooling2D)      (None, 1, 1, 512)    0           block5_conv3[1][0]               
__________________________________________________________________________________________________
flatten (Flatten)               (None, 512)          0           block5_pool[1][0]                
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 4096)         2101248     flatten[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        
__________________________________________________________________________________________________
dense (Dense)                   (None, 10)           40970       fc2[0][0]                        
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           40970       fc2[0][0]                        
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 20)           0           dense[0][0]                      
                                                                 dense_1[0][0]                    
==================================================================================================
Total params: 33,679,188
Trainable params: 33,679,188
Non-trainable params: 0
__________________________________________________________________________________________________
Start fitting
Train for 704 steps, validate for 79 steps
Epoch 1/150
704/704 - 18s - loss: 0.0180 - acc: 0.3757 - val_loss: 0.0114 - val_acc: 0.2958
Epoch 2/150
704/704 - 13s - loss: 0.0101 - acc: 0.2605 - val_loss: 0.0091 - val_acc: 0.2076
Epoch 3/150
704/704 - 15s - loss: 0.0081 - acc: 0.2128 - val_loss: 0.0083 - val_acc: 0.1716
Epoch 4/150
704/704 - 14s - loss: 0.0068 - acc: 0.1904 - val_loss: 0.0075 - val_acc: 0.1542
Epoch 5/150
704/704 - 13s - loss: 0.0058 - acc: 0.1692 - val_loss: 0.0070 - val_acc: 0.1456
Epoch 6/150
704/704 - 14s - loss: 0.0049 - acc: 0.1564 - val_loss: 0.0068 - val_acc: 0.1278
Epoch 7/150
704/704 - 13s - loss: 0.0041 - acc: 0.1466 - val_loss: 0.0067 - val_acc: 0.1184
Epoch 8/150
704/704 - 14s - loss: 0.0037 - acc: 0.1326 - val_loss: 0.0065 - val_acc: 0.1098
Epoch 9/150
704/704 - 13s - loss: 0.0030 - acc: 0.1200 - val_loss: 0.0062 - val_acc: 0.1008
Epoch 10/150
704/704 - 13s - loss: 0.0026 - acc: 0.1056 - val_loss: 0.0063 - val_acc: 0.1014
Epoch 11/150
704/704 - 13s - loss: 0.0023 - acc: 0.0928 - val_loss: 0.0065 - val_acc: 0.0876
Epoch 12/150
704/704 - 14s - loss: 0.0020 - acc: 0.0773 - val_loss: 0.0064 - val_acc: 0.0800
Epoch 13/150
704/704 - 13s - loss: 0.0017 - acc: 0.0646 - val_loss: 0.0063 - val_acc: 0.0788
Epoch 14/150
704/704 - 13s - loss: 0.0014 - acc: 0.0530 - val_loss: 0.0063 - val_acc: 0.0642
Epoch 15/150
704/704 - 13s - loss: 0.0012 - acc: 0.0402 - val_loss: 0.0065 - val_acc: 0.0606
Epoch 16/150
704/704 - 14s - loss: 0.0012 - acc: 0.0350 - val_loss: 0.0062 - val_acc: 0.0584
Epoch 17/150
704/704 - 13s - loss: 9.3185e-04 - acc: 0.0266 - val_loss: 0.0067 - val_acc: 0.0460
Epoch 18/150
704/704 - 13s - loss: 8.3736e-04 - acc: 0.0222 - val_loss: 0.0071 - val_acc: 0.0534
Epoch 19/150
704/704 - 13s - loss: 8.0485e-04 - acc: 0.0185 - val_loss: 0.0067 - val_acc: 0.0456
Epoch 20/150
704/704 - 13s - loss: 5.8895e-04 - acc: 0.0132 - val_loss: 0.0076 - val_acc: 0.0572
Epoch 21/150
704/704 - 12s - loss: 6.5229e-04 - acc: 0.0123 - val_loss: 0.0068 - val_acc: 0.0408
Epoch 22/150
704/704 - 13s - loss: 5.3878e-04 - acc: 0.0089 - val_loss: 0.0080 - val_acc: 0.0508
Epoch 23/150
704/704 - 13s - loss: 4.4961e-04 - acc: 0.0068 - val_loss: 0.0072 - val_acc: 0.0412
Epoch 24/150
704/704 - 12s - loss: 4.5757e-04 - acc: 0.0053 - val_loss: 0.0079 - val_acc: 0.0406
Epoch 25/150
704/704 - 12s - loss: 5.2389e-04 - acc: 0.0054 - val_loss: 0.0072 - val_acc: 0.0418
Epoch 26/150
704/704 - 13s - loss: 2.3373e-04 - acc: 0.0022 - val_loss: 0.0075 - val_acc: 0.0348
Epoch 27/150
704/704 - 12s - loss: 4.3671e-04 - acc: 0.0036 - val_loss: 0.0077 - val_acc: 0.0404
Epoch 28/150
704/704 - 12s - loss: 2.9890e-04 - acc: 0.0019 - val_loss: 0.0086 - val_acc: 0.0348
Epoch 29/150
704/704 - 12s - loss: 2.9499e-04 - acc: 0.0017 - val_loss: 0.0077 - val_acc: 0.0326
Epoch 30/150
704/704 - 13s - loss: 1.0637e-04 - acc: 2.2222e-04 - val_loss: 0.0079 - val_acc: 0.0312
Epoch 31/150
704/704 - 12s - loss: 5.0087e-04 - acc: 0.0040 - val_loss: 0.0076 - val_acc: 0.0386
Epoch 32/150
704/704 - 13s - loss: 1.7030e-04 - acc: 8.2222e-04 - val_loss: 0.0077 - val_acc: 0.0392
Epoch 33/150
704/704 - 13s - loss: 3.4866e-04 - acc: 0.0025 - val_loss: 0.0074 - val_acc: 0.0326
Epoch 34/150
704/704 - 13s - loss: 1.0626e-04 - acc: 4.0000e-04 - val_loss: 0.0079 - val_acc: 0.0354
Epoch 35/150
704/704 - 12s - loss: 2.2044e-04 - acc: 0.0010 - val_loss: 0.0089 - val_acc: 0.0314
Epoch 36/150
704/704 - 12s - loss: 2.1369e-04 - acc: 0.0012 - val_loss: 0.0086 - val_acc: 0.0348
Epoch 37/150
704/704 - 12s - loss: 3.0282e-04 - acc: 0.0018 - val_loss: 0.0078 - val_acc: 0.0344
Epoch 38/150
704/704 - 13s - loss: 9.0759e-05 - acc: 4.0000e-04 - val_loss: 0.0080 - val_acc: 0.0304
Epoch 39/150
704/704 - 12s - loss: 1.7120e-04 - acc: 0.0017 - val_loss: 0.0081 - val_acc: 0.0338
Epoch 40/150
704/704 - 12s - loss: 2.6522e-04 - acc: 0.0021 - val_loss: 0.0081 - val_acc: 0.0372
Epoch 41/150
704/704 - 12s - loss: 1.2380e-04 - acc: 7.5556e-04 - val_loss: 0.0093 - val_acc: 0.0390
Epoch 42/150
704/704 - 12s - loss: 2.2947e-04 - acc: 0.0011 - val_loss: 0.0082 - val_acc: 0.0386
Epoch 43/150
704/704 - 12s - loss: 2.2555e-04 - acc: 0.0017 - val_loss: 0.0085 - val_acc: 0.0426
Epoch 44/150
704/704 - 12s - loss: 1.2692e-04 - acc: 8.0000e-04 - val_loss: 0.0080 - val_acc: 0.0352
Epoch 45/150
704/704 - 13s - loss: 7.5696e-05 - acc: 3.1111e-04 - val_loss: 0.0080 - val_acc: 0.0354
Epoch 46/150
704/704 - 12s - loss: 2.1744e-04 - acc: 0.0016 - val_loss: 0.0076 - val_acc: 0.0400
Epoch 47/150
704/704 - 12s - loss: 1.7247e-04 - acc: 0.0013 - val_loss: 0.0079 - val_acc: 0.0336
Epoch 48/150
704/704 - 12s - loss: 1.3712e-04 - acc: 0.0011 - val_loss: 0.0082 - val_acc: 0.0336
Epoch 49/150
704/704 - 12s - loss: 1.1300e-04 - acc: 9.7778e-04 - val_loss: 0.0083 - val_acc: 0.0390
Epoch 50/150
704/704 - 12s - loss: 2.1544e-04 - acc: 0.0020 - val_loss: 0.0077 - val_acc: 0.0376
Epoch 51/150
704/704 - 13s - loss: 5.8006e-05 - acc: 3.5556e-04 - val_loss: 0.0080 - val_acc: 0.0322
Epoch 52/150
704/704 - 14s - loss: 1.2199e-05 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0330
Epoch 53/150
704/704 - 13s - loss: 9.5617e-06 - acc: 0.0000e+00 - val_loss: 0.0082 - val_acc: 0.0316
Epoch 54/150
704/704 - 12s - loss: 4.2197e-04 - acc: 0.0044 - val_loss: 0.0079 - val_acc: 0.0392
Epoch 55/150
704/704 - 12s - loss: 9.2985e-05 - acc: 7.5556e-04 - val_loss: 0.0088 - val_acc: 0.0402
Epoch 56/150
704/704 - 12s - loss: 8.3827e-05 - acc: 8.6667e-04 - val_loss: 0.0078 - val_acc: 0.0342
Epoch 57/150
704/704 - 13s - loss: 9.6382e-06 - acc: 0.0000e+00 - val_loss: 0.0079 - val_acc: 0.0320
Epoch 58/150
704/704 - 14s - loss: 6.6266e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0330
Epoch 59/150
704/704 - 13s - loss: 5.4790e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0310
Epoch 60/150
704/704 - 12s - loss: 5.6816e-06 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0302
Epoch 61/150
704/704 - 13s - loss: 3.9611e-06 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0306
Epoch 62/150
704/704 - 12s - loss: 3.1623e-04 - acc: 0.0041 - val_loss: 0.0080 - val_acc: 0.0548
Epoch 63/150
704/704 - 12s - loss: 2.7896e-04 - acc: 0.0035 - val_loss: 0.0077 - val_acc: 0.0402
Epoch 64/150
704/704 - 12s - loss: 5.6386e-05 - acc: 4.2222e-04 - val_loss: 0.0080 - val_acc: 0.0340
Epoch 65/150
704/704 - 12s - loss: 1.6933e-04 - acc: 0.0021 - val_loss: 0.0078 - val_acc: 0.0396
Epoch 66/150
704/704 - 12s - loss: 7.9362e-05 - acc: 7.5556e-04 - val_loss: 0.0077 - val_acc: 0.0336
Epoch 67/150
704/704 - 12s - loss: 1.3629e-05 - acc: 2.2222e-04 - val_loss: 0.0078 - val_acc: 0.0338
Epoch 68/150
704/704 - 12s - loss: 5.1951e-06 - acc: 0.0000e+00 - val_loss: 0.0079 - val_acc: 0.0320
Epoch 69/150
704/704 - 12s - loss: 4.5518e-06 - acc: 0.0000e+00 - val_loss: 0.0079 - val_acc: 0.0306
Epoch 70/150
704/704 - 13s - loss: 3.6602e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0306
Epoch 71/150
704/704 - 13s - loss: 3.3334e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0308
Epoch 72/150
704/704 - 13s - loss: 3.1130e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0302
Epoch 73/150
704/704 - 12s - loss: 3.6150e-04 - acc: 0.0038 - val_loss: 0.0083 - val_acc: 0.0360
Epoch 74/150
704/704 - 12s - loss: 9.2613e-05 - acc: 0.0012 - val_loss: 0.0084 - val_acc: 0.0394
Epoch 75/150
704/704 - 12s - loss: 1.0279e-04 - acc: 0.0011 - val_loss: 0.0084 - val_acc: 0.0348
Epoch 76/150
704/704 - 12s - loss: 1.0320e-04 - acc: 0.0011 - val_loss: 0.0082 - val_acc: 0.0352
Epoch 77/150
704/704 - 12s - loss: 9.7951e-05 - acc: 0.0012 - val_loss: 0.0081 - val_acc: 0.0360
Epoch 78/150
704/704 - 12s - loss: 1.0061e-05 - acc: 2.2222e-05 - val_loss: 0.0079 - val_acc: 0.0352
Epoch 79/150
704/704 - 12s - loss: 4.2836e-06 - acc: 0.0000e+00 - val_loss: 0.0079 - val_acc: 0.0346
Epoch 80/150
704/704 - 12s - loss: 3.2681e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0332
Epoch 81/150
704/704 - 12s - loss: 3.3474e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0326
Epoch 82/150
704/704 - 13s - loss: 2.8073e-06 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0330
Epoch 83/150
704/704 - 13s - loss: 2.5149e-06 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0316
Epoch 84/150
704/704 - 12s - loss: 3.0074e-06 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0316
Epoch 85/150
704/704 - 13s - loss: 2.2355e-06 - acc: 0.0000e+00 - val_loss: 0.0082 - val_acc: 0.0312
Epoch 86/150
704/704 - 12s - loss: 3.3802e-04 - acc: 0.0042 - val_loss: 0.0080 - val_acc: 0.0362
Epoch 87/150
704/704 - 12s - loss: 9.3771e-05 - acc: 0.0013 - val_loss: 0.0083 - val_acc: 0.0414
Epoch 88/150
704/704 - 12s - loss: 1.0241e-04 - acc: 0.0013 - val_loss: 0.0076 - val_acc: 0.0430
Epoch 89/150
704/704 - 12s - loss: 1.1996e-05 - acc: 8.8889e-05 - val_loss: 0.0078 - val_acc: 0.0330
Epoch 90/150
704/704 - 12s - loss: 3.4249e-06 - acc: 0.0000e+00 - val_loss: 0.0078 - val_acc: 0.0322
Epoch 91/150
704/704 - 12s - loss: 3.1465e-06 - acc: 0.0000e+00 - val_loss: 0.0079 - val_acc: 0.0310
Epoch 92/150
704/704 - 12s - loss: 2.3631e-06 - acc: 0.0000e+00 - val_loss: 0.0079 - val_acc: 0.0306
Epoch 93/150
704/704 - 12s - loss: 2.6866e-06 - acc: 0.0000e+00 - val_loss: 0.0079 - val_acc: 0.0296
Epoch 94/150
704/704 - 13s - loss: 2.0655e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0308
Epoch 95/150
704/704 - 12s - loss: 2.1540e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0300
Epoch 96/150
704/704 - 13s - loss: 1.6594e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0294
Epoch 97/150
704/704 - 12s - loss: 1.7715e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0304
Epoch 98/150
704/704 - 12s - loss: 1.7010e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0290
Epoch 99/150
704/704 - 13s - loss: 1.3416e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0298
Epoch 100/150
704/704 - 12s - loss: 1.4271e-06 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0288
Epoch 101/150
704/704 - 12s - loss: 4.1391e-04 - acc: 0.0049 - val_loss: 0.0096 - val_acc: 0.0372
Epoch 102/150
704/704 - 12s - loss: 7.5070e-05 - acc: 8.8889e-04 - val_loss: 0.0081 - val_acc: 0.0374
Epoch 103/150
704/704 - 12s - loss: 1.0787e-04 - acc: 0.0010 - val_loss: 0.0113 - val_acc: 0.0448
Epoch 104/150
704/704 - 12s - loss: 1.1183e-04 - acc: 0.0014 - val_loss: 0.0081 - val_acc: 0.0384
Epoch 105/150
704/704 - 12s - loss: 1.8408e-05 - acc: 1.3333e-04 - val_loss: 0.0080 - val_acc: 0.0348
Epoch 106/150
704/704 - 12s - loss: 1.2770e-05 - acc: 2.6667e-04 - val_loss: 0.0080 - val_acc: 0.0352
Epoch 107/150
704/704 - 12s - loss: 2.9172e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0344
Epoch 108/150
704/704 - 12s - loss: 1.9519e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0340
Epoch 109/150
704/704 - 13s - loss: 1.9318e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0332
Epoch 110/150
704/704 - 12s - loss: 1.6269e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0328
Epoch 111/150
704/704 - 12s - loss: 1.5123e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0324
Epoch 112/150
704/704 - 12s - loss: 1.4884e-06 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0320
Epoch 113/150
704/704 - 12s - loss: 1.7527e-06 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0312
Epoch 114/150
704/704 - 13s - loss: 1.3078e-06 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0318
Epoch 115/150
704/704 - 13s - loss: 1.2535e-06 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0320
Epoch 116/150
704/704 - 15s - loss: 1.0845e-06 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0308
Epoch 117/150
704/704 - 12s - loss: 2.7192e-04 - acc: 0.0027 - val_loss: 0.0079 - val_acc: 0.0418
Epoch 118/150
704/704 - 12s - loss: 4.9716e-05 - acc: 0.0012 - val_loss: 0.0083 - val_acc: 0.0468
Epoch 119/150
704/704 - 12s - loss: 8.7923e-05 - acc: 0.0010 - val_loss: 0.0078 - val_acc: 0.0402
Epoch 120/150
704/704 - 12s - loss: 1.2105e-05 - acc: 2.8889e-04 - val_loss: 0.0081 - val_acc: 0.0386
Epoch 121/150
704/704 - 12s - loss: 2.0416e-04 - acc: 0.0033 - val_loss: 0.0078 - val_acc: 0.0452
Epoch 122/150
704/704 - 12s - loss: 4.3525e-05 - acc: 8.2222e-04 - val_loss: 0.0078 - val_acc: 0.0440
Epoch 123/150
704/704 - 12s - loss: 4.0689e-06 - acc: 0.0000e+00 - val_loss: 0.0079 - val_acc: 0.0400
Epoch 124/150
704/704 - 12s - loss: 1.9541e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0388
Epoch 125/150
704/704 - 12s - loss: 1.6985e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0390
Epoch 126/150
704/704 - 12s - loss: 1.7531e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0370
Epoch 127/150
704/704 - 12s - loss: 1.6017e-06 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0368
Epoch 128/150
704/704 - 12s - loss: 1.2511e-06 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0368
Epoch 129/150
704/704 - 12s - loss: 1.3072e-06 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0366
Epoch 130/150
704/704 - 12s - loss: 1.1824e-06 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0362
Epoch 131/150
704/704 - 12s - loss: 1.5753e-06 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0346
Epoch 132/150
704/704 - 13s - loss: 8.9713e-07 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0360
Epoch 133/150
704/704 - 12s - loss: 1.1396e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0346
Epoch 134/150
704/704 - 13s - loss: 8.6152e-07 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0352
Epoch 135/150
704/704 - 12s - loss: 2.3892e-04 - acc: 0.0034 - val_loss: 0.0076 - val_acc: 0.0506
Epoch 136/150
704/704 - 12s - loss: 1.1510e-04 - acc: 0.0021 - val_loss: 0.0077 - val_acc: 0.0412
Epoch 137/150
704/704 - 12s - loss: 5.3238e-05 - acc: 7.1111e-04 - val_loss: 0.0078 - val_acc: 0.0388
Epoch 138/150
704/704 - 12s - loss: 7.8858e-06 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0374
Epoch 139/150
704/704 - 12s - loss: 7.6286e-05 - acc: 9.3333e-04 - val_loss: 0.0087 - val_acc: 0.0524
Epoch 140/150
704/704 - 12s - loss: 9.9211e-05 - acc: 0.0020 - val_loss: 0.0080 - val_acc: 0.0398
Epoch 141/150
704/704 - 12s - loss: 5.7476e-06 - acc: 6.6667e-05 - val_loss: 0.0081 - val_acc: 0.0380
Epoch 142/150
704/704 - 12s - loss: 6.3299e-05 - acc: 0.0012 - val_loss: 0.0080 - val_acc: 0.0404
Epoch 143/150
704/704 - 12s - loss: 9.8767e-05 - acc: 0.0014 - val_loss: 0.0077 - val_acc: 0.0388
Epoch 144/150
704/704 - 12s - loss: 3.3933e-06 - acc: 2.2222e-05 - val_loss: 0.0078 - val_acc: 0.0350
Epoch 145/150
704/704 - 12s - loss: 1.6686e-06 - acc: 0.0000e+00 - val_loss: 0.0079 - val_acc: 0.0350
Epoch 146/150
704/704 - 12s - loss: 1.5081e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0342
Epoch 147/150
704/704 - 12s - loss: 1.6399e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0352
Epoch 148/150
704/704 - 12s - loss: 1.2977e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0348
Epoch 149/150
704/704 - 12s - loss: 1.2510e-06 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0354
Epoch 150/150
704/704 - 12s - loss: 1.0767e-06 - acc: 0.0000e+00 - val_loss: 0.0081 - val_acc: 0.0350
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-11 13:30:37.583426: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-11 13:30:37.583607: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-11 13:30:37.583680: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-11 13:30:37.601696: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-11 13:30:37.601807: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Train for 704 steps, validate for 79 steps
Epoch 1/30
704/704 - 16s - loss: 0.0409 - acc: 0.9807 - val_loss: 0.7938 - val_acc: 0.8442
Epoch 2/30
704/704 - 14s - loss: 0.0090 - acc: 0.9969 - val_loss: 0.7720 - val_acc: 0.8472
Epoch 3/30
704/704 - 12s - loss: 0.0043 - acc: 0.9982 - val_loss: 0.9565 - val_acc: 0.8418
Epoch 4/30
704/704 - 12s - loss: 0.0094 - acc: 0.9965 - val_loss: 0.8083 - val_acc: 0.8504
Epoch 5/30
704/704 - 12s - loss: 0.0062 - acc: 0.9977 - val_loss: 0.8975 - val_acc: 0.8376
Epoch 6/30
704/704 - 12s - loss: 0.0049 - acc: 0.9978 - val_loss: 0.8991 - val_acc: 0.8382
Epoch 7/30
704/704 - 12s - loss: 0.0074 - acc: 0.9972 - val_loss: 0.8275 - val_acc: 0.8486
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-11 13:32:09.525069: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-11 13:32:09.525254: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-11 13:32:09.525328: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED
2020-05-11 13:32:09.543830: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-11 13:32:09.543971: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
Epoch 00007: early stopping
Train for 704 steps, validate for 79 steps
Epoch 1/30
704/704 - 17s - loss: 0.0479 - acc: 0.9908 - val_loss: 0.8021 - val_acc: 0.8568
Epoch 2/30
704/704 - 15s - loss: 0.0194 - acc: 0.9973 - val_loss: 0.8463 - val_acc: 0.8538
Epoch 3/30
704/704 - 14s - loss: 0.0156 - acc: 0.9985 - val_loss: 0.8920 - val_acc: 0.8600
Epoch 4/30
704/704 - 12s - loss: 0.0180 - acc: 0.9975 - val_loss: 0.8688 - val_acc: 0.8572
Epoch 5/30
704/704 - 12s - loss: 0.0174 - acc: 0.9979 - val_loss: 0.8740 - val_acc: 0.8514
Epoch 6/30
704/704 - 12s - loss: 0.0166 - acc: 0.9979 - val_loss: 0.9445 - val_acc: 0.8500
Epoch 00006: early stopping
Accuracy on original test dataset: 71.5%
tf.Tensor(
[[877  46  37   3   0   4   3   4   9  17]
 [  8 973   2   1   0   2   0   0   1  13]
 [ 59  28 784  16   5  68  25   9   2   4]
 [ 42  61  72 425   6 320  29  16   6  23]
 [ 68  49 163  37 351 189  55  68  10  10]
 [ 21  29  33  66   1 824   5  12   1   8]
 [ 21 100  58  24   3  70 704   1   7  12]
 [ 28  23  39  22   3  99   2 763   1  20]
 [144 131   6   1   0   3   1   0 683  31]
 [ 25 200   4   0   0   0   0   0   7 764]], shape=(10, 10), dtype=int32)
Correct: 7148, wrong: 2852, accuracy: 71.48%

Mean probability on true label of original test dataset when correctly predicted = 99.90%
Mean uncertainty on true label of original test dataset when correctly predicted = 1.02%
Mean probability on true label of original test dataset when wrongly predicted = 0.24%
Mean uncertainty on true label of original test dataset when wrongly predicted = 8.83%

Mean probability on highest predicted on original test dataset when wrong = 99.30%
Mean uncertainty on highest predicted on original test dataset when wrong = 5.39%

Mean probability on all not true label on original test dataset = 3.17%
Mean uncertainty on all not true label on original test dataset = 10.76%
creating scatterplot
0.7148


###############################################################################
Peregrine Cluster
Job 11369062 for user 's2934833'
Finished at: Mon May 11 13:33:38 CEST 2020

Job details:
============

Name                : CIFVAR
User                : s2934833
Partition           : gpu
Nodes               : pg-gpu37
Cores               : 12
State               : COMPLETED
Submit              : 2020-05-11T12:58:36
Start               : 2020-05-11T12:58:36
End                 : 2020-05-11T13:33:37
Reserved walltime   : 02:00:00
Used walltime       : 00:35:01
Used CPU time       : 00:38:07 (efficiency:  9.07%)
% User (Computation): 78.30%
% System (I/O)      : 21.70%
Mem reserved        : 32000M/node
Max Mem used        : 3.61G (pg-gpu37)
Max Disk Write      : 153.60K (pg-gpu37)
Max Disk Read       : 5.83M (pg-gpu37)
Average GPU usage   : 74.3% (pg-gpu37)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/additional_information/scientific_output

################################################################################
