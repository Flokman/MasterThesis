
The following have been reloaded with a version change:
  1) FFTW/3.3.8-gompic-2019b => FFTW/3.3.8-gompi-2019b
  2) OpenMPI/3.1.4-gcccuda-2019b => OpenMPI/3.1.4-GCC-8.3.0
  3) ScaLAPACK/2.0.2-gompic-2019b => ScaLAPACK/2.0.2-gompi-2019b
  4) SciPy-bundle/2019.10-fosscuda-2019b-Python-3.7.4 => SciPy-bundle/2019.10-foss-2019b-Python-3.7.4

2020-05-10 13:00:14.262280: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-10 13:00:24.985839: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-05-10 13:00:24.993870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-10 13:00:24.994348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-10 13:00:24.994436: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-10 13:00:25.000943: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-10 13:00:25.005192: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-10 13:00:25.007643: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-10 13:00:25.012484: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-10 13:00:25.015728: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-10 13:00:25.022184: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-10 13:00:25.022392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-10 13:00:25.022957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-10 13:00:25.023362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-05-10 13:00:25.026184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-10 13:00:25.026609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-10 13:00:25.026707: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-10 13:00:25.026786: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-10 13:00:25.026850: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-10 13:00:25.026912: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-10 13:00:25.026973: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-10 13:00:25.027035: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-10 13:00:25.027097: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-10 13:00:25.027234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-10 13:00:25.027716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-10 13:00:25.028108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-05-10 13:00:25.028199: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-10 13:00:25.663882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-10 13:00:25.664011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-05-10 13:00:25.664068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-05-10 13:00:25.664372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-10 13:00:25.665039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-10 13:00:25.665593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-10 13:00:25.666044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28652 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2020-05-10 13:00:25.666401: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-10 13:00:36.689278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-10 13:00:36.992745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-10 13:00:42.918171: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-10 13:00:42.918321: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1259] Profiler found 1 GPUs
2020-05-10 13:00:42.921511: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1
2020-05-10 13:00:43.022268: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-05-10 13:00:43.022888: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-05-10 13:00:43.458586: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-10 13:00:43.458749: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
dataset_name = /Messidor2_PNG_256.hdf5, batch_size = 64, num_classes = 5, epochs = 500,
        MCBN_PREDICTIONS = 256, Mini_batch_size = 128, test_img_idx = 66,
        train_test_split = 0.8, to_shuffle = False, augmentation = False, label_count = [1021, 270, 347, 75, 35],
        label_normalizer = False, save_augmentation_to_hdf5 = False, learn rate = 0.001,
        add_bn_inside = True, train_all_layers = True, weights_to_use = imagenet,
        es_patience = 50, train_val_split = 0.9, MIN_DELTA = 0.005, Early_monitor = val_accuracy
x_train shape: (1398, 256, 256, 3)
1398 train samples
350 test samples
block1_conv1
1
block1_conv2
3
block2_conv1
6
block2_conv2
8
block3_conv1
11
block3_conv2
13
block3_conv3
15
block4_conv1
18
block4_conv2
20
block4_conv3
22
block5_conv1
25
block5_conv2
27
block5_conv3
29
<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f24b3e9a3d0> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f24b4cc6c10> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f24b2b99c10> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f24b2b99ed0> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f249e8f3590> True
<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f24b00640d0> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f24b2bb8550> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f249e7ea090> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f24b0085c50> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f249e6f7d90> True
<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f24b008b110> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f24b0093f50> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f249e5a2f90> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f24b00936d0> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f24803f7dd0> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f24b0020ad0> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f248019b3d0> True
<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f24b0038950> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f24b003b250> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f249e568e90> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f24b0043990> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f244016d450> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f24b0049890> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f2440058650> True
<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f24b0057ad0> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f24b005cd50> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f2428266f50> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f249e98af50> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f240864ef50> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f249e98a7d0> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f240855e890> True
<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f249e99f950> True
<tensorflow.python.keras.layers.core.Flatten object at 0x7f23ec59fad0> True
<tensorflow.python.keras.layers.core.Dense object at 0x7f2408075a10> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f23ec4c7e50> True
<tensorflow.python.keras.layers.core.Dense object at 0x7f23ec4d5bd0> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f23ec4d6cd0> True
<tensorflow.python.keras.layers.core.Dense object at 0x7f23ec4b3fd0> True
Model: "model_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 256, 256, 3)]     0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      
_________________________________________________________________
batch_normalization (BatchNo (None, 256, 256, 64)      256       
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     
_________________________________________________________________
batch_normalization_1 (Batch (None, 256, 256, 64)      256       
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     
_________________________________________________________________
batch_normalization_2 (Batch (None, 128, 128, 128)     512       
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    
_________________________________________________________________
batch_normalization_3 (Batch (None, 128, 128, 128)     512       
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    
_________________________________________________________________
batch_normalization_4 (Batch (None, 64, 64, 256)       1024      
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
batch_normalization_5 (Batch (None, 64, 64, 256)       1024      
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
batch_normalization_6 (Batch (None, 64, 64, 256)       1024      
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   
_________________________________________________________________
batch_normalization_7 (Batch (None, 32, 32, 512)       2048      
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
batch_normalization_8 (Batch (None, 32, 32, 512)       2048      
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
batch_normalization_9 (Batch (None, 32, 32, 512)       2048      
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
batch_normalization_10 (Batc (None, 16, 16, 512)       2048      
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
batch_normalization_11 (Batc (None, 16, 16, 512)       2048      
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
batch_normalization_12 (Batc (None, 16, 16, 512)       2048      
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         
_________________________________________________________________
flatten (Flatten)            (None, 32768)             0         
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              134221824 
_________________________________________________________________
batch_normalization_13 (Batc (None, 4096)              16384     
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312  
_________________________________________________________________
batch_normalization_14 (Batc (None, 4096)              16384     
_________________________________________________________________
predictions (Dense)          (None, 5)                 20485     
=================================================================
Total params: 165,787,973
Trainable params: 165,763,141
Non-trainable params: 24,832
_________________________________________________________________
Start fitting monte carlo batch_normalization model
Train for 20 steps, validate for 3 steps
Epoch 1/500
20/20 - 26s - loss: 2.2114 - accuracy: 0.2218 - val_loss: 2.1273 - val_accuracy: 0.1714
Epoch 2/500
20/20 - 9s - loss: 1.7188 - accuracy: 0.4022 - val_loss: 2.2774 - val_accuracy: 0.1214
Epoch 3/500
20/20 - 9s - loss: 1.3990 - accuracy: 0.4857 - val_loss: 2.3589 - val_accuracy: 0.1786
Epoch 4/500
20/20 - 9s - loss: 1.1779 - accuracy: 0.5843 - val_loss: 2.3503 - val_accuracy: 0.1857
Epoch 5/500
20/20 - 9s - loss: 1.0159 - accuracy: 0.6789 - val_loss: 2.3265 - val_accuracy: 0.1857
Epoch 6/500
20/20 - 9s - loss: 0.8987 - accuracy: 0.7448 - val_loss: 2.2398 - val_accuracy: 0.2000
Epoch 7/500
20/20 - 9s - loss: 0.8000 - accuracy: 0.8124 - val_loss: 2.2574 - val_accuracy: 0.1571
Epoch 8/500
20/20 - 9s - loss: 0.7249 - accuracy: 0.8545 - val_loss: 2.2755 - val_accuracy: 0.2143
Epoch 9/500
20/20 - 9s - loss: 0.6570 - accuracy: 0.8728 - val_loss: 2.2066 - val_accuracy: 0.1929
Epoch 10/500
20/20 - 9s - loss: 0.6036 - accuracy: 0.8983 - val_loss: 2.2054 - val_accuracy: 0.1714
Epoch 11/500
20/20 - 9s - loss: 0.5550 - accuracy: 0.9237 - val_loss: 2.2397 - val_accuracy: 0.1929
Epoch 12/500
20/20 - 9s - loss: 0.5147 - accuracy: 0.9396 - val_loss: 2.3728 - val_accuracy: 0.2000
Epoch 13/500
20/20 - 9s - loss: 0.4761 - accuracy: 0.9531 - val_loss: 2.2216 - val_accuracy: 0.2286
Epoch 14/500
20/20 - 9s - loss: 0.4457 - accuracy: 0.9618 - val_loss: 2.1702 - val_accuracy: 0.2643
Epoch 15/500
20/20 - 12s - loss: 0.4179 - accuracy: 0.9666 - val_loss: 2.1233 - val_accuracy: 0.2714
Epoch 16/500
20/20 - 12s - loss: 0.3937 - accuracy: 0.9730 - val_loss: 2.0922 - val_accuracy: 0.2714
Epoch 17/500
20/20 - 9s - loss: 0.3693 - accuracy: 0.9801 - val_loss: 2.2574 - val_accuracy: 0.2857
Epoch 18/500
20/20 - 9s - loss: 0.3499 - accuracy: 0.9833 - val_loss: 2.2698 - val_accuracy: 0.2429
Epoch 19/500
20/20 - 9s - loss: 0.3310 - accuracy: 0.9857 - val_loss: 2.2607 - val_accuracy: 0.2500
Epoch 20/500
20/20 - 9s - loss: 0.3157 - accuracy: 0.9881 - val_loss: 2.2881 - val_accuracy: 0.2571
Epoch 21/500
20/20 - 9s - loss: 0.3000 - accuracy: 0.9889 - val_loss: 2.2357 - val_accuracy: 0.2643
Epoch 22/500
20/20 - 9s - loss: 0.2845 - accuracy: 0.9921 - val_loss: 2.1518 - val_accuracy: 0.2786
Epoch 23/500
20/20 - 9s - loss: 0.2722 - accuracy: 0.9913 - val_loss: 2.0971 - val_accuracy: 0.3000
Epoch 24/500
20/20 - 12s - loss: 0.2609 - accuracy: 0.9921 - val_loss: 2.0597 - val_accuracy: 0.2857
Epoch 25/500
20/20 - 12s - loss: 0.2485 - accuracy: 0.9928 - val_loss: 1.9783 - val_accuracy: 0.3143
Epoch 26/500
20/20 - 12s - loss: 0.2387 - accuracy: 0.9952 - val_loss: 1.9750 - val_accuracy: 0.3143
Epoch 27/500
20/20 - 9s - loss: 0.2293 - accuracy: 0.9960 - val_loss: 1.9800 - val_accuracy: 0.3286
Epoch 28/500
20/20 - 12s - loss: 0.2207 - accuracy: 0.9976 - val_loss: 1.9232 - val_accuracy: 0.3500
Epoch 29/500
20/20 - 13s - loss: 0.2125 - accuracy: 0.9976 - val_loss: 1.8946 - val_accuracy: 0.3429
Epoch 30/500
20/20 - 13s - loss: 0.2052 - accuracy: 0.9984 - val_loss: 1.8751 - val_accuracy: 0.3857
Epoch 31/500
20/20 - 9s - loss: 0.1978 - accuracy: 0.9992 - val_loss: 1.8842 - val_accuracy: 0.3929
Epoch 32/500
20/20 - 12s - loss: 0.1913 - accuracy: 0.9992 - val_loss: 1.8664 - val_accuracy: 0.4214
Epoch 33/500
20/20 - 9s - loss: 0.1850 - accuracy: 0.9992 - val_loss: 1.8669 - val_accuracy: 0.4357
Epoch 34/500
20/20 - 13s - loss: 0.1787 - accuracy: 0.9992 - val_loss: 1.8538 - val_accuracy: 0.4500
Epoch 35/500
20/20 - 9s - loss: 0.1733 - accuracy: 0.9992 - val_loss: 1.8597 - val_accuracy: 0.4714
Epoch 36/500
20/20 - 9s - loss: 0.1683 - accuracy: 0.9992 - val_loss: 1.8585 - val_accuracy: 0.4786
Epoch 37/500
20/20 - 9s - loss: 0.1628 - accuracy: 0.9992 - val_loss: 1.8650 - val_accuracy: 0.4786
Epoch 38/500
20/20 - 9s - loss: 0.1585 - accuracy: 0.9992 - val_loss: 1.8672 - val_accuracy: 0.4857
Epoch 39/500
20/20 - 9s - loss: 0.1542 - accuracy: 0.9992 - val_loss: 1.8750 - val_accuracy: 0.4786
Epoch 40/500
20/20 - 9s - loss: 0.1499 - accuracy: 0.9992 - val_loss: 1.8760 - val_accuracy: 0.4786
Epoch 41/500
20/20 - 9s - loss: 0.1462 - accuracy: 0.9992 - val_loss: 1.8826 - val_accuracy: 0.4857
Epoch 42/500
20/20 - 9s - loss: 0.1422 - accuracy: 0.9992 - val_loss: 1.8928 - val_accuracy: 0.4929
Epoch 43/500
20/20 - 9s - loss: 0.1388 - accuracy: 0.9992 - val_loss: 1.8942 - val_accuracy: 0.4929
Epoch 44/500
20/20 - 9s - loss: 0.1354 - accuracy: 0.9992 - val_loss: 1.8947 - val_accuracy: 0.4929
Epoch 45/500
20/20 - 9s - loss: 0.1319 - accuracy: 0.9992 - val_loss: 1.8899 - val_accuracy: 0.5000
Epoch 46/500
20/20 - 9s - loss: 0.1287 - accuracy: 0.9992 - val_loss: 1.8940 - val_accuracy: 0.5000
Epoch 47/500
20/20 - 9s - loss: 0.1257 - accuracy: 0.9992 - val_loss: 1.8951 - val_accuracy: 0.5000
Epoch 48/500
20/20 - 9s - loss: 0.1232 - accuracy: 0.9992 - val_loss: 1.8957 - val_accuracy: 0.5000
Epoch 49/500
20/20 - 9s - loss: 0.1205 - accuracy: 0.9992 - val_loss: 1.8925 - val_accuracy: 0.5071
Epoch 50/500
20/20 - 9s - loss: 0.1176 - accuracy: 0.9992 - val_loss: 1.8950 - val_accuracy: 0.5000
Epoch 51/500
20/20 - 9s - loss: 0.1153 - accuracy: 0.9992 - val_loss: 1.8979 - val_accuracy: 0.5071
Epoch 52/500
20/20 - 9s - loss: 0.1128 - accuracy: 0.9992 - val_loss: 1.8958 - val_accuracy: 0.5071
Epoch 53/500
20/20 - 9s - loss: 0.1105 - accuracy: 0.9992 - val_loss: 1.8995 - val_accuracy: 0.5000
Epoch 54/500
20/20 - 9s - loss: 0.1083 - accuracy: 0.9992 - val_loss: 1.8971 - val_accuracy: 0.5000
Epoch 55/500
20/20 - 9s - loss: 0.1062 - accuracy: 0.9992 - val_loss: 1.9022 - val_accuracy: 0.5000
Epoch 56/500
20/20 - 9s - loss: 0.1042 - accuracy: 0.9992 - val_loss: 1.8997 - val_accuracy: 0.5071
Epoch 57/500
20/20 - 9s - loss: 0.1023 - accuracy: 0.9992 - val_loss: 1.9000 - val_accuracy: 0.5000
Epoch 58/500
20/20 - 9s - loss: 0.1005 - accuracy: 0.9992 - val_loss: 1.9037 - val_accuracy: 0.5000
Epoch 59/500
20/20 - 9s - loss: 0.0986 - accuracy: 0.9992 - val_loss: 1.9034 - val_accuracy: 0.5071
Epoch 60/500
20/20 - 9s - loss: 0.0969 - accuracy: 0.9992 - val_loss: 1.9074 - val_accuracy: 0.5000
Epoch 61/500
20/20 - 9s - loss: 0.0952 - accuracy: 0.9992 - val_loss: 1.9060 - val_accuracy: 0.5071
Epoch 62/500
20/20 - 9s - loss: 0.0934 - accuracy: 0.9992 - val_loss: 1.9103 - val_accuracy: 0.5000
Epoch 63/500
20/20 - 9s - loss: 0.0920 - accuracy: 0.9992 - val_loss: 1.9081 - val_accuracy: 0.5000
Epoch 64/500
20/20 - 9s - loss: 0.0903 - accuracy: 0.9992 - val_loss: 1.9114 - val_accuracy: 0.5000
Epoch 65/500
20/20 - 9s - loss: 0.0889 - accuracy: 0.9992 - val_loss: 1.9132 - val_accuracy: 0.5000
Epoch 66/500
20/20 - 9s - loss: 0.0875 - accuracy: 0.9992 - val_loss: 1.9118 - val_accuracy: 0.5000
Epoch 67/500
20/20 - 9s - loss: 0.0861 - accuracy: 0.9992 - val_loss: 1.9132 - val_accuracy: 0.5000
Epoch 68/500
20/20 - 9s - loss: 0.0847 - accuracy: 0.9992 - val_loss: 1.9168 - val_accuracy: 0.5000
Epoch 69/500
20/20 - 9s - loss: 0.0834 - accuracy: 0.9992 - val_loss: 1.9185 - val_accuracy: 0.5000
Epoch 70/500
20/20 - 9s - loss: 0.0822 - accuracy: 0.9992 - val_loss: 1.9156 - val_accuracy: 0.5071
Epoch 71/500
20/20 - 9s - loss: 0.0811 - accuracy: 0.9992 - val_loss: 1.9192 - val_accuracy: 0.5000
Epoch 72/500
20/20 - 9s - loss: 0.0798 - accuracy: 0.9992 - val_loss: 1.9208 - val_accuracy: 0.5000
Epoch 73/500
20/20 - 9s - loss: 0.0787 - accuracy: 0.9992 - val_loss: 1.9203 - val_accuracy: 0.5071
Epoch 74/500
20/20 - 9s - loss: 0.0774 - accuracy: 0.9992 - val_loss: 1.9221 - val_accuracy: 0.5071
Epoch 75/500
20/20 - 9s - loss: 0.0765 - accuracy: 0.9992 - val_loss: 1.9258 - val_accuracy: 0.5071
Epoch 76/500
20/20 - 9s - loss: 0.0754 - accuracy: 0.9992 - val_loss: 1.9251 - val_accuracy: 0.5071
Epoch 77/500
20/20 - 9s - loss: 0.0743 - accuracy: 0.9992 - val_loss: 1.9244 - val_accuracy: 0.5143
Epoch 78/500
20/20 - 9s - loss: 0.0734 - accuracy: 0.9992 - val_loss: 1.9262 - val_accuracy: 0.5143
Epoch 79/500
20/20 - 9s - loss: 0.0723 - accuracy: 0.9992 - val_loss: 1.9271 - val_accuracy: 0.5143
Epoch 80/500
20/20 - 9s - loss: 0.0715 - accuracy: 0.9992 - val_loss: 1.9263 - val_accuracy: 0.5143
Epoch 81/500
20/20 - 9s - loss: 0.0706 - accuracy: 0.9992 - val_loss: 1.9293 - val_accuracy: 0.5143
Epoch 82/500
20/20 - 9s - loss: 0.0696 - accuracy: 0.9992 - val_loss: 1.9308 - val_accuracy: 0.5143
Epoch 83/500
20/20 - 9s - loss: 0.0687 - accuracy: 0.9992 - val_loss: 1.9315 - val_accuracy: 0.5143
Epoch 84/500
20/20 - 9s - loss: 0.0679 - accuracy: 0.9992 - val_loss: 1.9337 - val_accuracy: 0.5143
Epoch 85/500
20/20 - 9s - loss: 0.0670 - accuracy: 0.9992 - val_loss: 1.9342 - val_accuracy: 0.5143
Epoch 86/500
20/20 - 9s - loss: 0.0662 - accuracy: 0.9992 - val_loss: 1.9353 - val_accuracy: 0.5143
Epoch 87/500
20/20 - 9s - loss: 0.0654 - accuracy: 0.9992 - val_loss: 1.9356 - val_accuracy: 0.5143
Epoch 88/500
20/20 - 9s - loss: 0.0646 - accuracy: 0.9992 - val_loss: 1.9363 - val_accuracy: 0.5143
Epoch 89/500
20/20 - 9s - loss: 0.0638 - accuracy: 0.9992 - val_loss: 1.9375 - val_accuracy: 0.5143
Epoch 90/500
20/20 - 9s - loss: 0.0631 - accuracy: 0.9992 - val_loss: 1.9356 - val_accuracy: 0.5143
Epoch 91/500
20/20 - 9s - loss: 0.0624 - accuracy: 0.9992 - val_loss: 1.9411 - val_accuracy: 0.5143
Epoch 92/500
20/20 - 9s - loss: 0.0617 - accuracy: 0.9992 - val_loss: 1.9380 - val_accuracy: 0.5143
Epoch 93/500
20/20 - 9s - loss: 0.0610 - accuracy: 0.9992 - val_loss: 1.9391 - val_accuracy: 0.5143
Epoch 94/500
20/20 - 9s - loss: 0.0603 - accuracy: 0.9992 - val_loss: 1.9412 - val_accuracy: 0.5143
Epoch 95/500
20/20 - 9s - loss: 0.0597 - accuracy: 0.9992 - val_loss: 1.9431 - val_accuracy: 0.5143
Epoch 96/500
20/20 - 9s - loss: 0.0589 - accuracy: 0.9992 - val_loss: 1.9435 - val_accuracy: 0.5143
Epoch 97/500
20/20 - 9s - loss: 0.0584 - accuracy: 0.9992 - val_loss: 1.9482 - val_accuracy: 0.5143
Epoch 98/500
20/20 - 9s - loss: 0.0577 - accuracy: 0.9992 - val_loss: 1.9494 - val_accuracy: 0.5143
Epoch 99/500
20/20 - 9s - loss: 0.0571 - accuracy: 0.9992 - val_loss: 1.9472 - val_accuracy: 0.5143
Epoch 100/500
20/20 - 9s - loss: 0.0565 - accuracy: 0.9992 - val_loss: 1.9476 - val_accuracy: 0.5143
Epoch 101/500
20/20 - 9s - loss: 0.0559 - accuracy: 0.9992 - val_loss: 1.9461 - val_accuracy: 0.5214
Epoch 102/500
20/20 - 9s - loss: 0.0553 - accuracy: 0.9992 - val_loss: 1.9469 - val_accuracy: 0.5214
Epoch 103/500
20/20 - 9s - loss: 0.0548 - accuracy: 0.9992 - val_loss: 1.9491 - val_accuracy: 0.5214
Epoch 104/500
20/20 - 9s - loss: 0.0542 - accuracy: 0.9992 - val_loss: 1.9492 - val_accuracy: 0.5214
Epoch 105/500
20/20 - 9s - loss: 0.0537 - accuracy: 0.9992 - val_loss: 1.9491 - val_accuracy: 0.5214
Epoch 106/500
20/20 - 9s - loss: 0.0532 - accuracy: 0.9992 - val_loss: 1.9524 - val_accuracy: 0.5214
Epoch 107/500
20/20 - 9s - loss: 0.0527 - accuracy: 0.9992 - val_loss: 1.9535 - val_accuracy: 0.5214
Epoch 108/500
20/20 - 9s - loss: 0.0521 - accuracy: 0.9992 - val_loss: 1.9548 - val_accuracy: 0.5143
Epoch 109/500
20/20 - 9s - loss: 0.0516 - accuracy: 0.9992 - val_loss: 1.9559 - val_accuracy: 0.5214
Epoch 110/500
20/20 - 9s - loss: 0.0511 - accuracy: 0.9992 - val_loss: 1.9547 - val_accuracy: 0.5214
Epoch 111/500
20/20 - 9s - loss: 0.0507 - accuracy: 0.9992 - val_loss: 1.9528 - val_accuracy: 0.5214
Epoch 112/500
20/20 - 9s - loss: 0.0502 - accuracy: 0.9992 - val_loss: 1.9566 - val_accuracy: 0.5214
Epoch 113/500
20/20 - 9s - loss: 0.0497 - accuracy: 0.9992 - val_loss: 1.9562 - val_accuracy: 0.5214
Epoch 114/500
20/20 - 9s - loss: 0.0493 - accuracy: 0.9992 - val_loss: 1.9593 - val_accuracy: 0.5214
Epoch 115/500
20/20 - 9s - loss: 0.0488 - accuracy: 0.9992 - val_loss: 1.9593 - val_accuracy: 0.5214
Epoch 116/500
20/20 - 9s - loss: 0.0484 - accuracy: 0.9992 - val_loss: 1.9607 - val_accuracy: 0.5214
Epoch 117/500
20/20 - 9s - loss: 0.0480 - accuracy: 0.9992 - val_loss: 1.9599 - val_accuracy: 0.5214
Epoch 118/500
20/20 - 9s - loss: 0.0475 - accuracy: 0.9992 - val_loss: 1.9619 - val_accuracy: 0.5214
Epoch 119/500
20/20 - 9s - loss: 0.0471 - accuracy: 0.9992 - val_loss: 1.9620 - val_accuracy: 0.5214
Epoch 120/500
20/20 - 9s - loss: 0.0467 - accuracy: 0.9992 - val_loss: 1.9652 - val_accuracy: 0.5214
Epoch 121/500
20/20 - 9s - loss: 0.0463 - accuracy: 0.9992 - val_loss: 1.9658 - val_accuracy: 0.5214
Epoch 122/500
20/20 - 9s - loss: 0.0460 - accuracy: 0.9992 - val_loss: 1.9660 - val_accuracy: 0.5214
Epoch 123/500
20/20 - 9s - loss: 0.0455 - accuracy: 0.9992 - val_loss: 1.9663 - val_accuracy: 0.5214
Epoch 124/500
20/20 - 9s - loss: 0.0452 - accuracy: 0.9992 - val_loss: 1.9678 - val_accuracy: 0.5214
Epoch 125/500
20/20 - 9s - loss: 0.0448 - accuracy: 0.9992 - val_loss: 1.9707 - val_accuracy: 0.5214
Epoch 126/500
20/20 - 9s - loss: 0.0445 - accuracy: 0.9992 - val_loss: 1.9704 - val_accuracy: 0.5214
Epoch 127/500
20/20 - 9s - loss: 0.0441 - accuracy: 0.9992 - val_loss: 1.9699 - val_accuracy: 0.5214
Epoch 128/500
20/20 - 9s - loss: 0.0437 - accuracy: 0.9992 - val_loss: 1.9695 - val_accuracy: 0.5214
Epoch 129/500
20/20 - 9s - loss: 0.0433 - accuracy: 0.9992 - val_loss: 1.9703 - val_accuracy: 0.5214
Epoch 130/500
20/20 - 9s - loss: 0.0430 - accuracy: 0.9992 - val_loss: 1.9716 - val_accuracy: 0.5214
Epoch 131/500
20/20 - 9s - loss: 0.0427 - accuracy: 0.9992 - val_loss: 1.9707 - val_accuracy: 0.5214
Epoch 132/500
20/20 - 9s - loss: 0.0423 - accuracy: 0.9992 - val_loss: 1.9729 - val_accuracy: 0.5214
Epoch 133/500
20/20 - 9s - loss: 0.0420 - accuracy: 0.9992 - val_loss: 1.9738 - val_accuracy: 0.5214
Epoch 134/500
20/20 - 9s - loss: 0.0417 - accuracy: 0.9992 - val_loss: 1.9751 - val_accuracy: 0.5214
Epoch 135/500
20/20 - 9s - loss: 0.0413 - accuracy: 0.9992 - val_loss: 1.9760 - val_accuracy: 0.5214
Epoch 136/500
20/20 - 9s - loss: 0.0410 - accuracy: 0.9992 - val_loss: 1.9757 - val_accuracy: 0.5214
Epoch 137/500
20/20 - 9s - loss: 0.0407 - accuracy: 0.9992 - val_loss: 1.9777 - val_accuracy: 0.5214
Epoch 138/500
20/20 - 9s - loss: 0.0404 - accuracy: 0.9992 - val_loss: 1.9763 - val_accuracy: 0.5214
Epoch 139/500
20/20 - 9s - loss: 0.0401 - accuracy: 0.9992 - val_loss: 1.9777 - val_accuracy: 0.5214
Epoch 140/500
20/20 - 9s - loss: 0.0398 - accuracy: 0.9992 - val_loss: 1.9806 - val_accuracy: 0.5214
Epoch 141/500
20/20 - 9s - loss: 0.0395 - accuracy: 0.9992 - val_loss: 1.9798 - val_accuracy: 0.5214
Epoch 142/500
20/20 - 9s - loss: 0.0393 - accuracy: 0.9992 - val_loss: 1.9807 - val_accuracy: 0.5214
Epoch 143/500
20/20 - 9s - loss: 0.0390 - accuracy: 0.9992 - val_loss: 1.9802 - val_accuracy: 0.5214
Epoch 144/500
20/20 - 9s - loss: 0.0387 - accuracy: 0.9992 - val_loss: 1.9804 - val_accuracy: 0.5214
Epoch 145/500
20/20 - 9s - loss: 0.0384 - accuracy: 0.9992 - val_loss: 1.9829 - val_accuracy: 0.5214
Epoch 146/500
20/20 - 9s - loss: 0.0381 - accuracy: 0.9992 - val_loss: 1.9813 - val_accuracy: 0.5214
Epoch 147/500
20/20 - 9s - loss: 0.0379 - accuracy: 0.9992 - val_loss: 1.9829 - val_accuracy: 0.5214
Epoch 148/500
20/20 - 9s - loss: 0.0376 - accuracy: 0.9992 - val_loss: 1.9836 - val_accuracy: 0.5214
Epoch 149/500
20/20 - 9s - loss: 0.0374 - accuracy: 0.9992 - val_loss: 1.9847 - val_accuracy: 0.5214
Epoch 150/500
20/20 - 9s - loss: 0.0371 - accuracy: 0.9992 - val_loss: 1.9862 - val_accuracy: 0.5214
Epoch 151/500
20/20 - 9s - loss: 0.0368 - accuracy: 0.9992 - val_loss: 1.9866 - val_accuracy: 0.5214
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-10 13:23:59.508065: W tensorflow/core/kernels/gpu_utils.cc:48] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.
Epoch 00151: early stopping
Done fitting
input_1 False
block1_conv1 False
batch_normalization True
block1_conv2 False
batch_normalization_1 True
block1_pool False
block2_conv1 False
batch_normalization_2 True
block2_conv2 False
batch_normalization_3 True
block2_pool False
block3_conv1 False
batch_normalization_4 True
block3_conv2 False
batch_normalization_5 True
block3_conv3 False
batch_normalization_6 True
block3_pool False
block4_conv1 False
batch_normalization_7 True
block4_conv2 False
batch_normalization_8 True
block4_conv3 False
batch_normalization_9 True
block4_pool False
block5_conv1 False
batch_normalization_10 True
block5_conv2 False
batch_normalization_11 True
block5_conv3 False
batch_normalization_12 True
block5_pool False
flatten False
fc1 False
batch_normalization_13 True
fc2 False
batch_normalization_14 True
predictions False
1/1 [==============================] - 8s 8s/step - loss: 1.5192 - accuracy: 0.5114
[1.5191895961761475, 0.5114286]
input_1 False
block1_conv1 False
batch_normalization False
block1_conv2 False
batch_normalization_1 False
block1_pool False
block2_conv1 False
batch_normalization_2 False
block2_conv2 False
batch_normalization_3 False
block2_pool False
block3_conv1 False
batch_normalization_4 False
block3_conv2 False
batch_normalization_5 False
block3_conv3 False
batch_normalization_6 False
block3_pool False
block4_conv1 False
batch_normalization_7 False
block4_conv2 False
batch_normalization_8 False
block4_conv3 False
batch_normalization_9 False
block4_pool False
block5_conv1 False
batch_normalization_10 False
block5_conv2 False
batch_normalization_11 False
block5_conv3 False
batch_normalization_12 False
block5_pool False
flatten False
fc1 False
batch_normalization_13 False
fc2 False
batch_normalization_14 False
predictions False
  0/256 [..............................] - ETA: 0sWARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
  1/256 [..............................] - ETA: 50:36WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
  4/256 [..............................] - ETA: 19:17WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
  7/256 [..............................] - ETA: 14:44WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 10/256 [>.............................] - ETA: 12:51WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 13/256 [>.............................] - ETA: 11:46WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 16/256 [>.............................] - ETA: 11:03WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 19/256 [=>............................] - ETA: 10:32WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 22/256 [=>............................] - ETA: 10:08WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 25/256 [=>............................] - ETA: 9:48 WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 28/256 [==>...........................] - ETA: 9:31WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 31/256 [==>...........................] - ETA: 9:16WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 34/256 [==>...........................] - ETA: 9:02WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 37/256 [===>..........................] - ETA: 8:52WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 40/256 [===>..........................] - ETA: 8:40WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 43/256 [====>.........................] - ETA: 8:29WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 46/256 [====>.........................] - ETA: 8:19WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 49/256 [====>.........................] - ETA: 8:09WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 52/256 [=====>........................] - ETA: 7:59WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 55/256 [=====>........................] - ETA: 7:50WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 58/256 [=====>........................] - ETA: 7:41WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 61/256 [======>.......................] - ETA: 7:33WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 64/256 [======>.......................] - ETA: 7:24WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 67/256 [======>.......................] - ETA: 7:16WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 70/256 [=======>......................] - ETA: 7:08WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 73/256 [=======>......................] - ETA: 7:00WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 76/256 [=======>......................] - ETA: 6:52WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 79/256 [========>.....................] - ETA: 6:44WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 82/256 [========>.....................] - ETA: 6:37WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 85/256 [========>.....................] - ETA: 6:29WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 88/256 [=========>....................] - ETA: 6:22WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 91/256 [=========>....................] - ETA: 6:14WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 94/256 [==========>...................] - ETA: 6:07WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 97/256 [==========>...................] - ETA: 6:00WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
100/256 [==========>...................] - ETA: 5:52WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
103/256 [===========>..................] - ETA: 5:45WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
106/256 [===========>..................] - ETA: 5:38WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
109/256 [===========>..................] - ETA: 5:31WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
112/256 [============>.................] - ETA: 5:24WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
115/256 [============>.................] - ETA: 5:17WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
118/256 [============>.................] - ETA: 5:10WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
121/256 [=============>................] - ETA: 5:03WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
124/256 [=============>................] - ETA: 4:56WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
127/256 [=============>................] - ETA: 4:49WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
130/256 [==============>...............] - ETA: 4:42WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
132/256 [==============>...............] - ETA: 4:38WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
134/256 [==============>...............] - ETA: 4:34WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
136/256 [==============>...............] - ETA: 4:30WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
138/256 [===============>..............] - ETA: 4:26WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
140/256 [===============>..............] - ETA: 4:22WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
142/256 [===============>..............] - ETA: 4:18WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
144/256 [===============>..............] - ETA: 4:14WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
146/256 [================>.............] - ETA: 4:10WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
148/256 [================>.............] - ETA: 4:06WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
150/256 [================>.............] - ETA: 4:02WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
152/256 [================>.............] - ETA: 3:58WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
154/256 [=================>............] - ETA: 3:54WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
156/256 [=================>............] - ETA: 3:49WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
158/256 [=================>............] - ETA: 3:45WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
160/256 [=================>............] - ETA: 3:41WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
[pg-gpu24:00565] PMIX ERROR: UNPACK-PAST-END in file src/client/pmix_client.c at line 100
/var/spool/slurmd/job11351697/slurm_script: line 14:   565 Killed                  python Mess_MCBN.py
slurmstepd: error: Detected 3 oom-kill event(s) in step 11351697.batch cgroup. Some of your processes may have been killed by the cgroup out-of-memory handler.


###############################################################################
Peregrine Cluster
Job 11351697 for user 's2934833'
Finished at: Sun May 10 13:30:21 CEST 2020

Job details:
============

Name                : MESBN
User                : s2934833
Partition           : gpu
Nodes               : pg-gpu24
Cores               : 12
State               : OUT_OF_MEMORY
Submit              : 2020-05-10T13:00:05
Start               : 2020-05-10T13:00:05
End                 : 2020-05-10T13:30:21
Reserved walltime   : 02:00:00
Used walltime       : 00:30:16
Used CPU time       : 00:24:57 (efficiency:  6.87%)
% User (Computation): 67.12%
% System (I/O)      : 32.88%
Mem reserved        : 62.50G/node
Max Mem used        : 60.31G (pg-gpu24)
Max Disk Write      : 153.60K (pg-gpu24)
Max Disk Read       : 5.83M (pg-gpu24)
Average GPU usage   : 87.1% (pg-gpu24)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/additional_information/scientific_output

################################################################################
