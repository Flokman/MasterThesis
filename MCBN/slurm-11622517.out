
The following have been reloaded with a version change:
  1) FFTW/3.3.8-gompic-2019b => FFTW/3.3.8-gompi-2019b
  2) OpenMPI/3.1.4-gcccuda-2019b => OpenMPI/3.1.4-GCC-8.3.0
  3) ScaLAPACK/2.0.2-gompic-2019b => ScaLAPACK/2.0.2-gompi-2019b
  4) SciPy-bundle/2019.10-fosscuda-2019b-Python-3.7.4 => SciPy-bundle/2019.10-foss-2019b-Python-3.7.4

2020-05-20 10:56:38.981679: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-20 10:56:48.660859: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-05-20 10:56:48.668070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 10:56:48.668556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-20 10:56:48.668605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-20 10:56:48.673745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-20 10:56:48.677254: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-20 10:56:48.678675: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-20 10:56:48.682275: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-20 10:56:48.684197: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-20 10:56:48.689280: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-20 10:56:48.689451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 10:56:48.690153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 10:56:48.690552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-05-20 10:56:48.693101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 10:56:48.693630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-20 10:56:48.693675: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-20 10:56:48.693710: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-20 10:56:48.693732: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-20 10:56:48.693752: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-20 10:56:48.693773: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-20 10:56:48.693793: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-20 10:56:48.693814: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-20 10:56:48.693937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 10:56:48.694413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 10:56:48.694807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-05-20 10:56:48.694884: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-20 10:56:49.346956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-20 10:56:49.347041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-05-20 10:56:49.347057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-05-20 10:56:49.347322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 10:56:49.348004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 10:56:49.348534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 10:56:49.348970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28652 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2020-05-20 10:56:49.349316: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-20 10:57:01.431002: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-20 10:57:01.694340: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-20 10:57:03.438607: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-20 10:57:03.438705: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1259] Profiler found 1 GPUs
2020-05-20 10:57:03.441118: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1
2020-05-20 10:57:03.541684: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-05-20 10:57:03.542209: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-05-20 10:57:03.560481: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-20 10:57:03.560537: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
dataset_name = CIFAR10, batch_size = 32, num_classes = 10, epochs = 50,
        MCBN_PREDICTIONS = 25, Mini_batch_size = 32, test_img_idx = 4777,
        train_test_split = 0.8, to_shuffle = False, augmentation = False,
        label_normalizer = False, save_augmentation_to_hdf5 = False, learn rate = 0.001,
        add_bn_inside = True, train_all_layers = True, weights_to_use = imagenet,
        es_patience = 15, train_val_split = 0.875, MIN_DELTA = 0.005, Early_monitor = val_loss
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 test samples
Total labels in train set:  [5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]
Labels in validation set:  [139, 115, 122, 105, 118, 122, 127, 129, 131, 142]
Labels in test set:  [861, 885, 878, 895, 882, 878, 873, 871, 869, 858]
<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fde220bbcd0> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fde21f1ead0> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fde1809a850> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fde21f3cc90> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fde23ffe310> True
<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fde18173890> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fde21f3cf50> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddb8748810> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fde18188ad0> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddb8611350> True
<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fde1818f850> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fde18197f90> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddb83bc110> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fde18125bd0> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddb81d2f10> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fde1812dfd0> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fddb8670a50> True
<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fde18138a90> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fde181403d0> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd88568f90> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fde1814dad0> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd882e08d0> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fde1814d990> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd6c7d7e50> True
<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fde18158e90> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fde180def90> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd6c238f10> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fde180ebcd0> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd4e763d90> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fde180f2750> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd4e22d1d0> True
<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fde180f5990> True
<tensorflow.python.keras.layers.core.Flatten object at 0x7fde18105f50> True
<tensorflow.python.keras.layers.core.Dense object at 0x7fde180c7e10> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd4e11e390> True
<tensorflow.python.keras.layers.core.Dense object at 0x7fde18060e10> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fdd4db7fe50> True
<tensorflow.python.keras.layers.core.Dense object at 0x7fde180db910> True
Model: "model_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      
_________________________________________________________________
batch_normalization (BatchNo (None, 32, 32, 64)        256       
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     
_________________________________________________________________
batch_normalization_1 (Batch (None, 32, 32, 64)        256       
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     
_________________________________________________________________
batch_normalization_2 (Batch (None, 16, 16, 128)       512       
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    
_________________________________________________________________
batch_normalization_3 (Batch (None, 16, 16, 128)       512       
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    
_________________________________________________________________
batch_normalization_4 (Batch (None, 8, 8, 256)         1024      
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    
_________________________________________________________________
batch_normalization_5 (Batch (None, 8, 8, 256)         1024      
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    
_________________________________________________________________
batch_normalization_6 (Batch (None, 8, 8, 256)         1024      
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   
_________________________________________________________________
batch_normalization_7 (Batch (None, 4, 4, 512)         2048      
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   
_________________________________________________________________
batch_normalization_8 (Batch (None, 4, 4, 512)         2048      
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   
_________________________________________________________________
batch_normalization_9 (Batch (None, 4, 4, 512)         2048      
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   
_________________________________________________________________
batch_normalization_10 (Batc (None, 2, 2, 512)         2048      
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   
_________________________________________________________________
batch_normalization_11 (Batc (None, 2, 2, 512)         2048      
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   
_________________________________________________________________
batch_normalization_12 (Batc (None, 2, 2, 512)         2048      
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         
_________________________________________________________________
flatten (Flatten)            (None, 512)               0         
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              2101248   
_________________________________________________________________
batch_normalization_13 (Batc (None, 4096)              16384     
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312  
_________________________________________________________________
batch_normalization_14 (Batc (None, 4096)              16384     
_________________________________________________________________
predictions (Dense)          (None, 10)                40970     
=================================================================
Total params: 33,687,882
Trainable params: 33,663,050
Non-trainable params: 24,832
_________________________________________________________________
Start fitting monte carlo batch_normalization model
Train for 1563 steps, validate for 40 steps
Epoch 1/50
1563/1563 - 31s - loss: 1.1055 - accuracy: 0.6706 - val_loss: 0.5784 - val_accuracy: 0.7856
Epoch 2/50
1563/1563 - 24s - loss: 0.5166 - accuracy: 0.8271 - val_loss: 0.5192 - val_accuracy: 0.8192
Epoch 3/50
1563/1563 - 24s - loss: 0.2919 - accuracy: 0.8976 - val_loss: 0.4900 - val_accuracy: 0.8432
Epoch 4/50
1563/1563 - 24s - loss: 0.1563 - accuracy: 0.9449 - val_loss: 0.5342 - val_accuracy: 0.8360
Epoch 5/50
1563/1563 - 24s - loss: 0.0845 - accuracy: 0.9700 - val_loss: 0.6282 - val_accuracy: 0.8456
Epoch 6/50
1563/1563 - 24s - loss: 0.0647 - accuracy: 0.9776 - val_loss: 0.6703 - val_accuracy: 0.8416
Epoch 7/50
1563/1563 - 24s - loss: 0.0503 - accuracy: 0.9822 - val_loss: 0.6449 - val_accuracy: 0.8480
Epoch 8/50
1563/1563 - 24s - loss: 0.0335 - accuracy: 0.9887 - val_loss: 0.7000 - val_accuracy: 0.8552
Epoch 9/50
1563/1563 - 24s - loss: 0.0255 - accuracy: 0.9915 - val_loss: 0.7209 - val_accuracy: 0.8536
Epoch 10/50
1563/1563 - 24s - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.7764 - val_accuracy: 0.8512
Epoch 11/50
1563/1563 - 24s - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.7158 - val_accuracy: 0.8600
Epoch 12/50
1563/1563 - 24s - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.6817 - val_accuracy: 0.8744
Epoch 13/50
1563/1563 - 24s - loss: 2.8717e-04 - accuracy: 1.0000 - val_loss: 0.6857 - val_accuracy: 0.8776
Epoch 14/50
1563/1563 - 24s - loss: 1.7217e-04 - accuracy: 1.0000 - val_loss: 0.6888 - val_accuracy: 0.8792
Epoch 15/50
1563/1563 - 24s - loss: 1.3497e-04 - accuracy: 1.0000 - val_loss: 0.6915 - val_accuracy: 0.8752
Epoch 16/50
1563/1563 - 24s - loss: 1.1494e-04 - accuracy: 1.0000 - val_loss: 0.7014 - val_accuracy: 0.8768
Epoch 17/50
1563/1563 - 24s - loss: 1.0098e-04 - accuracy: 1.0000 - val_loss: 0.7113 - val_accuracy: 0.8752
Epoch 18/50
1563/1563 - 24s - loss: 9.0473e-05 - accuracy: 1.0000 - val_loss: 0.7045 - val_accuracy: 0.8800
Epoch 00018: early stopping
input_1 False
block1_conv1 False
batch_normalization True
block1_conv2 False
batch_normalization_1 True
block1_pool False
block2_conv1 False
batch_normalization_2 True
block2_conv2 False
batch_normalization_3 True
block2_pool False
block3_conv1 False
batch_normalization_4 True
block3_conv2 False
batch_normalization_5 True
block3_conv3 False
batch_normalization_6 True
block3_pool False
block4_conv1 False
batch_normalization_7 True
block4_conv2 False
batch_normalization_8 True
block4_conv3 False
batch_normalization_9 True
block4_pool False
block5_conv1 False
batch_normalization_10 True
block5_conv2 False
batch_normalization_11 True
block5_conv3 False
batch_normalization_12 True
block5_pool False
flatten False
fc1 False
batch_normalization_13 True
fc2 False
batch_normalization_14 True
predictions False
 0/25 [..............................] - ETA: 0sWARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 2/25 [=>............................] - ETA: 1:03WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
 6/25 [======>.......................] - ETA: 35s WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
10/25 [===========>..................] - ETA: 25sWARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
14/25 [===============>..............] - ETA: 18sWARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
18/25 [====================>.........] - ETA: 11sWARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
22/25 [=========================>....] - ETA: 4s WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
MCBN accuracy: 82.2%
MCBN-ensemble accuracy: 82.8%
tf.Tensor(
[[711   9  29  18  11   2   8  11  49  13]
 [  9 819   0   4   0   0   4   4   8  37]
 [ 30   0 679  37  27  37  39  16  11   2]
 [  7   2  36 605  34 123  38  35   7   8]
 [ 12   2  55  60 641  46  33  31   2   0]
 [  9   1  22 125  14 654  13  39   1   0]
 [  5   2  14  40  11   9 786   3   3   0]
 [  7   1   7  20  23  21   4 780   3   5]
 [ 24  11   5   4   3   1   2   1 804  14]
 [ 16  33   4   5   2   4   6   9  13 766]], shape=(10, 10), dtype=int32)
posterior mean: 5
true label: 5

class: 0; proba: 0.0%; var: 0.00% 
class: 1; proba: 0.0%; var: 0.01% 
class: 2; proba: 0.0%; var: 0.00% 
class: 3; proba: 0.1%; var: 0.01% 
class: 4; proba: 0.0%; var: 0.00% 
class: 5; proba: 95.4%; var: 4.71% 
class: 6; proba: 0.0%; var: 0.00% 
class: 7; proba: 4.5%; var: 4.69% 
class: 8; proba: 0.0%; var: 0.00% 
class: 9; proba: 0.0%; var: 0.00% 


###############################################################################
Peregrine Cluster
Job 11622517 for user 's2934833'
Finished at: Wed May 20 11:05:01 CEST 2020

Job details:
============

Name                : CIFBN
User                : s2934833
Partition           : gpu
Nodes               : pg-gpu35
Cores               : 12
State               : COMPLETED
Submit              : 2020-05-20T10:56:05
Start               : 2020-05-20T10:56:32
End                 : 2020-05-20T11:05:01
Reserved walltime   : 02:00:00
Used walltime       : 00:08:29
Used CPU time       : 00:09:28 (efficiency:  9.31%)
% User (Computation): 82.94%
% System (I/O)      : 17.06%
Mem reserved        : 62.50G/node
Max Mem used        : 4.29G (pg-gpu35)
Max Disk Write      : 153.60K (pg-gpu35)
Max Disk Read       : 5.83M (pg-gpu35)
Average GPU usage   : 57.6% (pg-gpu35)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/additional_information/scientific_output

################################################################################
