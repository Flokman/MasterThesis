Random seed for replication: 56
Random seed for replication: 129
dataset_name = /Polar_PNG_256.hdf5, batch_size = 16, num_classes = 3, epochs = 150,
        MCBN_PREDICTIONS = 50, Mini_batch_size = 16, test_img_idx = 11,
        train_test_split = 0.8, to_shuffle = True, augmentation = False,
        label_normalizer = False, save_augmentation_to_hdf5 = False, learn rate = 0.001,
        add_bn_inside = True, train_all_layers = False, weights_to_use = imagenet,
        es_patience = 5, train_val_split = 0.9, MIN_DELTA = 0.005, Early_monitor = val_loss
x_train shape: (184, 256, 256, 3)
184 train samples
54 test samples
<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fca4317bb38> False
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fca53f0d4a8> False
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fca3dfbfd30> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fca423b1c50> False
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fca3df37e10> True
<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fca423b1da0> False
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fca423686d8> False
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fca3dfbf710> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fca3e00da20> False
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fca38149f28> True
<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fca3e00dd68> False
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fca3e019470> False
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fca380975c0> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fca3e0257b8> False
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fca2c745710> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fca3e025a58> False
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fca2c652710> True
<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fca3e02be80> False
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fca3e02b6d8> False
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fca2c503518> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fca3e032f60> False
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fca2c41ba20> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fca3e03be80> False
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fca2c288f98> True
<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fca3e03be48> False
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fca3e046128> False
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fca2c1204e0> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fca3dfcec18> False
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fca3dec42e8> True
<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fca3dfcec88> False
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fca202aaf98> True
<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fca3dfd7b70> False
<tensorflow.python.keras.layers.core.Flatten object at 0x7fca3dfe9cc0> True
<tensorflow.python.keras.layers.core.Dense object at 0x7fca3dfe9c50> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fca200a3668> True
<tensorflow.python.keras.layers.core.Dense object at 0x7fca3dfa46d8> True
<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fc9d809a710> True
<tensorflow.python.keras.layers.core.Dense object at 0x7fca3dfab048> True
Model: "model_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 256, 256, 3)]     0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      
_________________________________________________________________
batch_normalization (BatchNo (None, 256, 256, 64)      256       
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     
_________________________________________________________________
batch_normalization_1 (Batch (None, 256, 256, 64)      256       
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     
_________________________________________________________________
batch_normalization_2 (Batch (None, 128, 128, 128)     512       
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    
_________________________________________________________________
batch_normalization_3 (Batch (None, 128, 128, 128)     512       
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    
_________________________________________________________________
batch_normalization_4 (Batch (None, 64, 64, 256)       1024      
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
batch_normalization_5 (Batch (None, 64, 64, 256)       1024      
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
batch_normalization_6 (Batch (None, 64, 64, 256)       1024      
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   
_________________________________________________________________
batch_normalization_7 (Batch (None, 32, 32, 512)       2048      
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
batch_normalization_8 (Batch (None, 32, 32, 512)       2048      
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
batch_normalization_9 (Batch (None, 32, 32, 512)       2048      
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
batch_normalization_10 (Batc (None, 16, 16, 512)       2048      
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
batch_normalization_11 (Batc (None, 16, 16, 512)       2048      
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
batch_normalization_12 (Batc (None, 16, 16, 512)       2048      
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         
_________________________________________________________________
flatten (Flatten)            (None, 32768)             0         
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              134221824 
_________________________________________________________________
batch_normalization_13 (Batc (None, 4096)              16384     
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312  
_________________________________________________________________
batch_normalization_14 (Batc (None, 4096)              16384     
_________________________________________________________________
predictions (Dense)          (None, 3)                 12291     
=================================================================
Total params: 165,779,779
Trainable params: 151,040,259
Non-trainable params: 14,739,520
_________________________________________________________________
Start fitting monte carlo batch_normalization model
Train for 11 steps, validate for 2 steps
Epoch 1/150
11/11 - 8s - loss: 1.8950 - accuracy: 0.4000 - val_loss: 0.9457 - val_accuracy: 0.4211
Epoch 2/150
11/11 - 11s - loss: 1.4605 - accuracy: 0.8242 - val_loss: 0.7478 - val_accuracy: 0.7368
Epoch 3/150
11/11 - 3s - loss: 0.3847 - accuracy: 0.9273 - val_loss: 0.7124 - val_accuracy: 0.7368
Epoch 4/150
11/11 - 3s - loss: 0.3512 - accuracy: 0.9515 - val_loss: 0.7826 - val_accuracy: 0.7368
Epoch 5/150
11/11 - 3s - loss: 0.0827 - accuracy: 0.9818 - val_loss: 0.6541 - val_accuracy: 0.7368
Epoch 6/150
11/11 - 3s - loss: 0.0715 - accuracy: 0.9879 - val_loss: 0.6342 - val_accuracy: 0.7368
Epoch 7/150
11/11 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6066 - val_accuracy: 0.7368
Epoch 8/150
11/11 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5955 - val_accuracy: 0.7368
Epoch 9/150
11/11 - 3s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6044 - val_accuracy: 0.7368
Epoch 10/150
11/11 - 3s - loss: 9.4363e-04 - accuracy: 1.0000 - val_loss: 0.6292 - val_accuracy: 0.7368
Epoch 11/150
11/11 - 3s - loss: 7.4065e-04 - accuracy: 1.0000 - val_loss: 0.6727 - val_accuracy: 0.6842
Epoch 12/150
11/11 - 3s - loss: 6.1983e-04 - accuracy: 1.0000 - val_loss: 0.7471 - val_accuracy: 0.6316
Epoch 13/150
11/11 - 3s - loss: 5.4812e-04 - accuracy: 1.0000 - val_loss: 0.8588 - val_accuracy: 0.6316
Epoch 00013: early stopping
input_1 False
block1_conv1 False
batch_normalization True
block1_conv2 False
batch_normalization_1 True
block1_pool False
block2_conv1 False
batch_normalization_2 True
block2_conv2 False
batch_normalization_3 True
block2_pool False
block3_conv1 False
batch_normalization_4 True
block3_conv2 False
batch_normalization_5 True
block3_conv3 False
batch_normalization_6 True
block3_pool False
block4_conv1 False
batch_normalization_7 True
block4_conv2 False
batch_normalization_8 True
block4_conv3 False
batch_normalization_9 True
block4_pool False
block5_conv1 False
batch_normalization_10 True
block5_conv2 False
batch_normalization_11 True
block5_conv3 False
batch_normalization_12 True
block5_pool False
flatten False
fc1 False
batch_normalization_13 True
fc2 False
batch_normalization_14 True
predictions False
 0/50 [..............................] - ETA: 0s 8/50 [===>..........................] - ETA: 28s18/50 [=========>....................] - ETA: 19s28/50 [===============>..............] - ETA: 12s38/50 [=====================>........] - ETA: 6s 48/50 [===========================>..] - ETA: 1sMCBN accuracy: 58.9%
MCBN-ensemble accuracy: 59.3%
tf.Tensor(
[[ 0  0 14]
 [ 0  0  7]
 [ 1  0 32]], shape=(3, 3), dtype=int32)
posterior mean: 2
true label: 1

class: 0; proba: 10.7%; var: 6.91% 
class: 1; proba: 3.5%; var: 3.33% 
class: 2; proba: 85.7%; var: 9.79% 
