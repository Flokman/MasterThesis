
The following have been reloaded with a version change:
  1) FFTW/3.3.7-gompic-2018a => FFTW/3.3.7-gompi-2018a
  2) OpenMPI/2.1.2-gcccuda-2018a => OpenMPI/2.1.2-GCC-6.4.0-2.28
  3) Python/3.6.4-fosscuda-2018a => Python/3.6.4-foss-2018a
  4) ScaLAPACK/2.0.2-gompic-2018a-OpenBLAS-0.2.20 => ScaLAPACK/2.0.2-gompi-2018a-OpenBLAS-0.2.20

2020-01-16 10:43:13.288001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 10:43:13.288517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GRID V100D-32Q major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:02:00.0
totalMemory: 31.87GiB freeMemory: 29.56GiB
2020-01-16 10:43:13.288565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-16 10:43:13.814538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-16 10:43:13.814642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-16 10:43:13.814662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-16 10:43:13.814774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28669 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2020-01-16 10:43:13.815918: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
dataset_name = /Messidor2_PNG_AUG_256.hdf5, batch_size = 64, num_classes = 5, epochs = 500, MCDO_amount_of_predictions = 500, MCDO_batch_size = 250, test_img_idx = 140, train_test_split = 0.8, to_shuffle = True, augmentation = False, label_count = [1261, 1416, 1397, 1455, 1463], label_normalizer = True, save_augmentation_to_hdf5 = True, learn rate = 0.0001
x_train shape: (5593, 256, 256, 3)
5593 train samples
1399 test samples
block1_pool
3
block2_pool
7
block3_pool
12
block4_pool
17
block5_pool
22
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 256, 256, 3)       0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         
_________________________________________________________________
dropout (Dropout)            (None, 128, 128, 64)      0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 64, 64, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 32, 32, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 16, 16, 512)       0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 8, 8, 512)         0         
_________________________________________________________________
flatten (Flatten)            (None, 32768)             0         
_________________________________________________________________
dense (Dense)                (None, 5)                 163845    
=================================================================
Total params: 14,878,533
Trainable params: 14,878,533
Non-trainable params: 0
_________________________________________________________________
Start fitting monte carlo dropout model
Train on 5593 samples, validate on 1399 samples
Epoch 1/500
 - 56s - loss: 1.5612 - acc: 0.2925 - val_loss: 1.4828 - val_acc: 0.3274
Epoch 2/500
 - 45s - loss: 1.4586 - acc: 0.3286 - val_loss: 1.4851 - val_acc: 0.3188
Epoch 3/500
 - 45s - loss: 1.4395 - acc: 0.3556 - val_loss: 1.4159 - val_acc: 0.3724
Epoch 4/500
 - 45s - loss: 1.4253 - acc: 0.3662 - val_loss: 1.3736 - val_acc: 0.4067
Epoch 5/500
 - 45s - loss: 1.4013 - acc: 0.3807 - val_loss: 1.3876 - val_acc: 0.3967
Epoch 6/500
 - 45s - loss: 1.3552 - acc: 0.4214 - val_loss: 1.3248 - val_acc: 0.4303
Epoch 7/500
 - 45s - loss: 1.3394 - acc: 0.4262 - val_loss: 1.3631 - val_acc: 0.3960
Epoch 8/500
 - 45s - loss: 1.2703 - acc: 0.4677 - val_loss: 1.2347 - val_acc: 0.4782
Epoch 9/500
 - 45s - loss: 1.1826 - acc: 0.5040 - val_loss: 1.1224 - val_acc: 0.5490
Epoch 10/500
 - 45s - loss: 1.1124 - acc: 0.5394 - val_loss: 1.0512 - val_acc: 0.5675
Epoch 11/500
 - 45s - loss: 1.0156 - acc: 0.5841 - val_loss: 1.0497 - val_acc: 0.5497
Epoch 12/500
 - 45s - loss: 0.9035 - acc: 0.6319 - val_loss: 0.9134 - val_acc: 0.6254
Epoch 13/500
 - 45s - loss: 0.8362 - acc: 0.6617 - val_loss: 0.7642 - val_acc: 0.6833
Epoch 14/500
 - 46s - loss: 0.7619 - acc: 0.7021 - val_loss: 0.7127 - val_acc: 0.7127
Epoch 15/500
 - 45s - loss: 0.6317 - acc: 0.7382 - val_loss: 0.6719 - val_acc: 0.7420
Epoch 16/500
 - 45s - loss: 0.5804 - acc: 0.7665 - val_loss: 0.6081 - val_acc: 0.7613
Epoch 17/500
 - 45s - loss: 0.5377 - acc: 0.7865 - val_loss: 0.5489 - val_acc: 0.7920
Epoch 18/500
 - 45s - loss: 0.4634 - acc: 0.8108 - val_loss: 0.6359 - val_acc: 0.7748
Epoch 19/500
 - 45s - loss: 0.4331 - acc: 0.8278 - val_loss: 0.5694 - val_acc: 0.7856
Epoch 20/500
 - 45s - loss: 0.3739 - acc: 0.8557 - val_loss: 0.4806 - val_acc: 0.8170
Epoch 21/500
 - 45s - loss: 0.3491 - acc: 0.8693 - val_loss: 0.4388 - val_acc: 0.8549
Epoch 22/500
 - 45s - loss: 0.3158 - acc: 0.8895 - val_loss: 0.4777 - val_acc: 0.8227
Epoch 23/500
 - 45s - loss: 0.2715 - acc: 0.8938 - val_loss: 0.5008 - val_acc: 0.8342
Epoch 24/500
 - 45s - loss: 0.2568 - acc: 0.9008 - val_loss: 0.4796 - val_acc: 0.8227
Epoch 25/500
 - 45s - loss: 0.2214 - acc: 0.9251 - val_loss: 0.4453 - val_acc: 0.8506
Epoch 26/500
 - 45s - loss: 0.2150 - acc: 0.9197 - val_loss: 0.4829 - val_acc: 0.8327
Epoch 27/500
 - 45s - loss: 0.1829 - acc: 0.9297 - val_loss: 0.4610 - val_acc: 0.8599
Epoch 28/500
 - 45s - loss: 0.1607 - acc: 0.9446 - val_loss: 0.4712 - val_acc: 0.8592
Epoch 29/500
 - 45s - loss: 0.1429 - acc: 0.9503 - val_loss: 0.4717 - val_acc: 0.8549
Epoch 30/500
 - 45s - loss: 0.1387 - acc: 0.9490 - val_loss: 0.3934 - val_acc: 0.8678
Epoch 31/500
 - 45s - loss: 0.1206 - acc: 0.9596 - val_loss: 0.4456 - val_acc: 0.8728
Epoch 32/500
 - 46s - loss: 0.1076 - acc: 0.9616 - val_loss: 0.4426 - val_acc: 0.8821
Epoch 33/500
 - 45s - loss: 0.0938 - acc: 0.9687 - val_loss: 0.4345 - val_acc: 0.8785
Epoch 34/500
 - 45s - loss: 0.0995 - acc: 0.9651 - val_loss: 0.5314 - val_acc: 0.8778
Epoch 35/500
 - 49s - loss: 0.0814 - acc: 0.9753 - val_loss: 0.5395 - val_acc: 0.8542
Epoch 36/500
 - 45s - loss: 0.0818 - acc: 0.9730 - val_loss: 0.4840 - val_acc: 0.8792
Epoch 37/500
 - 45s - loss: 0.0810 - acc: 0.9718 - val_loss: 0.4759 - val_acc: 0.8778
Epoch 38/500
 - 45s - loss: 0.0784 - acc: 0.9728 - val_loss: 0.4930 - val_acc: 0.8763
Epoch 39/500
 - 45s - loss: 0.0873 - acc: 0.9725 - val_loss: 0.4575 - val_acc: 0.8792
Epoch 40/500
 - 45s - loss: 0.0845 - acc: 0.9719 - val_loss: 0.4181 - val_acc: 0.8728
Epoch 41/500
 - 45s - loss: 0.0757 - acc: 0.9723 - val_loss: 0.5475 - val_acc: 0.8749
Epoch 42/500
 - 45s - loss: 0.0520 - acc: 0.9823 - val_loss: 0.5365 - val_acc: 0.8756
Epoch 43/500
 - 45s - loss: 0.0493 - acc: 0.9832 - val_loss: 0.5549 - val_acc: 0.8728
Epoch 44/500
 - 45s - loss: 0.0602 - acc: 0.9794 - val_loss: 0.5572 - val_acc: 0.8713
Epoch 45/500
 - 45s - loss: 0.0595 - acc: 0.9787 - val_loss: 0.4587 - val_acc: 0.8935
Epoch 46/500
 - 45s - loss: 0.0667 - acc: 0.9759 - val_loss: 0.4478 - val_acc: 0.8928
Epoch 47/500
 - 45s - loss: 0.0511 - acc: 0.9810 - val_loss: 0.5064 - val_acc: 0.8778
Epoch 48/500
 - 45s - loss: 0.0545 - acc: 0.9800 - val_loss: 0.4790 - val_acc: 0.8771
Epoch 49/500
 - 45s - loss: 0.0452 - acc: 0.9857 - val_loss: 0.5370 - val_acc: 0.8828
Epoch 50/500
 - 45s - loss: 0.0627 - acc: 0.9780 - val_loss: 0.4992 - val_acc: 0.8856
Epoch 51/500
 - 45s - loss: 0.0475 - acc: 0.9828 - val_loss: 0.5759 - val_acc: 0.8785
Epoch 52/500
 - 45s - loss: 0.0461 - acc: 0.9812 - val_loss: 0.5659 - val_acc: 0.8806
Epoch 53/500
 - 45s - loss: 0.0449 - acc: 0.9852 - val_loss: 0.4597 - val_acc: 0.8871
Epoch 54/500
 - 46s - loss: 0.0375 - acc: 0.9873 - val_loss: 0.6612 - val_acc: 0.8699
Epoch 55/500
 - 45s - loss: 0.0495 - acc: 0.9834 - val_loss: 0.5891 - val_acc: 0.8771
Epoch 56/500
 - 45s - loss: 0.0481 - acc: 0.9827 - val_loss: 0.6547 - val_acc: 0.8499
Epoch 57/500
 - 45s - loss: 0.0578 - acc: 0.9809 - val_loss: 0.5768 - val_acc: 0.8821
Epoch 58/500
 - 45s - loss: 0.0523 - acc: 0.9814 - val_loss: 0.4807 - val_acc: 0.8856
Epoch 59/500
 - 45s - loss: 0.0569 - acc: 0.9787 - val_loss: 0.5239 - val_acc: 0.8856
Epoch 60/500
 - 45s - loss: 0.0336 - acc: 0.9869 - val_loss: 0.6410 - val_acc: 0.8842
Epoch 61/500
 - 45s - loss: 0.0347 - acc: 0.9875 - val_loss: 0.7045 - val_acc: 0.8670
Epoch 62/500
 - 45s - loss: 0.0401 - acc: 0.9848 - val_loss: 0.6681 - val_acc: 0.8763
Epoch 63/500
 - 45s - loss: 0.0537 - acc: 0.9821 - val_loss: 0.6250 - val_acc: 0.8799
Epoch 64/500
 - 45s - loss: 0.0574 - acc: 0.9800 - val_loss: 0.5462 - val_acc: 0.8706
Epoch 65/500
 - 45s - loss: 0.0809 - acc: 0.9682 - val_loss: 0.6256 - val_acc: 0.8635
Epoch 66/500
 - 45s - loss: 0.0380 - acc: 0.9855 - val_loss: 0.5845 - val_acc: 0.8863
Epoch 67/500
 - 45s - loss: 0.0296 - acc: 0.9889 - val_loss: 0.6439 - val_acc: 0.8806
Epoch 68/500
 - 45s - loss: 0.0234 - acc: 0.9907 - val_loss: 0.6003 - val_acc: 0.8928
Epoch 69/500
 - 45s - loss: 0.0277 - acc: 0.9880 - val_loss: 0.6420 - val_acc: 0.8735
Epoch 70/500
 - 45s - loss: 0.0602 - acc: 0.9773 - val_loss: 0.5961 - val_acc: 0.8799
Epoch 71/500
 - 45s - loss: 0.0435 - acc: 0.9837 - val_loss: 0.6142 - val_acc: 0.8742
Epoch 72/500
 - 45s - loss: 0.0382 - acc: 0.9846 - val_loss: 0.5027 - val_acc: 0.8878
Epoch 73/500
 - 45s - loss: 0.0324 - acc: 0.9864 - val_loss: 0.6979 - val_acc: 0.8785
Epoch 74/500
 - 45s - loss: 0.0367 - acc: 0.9837 - val_loss: 0.6320 - val_acc: 0.8842
Epoch 75/500
 - 45s - loss: 0.0568 - acc: 0.9796 - val_loss: 0.6045 - val_acc: 0.8849
Epoch 76/500
 - 45s - loss: 0.0437 - acc: 0.9836 - val_loss: 0.6345 - val_acc: 0.8878
Epoch 77/500
 - 45s - loss: 0.0365 - acc: 0.9862 - val_loss: 0.5458 - val_acc: 0.8885
Epoch 78/500
 - 45s - loss: 0.0299 - acc: 0.9866 - val_loss: 0.6468 - val_acc: 0.8992
Epoch 79/500
 - 45s - loss: 0.0254 - acc: 0.9895 - val_loss: 0.5585 - val_acc: 0.8842
Epoch 80/500
 - 45s - loss: 0.0386 - acc: 0.9837 - val_loss: 0.6383 - val_acc: 0.8806
Epoch 81/500
 - 45s - loss: 0.0664 - acc: 0.9768 - val_loss: 0.5550 - val_acc: 0.8928
Epoch 82/500
 - 45s - loss: 0.0265 - acc: 0.9878 - val_loss: 0.6077 - val_acc: 0.8892
Epoch 83/500
 - 45s - loss: 0.0324 - acc: 0.9875 - val_loss: 0.5905 - val_acc: 0.8799
Epoch 84/500
 - 45s - loss: 0.0267 - acc: 0.9886 - val_loss: 0.5397 - val_acc: 0.8871
Epoch 85/500
 - 45s - loss: 0.0314 - acc: 0.9855 - val_loss: 0.6095 - val_acc: 0.8806
Epoch 86/500
 - 45s - loss: 0.0432 - acc: 0.9823 - val_loss: 0.7461 - val_acc: 0.8678
Epoch 87/500
 - 45s - loss: 0.0390 - acc: 0.9848 - val_loss: 0.5942 - val_acc: 0.8813
Epoch 88/500
 - 45s - loss: 0.0268 - acc: 0.9887 - val_loss: 0.5694 - val_acc: 0.8821
Epoch 89/500
 - 45s - loss: 0.0296 - acc: 0.9880 - val_loss: 0.6756 - val_acc: 0.8863
Epoch 90/500
 - 45s - loss: 0.0225 - acc: 0.9891 - val_loss: 0.5824 - val_acc: 0.8928
Epoch 91/500
 - 45s - loss: 0.0226 - acc: 0.9893 - val_loss: 0.5849 - val_acc: 0.8878
Epoch 92/500
 - 45s - loss: 0.0383 - acc: 0.9832 - val_loss: 0.5429 - val_acc: 0.8906
Epoch 93/500
 - 45s - loss: 0.0234 - acc: 0.9900 - val_loss: 0.6174 - val_acc: 0.8806
Epoch 94/500
 - 45s - loss: 0.0260 - acc: 0.9891 - val_loss: 0.6739 - val_acc: 0.8763
Epoch 95/500
 - 45s - loss: 0.0701 - acc: 0.9743 - val_loss: 0.6273 - val_acc: 0.8806
Epoch 96/500
 - 45s - loss: 0.0440 - acc: 0.9819 - val_loss: 0.6577 - val_acc: 0.8713
Epoch 97/500
 - 45s - loss: 0.0555 - acc: 0.9775 - val_loss: 0.5315 - val_acc: 0.8842
Epoch 98/500
 - 45s - loss: 0.0312 - acc: 0.9857 - val_loss: 0.5493 - val_acc: 0.8906
Epoch 99/500
 - 45s - loss: 0.0244 - acc: 0.9891 - val_loss: 0.5401 - val_acc: 0.8914
Epoch 100/500
 - 45s - loss: 0.0415 - acc: 0.9850 - val_loss: 0.5791 - val_acc: 0.8892
Epoch 101/500
 - 45s - loss: 0.0286 - acc: 0.9878 - val_loss: 0.7258 - val_acc: 0.8799
Epoch 102/500
 - 45s - loss: 0.0272 - acc: 0.9882 - val_loss: 0.6006 - val_acc: 0.8914
Epoch 103/500
 - 45s - loss: 0.0211 - acc: 0.9909 - val_loss: 0.6033 - val_acc: 0.8935
Epoch 104/500
 - 45s - loss: 0.0235 - acc: 0.9905 - val_loss: 0.6587 - val_acc: 0.8949
Epoch 105/500
 - 45s - loss: 0.0198 - acc: 0.9912 - val_loss: 0.6398 - val_acc: 0.8935
Epoch 106/500
 - 45s - loss: 0.0155 - acc: 0.9912 - val_loss: 0.6624 - val_acc: 0.8842
Epoch 107/500
 - 45s - loss: 0.0160 - acc: 0.9903 - val_loss: 0.7175 - val_acc: 0.8871
Epoch 108/500
 - 45s - loss: 0.0164 - acc: 0.9905 - val_loss: 0.6629 - val_acc: 0.8928
Epoch 109/500
 - 45s - loss: 0.0145 - acc: 0.9903 - val_loss: 0.6618 - val_acc: 0.8949
Epoch 110/500
 - 45s - loss: 0.0142 - acc: 0.9914 - val_loss: 0.8560 - val_acc: 0.8828
Epoch 111/500
 - 45s - loss: 0.0425 - acc: 0.9836 - val_loss: 0.6078 - val_acc: 0.8828
Epoch 112/500
 - 45s - loss: 0.0541 - acc: 0.9805 - val_loss: 0.6330 - val_acc: 0.8842
Epoch 113/500
 - 45s - loss: 0.0585 - acc: 0.9784 - val_loss: 0.7288 - val_acc: 0.8599
Epoch 114/500
 - 45s - loss: 0.0531 - acc: 0.9805 - val_loss: 0.5537 - val_acc: 0.8742
Epoch 115/500
 - 45s - loss: 0.0297 - acc: 0.9866 - val_loss: 0.5621 - val_acc: 0.8871
Epoch 116/500
 - 45s - loss: 0.0271 - acc: 0.9877 - val_loss: 0.6187 - val_acc: 0.8620
Epoch 117/500
 - 45s - loss: 0.0219 - acc: 0.9898 - val_loss: 0.5868 - val_acc: 0.8964
Epoch 118/500
 - 45s - loss: 0.0248 - acc: 0.9889 - val_loss: 0.7484 - val_acc: 0.8863
Epoch 119/500
 - 45s - loss: 0.0237 - acc: 0.9886 - val_loss: 0.7004 - val_acc: 0.8935
Epoch 120/500
 - 45s - loss: 0.0193 - acc: 0.9911 - val_loss: 0.6364 - val_acc: 0.8928
Epoch 121/500
 - 45s - loss: 0.0190 - acc: 0.9902 - val_loss: 0.6305 - val_acc: 0.8799
Epoch 122/500
 - 45s - loss: 0.0260 - acc: 0.9877 - val_loss: 0.4825 - val_acc: 0.8885
Epoch 123/500
 - 45s - loss: 0.0189 - acc: 0.9903 - val_loss: 0.6871 - val_acc: 0.8756
Epoch 124/500
 - 45s - loss: 0.0295 - acc: 0.9880 - val_loss: 0.8016 - val_acc: 0.8771
Epoch 125/500
 - 45s - loss: 0.0408 - acc: 0.9834 - val_loss: 0.7620 - val_acc: 0.8749
Epoch 126/500
 - 45s - loss: 0.0394 - acc: 0.9832 - val_loss: 0.5899 - val_acc: 0.8735
Epoch 127/500
 - 45s - loss: 0.0238 - acc: 0.9895 - val_loss: 0.6930 - val_acc: 0.8778
Epoch 128/500
 - 45s - loss: 0.0381 - acc: 0.9844 - val_loss: 0.6494 - val_acc: 0.8871
Epoch 129/500
 - 45s - loss: 0.0194 - acc: 0.9911 - val_loss: 0.6614 - val_acc: 0.8878
Epoch 130/500
 - 45s - loss: 0.0179 - acc: 0.9909 - val_loss: 0.6060 - val_acc: 0.8978
Epoch 131/500
 - 45s - loss: 0.0150 - acc: 0.9914 - val_loss: 0.6367 - val_acc: 0.8899
Epoch 132/500
 - 45s - loss: 0.0128 - acc: 0.9936 - val_loss: 0.6060 - val_acc: 0.8921
Epoch 133/500
 - 45s - loss: 0.0122 - acc: 0.9928 - val_loss: 0.6674 - val_acc: 0.8992
Epoch 134/500
 - 45s - loss: 0.0125 - acc: 0.9927 - val_loss: 0.6697 - val_acc: 0.8999
Epoch 135/500
 - 45s - loss: 0.0114 - acc: 0.9927 - val_loss: 0.7896 - val_acc: 0.8949
Epoch 136/500
 - 45s - loss: 0.0704 - acc: 0.9743 - val_loss: 0.6306 - val_acc: 0.8649
Epoch 137/500
 - 45s - loss: 0.0515 - acc: 0.9805 - val_loss: 0.6592 - val_acc: 0.8670
Epoch 138/500
 - 45s - loss: 0.0462 - acc: 0.9816 - val_loss: 0.7544 - val_acc: 0.8778
Epoch 139/500
 - 45s - loss: 0.0236 - acc: 0.9887 - val_loss: 0.5899 - val_acc: 0.8863
Epoch 140/500
 - 45s - loss: 0.0195 - acc: 0.9905 - val_loss: 0.7574 - val_acc: 0.8813
Epoch 141/500
 - 45s - loss: 0.0192 - acc: 0.9912 - val_loss: 0.6523 - val_acc: 0.8928
Epoch 142/500
 - 45s - loss: 0.0129 - acc: 0.9925 - val_loss: 0.6677 - val_acc: 0.9006
Epoch 143/500
 - 45s - loss: 0.0161 - acc: 0.9907 - val_loss: 0.6937 - val_acc: 0.8949
Epoch 144/500
 - 45s - loss: 0.0213 - acc: 0.9907 - val_loss: 0.6303 - val_acc: 0.9021
Epoch 145/500
 - 45s - loss: 0.0165 - acc: 0.9893 - val_loss: 0.7105 - val_acc: 0.8956
Epoch 146/500
 - 45s - loss: 0.0143 - acc: 0.9912 - val_loss: 0.7127 - val_acc: 0.8842
Epoch 147/500
 - 45s - loss: 0.0207 - acc: 0.9903 - val_loss: 0.7745 - val_acc: 0.8735
Epoch 148/500
 - 45s - loss: 0.0521 - acc: 0.9812 - val_loss: 0.5347 - val_acc: 0.8914
Epoch 149/500
 - 45s - loss: 0.0330 - acc: 0.9866 - val_loss: 0.6267 - val_acc: 0.8899
Epoch 150/500
 - 45s - loss: 0.0237 - acc: 0.9912 - val_loss: 0.6107 - val_acc: 0.8928
Epoch 151/500
 - 45s - loss: 0.0218 - acc: 0.9900 - val_loss: 0.6383 - val_acc: 0.8906
Epoch 152/500
 - 45s - loss: 0.0159 - acc: 0.9918 - val_loss: 0.7617 - val_acc: 0.8863
Epoch 153/500
 - 45s - loss: 0.0158 - acc: 0.9907 - val_loss: 0.8170 - val_acc: 0.8863
Epoch 154/500
 - 45s - loss: 0.0259 - acc: 0.9900 - val_loss: 0.6206 - val_acc: 0.8828
Epoch 155/500
 - 45s - loss: 0.0229 - acc: 0.9902 - val_loss: 0.8284 - val_acc: 0.8778
Epoch 156/500
 - 45s - loss: 0.0202 - acc: 0.9887 - val_loss: 0.7982 - val_acc: 0.8835
Epoch 157/500
 - 45s - loss: 0.0297 - acc: 0.9873 - val_loss: 0.7737 - val_acc: 0.8792
Epoch 158/500
 - 45s - loss: 0.0236 - acc: 0.9875 - val_loss: 0.7118 - val_acc: 0.8828
Epoch 159/500
 - 45s - loss: 0.0254 - acc: 0.9893 - val_loss: 0.7589 - val_acc: 0.8806
Epoch 160/500
 - 45s - loss: 0.0248 - acc: 0.9896 - val_loss: 0.6567 - val_acc: 0.9028
Epoch 161/500
 - 45s - loss: 0.0330 - acc: 0.9857 - val_loss: 0.7924 - val_acc: 0.8642
Epoch 162/500
 - 45s - loss: 0.0291 - acc: 0.9873 - val_loss: 0.6981 - val_acc: 0.8842
Epoch 163/500
 - 45s - loss: 0.0225 - acc: 0.9882 - val_loss: 0.6427 - val_acc: 0.8899
Epoch 164/500
 - 45s - loss: 0.0345 - acc: 0.9857 - val_loss: 0.6750 - val_acc: 0.8871
Epoch 165/500
 - 45s - loss: 0.0201 - acc: 0.9907 - val_loss: 0.6797 - val_acc: 0.8878
Epoch 166/500
 - 45s - loss: 0.0142 - acc: 0.9925 - val_loss: 0.6444 - val_acc: 0.8899
Epoch 167/500
 - 45s - loss: 0.0171 - acc: 0.9903 - val_loss: 0.6970 - val_acc: 0.8778
Epoch 168/500
 - 45s - loss: 0.0224 - acc: 0.9887 - val_loss: 0.6657 - val_acc: 0.9006
Epoch 169/500
 - 45s - loss: 0.0139 - acc: 0.9912 - val_loss: 0.6126 - val_acc: 0.8978
Epoch 170/500
 - 45s - loss: 0.0162 - acc: 0.9905 - val_loss: 0.8206 - val_acc: 0.8806
Epoch 171/500
 - 45s - loss: 0.0235 - acc: 0.9882 - val_loss: 0.7576 - val_acc: 0.8914
Epoch 172/500
 - 45s - loss: 0.0243 - acc: 0.9878 - val_loss: 0.8343 - val_acc: 0.8799
Epoch 173/500
 - 45s - loss: 0.0716 - acc: 0.9757 - val_loss: 0.6526 - val_acc: 0.8785
Epoch 174/500
 - 45s - loss: 0.0253 - acc: 0.9884 - val_loss: 0.6818 - val_acc: 0.8935
Epoch 175/500
 - 45s - loss: 0.0135 - acc: 0.9921 - val_loss: 0.7354 - val_acc: 0.8964
Epoch 176/500
 - 45s - loss: 0.0117 - acc: 0.9923 - val_loss: 0.6633 - val_acc: 0.9028
Epoch 177/500
 - 45s - loss: 0.0142 - acc: 0.9911 - val_loss: 0.7132 - val_acc: 0.8878
Epoch 178/500
 - 45s - loss: 0.0117 - acc: 0.9921 - val_loss: 0.7125 - val_acc: 0.8949
Epoch 179/500
 - 45s - loss: 0.0115 - acc: 0.9925 - val_loss: 0.6857 - val_acc: 0.8956
Epoch 180/500
 - 46s - loss: 0.0114 - acc: 0.9925 - val_loss: 0.7003 - val_acc: 0.8985
Epoch 181/500
 - 45s - loss: 0.0114 - acc: 0.9918 - val_loss: 0.6643 - val_acc: 0.9035
Epoch 182/500
 - 45s - loss: 0.0129 - acc: 0.9916 - val_loss: 0.8726 - val_acc: 0.8856
Epoch 183/500
 - 45s - loss: 0.0230 - acc: 0.9889 - val_loss: 0.7493 - val_acc: 0.8828
Epoch 184/500
 - 45s - loss: 0.0587 - acc: 0.9816 - val_loss: 0.6903 - val_acc: 0.8856
Epoch 185/500
 - 45s - loss: 0.0564 - acc: 0.9775 - val_loss: 0.7237 - val_acc: 0.8828
Epoch 186/500
 - 45s - loss: 0.0318 - acc: 0.9871 - val_loss: 0.7120 - val_acc: 0.8792
Epoch 187/500
 - 45s - loss: 0.0199 - acc: 0.9905 - val_loss: 0.7463 - val_acc: 0.8892
Epoch 188/500
 - 45s - loss: 0.0163 - acc: 0.9905 - val_loss: 0.8689 - val_acc: 0.8821
Epoch 189/500
 - 45s - loss: 0.0191 - acc: 0.9909 - val_loss: 0.7395 - val_acc: 0.8885
Epoch 190/500
 - 45s - loss: 0.0479 - acc: 0.9832 - val_loss: 0.7621 - val_acc: 0.8806
Epoch 191/500
 - 45s - loss: 0.0210 - acc: 0.9896 - val_loss: 0.7209 - val_acc: 0.8871
Epoch 192/500
 - 45s - loss: 0.0136 - acc: 0.9909 - val_loss: 0.6862 - val_acc: 0.8906
Epoch 193/500
 - 45s - loss: 0.0260 - acc: 0.9887 - val_loss: 0.7705 - val_acc: 0.8771
Epoch 194/500
 - 45s - loss: 0.0249 - acc: 0.9887 - val_loss: 0.7130 - val_acc: 0.8871
Epoch 195/500
 - 45s - loss: 0.0219 - acc: 0.9886 - val_loss: 0.7562 - val_acc: 0.8878
Epoch 196/500
 - 45s - loss: 0.0193 - acc: 0.9896 - val_loss: 0.8064 - val_acc: 0.8885
Epoch 197/500
 - 45s - loss: 0.0192 - acc: 0.9902 - val_loss: 0.8001 - val_acc: 0.8842
Epoch 198/500
 - 45s - loss: 0.0169 - acc: 0.9909 - val_loss: 0.6742 - val_acc: 0.8871
Epoch 199/500
 - 45s - loss: 0.0300 - acc: 0.9868 - val_loss: 0.8070 - val_acc: 0.8771
Epoch 200/500
 - 45s - loss: 0.0367 - acc: 0.9859 - val_loss: 0.7532 - val_acc: 0.8842
Epoch 201/500
 - 45s - loss: 0.0163 - acc: 0.9911 - val_loss: 0.6752 - val_acc: 0.8885
Epoch 202/500
 - 46s - loss: 0.0143 - acc: 0.9918 - val_loss: 0.6864 - val_acc: 0.8942
Epoch 203/500
 - 45s - loss: 0.0132 - acc: 0.9925 - val_loss: 0.7294 - val_acc: 0.8921
Epoch 204/500
 - 45s - loss: 0.0222 - acc: 0.9902 - val_loss: 0.8656 - val_acc: 0.8863
Epoch 205/500
 - 45s - loss: 0.0164 - acc: 0.9905 - val_loss: 0.6990 - val_acc: 0.8885
Epoch 206/500
 - 45s - loss: 0.0113 - acc: 0.9930 - val_loss: 0.8196 - val_acc: 0.8942
Epoch 207/500
 - 45s - loss: 0.0121 - acc: 0.9925 - val_loss: 0.7258 - val_acc: 0.8949
Epoch 208/500
 - 45s - loss: 0.0109 - acc: 0.9923 - val_loss: 0.7854 - val_acc: 0.9014
Epoch 209/500
 - 45s - loss: 0.0116 - acc: 0.9912 - val_loss: 0.8078 - val_acc: 0.8863
Epoch 210/500
 - 45s - loss: 0.0131 - acc: 0.9912 - val_loss: 0.8047 - val_acc: 0.8835
Epoch 211/500
 - 45s - loss: 0.0139 - acc: 0.9911 - val_loss: 0.8551 - val_acc: 0.8885
Epoch 212/500
 - 45s - loss: 0.0275 - acc: 0.9869 - val_loss: 0.9831 - val_acc: 0.8570
Epoch 213/500
 - 45s - loss: 0.0623 - acc: 0.9768 - val_loss: 0.8058 - val_acc: 0.8749
Epoch 214/500
 - 45s - loss: 0.0394 - acc: 0.9828 - val_loss: 0.6166 - val_acc: 0.8863
Epoch 215/500
 - 45s - loss: 0.0273 - acc: 0.9866 - val_loss: 0.7341 - val_acc: 0.8906
Epoch 216/500
 - 45s - loss: 0.0164 - acc: 0.9896 - val_loss: 0.7387 - val_acc: 0.8999
Epoch 217/500
 - 45s - loss: 0.0148 - acc: 0.9912 - val_loss: 0.7542 - val_acc: 0.8899
Epoch 218/500
 - 45s - loss: 0.0203 - acc: 0.9889 - val_loss: 0.7269 - val_acc: 0.8935
Epoch 219/500
 - 45s - loss: 0.0136 - acc: 0.9914 - val_loss: 0.6974 - val_acc: 0.8971
Epoch 220/500
 - 45s - loss: 0.0125 - acc: 0.9907 - val_loss: 0.7993 - val_acc: 0.8956
Epoch 221/500
 - 45s - loss: 0.0125 - acc: 0.9905 - val_loss: 0.8339 - val_acc: 0.8849
Epoch 222/500
 - 45s - loss: 0.0322 - acc: 0.9875 - val_loss: 0.7332 - val_acc: 0.8856
Epoch 223/500
 - 45s - loss: 0.0334 - acc: 0.9882 - val_loss: 0.6848 - val_acc: 0.8964
Epoch 224/500
 - 45s - loss: 0.0144 - acc: 0.9920 - val_loss: 0.7911 - val_acc: 0.8878
Epoch 225/500
 - 45s - loss: 0.0138 - acc: 0.9916 - val_loss: 0.8845 - val_acc: 0.8892
Epoch 226/500
 - 45s - loss: 0.0176 - acc: 0.9907 - val_loss: 0.7551 - val_acc: 0.8821
Epoch 227/500
 - 45s - loss: 0.0119 - acc: 0.9918 - val_loss: 0.7509 - val_acc: 0.8971
Epoch 228/500
 - 45s - loss: 0.0113 - acc: 0.9927 - val_loss: 0.8015 - val_acc: 0.8921
Epoch 229/500
 - 45s - loss: 0.0108 - acc: 0.9927 - val_loss: 0.7615 - val_acc: 0.8964
