
The following have been reloaded with a version change:
  1) FFTW/3.3.7-gompic-2018a => FFTW/3.3.7-gompi-2018a
  2) OpenMPI/2.1.2-gcccuda-2018a => OpenMPI/2.1.2-GCC-6.4.0-2.28
  3) Python/3.6.4-fosscuda-2018a => Python/3.6.4-foss-2018a
  4) ScaLAPACK/2.0.2-gompic-2018a-OpenBLAS-0.2.20 => ScaLAPACK/2.0.2-gompi-2018a-OpenBLAS-0.2.20

2020-02-11 13:48:19.077200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-11 13:48:19.077790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GRID V100D-32Q major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:02:00.0
totalMemory: 31.87GiB freeMemory: 29.56GiB
2020-02-11 13:48:19.077844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-02-11 13:48:19.617850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-11 13:48:19.617989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-02-11 13:48:19.618009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-02-11 13:48:19.618154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28669 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2020-02-11 13:48:19.619311: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Random seed for replication: 365
dataset_name = /Messidor2_PNG_AUG_256.hdf5, batch_size = 32, num_classes = 5, epochs = 500,
        MCDO_amount_of_predictions = 50, MCDO_batch_size = 250, test_img_idx = 223,
        train_test_split = 0.8, to_shuffle = True, augmentation = False, label_count = [1261, 1416, 1397, 1455, 1463],
        label_normalizer = True, save_augmentation_to_hdf5 = True, learn rate = 1e-05,
        add_dropout_inside = True, train_all_layers = True, weights_to_use = None,
        mcdo = True, es_patience = 30, train_val_split = 0.9
x_train shape: (5593, 256, 256, 3)
5593 train samples
1399 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 256, 256, 3)       0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         
_________________________________________________________________
MCDropout_1 (MCDropout)      (None, 128, 128, 64)      0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         
_________________________________________________________________
MCDropout_2 (MCDropout)      (None, 64, 64, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         
_________________________________________________________________
MCDropout_3 (MCDropout)      (None, 32, 32, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         
_________________________________________________________________
MCDropout_4 (MCDropout)      (None, 16, 16, 512)       0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         
_________________________________________________________________
MCDropout_5 (MCDropout)      (None, 8, 8, 512)         0         
_________________________________________________________________
flatten (Flatten)            (None, 32768)             0         
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              134221824 
_________________________________________________________________
MCDropout_6 (MCDropout)      (None, 4096)              0         
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312  
_________________________________________________________________
MCDropout_7 (MCDropout)      (None, 4096)              0         
_________________________________________________________________
predictions (Dense)          (None, 5)                 20485     
=================================================================
Total params: 165,738,309
Trainable params: 165,738,309
Non-trainable params: 0
_________________________________________________________________
Start fitting monte carlo dropout model
Epoch 1/500
 - 50s - loss: 1.6075 - acc: 0.2065 - val_loss: 1.6025 - val_acc: 0.2411
Epoch 2/500
 - 40s - loss: 1.6040 - acc: 0.2088 - val_loss: 1.5917 - val_acc: 0.2393
Epoch 3/500
 - 42s - loss: 1.5888 - acc: 0.2401 - val_loss: 1.5577 - val_acc: 0.2571
Epoch 4/500
 - 42s - loss: 1.5479 - acc: 0.3085 - val_loss: 1.4813 - val_acc: 0.3250
Epoch 5/500
 - 43s - loss: 1.4174 - acc: 0.3781 - val_loss: 1.4036 - val_acc: 0.3589
Epoch 6/500
 - 43s - loss: 1.3423 - acc: 0.4152 - val_loss: 1.3503 - val_acc: 0.3911
Epoch 7/500
 - 44s - loss: 1.3095 - acc: 0.4183 - val_loss: 1.3804 - val_acc: 0.3786
Epoch 8/500
 - 43s - loss: 1.2858 - acc: 0.4425 - val_loss: 1.2984 - val_acc: 0.4589
Epoch 9/500
 - 43s - loss: 1.2522 - acc: 0.4651 - val_loss: 1.2943 - val_acc: 0.4429
Epoch 10/500
 - 43s - loss: 1.2305 - acc: 0.4827 - val_loss: 1.2839 - val_acc: 0.4661
Epoch 11/500
 - 44s - loss: 1.2206 - acc: 0.4850 - val_loss: 1.2574 - val_acc: 0.4696
Epoch 12/500
 - 44s - loss: 1.1883 - acc: 0.5125 - val_loss: 1.2411 - val_acc: 0.4732
Epoch 13/500
 - 43s - loss: 1.1665 - acc: 0.5182 - val_loss: 1.2272 - val_acc: 0.4857
Epoch 14/500
 - 43s - loss: 1.1269 - acc: 0.5384 - val_loss: 1.1919 - val_acc: 0.5018
Epoch 15/500
 - 43s - loss: 1.1119 - acc: 0.5411 - val_loss: 1.1849 - val_acc: 0.5054
Epoch 16/500
 - 44s - loss: 1.0925 - acc: 0.5575 - val_loss: 1.1617 - val_acc: 0.4982
Epoch 17/500
 - 43s - loss: 1.0485 - acc: 0.5702 - val_loss: 1.1862 - val_acc: 0.4946
Epoch 18/500
 - 44s - loss: 1.0283 - acc: 0.5827 - val_loss: 1.1073 - val_acc: 0.5411
Epoch 19/500
 - 43s - loss: 0.9969 - acc: 0.6072 - val_loss: 1.1304 - val_acc: 0.5357
Epoch 20/500
 - 43s - loss: 0.9776 - acc: 0.6070 - val_loss: 1.1660 - val_acc: 0.5196
Epoch 21/500
 - 43s - loss: 0.9500 - acc: 0.6156 - val_loss: 1.1009 - val_acc: 0.5571
Epoch 22/500
 - 45s - loss: 0.9214 - acc: 0.6280 - val_loss: 1.1220 - val_acc: 0.5482
Epoch 23/500
 - 43s - loss: 0.8964 - acc: 0.6429 - val_loss: 1.0885 - val_acc: 0.5750
Epoch 24/500
 - 43s - loss: 0.8807 - acc: 0.6480 - val_loss: 1.0277 - val_acc: 0.6018
Epoch 25/500
 - 46s - loss: 0.8361 - acc: 0.6641 - val_loss: 1.1123 - val_acc: 0.5696
Epoch 26/500
 - 43s - loss: 0.8215 - acc: 0.6806 - val_loss: 1.0601 - val_acc: 0.5893
Epoch 27/500
 - 43s - loss: 0.7982 - acc: 0.6864 - val_loss: 1.1078 - val_acc: 0.5714
Epoch 28/500
 - 43s - loss: 0.7627 - acc: 0.6989 - val_loss: 1.1475 - val_acc: 0.5804
Epoch 29/500
 - 43s - loss: 0.7441 - acc: 0.7032 - val_loss: 1.0540 - val_acc: 0.6036
Epoch 30/500
 - 43s - loss: 0.7191 - acc: 0.7209 - val_loss: 0.9841 - val_acc: 0.6232
Epoch 31/500
 - 45s - loss: 0.6938 - acc: 0.7297 - val_loss: 0.9495 - val_acc: 0.6304
Epoch 32/500
 - 43s - loss: 0.6553 - acc: 0.7430 - val_loss: 1.0428 - val_acc: 0.6446
Epoch 33/500
 - 43s - loss: 0.6397 - acc: 0.7496 - val_loss: 0.9604 - val_acc: 0.6482
Epoch 34/500
 - 43s - loss: 0.6091 - acc: 0.7569 - val_loss: 0.9613 - val_acc: 0.6464
Epoch 35/500
 - 43s - loss: 0.5828 - acc: 0.7720 - val_loss: 0.9310 - val_acc: 0.6946
Epoch 36/500
 - 43s - loss: 0.5757 - acc: 0.7782 - val_loss: 0.9949 - val_acc: 0.6518
Epoch 37/500
 - 43s - loss: 0.5305 - acc: 0.7955 - val_loss: 0.9240 - val_acc: 0.6679
Epoch 38/500
 - 43s - loss: 0.5053 - acc: 0.8041 - val_loss: 0.9809 - val_acc: 0.6500
Epoch 39/500
 - 43s - loss: 0.4856 - acc: 0.8168 - val_loss: 0.9118 - val_acc: 0.6929
Epoch 40/500
 - 43s - loss: 0.4645 - acc: 0.8210 - val_loss: 0.9461 - val_acc: 0.6875
Epoch 41/500
 - 43s - loss: 0.4445 - acc: 0.8245 - val_loss: 1.0410 - val_acc: 0.6304
Epoch 42/500
 - 43s - loss: 0.4305 - acc: 0.8349 - val_loss: 0.9842 - val_acc: 0.6893
Epoch 43/500
 - 43s - loss: 0.4005 - acc: 0.8486 - val_loss: 1.0333 - val_acc: 0.6857
Epoch 44/500
 - 43s - loss: 0.3971 - acc: 0.8486 - val_loss: 1.0367 - val_acc: 0.6768
Epoch 45/500
 - 43s - loss: 0.3645 - acc: 0.8645 - val_loss: 0.9791 - val_acc: 0.6964
Epoch 46/500
 - 43s - loss: 0.3463 - acc: 0.8665 - val_loss: 1.0353 - val_acc: 0.7054
Epoch 47/500
 - 42s - loss: 0.3359 - acc: 0.8713 - val_loss: 0.9856 - val_acc: 0.7036
Epoch 48/500
 - 43s - loss: 0.3110 - acc: 0.8812 - val_loss: 1.0930 - val_acc: 0.6857
Epoch 49/500
 - 43s - loss: 0.2997 - acc: 0.8893 - val_loss: 1.0063 - val_acc: 0.7000
Epoch 50/500
 - 43s - loss: 0.2980 - acc: 0.8917 - val_loss: 1.0501 - val_acc: 0.6946
Epoch 51/500
 - 42s - loss: 0.2806 - acc: 0.8959 - val_loss: 1.1727 - val_acc: 0.7018
Epoch 52/500
 - 43s - loss: 0.2575 - acc: 0.9026 - val_loss: 1.1697 - val_acc: 0.6821
Epoch 53/500
 - 43s - loss: 0.2487 - acc: 0.9041 - val_loss: 1.1147 - val_acc: 0.7250
Epoch 54/500
 - 43s - loss: 0.2194 - acc: 0.9156 - val_loss: 1.1831 - val_acc: 0.7179
Epoch 55/500
 - 43s - loss: 0.2375 - acc: 0.9115 - val_loss: 1.1611 - val_acc: 0.7071
Epoch 56/500
 - 43s - loss: 0.2093 - acc: 0.9248 - val_loss: 1.2450 - val_acc: 0.6929
Epoch 57/500
 - 43s - loss: 0.2236 - acc: 0.9193 - val_loss: 1.3096 - val_acc: 0.6893
Epoch 58/500
 - 43s - loss: 0.2161 - acc: 0.9229 - val_loss: 1.2199 - val_acc: 0.6964
Epoch 59/500
 - 43s - loss: 0.1911 - acc: 0.9319 - val_loss: 1.1880 - val_acc: 0.7214
Epoch 60/500
 - 45s - loss: 0.1952 - acc: 0.9275 - val_loss: 1.2088 - val_acc: 0.7196
Epoch 61/500
 - 43s - loss: 0.1747 - acc: 0.9339 - val_loss: 1.2197 - val_acc: 0.7321
Epoch 62/500
 - 43s - loss: 0.1795 - acc: 0.9355 - val_loss: 1.1561 - val_acc: 0.7107
Epoch 63/500
 - 43s - loss: 0.1529 - acc: 0.9467 - val_loss: 1.2179 - val_acc: 0.7339
Epoch 64/500
 - 43s - loss: 0.1734 - acc: 0.9374 - val_loss: 1.3473 - val_acc: 0.7036
Epoch 65/500
 - 43s - loss: 0.1520 - acc: 0.9444 - val_loss: 1.2664 - val_acc: 0.7143
Epoch 66/500
 - 43s - loss: 0.1497 - acc: 0.9474 - val_loss: 1.3007 - val_acc: 0.7214
Epoch 67/500
 - 43s - loss: 0.1457 - acc: 0.9509 - val_loss: 1.2613 - val_acc: 0.7375
Epoch 68/500
 - 43s - loss: 0.1359 - acc: 0.9517 - val_loss: 1.4750 - val_acc: 0.6893
Epoch 69/500
 - 43s - loss: 0.1430 - acc: 0.9506 - val_loss: 1.2388 - val_acc: 0.7357
Epoch 00069: early stopping
Saved mcdo_model to disk
 0/50 [..............................] - ETA: 0s 1/50 [..............................] - ETA: 10:29 3/50 [>.............................] - ETA: 5:38  5/50 [==>...........................] - ETA: 4:33 7/50 [===>..........................] - ETA: 4:00 9/50 [====>.........................] - ETA: 3:3711/50 [=====>........................] - ETA: 3:1913/50 [======>.......................] - ETA: 3:0415/50 [========>.....................] - ETA: 2:5117/50 [=========>....................] - ETA: 2:3819/50 [==========>...................] - ETA: 2:2721/50 [===========>..................] - ETA: 2:1623/50 [============>.................] - ETA: 2:0525/50 [==============>...............] - ETA: 1:5527/50 [===============>..............] - ETA: 1:4529/50 [================>.............] - ETA: 1:3631/50 [=================>............] - ETA: 1:2633/50 [==================>...........] - ETA: 1:1735/50 [====================>.........] - ETA: 1:0737/50 [=====================>........] - ETA: 58s 39/50 [======================>.......] - ETA: 49s41/50 [=======================>......] - ETA: 40s43/50 [========================>.....] - ETA: 31s45/50 [==========================>...] - ETA: 22s47/50 [===========================>..] - ETA: 13s49/50 [============================>.] - ETA: 4s 2020-02-11 14:41:56.163890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-02-11 14:41:56.163999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-11 14:41:56.164019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-02-11 14:41:56.164034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-02-11 14:41:56.164137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28669 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
/software/software/h5py/2.7.1-fosscuda-2018a-Python-3.6.4/lib/python3.6/site-packages/h5py-2.7.1-py3.6-linux-x86_64.egg/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
MCDO accuracy: 64.1%
MCDO-ensemble accuracy: 67.7%
[[167  44  34  16   6]
 [ 31 187  53  24  15]
 [ 36  48 162  33   9]
 [  5  13  24 224  10]
 [  8  20  14   9 207]]
posterior mean: 4
true label: 4

class: 0; proba: 0.0%; var: 0.00% 
class: 1; proba: 0.0%; var: 0.00% 
class: 2; proba: 0.0%; var: 0.00% 
class: 3; proba: 0.0%; var: 0.00% 
class: 4; proba: 100.0%; var: 0.00% 


###############################################################################
Peregrine Cluster
Job 9512305 for user 's2934833'
Finished at: Tue Feb 11 14:41:59 CET 2020

Job details:
============

Name                : mcdo_astro
User                : s2934833
Partition           : gpu
Nodes               : pg-gpu37
Cores               : 12
State               : COMPLETED
Submit              : 2020-02-11T13:32:31
Start               : 2020-02-11T13:47:55
End                 : 2020-02-11T14:41:59
Reserved walltime   : 04:00:00
Used walltime       : 00:54:04
Used CPU time       : 00:45:22 (efficiency:  6.99%)
% User (Computation): 69.92%
% System (I/O)      : 30.08%
Mem reserved        : 62.50G/node
Max Mem used        : 10.79G (pg-gpu37)
Max Disk Write      : 184.32K (pg-gpu37)
Max Disk Read       : 5.47M (pg-gpu37)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/additional_information/scientific_output

################################################################################
