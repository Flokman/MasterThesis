
The following have been reloaded with a version change:
  1) FFTW/3.3.7-gompi-2018a => FFTW/3.3.7-gompic-2018a
  2) OpenMPI/2.1.2-GCC-6.4.0-2.28 => OpenMPI/2.1.2-gcccuda-2018a
  3) Python/3.6.4-foss-2018a => Python/3.6.4-fosscuda-2018a
  4) ScaLAPACK/2.0.2-gompi-2018a-OpenBLAS-0.2.20 => ScaLAPACK/2.0.2-gompic-2018a-OpenBLAS-0.2.20


The following have been reloaded with a version change:
  1) Python/3.6.4-fosscuda-2018a => Python/3.6.4-foss-2018a

2019-12-17 14:43:28.637808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-12-17 14:43:28.640411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GRID V100D-32Q major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:02:00.0
totalMemory: 31.87GiB freeMemory: 29.56GiB
2019-12-17 14:43:28.640467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-12-17 14:43:29.148982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-12-17 14:43:29.149073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-12-17 14:43:29.149091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-12-17 14:43:29.149207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28669 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2019-12-17 14:43:29.150528: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
dataset_name = /Messidor2_PNG_256.hdf5, batch_size = 32, num_classes = 5, epochs = 100, MCDO_amount_of_predictions = 500, MCDO_batch_size = 1000, test_img_idx = 192
x_train shape: (1398, 256, 256, 3)
1398 train samples
350 test samples
Start fitting monte carlo dropout model
Train on 1398 samples, validate on 350 samples
Epoch 1/100
 - 7s - loss: 1.6841 - acc: 0.5472 - val_loss: 1.1119 - val_acc: 0.5543
Epoch 2/100
 - 4s - loss: 1.1182 - acc: 0.5694 - val_loss: 1.0853 - val_acc: 0.5543
Epoch 3/100
 - 4s - loss: 1.0886 - acc: 0.5901 - val_loss: 1.0908 - val_acc: 0.5600
Epoch 4/100
 - 4s - loss: 1.0903 - acc: 0.5923 - val_loss: 1.0635 - val_acc: 0.5657
Epoch 5/100
 - 4s - loss: 1.0747 - acc: 0.5930 - val_loss: 1.0896 - val_acc: 0.5400
Epoch 6/100
 - 4s - loss: 1.0624 - acc: 0.6137 - val_loss: 1.0484 - val_acc: 0.5943
Epoch 7/100
 - 4s - loss: 1.0554 - acc: 0.6144 - val_loss: 1.0842 - val_acc: 0.5343
Epoch 8/100
 - 4s - loss: 1.0314 - acc: 0.6116 - val_loss: 1.0869 - val_acc: 0.5857
Epoch 9/100
 - 4s - loss: 1.0299 - acc: 0.6209 - val_loss: 1.0477 - val_acc: 0.5743
Epoch 10/100
 - 4s - loss: 1.0064 - acc: 0.6230 - val_loss: 1.0545 - val_acc: 0.5886
Epoch 11/100
 - 4s - loss: 1.0154 - acc: 0.6288 - val_loss: 1.0252 - val_acc: 0.5914
Epoch 12/100
 - 4s - loss: 0.9882 - acc: 0.6323 - val_loss: 1.0377 - val_acc: 0.5771
Epoch 13/100
 - 4s - loss: 0.9790 - acc: 0.6352 - val_loss: 1.0465 - val_acc: 0.5714
Epoch 14/100
 - 4s - loss: 0.9760 - acc: 0.6323 - val_loss: 1.0550 - val_acc: 0.5914
Epoch 15/100
 - 4s - loss: 0.9600 - acc: 0.6409 - val_loss: 1.0134 - val_acc: 0.5971
Epoch 16/100
 - 4s - loss: 0.9499 - acc: 0.6438 - val_loss: 1.0585 - val_acc: 0.5886
Epoch 17/100
 - 4s - loss: 0.9228 - acc: 0.6481 - val_loss: 1.0664 - val_acc: 0.5943
Epoch 18/100
 - 4s - loss: 0.9138 - acc: 0.6516 - val_loss: 1.0747 - val_acc: 0.5914
Epoch 19/100
 - 4s - loss: 0.9079 - acc: 0.6567 - val_loss: 1.0539 - val_acc: 0.6086
Epoch 20/100
 - 4s - loss: 0.8997 - acc: 0.6652 - val_loss: 1.0018 - val_acc: 0.6057
Epoch 21/100
 - 4s - loss: 0.8651 - acc: 0.6688 - val_loss: 1.0053 - val_acc: 0.5943
Epoch 22/100
 - 4s - loss: 0.8679 - acc: 0.6674 - val_loss: 1.1835 - val_acc: 0.5886
Epoch 23/100
 - 4s - loss: 0.8363 - acc: 0.6717 - val_loss: 1.1445 - val_acc: 0.5829
Epoch 24/100
 - 4s - loss: 0.8281 - acc: 0.6738 - val_loss: 1.0504 - val_acc: 0.6086
Epoch 25/100
 - 4s - loss: 0.8273 - acc: 0.6860 - val_loss: 1.0442 - val_acc: 0.5886
Epoch 26/100
 - 4s - loss: 0.7933 - acc: 0.6881 - val_loss: 1.1418 - val_acc: 0.5771
Epoch 27/100
 - 4s - loss: 0.7828 - acc: 0.6953 - val_loss: 1.0751 - val_acc: 0.5943
Epoch 28/100
 - 4s - loss: 0.7639 - acc: 0.6960 - val_loss: 1.2283 - val_acc: 0.5743
Epoch 29/100
 - 4s - loss: 0.7570 - acc: 0.7053 - val_loss: 1.1673 - val_acc: 0.5800
Epoch 30/100
 - 4s - loss: 0.7078 - acc: 0.7160 - val_loss: 1.2133 - val_acc: 0.6257
Epoch 31/100
 - 4s - loss: 0.6814 - acc: 0.7217 - val_loss: 1.1986 - val_acc: 0.5971
Epoch 32/100
 - 4s - loss: 0.6866 - acc: 0.7296 - val_loss: 1.3526 - val_acc: 0.6057
Epoch 33/100
 - 4s - loss: 0.6734 - acc: 0.7275 - val_loss: 1.2495 - val_acc: 0.6086
Epoch 34/100
 - 4s - loss: 0.6549 - acc: 0.7368 - val_loss: 1.1747 - val_acc: 0.6057
Epoch 35/100
 - 4s - loss: 0.6320 - acc: 0.7389 - val_loss: 1.3019 - val_acc: 0.6029
Epoch 36/100
 - 4s - loss: 0.5824 - acc: 0.7582 - val_loss: 1.3869 - val_acc: 0.5943
Epoch 37/100
 - 4s - loss: 0.5799 - acc: 0.7639 - val_loss: 1.4814 - val_acc: 0.5886
Epoch 38/100
 - 4s - loss: 0.5370 - acc: 0.7897 - val_loss: 1.2314 - val_acc: 0.5971
Epoch 39/100
 - 4s - loss: 0.5194 - acc: 0.7804 - val_loss: 1.4331 - val_acc: 0.5771
Epoch 40/100
 - 4s - loss: 0.5125 - acc: 0.7868 - val_loss: 1.3745 - val_acc: 0.6114
Epoch 41/100
 - 4s - loss: 0.5039 - acc: 0.8019 - val_loss: 1.3949 - val_acc: 0.6086
Epoch 42/100
 - 4s - loss: 0.4607 - acc: 0.8190 - val_loss: 1.5827 - val_acc: 0.5657
Epoch 43/100
 - 4s - loss: 0.4588 - acc: 0.8219 - val_loss: 1.4648 - val_acc: 0.5771
Epoch 44/100
 - 4s - loss: 0.4346 - acc: 0.8247 - val_loss: 1.5778 - val_acc: 0.5857
Epoch 45/100
 - 4s - loss: 0.4339 - acc: 0.8333 - val_loss: 1.8028 - val_acc: 0.5829
Epoch 46/100
 - 4s - loss: 0.4012 - acc: 0.8562 - val_loss: 1.5976 - val_acc: 0.5857
Epoch 47/100
 - 4s - loss: 0.3681 - acc: 0.8548 - val_loss: 1.4702 - val_acc: 0.6029
Epoch 48/100
 - 4s - loss: 0.3496 - acc: 0.8634 - val_loss: 1.5809 - val_acc: 0.5971
Epoch 49/100
 - 4s - loss: 0.3472 - acc: 0.8655 - val_loss: 2.0193 - val_acc: 0.6057
Epoch 50/100
 - 4s - loss: 0.3698 - acc: 0.8734 - val_loss: 1.6091 - val_acc: 0.5886
Epoch 51/100
 - 4s - loss: 0.3375 - acc: 0.8727 - val_loss: 1.8563 - val_acc: 0.5800
Epoch 52/100
 - 4s - loss: 0.3106 - acc: 0.8784 - val_loss: 1.6945 - val_acc: 0.5771
Epoch 53/100
 - 4s - loss: 0.3246 - acc: 0.8734 - val_loss: 1.8348 - val_acc: 0.5800
Epoch 54/100
 - 4s - loss: 0.2806 - acc: 0.8913 - val_loss: 1.7861 - val_acc: 0.5943
Epoch 55/100
 - 4s - loss: 0.2605 - acc: 0.9056 - val_loss: 1.8112 - val_acc: 0.5857
Epoch 56/100
 - 4s - loss: 0.2689 - acc: 0.8977 - val_loss: 1.8720 - val_acc: 0.5629
Epoch 57/100
 - 4s - loss: 0.2567 - acc: 0.8956 - val_loss: 2.0730 - val_acc: 0.5743
Epoch 58/100
 - 4s - loss: 0.2627 - acc: 0.8999 - val_loss: 1.7929 - val_acc: 0.5543
Epoch 59/100
 - 4s - loss: 0.2550 - acc: 0.9027 - val_loss: 2.0319 - val_acc: 0.5800
Epoch 60/100
 - 4s - loss: 0.2103 - acc: 0.9149 - val_loss: 1.8398 - val_acc: 0.6114
Epoch 61/100
 - 4s - loss: 0.2308 - acc: 0.9149 - val_loss: 1.9043 - val_acc: 0.5829
Epoch 62/100
 - 4s - loss: 0.2272 - acc: 0.9127 - val_loss: 2.2576 - val_acc: 0.5514
Epoch 63/100
 - 4s - loss: 0.2174 - acc: 0.9177 - val_loss: 2.1657 - val_acc: 0.5829
Epoch 64/100
 - 4s - loss: 0.2378 - acc: 0.9120 - val_loss: 2.0614 - val_acc: 0.6000
Epoch 65/100
 - 4s - loss: 0.2011 - acc: 0.9227 - val_loss: 2.1203 - val_acc: 0.5914
Epoch 66/100
 - 4s - loss: 0.1732 - acc: 0.9328 - val_loss: 2.2874 - val_acc: 0.6057
Epoch 67/100
 - 4s - loss: 0.1798 - acc: 0.9278 - val_loss: 2.0977 - val_acc: 0.5800
Epoch 68/100
 - 4s - loss: 0.1895 - acc: 0.9313 - val_loss: 2.2895 - val_acc: 0.5971
Epoch 69/100
 - 4s - loss: 0.1913 - acc: 0.9306 - val_loss: 2.4280 - val_acc: 0.5800
Epoch 70/100
 - 4s - loss: 0.2036 - acc: 0.9249 - val_loss: 1.8211 - val_acc: 0.5914
Epoch 71/100
 - 4s - loss: 0.1717 - acc: 0.9356 - val_loss: 1.9751 - val_acc: 0.5600
Epoch 72/100
 - 4s - loss: 0.1835 - acc: 0.9313 - val_loss: 2.5248 - val_acc: 0.5771
Epoch 73/100
 - 4s - loss: 0.1751 - acc: 0.9306 - val_loss: 2.3682 - val_acc: 0.5829
Epoch 74/100
 - 4s - loss: 0.1589 - acc: 0.9349 - val_loss: 2.3810 - val_acc: 0.5829
Epoch 75/100
 - 4s - loss: 0.1479 - acc: 0.9428 - val_loss: 2.0760 - val_acc: 0.6114
Epoch 76/100
 - 4s - loss: 0.1776 - acc: 0.9292 - val_loss: 2.1974 - val_acc: 0.6171
Epoch 77/100
 - 4s - loss: 0.1547 - acc: 0.9399 - val_loss: 2.4572 - val_acc: 0.5800
Epoch 78/100
 - 4s - loss: 0.1465 - acc: 0.9421 - val_loss: 2.2426 - val_acc: 0.6286
Epoch 79/100
 - 4s - loss: 0.1320 - acc: 0.9378 - val_loss: 2.3060 - val_acc: 0.5771
Epoch 80/100
 - 4s - loss: 0.1330 - acc: 0.9464 - val_loss: 2.3533 - val_acc: 0.6143
Epoch 81/100
 - 4s - loss: 0.1384 - acc: 0.9378 - val_loss: 2.6050 - val_acc: 0.6171
Epoch 82/100
 - 4s - loss: 0.1425 - acc: 0.9464 - val_loss: 2.8772 - val_acc: 0.6000
Epoch 83/100
 - 4s - loss: 0.1508 - acc: 0.9421 - val_loss: 2.3895 - val_acc: 0.6200
Epoch 84/100
 - 4s - loss: 0.1316 - acc: 0.9428 - val_loss: 2.5048 - val_acc: 0.5800
Epoch 85/100
 - 4s - loss: 0.1438 - acc: 0.9349 - val_loss: 2.5215 - val_acc: 0.6029
Epoch 86/100
 - 4s - loss: 0.1512 - acc: 0.9342 - val_loss: 2.2647 - val_acc: 0.5771
Epoch 87/100
 - 4s - loss: 0.1346 - acc: 0.9506 - val_loss: 2.5590 - val_acc: 0.5886
Epoch 88/100
 - 4s - loss: 0.1360 - acc: 0.9392 - val_loss: 2.5698 - val_acc: 0.5943
Epoch 89/100
 - 4s - loss: 0.1300 - acc: 0.9485 - val_loss: 2.9140 - val_acc: 0.5800
Epoch 90/100
 - 4s - loss: 0.1155 - acc: 0.9521 - val_loss: 2.4150 - val_acc: 0.5714
Epoch 91/100
 - 4s - loss: 0.1491 - acc: 0.9435 - val_loss: 2.6599 - val_acc: 0.6086
Epoch 92/100
 - 4s - loss: 0.1257 - acc: 0.9492 - val_loss: 2.6700 - val_acc: 0.6143
Epoch 93/100
 - 4s - loss: 0.1187 - acc: 0.9485 - val_loss: 2.8338 - val_acc: 0.5914
Epoch 94/100
 - 4s - loss: 0.1359 - acc: 0.9521 - val_loss: 2.7834 - val_acc: 0.6200
Epoch 95/100
 - 4s - loss: 0.1080 - acc: 0.9557 - val_loss: 2.5269 - val_acc: 0.5886
Epoch 96/100
 - 4s - loss: 0.1192 - acc: 0.9428 - val_loss: 2.6985 - val_acc: 0.6057
Epoch 97/100
 - 4s - loss: 0.1280 - acc: 0.9464 - val_loss: 2.8751 - val_acc: 0.5857
Epoch 98/100
 - 4s - loss: 0.1206 - acc: 0.9471 - val_loss: 2.9358 - val_acc: 0.5829
Epoch 99/100
 - 4s - loss: 0.1222 - acc: 0.9464 - val_loss: 2.7269 - val_acc: 0.5914
Epoch 100/100
 - 4s - loss: 0.1181 - acc: 0.9456 - val_loss: 2.5842 - val_acc: 0.5914
  0/500 [..............................] - ETA: 0s 12/500 [..............................] - ETA: 3:38 25/500 [>.............................] - ETA: 3:17 38/500 [=>............................] - ETA: 3:08 51/500 [==>...........................] - ETA: 3:00 64/500 [==>...........................] - ETA: 2:54 77/500 [===>..........................] - ETA: 2:47 90/500 [====>.........................] - ETA: 2:42103/500 [=====>........................] - ETA: 2:36116/500 [=====>........................] - ETA: 2:31129/500 [======>.......................] - ETA: 2:26142/500 [=======>......................] - ETA: 2:20155/500 [========>.....................] - ETA: 2:15168/500 [=========>....................] - ETA: 2:10181/500 [=========>....................] - ETA: 2:05194/500 [==========>...................] - ETA: 1:59207/500 [===========>..................] - ETA: 1:54220/500 [============>.................] - ETA: 1:49233/500 [============>.................] - ETA: 1:44246/500 [=============>................] - ETA: 1:39259/500 [==============>...............] - ETA: 1:34272/500 [===============>..............] - ETA: 1:29285/500 [================>.............] - ETA: 1:23298/500 [================>.............] - ETA: 1:18311/500 [=================>............] - ETA: 1:13324/500 [==================>...........] - ETA: 1:08337/500 [===================>..........] - ETA: 1:03350/500 [====================>.........] - ETA: 58s 363/500 [====================>.........] - ETA: 53s376/500 [=====================>........] - ETA: 48s389/500 [======================>.......] - ETA: 43s402/500 [=======================>......] - ETA: 38s415/500 [=======================>......] - ETA: 33s428/500 [========================>.....] - ETA: 28s441/500 [=========================>....] - ETA: 22s454/500 [==========================>...] - ETA: 17s467/500 [===========================>..] - ETA: 12s480/500 [===========================>..] - ETA: 7s 493/500 [============================>.] - ETA: 2s/software/software/h5py/2.7.1-fosscuda-2018a-Python-3.6.4/lib/python3.6/site-packages/h5py-2.7.1-py3.6-linux-x86_64.egg/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
MC accuracy: 59.6%
MC-ensemble accuracy: 62.3%
Tensor("confusion_matrix/SparseTensorDenseAdd:0", shape=(5, 5), dtype=int32)
posterior mean: 0
true label: 0

class: 0; proba: 96.8%; var: 8.72% 
class: 1; proba: 2.1%; var: 6.75% 
class: 2; proba: 0.9%; var: 4.13% 
class: 3; proba: 0.0%; var: 0.10% 
class: 4; proba: 0.2%; var: 2.24% 


###############################################################################
Peregrine Cluster
Job 9071911 for user 's2934833'
Finished at: Tue Dec 17 14:53:54 CET 2019

Job details:
============

Name                : MCDropoutMessidor2
User                : s2934833
Partition           : gpu
Nodes               : pg-gpu38
Cores               : 12
State               : COMPLETED
Submit              : 2019-12-17T14:43:14
Start               : 2019-12-17T14:43:14
End                 : 2019-12-17T14:53:54
Reserved walltime   : 00:35:00
Used walltime       : 00:10:40
Used CPU time       : 00:09:18 (efficiency:  7.27%)
% User (Computation): 74.13%
% System (I/O)      : 25.87%
Mem reserved        : 32000M/node
Max Mem used        : 4.77G (pg-gpu38)
Max Disk Write      : 133.12K (pg-gpu38)
Max Disk Read       : 4.96M (pg-gpu38)


Acknowledgements:
=================

Please see this page if you want to acknowledge Peregrine in your publications:

https://redmine.hpc.rug.nl/redmine/projects/peregrine/wiki/ScientificOutput

################################################################################
