
The following have been reloaded with a version change:
  1) FFTW/3.3.7-gompi-2018a => FFTW/3.3.7-gompic-2018a
  2) OpenMPI/2.1.2-GCC-6.4.0-2.28 => OpenMPI/2.1.2-gcccuda-2018a
  3) Python/3.6.4-foss-2018a => Python/3.6.4-fosscuda-2018a
  4) ScaLAPACK/2.0.2-gompi-2018a-OpenBLAS-0.2.20 => ScaLAPACK/2.0.2-gompic-2018a-OpenBLAS-0.2.20


The following have been reloaded with a version change:
  1) Python/3.6.4-fosscuda-2018a => Python/3.6.4-foss-2018a

2019-12-17 14:58:40.594149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-12-17 14:58:40.594655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GRID V100D-32Q major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:02:00.0
totalMemory: 31.87GiB freeMemory: 29.56GiB
2019-12-17 14:58:40.594701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-12-17 14:58:41.091722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-12-17 14:58:41.091812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-12-17 14:58:41.091830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-12-17 14:58:41.091952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28669 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2019-12-17 14:58:41.093064: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
dataset_name = /Messidor2_PNG_256.hdf5, batch_size = 32, num_classes = 5, epochs = 100, MCDO_amount_of_predictions = 500, MCDO_batch_size = 1000, test_img_idx = 18
x_train shape: (1398, 256, 256, 3)
1398 train samples
350 test samples
Start fitting monte carlo dropout model
Train on 1398 samples, validate on 350 samples
Epoch 1/100
 - 7s - loss: 1.7521 - acc: 0.5579 - val_loss: 1.2203 - val_acc: 0.5200
Epoch 2/100
 - 4s - loss: 1.1103 - acc: 0.5873 - val_loss: 1.1042 - val_acc: 0.5714
Epoch 3/100
 - 4s - loss: 1.0907 - acc: 0.5873 - val_loss: 1.0812 - val_acc: 0.5886
Epoch 4/100
 - 4s - loss: 1.0871 - acc: 0.5944 - val_loss: 1.1186 - val_acc: 0.5600
Epoch 5/100
 - 4s - loss: 1.0695 - acc: 0.6030 - val_loss: 1.1131 - val_acc: 0.5800
Epoch 6/100
 - 4s - loss: 1.0460 - acc: 0.6159 - val_loss: 1.0642 - val_acc: 0.5800
Epoch 7/100
 - 4s - loss: 1.0605 - acc: 0.6094 - val_loss: 1.0432 - val_acc: 0.5886
Epoch 8/100
 - 4s - loss: 1.0286 - acc: 0.6052 - val_loss: 1.0616 - val_acc: 0.5829
Epoch 9/100
 - 4s - loss: 1.0170 - acc: 0.6202 - val_loss: 1.2355 - val_acc: 0.4686
Epoch 10/100
 - 4s - loss: 1.0006 - acc: 0.6180 - val_loss: 1.0145 - val_acc: 0.5771
Epoch 11/100
 - 4s - loss: 0.9833 - acc: 0.6295 - val_loss: 1.0522 - val_acc: 0.5686
Epoch 12/100
 - 4s - loss: 0.9869 - acc: 0.6309 - val_loss: 1.0550 - val_acc: 0.5914
Epoch 13/100
 - 4s - loss: 0.9472 - acc: 0.6338 - val_loss: 1.0431 - val_acc: 0.5800
Epoch 14/100
 - 4s - loss: 0.9411 - acc: 0.6431 - val_loss: 1.0967 - val_acc: 0.5714
Epoch 15/100
 - 4s - loss: 0.9174 - acc: 0.6574 - val_loss: 1.0292 - val_acc: 0.6000
Epoch 16/100
 - 4s - loss: 0.8843 - acc: 0.6502 - val_loss: 1.0637 - val_acc: 0.5886
Epoch 17/100
 - 4s - loss: 0.9002 - acc: 0.6524 - val_loss: 1.0736 - val_acc: 0.5800
Epoch 18/100
 - 4s - loss: 0.8758 - acc: 0.6617 - val_loss: 1.0656 - val_acc: 0.5857
Epoch 19/100
 - 4s - loss: 0.8402 - acc: 0.6867 - val_loss: 1.1394 - val_acc: 0.5857
Epoch 20/100
 - 4s - loss: 0.8133 - acc: 0.6738 - val_loss: 1.1061 - val_acc: 0.5943
Epoch 21/100
 - 4s - loss: 0.8058 - acc: 0.6838 - val_loss: 1.0443 - val_acc: 0.5886
Epoch 22/100
 - 4s - loss: 0.7644 - acc: 0.6967 - val_loss: 1.0988 - val_acc: 0.5829
Epoch 23/100
 - 4s - loss: 0.7549 - acc: 0.7046 - val_loss: 1.1680 - val_acc: 0.6000
Epoch 24/100
 - 4s - loss: 0.7362 - acc: 0.7060 - val_loss: 1.1290 - val_acc: 0.5743
Epoch 25/100
 - 4s - loss: 0.6988 - acc: 0.7182 - val_loss: 1.1469 - val_acc: 0.5714
Epoch 26/100
 - 4s - loss: 0.6549 - acc: 0.7418 - val_loss: 1.1285 - val_acc: 0.5771
Epoch 27/100
 - 4s - loss: 0.6567 - acc: 0.7310 - val_loss: 1.3081 - val_acc: 0.5714
Epoch 28/100
 - 4s - loss: 0.6119 - acc: 0.7511 - val_loss: 1.1937 - val_acc: 0.5743
Epoch 29/100
 - 4s - loss: 0.5646 - acc: 0.7783 - val_loss: 1.2008 - val_acc: 0.6086
Epoch 30/100
 - 4s - loss: 0.5426 - acc: 0.7947 - val_loss: 1.3688 - val_acc: 0.5800
Epoch 31/100
 - 4s - loss: 0.5326 - acc: 0.7790 - val_loss: 1.2586 - val_acc: 0.5857
Epoch 32/100
 - 4s - loss: 0.4893 - acc: 0.8097 - val_loss: 1.2134 - val_acc: 0.6000
Epoch 33/100
 - 4s - loss: 0.4542 - acc: 0.8240 - val_loss: 1.3775 - val_acc: 0.5771
Epoch 34/100
 - 4s - loss: 0.4127 - acc: 0.8441 - val_loss: 1.4957 - val_acc: 0.5743
Epoch 35/100
 - 4s - loss: 0.3967 - acc: 0.8534 - val_loss: 1.4062 - val_acc: 0.5914
Epoch 36/100
 - 4s - loss: 0.3700 - acc: 0.8534 - val_loss: 1.5828 - val_acc: 0.5714
Epoch 37/100
 - 4s - loss: 0.3581 - acc: 0.8641 - val_loss: 1.3849 - val_acc: 0.5857
Epoch 38/100
 - 4s - loss: 0.2941 - acc: 0.8913 - val_loss: 1.4783 - val_acc: 0.6000
Epoch 39/100
 - 4s - loss: 0.3119 - acc: 0.8813 - val_loss: 1.7913 - val_acc: 0.5771
Epoch 40/100
 - 4s - loss: 0.2906 - acc: 0.8991 - val_loss: 1.4640 - val_acc: 0.5743
Epoch 41/100
 - 4s - loss: 0.2445 - acc: 0.9149 - val_loss: 1.6657 - val_acc: 0.5771
Epoch 42/100
 - 4s - loss: 0.2492 - acc: 0.9120 - val_loss: 1.4573 - val_acc: 0.6114
Epoch 43/100
 - 4s - loss: 0.2463 - acc: 0.9113 - val_loss: 1.7914 - val_acc: 0.5629
Epoch 44/100
 - 4s - loss: 0.2263 - acc: 0.9185 - val_loss: 1.7446 - val_acc: 0.5629
Epoch 45/100
 - 4s - loss: 0.2120 - acc: 0.9270 - val_loss: 1.5996 - val_acc: 0.5629
Epoch 46/100
 - 4s - loss: 0.2165 - acc: 0.9278 - val_loss: 1.7510 - val_acc: 0.5914
Epoch 47/100
 - 4s - loss: 0.1840 - acc: 0.9356 - val_loss: 1.8590 - val_acc: 0.5914
Epoch 48/100
 - 4s - loss: 0.1835 - acc: 0.9320 - val_loss: 2.0429 - val_acc: 0.5629
Epoch 49/100
 - 4s - loss: 0.1767 - acc: 0.9356 - val_loss: 1.8943 - val_acc: 0.5971
Epoch 50/100
 - 4s - loss: 0.1623 - acc: 0.9413 - val_loss: 1.9710 - val_acc: 0.6029
Epoch 51/100
 - 4s - loss: 0.1986 - acc: 0.9242 - val_loss: 1.7821 - val_acc: 0.5914
Epoch 52/100
 - 4s - loss: 0.1547 - acc: 0.9528 - val_loss: 1.8901 - val_acc: 0.6000
Epoch 53/100
 - 4s - loss: 0.1373 - acc: 0.9506 - val_loss: 1.7799 - val_acc: 0.5886
Epoch 54/100
 - 4s - loss: 0.1386 - acc: 0.9464 - val_loss: 2.0715 - val_acc: 0.5800
Epoch 55/100
 - 4s - loss: 0.1441 - acc: 0.9442 - val_loss: 2.1194 - val_acc: 0.6029
Epoch 56/100
 - 4s - loss: 0.1468 - acc: 0.9399 - val_loss: 2.1614 - val_acc: 0.6029
Epoch 57/100
 - 4s - loss: 0.1399 - acc: 0.9492 - val_loss: 2.1616 - val_acc: 0.5829
Epoch 58/100
 - 4s - loss: 0.1280 - acc: 0.9542 - val_loss: 2.1486 - val_acc: 0.6286
Epoch 59/100
 - 4s - loss: 0.1196 - acc: 0.9542 - val_loss: 1.9388 - val_acc: 0.6257
Epoch 60/100
 - 4s - loss: 0.1234 - acc: 0.9506 - val_loss: 2.0702 - val_acc: 0.6314
Epoch 61/100
 - 4s - loss: 0.1305 - acc: 0.9506 - val_loss: 2.4291 - val_acc: 0.5829
Epoch 62/100
 - 4s - loss: 0.1096 - acc: 0.9521 - val_loss: 1.9871 - val_acc: 0.5886
Epoch 63/100
 - 4s - loss: 0.1098 - acc: 0.9571 - val_loss: 2.2409 - val_acc: 0.6029
Epoch 64/100
 - 4s - loss: 0.1181 - acc: 0.9521 - val_loss: 2.1091 - val_acc: 0.6086
Epoch 65/100
 - 4s - loss: 0.1213 - acc: 0.9499 - val_loss: 2.1565 - val_acc: 0.5943
Epoch 66/100
 - 4s - loss: 0.1106 - acc: 0.9506 - val_loss: 2.3637 - val_acc: 0.5943
Epoch 67/100
 - 4s - loss: 0.1092 - acc: 0.9471 - val_loss: 2.8184 - val_acc: 0.5886
Epoch 68/100
 - 4s - loss: 0.1188 - acc: 0.9485 - val_loss: 2.4610 - val_acc: 0.5571
Epoch 69/100
 - 4s - loss: 0.1208 - acc: 0.9471 - val_loss: 2.4214 - val_acc: 0.6057
Epoch 70/100
 - 4s - loss: 0.0972 - acc: 0.9592 - val_loss: 2.2734 - val_acc: 0.5914
Epoch 71/100
 - 4s - loss: 0.0857 - acc: 0.9599 - val_loss: 2.6710 - val_acc: 0.6029
Epoch 72/100
 - 4s - loss: 0.1005 - acc: 0.9571 - val_loss: 2.2062 - val_acc: 0.5800
Epoch 73/100
 - 4s - loss: 0.1128 - acc: 0.9614 - val_loss: 2.3164 - val_acc: 0.5829
Epoch 74/100
 - 4s - loss: 0.1024 - acc: 0.9592 - val_loss: 2.3352 - val_acc: 0.6086
Epoch 75/100
 - 4s - loss: 0.0915 - acc: 0.9621 - val_loss: 2.5391 - val_acc: 0.5914
Epoch 76/100
 - 4s - loss: 0.0998 - acc: 0.9571 - val_loss: 2.0695 - val_acc: 0.6114
Epoch 77/100
 - 4s - loss: 0.0959 - acc: 0.9557 - val_loss: 2.5619 - val_acc: 0.6029
Epoch 78/100
 - 4s - loss: 0.0873 - acc: 0.9564 - val_loss: 2.7368 - val_acc: 0.6029
Epoch 79/100
 - 4s - loss: 0.0912 - acc: 0.9599 - val_loss: 2.4187 - val_acc: 0.6114
Epoch 80/100
 - 4s - loss: 0.0928 - acc: 0.9578 - val_loss: 2.5858 - val_acc: 0.5886
Epoch 81/100
 - 4s - loss: 0.0935 - acc: 0.9578 - val_loss: 2.2591 - val_acc: 0.6229
Epoch 82/100
 - 4s - loss: 0.0852 - acc: 0.9635 - val_loss: 2.5045 - val_acc: 0.5971
Epoch 83/100
 - 4s - loss: 0.0803 - acc: 0.9599 - val_loss: 2.4816 - val_acc: 0.6000
Epoch 84/100
 - 4s - loss: 0.0929 - acc: 0.9557 - val_loss: 2.5306 - val_acc: 0.6114
Epoch 85/100
 - 4s - loss: 0.0833 - acc: 0.9585 - val_loss: 2.6166 - val_acc: 0.6086
Epoch 86/100
 - 4s - loss: 0.0901 - acc: 0.9592 - val_loss: 2.4893 - val_acc: 0.6200
Epoch 87/100
 - 4s - loss: 0.0835 - acc: 0.9564 - val_loss: 3.0162 - val_acc: 0.5857
Epoch 88/100
 - 4s - loss: 0.0988 - acc: 0.9557 - val_loss: 2.4919 - val_acc: 0.5886
Epoch 89/100
 - 4s - loss: 0.0892 - acc: 0.9628 - val_loss: 2.6900 - val_acc: 0.5857
Epoch 90/100
 - 4s - loss: 0.0786 - acc: 0.9657 - val_loss: 2.6913 - val_acc: 0.5886
Epoch 91/100
 - 4s - loss: 0.0746 - acc: 0.9607 - val_loss: 2.6743 - val_acc: 0.6200
Epoch 92/100
 - 4s - loss: 0.0890 - acc: 0.9549 - val_loss: 2.7362 - val_acc: 0.6114
Epoch 93/100
 - 4s - loss: 0.0793 - acc: 0.9614 - val_loss: 2.6756 - val_acc: 0.6143
Epoch 94/100
 - 4s - loss: 0.0899 - acc: 0.9549 - val_loss: 2.3824 - val_acc: 0.6286
Epoch 95/100
 - 4s - loss: 0.0803 - acc: 0.9578 - val_loss: 2.4016 - val_acc: 0.6143
Epoch 96/100
 - 4s - loss: 0.0779 - acc: 0.9621 - val_loss: 2.5616 - val_acc: 0.6000
Epoch 97/100
 - 4s - loss: 0.0843 - acc: 0.9585 - val_loss: 2.2644 - val_acc: 0.5714
Epoch 98/100
 - 4s - loss: 0.0762 - acc: 0.9621 - val_loss: 2.6455 - val_acc: 0.6143
Epoch 99/100
 - 4s - loss: 0.0738 - acc: 0.9642 - val_loss: 2.6324 - val_acc: 0.5714
Epoch 100/100
 - 4s - loss: 0.0658 - acc: 0.9671 - val_loss: 2.9799 - val_acc: 0.5943
  0/500 [..............................] - ETA: 0s 12/500 [..............................] - ETA: 3:38 25/500 [>.............................] - ETA: 3:17 38/500 [=>............................] - ETA: 3:07 51/500 [==>...........................] - ETA: 3:00 64/500 [==>...........................] - ETA: 2:54 77/500 [===>..........................] - ETA: 2:48 90/500 [====>.........................] - ETA: 2:42103/500 [=====>........................] - ETA: 2:36116/500 [=====>........................] - ETA: 2:31129/500 [======>.......................] - ETA: 2:25142/500 [=======>......................] - ETA: 2:20155/500 [========>.....................] - ETA: 2:15168/500 [=========>....................] - ETA: 2:09181/500 [=========>....................] - ETA: 2:04194/500 [==========>...................] - ETA: 1:59207/500 [===========>..................] - ETA: 1:54220/500 [============>.................] - ETA: 1:49233/500 [============>.................] - ETA: 1:44246/500 [=============>................] - ETA: 1:39259/500 [==============>...............] - ETA: 1:34272/500 [===============>..............] - ETA: 1:28285/500 [================>.............] - ETA: 1:23298/500 [================>.............] - ETA: 1:18311/500 [=================>............] - ETA: 1:13324/500 [==================>...........] - ETA: 1:08337/500 [===================>..........] - ETA: 1:03350/500 [====================>.........] - ETA: 58s 363/500 [====================>.........] - ETA: 53s376/500 [=====================>........] - ETA: 48s389/500 [======================>.......] - ETA: 43s402/500 [=======================>......] - ETA: 38s415/500 [=======================>......] - ETA: 33s428/500 [========================>.....] - ETA: 27s441/500 [=========================>....] - ETA: 22s454/500 [==========================>...] - ETA: 17s467/500 [===========================>..] - ETA: 12s480/500 [===========================>..] - ETA: 7s 493/500 [============================>.] - ETA: 2s/software/software/h5py/2.7.1-fosscuda-2018a-Python-3.6.4/lib/python3.6/site-packages/h5py-2.7.1-py3.6-linux-x86_64.egg/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
MC accuracy: 60.1%
MC-ensemble accuracy: 61.1%
posterior mean: 0
true label: 0

class: 0; proba: 99.8%; var: 0.84% 
class: 1; proba: 0.1%; var: 0.43% 
class: 2; proba: 0.1%; var: 0.41% 
class: 3; proba: 0.0%; var: 0.47% 
class: 4; proba: 0.0%; var: 0.02% 


###############################################################################
Peregrine Cluster
Job 9071960 for user 's2934833'
Finished at: Tue Dec 17 15:09:05 CET 2019

Job details:
============

Name                : MCDropoutMessidor2
User                : s2934833
Partition           : gpu
Nodes               : pg-gpu38
Cores               : 12
State               : COMPLETED
Submit              : 2019-12-17T14:58:25
Start               : 2019-12-17T14:58:26
End                 : 2019-12-17T15:09:04
Reserved walltime   : 00:35:00
Used walltime       : 00:10:38
Used CPU time       : 00:09:18 (efficiency:  7.29%)
% User (Computation): 74.67%
% System (I/O)      : 25.33%
Mem reserved        : 32000M/node
Max Mem used        : 4.76G (pg-gpu38)
Max Disk Write      : 133.12K (pg-gpu38)
Max Disk Read       : 4.96M (pg-gpu38)


Acknowledgements:
=================

Please see this page if you want to acknowledge Peregrine in your publications:

https://redmine.hpc.rug.nl/redmine/projects/peregrine/wiki/ScientificOutput

################################################################################
