
The following have been reloaded with a version change:
  1) FFTW/3.3.7-gompic-2018a => FFTW/3.3.7-gompi-2018a
  2) OpenMPI/2.1.2-gcccuda-2018a => OpenMPI/2.1.2-GCC-6.4.0-2.28
  3) Python/3.6.4-fosscuda-2018a => Python/3.6.4-foss-2018a
  4) ScaLAPACK/2.0.2-gompic-2018a-OpenBLAS-0.2.20 => ScaLAPACK/2.0.2-gompi-2018a-OpenBLAS-0.2.20

2020-01-28 12:56:26.382092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-28 12:56:26.382610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GRID V100D-32Q major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:02:00.0
totalMemory: 31.87GiB freeMemory: 29.56GiB
2020-01-28 12:56:26.382657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-28 12:56:26.880060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-28 12:56:26.880148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-28 12:56:26.880166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-28 12:56:26.880280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28669 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2020-01-28 12:56:26.881539: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
/home/s2934833/MasterThesis/Test/test_images/*
x_pred shape: (3, 256, 256, 3)
3 x_pred samples
/home/s2934833/MasterThesis/Dropout/None_Yes_Retrain_64_73
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 256, 256, 3)       0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         
_________________________________________________________________
flatten (Flatten)            (None, 32768)             0         
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              134221824 
_________________________________________________________________
dropout (Dropout)            (None, 4096)              0         
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312  
_________________________________________________________________
dropout_1 (Dropout)          (None, 4096)              0         
_________________________________________________________________
predictions (Dense)          (None, 5)                 20485     
=================================================================
Total params: 165,738,309
Trainable params: 165,738,309
Non-trainable params: 0
_________________________________________________________________
  0/250 [..............................] - ETA: 0s247/250 [============================>.] - ETA: 0s/software/software/h5py/2.7.1-fosscuda-2018a-Python-3.6.4/lib/python3.6/site-packages/h5py-2.7.1-py3.6-linux-x86_64.egg/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
posterior mean: 4
class: 0; proba: 0.0%; var: 0.15% 
class: 1; proba: 0.0%; var: 0.12% 
class: 2; proba: 0.0%; var: 0.00% 
class: 3; proba: 3.1%; var: 12.22% 
class: 4; proba: 96.9%; var: 12.24% 
posterior mean: 4
class: 0; proba: 0.1%; var: 0.53% 
class: 1; proba: 0.0%; var: 0.01% 
class: 2; proba: 28.0%; var: 33.97% 
class: 3; proba: 33.0%; var: 36.68% 
class: 4; proba: 38.9%; var: 37.20% 
posterior mean: 4
class: 0; proba: 0.0%; var: 0.01% 
class: 1; proba: 0.0%; var: 0.00% 
class: 2; proba: 0.1%; var: 0.51% 
class: 3; proba: 2.1%; var: 8.19% 
class: 4; proba: 97.8%; var: 8.27% 


###############################################################################
Peregrine Cluster
Job 9399672 for user 's2934833'
Finished at: Tue Jan 28 12:56:46 CET 2020

Job details:
============

Name                : use_MCDO
User                : s2934833
Partition           : gpu
Nodes               : pg-gpu39
Cores               : 12
State               : COMPLETED
Submit              : 2020-01-28T12:56:11
Start               : 2020-01-28T12:56:13
End                 : 2020-01-28T12:56:46
Reserved walltime   : 00:05:00
Used walltime       : 00:00:33
Used CPU time       : 00:00:24 (efficiency:  6.07%)
% User (Computation): 66.34%
% System (I/O)      : 33.66%
Mem reserved        : 32000M/node
Max Mem used        : 3.98G (pg-gpu39)
Max Disk Write      : 184.32K (pg-gpu39)
Max Disk Read       : 6.44M (pg-gpu39)


Acknowledgements:
=================

Please see this page if you want to acknowledge Peregrine in your publications:

https://redmine.hpc.rug.nl/redmine/projects/peregrine/wiki/ScientificOutput

################################################################################
