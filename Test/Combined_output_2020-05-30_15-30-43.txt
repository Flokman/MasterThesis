
START MCDO
MNIST data returning
Total labels in train set:  [5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]
Labels in test set:  [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]
/data/s2934833/MasterThesis/MCDO/CIFAR10/2020-05-20_11-01_imagenet_32B_68.6%A
MCDO combined accuracy: 85.5%
tf.Tensor(
[[903   6  20  10   8   3   7  10  23  10]
 [ 15 918   0   0   0   5   3   2  14  43]
 [ 24   1 820  19  45  39  42   8   1   1]
 [  7   4  37 570  46 254  46  21   4  11]
 [ 11   1  35  19 841  28  23  36   5   1]
 [  4   0  15  55  20 870  16  18   0   2]
 [  4   2  23  23  10  16 916   1   3   2]
 [  5   1  12  15  26  57   2 876   1   5]
 [ 39   9   5   3   4   2   1   1 928   8]
 [ 17  37   3   4   1   5   7   3  12 911]], shape=(10, 10), dtype=int32)
Correct: 8553, wrong: 1447, accuracy: 85.53%

Mean probability on true label of CIFAR10 test dataset when correctly predicted = 94.62%
Mean uncertainty on true label of CIFAR10 test dataset when correctly predicted = 2.39%
Mean probability on true label of CIFAR10 test dataset when wrongly predicted = 13.94%
Mean uncertainty on true label of CIFAR10 test dataset when wrongly predicted = 6.16%

Mean probability on highest predicted on CIFAR10 test dataset when wrong = 91.36%
Mean uncertainty on highest predicted on CIFAR10 test dataset when wrong = 3.37%

Mean probability on all not true label on CIFAR10 test dataset = 0.96%
Mean uncertainty on all not true label on CIFAR10 test dataset = 0.49%
creating scatterplot

Mean probability on highest predicted class of MNIST data = 75.66%
Mean uncertainty on highest predicted class of MNIST data = 8.63%
Mean probability on not predicted classes of MNIST data = 2.70%
Mean uncertainty on not predicted classes of MNIST data = 1.47%

START MCBN
MNIST data returning
Total labels in train set:  [5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]
Labels in test set:  [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]
/data/s2934833/MasterThesis/MCBN/CIFAR10/2020-05-20_11-04_imagenet_32B_82.8%A
MCBN combined accuracy: 83.6%
tf.Tensor(
[[869  10  18  14   9   3   5  14  29  29]
 [ 11 911   1   4   0   2   1   4  14  52]
 [ 43   2 764  64  40  32  27  17   5   6]
 [  8   4  30 704  34 150  26  27   3  14]
 [ 17   1  41  49 802  31  21  31   4   3]
 [  6   0  23 141  15 769   8  32   3   3]
 [  5   6  27  65  20  17 845   6   6   3]
 [  8   2  12  29  21  43   3 873   4   5]
 [ 34  18   5  13   3   0   1   2 906  18]
 [ 16  32   5   6   0   2   3   8  13 915]], shape=(10, 10), dtype=int32)
Correct: 8358, wrong: 1642, accuracy: 83.58%

Mean probability on true label of CIFAR10 test dataset when correctly predicted = 93.10%
Mean uncertainty on true label of CIFAR10 test dataset when correctly predicted = 4.30%
Mean probability on true label of CIFAR10 test dataset when wrongly predicted = 15.44%
Mean uncertainty on true label of CIFAR10 test dataset when wrongly predicted = 9.30%

Mean probability on highest predicted on CIFAR10 test dataset when wrong = 89.33%
Mean uncertainty on highest predicted on CIFAR10 test dataset when wrong = 5.82%

Mean probability on all not true label on CIFAR10 test dataset = 1.19%
Mean uncertainty on all not true label on CIFAR10 test dataset = 0.84%
creating scatterplot

Mean probability on highest predicted class of MNIST data = 76.63%
Mean uncertainty on highest predicted class of MNIST data = 1.80%
Mean probability on not predicted classes of MNIST data = 2.60%
Mean uncertainty on not predicted classes of MNIST data = 0.28%

START Ensemble
Dataset_name: CIFAR10, N_folders: 1, total mebers: 3
MNIST data returning
(10000, 75, 75, 3)
Total labels in train set:  [5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]
Labels in test set:  [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]
loaded: ensemble_weights_Xception_0.h5
loaded: ensemble_weights_Xception_1.h5
loaded: ensemble_weights_Xception_2.h5
loaded: ensemble_weights_VGG16_0.h5
loaded: ensemble_weights_VGG16_1.h5
loaded: ensemble_weights_VGG16_2.h5
loaded: ensemble_weights_VGG19_0.h5
loaded: ensemble_weights_VGG19_1.h5
loaded: ensemble_weights_VGG19_2.h5
loaded: ensemble_weights_ResNet50_0.h5
loaded: ensemble_weights_ResNet50_1.h5
loaded: ensemble_weights_ResNet50_2.h5
loaded: ensemble_weights_ResNet101_0.h5
loaded: ensemble_weights_ResNet101_1.h5
loaded: ensemble_weights_ResNet101_2.h5
loaded: ensemble_weights_ResNet152_0.h5
loaded: ensemble_weights_ResNet152_1.h5
loaded: ensemble_weights_ResNet152_2.h5
loaded: ensemble_weights_ResNet50V2_0.h5
loaded: ensemble_weights_ResNet50V2_1.h5
loaded: ensemble_weights_ResNet50V2_2.h5
loaded: ensemble_weights_ResNet101V2_0.h5
loaded: ensemble_weights_ResNet101V2_1.h5
loaded: ensemble_weights_ResNet101V2_2.h5
loaded: ensemble_weights_ResNet152V2_0.h5
loaded: ensemble_weights_ResNet152V2_1.h5
loaded: ensemble_weights_ResNet152V2_2.h5
loaded: ensemble_weights_InceptionV3_0.h5
loaded: ensemble_weights_InceptionV3_1.h5
loaded: ensemble_weights_InceptionV3_2.h5
loaded: ensemble_weights_InceptionResNetV2_0.h5
loaded: ensemble_weights_InceptionResNetV2_1.h5
loaded: ensemble_weights_InceptionResNetV2_2.h5
loaded: ensemble_weights_DenseNet121_0.h5
loaded: ensemble_weights_DenseNet121_1.h5
loaded: ensemble_weights_DenseNet121_2.h5
loaded: ensemble_weights_DenseNet169_0.h5
loaded: ensemble_weights_DenseNet169_1.h5
loaded: ensemble_weights_DenseNet169_2.h5
loaded: ensemble_weights_DenseNet201_0.h5
loaded: ensemble_weights_DenseNet201_1.h5
loaded: ensemble_weights_DenseNet201_2.h5
Ensemble combined accuracy: 79.4%
tf.Tensor(
[[832  13  19  13   6   2   7  11  65  32]
 [ 12 888   1   1   0   4   8   3  16  67]
 [ 59   2 679  41  85  38  55  22  10   9]
 [ 16   7  57 644  39 125  52  33  13  14]
 [ 23   2  42  43 759  20  41  59   9   2]
 [ 10   4  34 152  41 700  12  38   1   8]
 [  6   5  25  43  26  18 868   2   4   3]
 [ 14   4  16  33  45  39   5 827   2  15]
 [ 42  28  10  10   4   1   1   3 882  19]
 [ 18  58   8   9   2   7   4   7  30 857]], shape=(10, 10), dtype=int32)
Correct: 7936, wrong: 2064, accuracy: 79.36%

Mean probability on true label of CIFAR10 test dataset when correctly predicted = 68.11%
Mean uncertainty on true label of CIFAR10 test dataset when correctly predicted = 25.07%
Mean probability on true label of CIFAR10 test dataset when wrongly predicted = 20.33%
Mean uncertainty on true label of CIFAR10 test dataset when wrongly predicted = 20.27%

Mean probability on highest predicted on CIFAR10 test dataset when wrong = 63.21%
Mean uncertainty on highest predicted on CIFAR10 test dataset when wrong = 25.64%

Mean probability on all not true label on CIFAR10 test dataset = 4.09%
Mean uncertainty on all not true label on CIFAR10 test dataset = 5.67%
creating scatterplot
loaded: ensemble_weights_Xception_0.h5

START VarianceOutput
MNIST data returning
Total labels in train set:  [5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]
Labels in test set:  [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]
/data/s2934833/MasterThesis/VarianceOutput/CIFAR10/2020-05-20_11-16_imagenet_128B_69.4%A
Accuracy on original test dataset: 83.8%
tf.Tensor(
[[883   7  13  26   8   1   2   8  37  15]
 [ 11 905   1  10   0   4   4   1  12  52]
 [ 42   2 758  73  45  33  30  14   2   1]
 [  8   4  22 745  38 129  25  19   4   6]
 [ 11   1  25  80 807  23  18  26   8   1]
 [  1   1  11 170  19 761  11  23   1   2]
 [  3   3  16  65  17  16 874   2   4   0]
 [  9   3   8  46  39  55   3 831   0   6]
 [ 43  10   5   7   4   1   1   2 917  10]
 [ 15  50   2  12   0   3   4   2  14 898]], shape=(10, 10), dtype=int32)
Correct: 8379, wrong: 1621, accuracy: 83.78999999999999%

Mean probability on true label of original test dataset when correctly predicted = 98.54%
Mean uncertainty on true label of original test dataset when correctly predicted = 10.22%
Mean probability on true label of original test dataset when wrongly predicted = 6.36%
Mean uncertainty on true label of original test dataset when wrongly predicted = 10.56%

Mean probability on highest predicted on original test dataset when wrong = 89.08%
Mean uncertainty on highest predicted on original test dataset when wrong = 10.74%

Mean probability on all not true label on original test dataset = 1.82%
Mean uncertainty on all not true label on original test dataset = 9.97%
creating scatterplot
With error converted to uncertainty
Accuracy on original test dataset: 83.8%
tf.Tensor(
[[883   7  13  26   8   1   2   8  37  15]
 [ 11 905   1  10   0   4   4   1  12  52]
 [ 42   2 758  73  45  33  30  14   2   1]
 [  8   4  22 745  38 129  25  19   4   6]
 [ 11   1  25  80 807  23  18  26   8   1]
 [  1   1  11 170  19 761  11  23   1   2]
 [  3   3  16  65  17  16 874   2   4   0]
 [  9   3   8  46  39  55   3 831   0   6]
 [ 43  10   5   7   4   1   1   2 917  10]
 [ 15  50   2  12   0   3   4   2  14 898]], shape=(10, 10), dtype=int32)
Correct: 8379, wrong: 1621, accuracy: 83.78999999999999%

Mean probability on true label of original test dataset when correctly predicted = 98.54%
Mean uncertainty on true label of original test dataset when correctly predicted = 10.04%
Mean probability on true label of original test dataset when wrongly predicted = 6.36%
Mean uncertainty on true label of original test dataset when wrongly predicted = 9.57%

Mean probability on highest predicted on original test dataset when wrong = 89.08%
Mean uncertainty on highest predicted on original test dataset when wrong = 9.74%

Mean probability on all not true label on original test dataset = 1.82%
Mean uncertainty on all not true label on original test dataset = 9.92%
creating scatterplot

#################################
Function main called 1 times. 
Execution time max: 1409.811, average: 1409.811
#################################
