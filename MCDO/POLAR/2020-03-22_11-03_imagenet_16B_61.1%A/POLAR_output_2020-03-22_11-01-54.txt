Random seed for replication: 912
Random seed for replication: 777
augmentation of train set done
augmentation test set done
dataset_name = /Polar_PNG_256.hdf5, batch_size = 16, num_classes = 3, epochs = 500,
        MCDO_PREDICTIONS = 250, MCDO_BATCH_SIZE = 16, test_img_idx = 5,
        train_test_split = 0.8, to_shuffle = True, augmentation = True, train_label_count = [42, 22, 120],
        test_label_count = [14, 7, 33], label_normalizer = False, save_augmentation_to_hdf5 = False, learn rate = 0.01,
        add_dropout_inside = True, train_all_layers = True, weights_to_use = imagenet,
        es_patience = 10, train_val_split = 0.9, MIN_DELTA = 0.005, Early_monitor = val_accuracy
x_train shape: (184, 256, 256, 3)
184 train samples
54 test samples
Model: "model_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 256, 256, 3)]     0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         
_________________________________________________________________
dropout (Dropout)            (None, 128, 128, 64)      0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 64, 64, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 32, 32, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 16, 16, 512)       0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 8, 8, 512)         0         
_________________________________________________________________
flatten (Flatten)            (None, 32768)             0         
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              134221824 
_________________________________________________________________
dropout_5 (Dropout)          (None, 4096)              0         
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312  
_________________________________________________________________
dropout_6 (Dropout)          (None, 4096)              0         
_________________________________________________________________
predictions (Dense)          (None, 3)                 12291     
=================================================================
Total params: 165,730,115
Trainable params: 165,730,115
Non-trainable params: 0
_________________________________________________________________
Start fitting monte carlo dropout model
Train for 11 steps, validate for 2 steps
Epoch 1/500
11/11 - 7s - loss: 330115680815.3349 - accuracy: 0.3758 - val_loss: 79193852.0000 - val_accuracy: 0.5789
Epoch 2/500
11/11 - 3s - loss: 7279230.3887 - accuracy: 0.5273 - val_loss: 2653998.5625 - val_accuracy: 0.5263
Epoch 3/500
11/11 - 3s - loss: 1100135.7845 - accuracy: 0.4788 - val_loss: 87881.0176 - val_accuracy: 0.5263
Epoch 4/500
11/11 - 3s - loss: 2609175.3834 - accuracy: 0.5152 - val_loss: 21609.2488 - val_accuracy: 0.5263
Epoch 5/500
11/11 - 3s - loss: 100534.9269 - accuracy: 0.4909 - val_loss: 5632.8398 - val_accuracy: 0.3684
Epoch 6/500
11/11 - 3s - loss: 27021.2596 - accuracy: 0.3455 - val_loss: 2620.7062 - val_accuracy: 0.5263
Epoch 7/500
11/11 - 3s - loss: 2124.8919 - accuracy: 0.5818 - val_loss: 276.6787 - val_accuracy: 0.4737
Epoch 8/500
11/11 - 3s - loss: 5854.4681 - accuracy: 0.4061 - val_loss: 6969.5217 - val_accuracy: 0.4737
Epoch 9/500
11/11 - 3s - loss: 5253.2154 - accuracy: 0.4727 - val_loss: 5795.5466 - val_accuracy: 0.2632
Epoch 10/500
11/11 - 3s - loss: 1818.9111 - accuracy: 0.5152 - val_loss: 922.9483 - val_accuracy: 0.4211
Epoch 11/500
11/11 - 3s - loss: 947.0767 - accuracy: 0.4727 - val_loss: 667.3428 - val_accuracy: 0.5263
Epoch 00011: early stopping
  0/250 [..............................] - ETA: 0s 15/250 [>.............................] - ETA: 1:18 32/250 [==>...........................] - ETA: 1:08 49/250 [====>.........................] - ETA: 1:02 66/250 [======>.......................] - ETA: 56s  83/250 [========>.....................] - ETA: 50s100/250 [===========>..................] - ETA: 45s117/250 [=============>................] - ETA: 40s134/250 [===============>..............] - ETA: 35s151/250 [=================>............] - ETA: 29s168/250 [===================>..........] - ETA: 24s185/250 [=====================>........] - ETA: 19s202/250 [=======================>......] - ETA: 14s219/250 [=========================>....] - ETA: 9s 236/250 [===========================>..] - ETA: 4sMCDO accuracy: 50.9%
MCDO-ensemble accuracy: 61.1%
tf.Tensor(
[[ 0  0 14]
 [ 0  0  7]
 [ 0  0 33]], shape=(3, 3), dtype=int32)
posterior mean: 2
true label: 2

class: 0; proba: 14.8%; var: 35.51% 
class: 1; proba: 12.8%; var: 33.33% 
class: 2; proba: 72.4%; var: 44.66% 
