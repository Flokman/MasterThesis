Random seed for replication: 924
Random seed for replication: 202
augmentation of train set done
augmentation test set done
dataset_name = /Polar_PNG_256.hdf5, batch_size = 8, num_classes = 3, epochs = 500,
        MCDO_PREDICTIONS = 250, MCDO_BATCH_SIZE = 16, test_img_idx = 14,
        train_test_split = 0.8, to_shuffle = True, augmentation = True, train_label_count = [42, 22, 120],
        test_label_count = [14, 7, 33], label_normalizer = False, save_augmentation_to_hdf5 = False, learn rate = 0.01,
        add_dropout_inside = True, train_all_layers = True, weights_to_use = imagenet,
        es_patience = 10, train_val_split = 0.9, MIN_DELTA = 0.005, Early_monitor = val_accuracy
x_train shape: (184, 256, 256, 3)
184 train samples
54 test samples
Model: "model_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 256, 256, 3)]     0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         
_________________________________________________________________
dropout (Dropout)            (None, 128, 128, 64)      0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 64, 64, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 32, 32, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 16, 16, 512)       0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 8, 8, 512)         0         
_________________________________________________________________
flatten (Flatten)            (None, 32768)             0         
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              134221824 
_________________________________________________________________
dropout_5 (Dropout)          (None, 4096)              0         
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312  
_________________________________________________________________
dropout_6 (Dropout)          (None, 4096)              0         
_________________________________________________________________
predictions (Dense)          (None, 3)                 12291     
=================================================================
Total params: 165,730,115
Trainable params: 165,730,115
Non-trainable params: 0
_________________________________________________________________
Start fitting monte carlo dropout model
Train for 21 steps, validate for 3 steps
Epoch 1/500
21/21 - 7s - loss: 59170200134.1903 - accuracy: 0.3273 - val_loss: 108757.6973 - val_accuracy: 0.5789
Epoch 2/500
21/21 - 4s - loss: 256110.3942 - accuracy: 0.5030 - val_loss: 66076.8242 - val_accuracy: 0.2105
Epoch 3/500
21/21 - 4s - loss: 22562.5834 - accuracy: 0.5758 - val_loss: 3358.8088 - val_accuracy: 0.3684
Epoch 4/500
21/21 - 4s - loss: 10932.0016 - accuracy: 0.5576 - val_loss: 1582.5467 - val_accuracy: 0.5263
Epoch 5/500
21/21 - 4s - loss: 15222.4548 - accuracy: 0.4970 - val_loss: 426.5391 - val_accuracy: 0.4737
Epoch 6/500
21/21 - 4s - loss: 4900.8566 - accuracy: 0.5455 - val_loss: 245.3199 - val_accuracy: 0.3684
Epoch 7/500
21/21 - 4s - loss: 474.6667 - accuracy: 0.4485 - val_loss: 1.2249 - val_accuracy: 0.6316
Epoch 8/500
21/21 - 4s - loss: 1.5094 - accuracy: 0.5030 - val_loss: 1.1229 - val_accuracy: 0.6842
Epoch 9/500
21/21 - 4s - loss: 1.0123 - accuracy: 0.5697 - val_loss: 1.5897 - val_accuracy: 0.3158
Epoch 10/500
21/21 - 4s - loss: 1.0330 - accuracy: 0.6121 - val_loss: 1.2026 - val_accuracy: 0.5789
Epoch 11/500
21/21 - 4s - loss: 0.9228 - accuracy: 0.6303 - val_loss: 1.3772 - val_accuracy: 0.6316
Epoch 12/500
21/21 - 4s - loss: 0.9389 - accuracy: 0.6242 - val_loss: 1.1244 - val_accuracy: 0.6842
Epoch 13/500
21/21 - 4s - loss: 0.9543 - accuracy: 0.6485 - val_loss: 1.2480 - val_accuracy: 0.6316
Epoch 14/500
21/21 - 4s - loss: 0.9114 - accuracy: 0.6303 - val_loss: 1.1640 - val_accuracy: 0.5789
Epoch 15/500
21/21 - 4s - loss: 0.8981 - accuracy: 0.6424 - val_loss: 1.1601 - val_accuracy: 0.6316
Epoch 16/500
21/21 - 4s - loss: 0.9724 - accuracy: 0.6545 - val_loss: 1.1625 - val_accuracy: 0.6316
Epoch 17/500
21/21 - 4s - loss: 0.8784 - accuracy: 0.6545 - val_loss: 0.9386 - val_accuracy: 0.6316
Epoch 18/500
21/21 - 4s - loss: 0.8634 - accuracy: 0.6545 - val_loss: 1.0936 - val_accuracy: 0.6316
Epoch 00018: early stopping
  0/250 [..............................] - ETA: 0s 13/250 [>.............................] - ETA: 1:32 30/250 [==>...........................] - ETA: 1:14 47/250 [====>.........................] - ETA: 1:05 64/250 [======>.......................] - ETA: 58s  81/250 [========>.....................] - ETA: 52s 98/250 [==========>...................] - ETA: 47s115/250 [============>.................] - ETA: 41s132/250 [==============>...............] - ETA: 36s149/250 [================>.............] - ETA: 30s166/250 [==================>...........] - ETA: 25s183/250 [====================>.........] - ETA: 20s200/250 [=======================>......] - ETA: 15s217/250 [=========================>....] - ETA: 10s234/250 [===========================>..] - ETA: 4s MCDO accuracy: 57.9%
MCDO-ensemble accuracy: 59.3%
tf.Tensor(
[[ 0  0 14]
 [ 0  0  7]
 [ 1  0 32]], shape=(3, 3), dtype=int32)
posterior mean: 2
true label: 1

class: 0; proba: 2.0%; var: 14.00% 
class: 1; proba: 1.2%; var: 10.89% 
class: 2; proba: 96.8%; var: 17.60% 
