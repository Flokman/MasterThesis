
The following have been reloaded with a version change:
  1) FFTW/3.3.8-gompic-2019b => FFTW/3.3.8-gompi-2019b
  2) OpenMPI/3.1.4-gcccuda-2019b => OpenMPI/3.1.4-GCC-8.3.0
  3) ScaLAPACK/2.0.2-gompic-2019b => ScaLAPACK/2.0.2-gompi-2019b
  4) SciPy-bundle/2019.10-fosscuda-2019b-Python-3.7.4 => SciPy-bundle/2019.10-foss-2019b-Python-3.7.4

2020-05-14 11:45:45.105193: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-14 11:45:57.430732: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-05-14 11:45:57.450599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 11:45:57.451217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-14 11:45:57.451295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-14 11:45:57.457314: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-14 11:45:57.461028: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-14 11:45:57.462463: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-14 11:45:57.466038: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-14 11:45:57.468246: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-14 11:45:57.473956: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-14 11:45:57.474144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 11:45:57.474766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 11:45:57.475159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-05-14 11:45:57.477848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 11:45:57.478303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-14 11:45:57.478355: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-14 11:45:57.478389: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-14 11:45:57.478411: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-14 11:45:57.478432: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-14 11:45:57.478452: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-14 11:45:57.478472: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-14 11:45:57.478492: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-14 11:45:57.478614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 11:45:57.479077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 11:45:57.479454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-05-14 11:45:57.479503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-14 11:45:58.134161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-14 11:45:58.134271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-05-14 11:45:58.134288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-05-14 11:45:58.134579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 11:45:58.135229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 11:45:58.135778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 11:45:58.136233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28652 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2020-05-14 11:45:58.136554: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-14 11:46:03.321385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-14 11:46:03.606412: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-14 11:46:09.504464: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-14 11:46:09.504609: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1259] Profiler found 1 GPUs
2020-05-14 11:46:09.507095: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1
2020-05-14 11:46:09.607701: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-05-14 11:46:09.608289: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-05-14 11:46:10.003895: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-14 11:46:10.003989: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
main
loaded data
dataset_name = /Messidor2_PNG_AUG_256.hdf5, batch_size = 64, num_classes = 5, epochs = 500,
        MCDO_amount_of_predictions = 256, MCDO_batch_size = 250, test_img_idx = 80,
        train_test_split = 0.7, to_shuffle = False, augmentation = False, label_count = [840, 840, 839, 838, 836],
        label_normalizer = False, save_augmentation_to_hdf5 = True, learn rate = 1e-05,
        add_dropout_inside = True, train_all_layers = True, weights_to_use = imagenet,
        mcdo = True, es_patience = 50, train_val_split = 0.33, Dropoutrates: [0.05, 0.1, 0.15, 0.2, 0.2, 0.2, 0.25, 0.25], MIN_DELTA = 0.005, Early_monitor = val_accuracy
x_train shape: (4193, 256, 256, 3)
4193 train samples
158 test samples
Model: "model_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 256, 256, 3)]     0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         
_________________________________________________________________
dropout (Dropout)            (None, 128, 128, 64)      0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 64, 64, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 32, 32, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 16, 16, 512)       0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 8, 8, 512)         0         
_________________________________________________________________
flatten (Flatten)            (None, 32768)             0         
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              134221824 
_________________________________________________________________
dropout_5 (Dropout)          (None, 4096)              0         
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312  
_________________________________________________________________
dropout_6 (Dropout)          (None, 4096)              0         
_________________________________________________________________
predictions (Dense)          (None, 5)                 20485     
=================================================================
Total params: 165,738,309
Trainable params: 165,738,309
Non-trainable params: 0
_________________________________________________________________
Start fitting monte carlo dropout model
Train for 66 steps, validate for 6 steps
Epoch 1/500
66/66 - 42s - loss: 1.6417 - accuracy: 0.2528 - val_loss: 1.1991 - val_accuracy: 0.5504
Epoch 2/500
66/66 - 31s - loss: 1.4485 - accuracy: 0.3701 - val_loss: 0.9762 - val_accuracy: 0.6076
Epoch 3/500
66/66 - 27s - loss: 1.2943 - accuracy: 0.4701 - val_loss: 1.0421 - val_accuracy: 0.5913
Epoch 4/500
66/66 - 27s - loss: 1.1570 - accuracy: 0.5209 - val_loss: 1.0476 - val_accuracy: 0.5804
Epoch 5/500
66/66 - 27s - loss: 1.0226 - accuracy: 0.5922 - val_loss: 1.0170 - val_accuracy: 0.5831
Epoch 6/500
66/66 - 27s - loss: 0.9046 - accuracy: 0.6370 - val_loss: 1.0807 - val_accuracy: 0.5858
Epoch 7/500
66/66 - 27s - loss: 0.7782 - accuracy: 0.6928 - val_loss: 1.0557 - val_accuracy: 0.6022
Epoch 8/500
66/66 - 27s - loss: 0.6953 - accuracy: 0.7262 - val_loss: 1.1120 - val_accuracy: 0.6022
Epoch 9/500
66/66 - 27s - loss: 0.6109 - accuracy: 0.7617 - val_loss: 1.0859 - val_accuracy: 0.5858
Epoch 10/500
66/66 - 27s - loss: 0.5536 - accuracy: 0.7780 - val_loss: 1.0733 - val_accuracy: 0.5886
Epoch 11/500
66/66 - 27s - loss: 0.4853 - accuracy: 0.8121 - val_loss: 1.1443 - val_accuracy: 0.5804
Epoch 12/500
66/66 - 27s - loss: 0.4626 - accuracy: 0.8202 - val_loss: 1.1740 - val_accuracy: 0.5940
Epoch 13/500
66/66 - 27s - loss: 0.3969 - accuracy: 0.8502 - val_loss: 1.1384 - val_accuracy: 0.5940
Epoch 14/500
66/66 - 27s - loss: 0.3705 - accuracy: 0.8583 - val_loss: 1.2735 - val_accuracy: 0.5804
Epoch 15/500
66/66 - 27s - loss: 0.3337 - accuracy: 0.8705 - val_loss: 1.2517 - val_accuracy: 0.5749
Epoch 16/500
66/66 - 27s - loss: 0.3001 - accuracy: 0.8827 - val_loss: 1.3449 - val_accuracy: 0.5967
Epoch 17/500
66/66 - 27s - loss: 0.2742 - accuracy: 0.8982 - val_loss: 1.2514 - val_accuracy: 0.6076
Epoch 18/500
66/66 - 27s - loss: 0.2486 - accuracy: 0.9082 - val_loss: 1.2540 - val_accuracy: 0.6049
Epoch 19/500
66/66 - 27s - loss: 0.2355 - accuracy: 0.9127 - val_loss: 1.3763 - val_accuracy: 0.6158
Epoch 20/500
66/66 - 27s - loss: 0.2122 - accuracy: 0.9196 - val_loss: 1.3920 - val_accuracy: 0.6104
Epoch 21/500
66/66 - 27s - loss: 0.2002 - accuracy: 0.9261 - val_loss: 1.4568 - val_accuracy: 0.6022
Epoch 22/500
66/66 - 27s - loss: 0.1768 - accuracy: 0.9361 - val_loss: 1.5148 - val_accuracy: 0.6049
Epoch 23/500
66/66 - 27s - loss: 0.1776 - accuracy: 0.9358 - val_loss: 1.2519 - val_accuracy: 0.6240
Epoch 24/500
66/66 - 27s - loss: 0.1605 - accuracy: 0.9420 - val_loss: 1.3192 - val_accuracy: 0.6049
Epoch 25/500
66/66 - 27s - loss: 0.1474 - accuracy: 0.9459 - val_loss: 1.6271 - val_accuracy: 0.5995
Epoch 26/500
66/66 - 27s - loss: 0.1257 - accuracy: 0.9561 - val_loss: 1.4689 - val_accuracy: 0.6240
Epoch 27/500
66/66 - 27s - loss: 0.1396 - accuracy: 0.9518 - val_loss: 1.3880 - val_accuracy: 0.6213
Epoch 28/500
66/66 - 27s - loss: 0.1177 - accuracy: 0.9575 - val_loss: 1.7296 - val_accuracy: 0.6022
Epoch 29/500
66/66 - 27s - loss: 0.1141 - accuracy: 0.9611 - val_loss: 1.6689 - val_accuracy: 0.6076
Epoch 30/500
66/66 - 27s - loss: 0.1193 - accuracy: 0.9573 - val_loss: 1.5276 - val_accuracy: 0.6049
Epoch 31/500
66/66 - 27s - loss: 0.1039 - accuracy: 0.9635 - val_loss: 1.5991 - val_accuracy: 0.6185
Epoch 32/500
66/66 - 27s - loss: 0.1079 - accuracy: 0.9595 - val_loss: 1.4622 - val_accuracy: 0.6104
Epoch 33/500
66/66 - 27s - loss: 0.1121 - accuracy: 0.9640 - val_loss: 1.5026 - val_accuracy: 0.6349
Epoch 34/500
66/66 - 27s - loss: 0.0942 - accuracy: 0.9678 - val_loss: 1.7642 - val_accuracy: 0.6049
Epoch 35/500
66/66 - 27s - loss: 0.0934 - accuracy: 0.9699 - val_loss: 1.8623 - val_accuracy: 0.6049
Epoch 36/500
66/66 - 27s - loss: 0.0839 - accuracy: 0.9707 - val_loss: 1.8005 - val_accuracy: 0.5831
Epoch 37/500
66/66 - 27s - loss: 0.0834 - accuracy: 0.9692 - val_loss: 1.5579 - val_accuracy: 0.6158
Epoch 38/500
66/66 - 27s - loss: 0.0819 - accuracy: 0.9733 - val_loss: 1.8517 - val_accuracy: 0.5913
Epoch 39/500
66/66 - 27s - loss: 0.0772 - accuracy: 0.9738 - val_loss: 1.7072 - val_accuracy: 0.6076
Epoch 40/500
66/66 - 27s - loss: 0.0706 - accuracy: 0.9764 - val_loss: 1.6935 - val_accuracy: 0.6376
Epoch 41/500
66/66 - 27s - loss: 0.0638 - accuracy: 0.9802 - val_loss: 2.0161 - val_accuracy: 0.6022
Epoch 42/500
66/66 - 27s - loss: 0.0801 - accuracy: 0.9723 - val_loss: 1.9014 - val_accuracy: 0.6049
Epoch 43/500
66/66 - 27s - loss: 0.0701 - accuracy: 0.9738 - val_loss: 1.7737 - val_accuracy: 0.6213
Epoch 44/500
66/66 - 27s - loss: 0.0557 - accuracy: 0.9812 - val_loss: 1.9793 - val_accuracy: 0.6267
Epoch 45/500
66/66 - 27s - loss: 0.0507 - accuracy: 0.9833 - val_loss: 1.8637 - val_accuracy: 0.6213
Epoch 46/500
66/66 - 27s - loss: 0.0488 - accuracy: 0.9831 - val_loss: 2.0832 - val_accuracy: 0.5995
Epoch 47/500
66/66 - 27s - loss: 0.0568 - accuracy: 0.9793 - val_loss: 2.0146 - val_accuracy: 0.6022
Epoch 48/500
66/66 - 27s - loss: 0.0562 - accuracy: 0.9814 - val_loss: 2.1788 - val_accuracy: 0.6158
Epoch 49/500
66/66 - 27s - loss: 0.0614 - accuracy: 0.9778 - val_loss: 1.8252 - val_accuracy: 0.6294
Epoch 50/500
66/66 - 27s - loss: 0.0538 - accuracy: 0.9835 - val_loss: 2.0729 - val_accuracy: 0.6240
Epoch 51/500
66/66 - 27s - loss: 0.0512 - accuracy: 0.9833 - val_loss: 1.9841 - val_accuracy: 0.6185
Epoch 52/500
66/66 - 27s - loss: 0.0537 - accuracy: 0.9795 - val_loss: 2.0778 - val_accuracy: 0.6131
Epoch 53/500
66/66 - 27s - loss: 0.0513 - accuracy: 0.9828 - val_loss: 1.9591 - val_accuracy: 0.6267
Epoch 54/500
66/66 - 27s - loss: 0.0496 - accuracy: 0.9840 - val_loss: 2.0204 - val_accuracy: 0.6104
Epoch 55/500
66/66 - 27s - loss: 0.0487 - accuracy: 0.9843 - val_loss: 1.8251 - val_accuracy: 0.6076
Epoch 56/500
66/66 - 27s - loss: 0.0490 - accuracy: 0.9824 - val_loss: 2.0424 - val_accuracy: 0.5995
Epoch 57/500
66/66 - 27s - loss: 0.0470 - accuracy: 0.9819 - val_loss: 2.0860 - val_accuracy: 0.6267
Epoch 58/500
66/66 - 27s - loss: 0.0479 - accuracy: 0.9835 - val_loss: 2.0923 - val_accuracy: 0.6049
Epoch 59/500
66/66 - 27s - loss: 0.0497 - accuracy: 0.9821 - val_loss: 1.9934 - val_accuracy: 0.6240
Epoch 60/500
66/66 - 27s - loss: 0.0410 - accuracy: 0.9850 - val_loss: 1.9628 - val_accuracy: 0.6458
Epoch 61/500
66/66 - 27s - loss: 0.0394 - accuracy: 0.9857 - val_loss: 2.0055 - val_accuracy: 0.6294
Epoch 62/500
66/66 - 27s - loss: 0.0416 - accuracy: 0.9869 - val_loss: 1.9056 - val_accuracy: 0.6294
Epoch 63/500
66/66 - 27s - loss: 0.0468 - accuracy: 0.9831 - val_loss: 1.9746 - val_accuracy: 0.6267
Epoch 64/500
66/66 - 27s - loss: 0.0343 - accuracy: 0.9876 - val_loss: 2.1064 - val_accuracy: 0.6240
Epoch 65/500
66/66 - 27s - loss: 0.0428 - accuracy: 0.9838 - val_loss: 1.8731 - val_accuracy: 0.6267
Epoch 66/500
66/66 - 27s - loss: 0.0372 - accuracy: 0.9859 - val_loss: 1.9681 - val_accuracy: 0.6376
Epoch 67/500
66/66 - 27s - loss: 0.0416 - accuracy: 0.9845 - val_loss: 1.8280 - val_accuracy: 0.6458
Epoch 68/500
66/66 - 27s - loss: 0.0412 - accuracy: 0.9869 - val_loss: 2.0681 - val_accuracy: 0.6676
Epoch 69/500
66/66 - 27s - loss: 0.0376 - accuracy: 0.9862 - val_loss: 2.2807 - val_accuracy: 0.6349
Epoch 70/500
66/66 - 27s - loss: 0.0472 - accuracy: 0.9835 - val_loss: 2.0194 - val_accuracy: 0.6213
Epoch 71/500
66/66 - 27s - loss: 0.0379 - accuracy: 0.9862 - val_loss: 1.9678 - val_accuracy: 0.6403
Epoch 72/500
66/66 - 27s - loss: 0.0347 - accuracy: 0.9878 - val_loss: 2.1698 - val_accuracy: 0.6158
Epoch 73/500
66/66 - 27s - loss: 0.0328 - accuracy: 0.9857 - val_loss: 2.2299 - val_accuracy: 0.6213
Epoch 74/500
66/66 - 27s - loss: 0.0397 - accuracy: 0.9862 - val_loss: 1.9622 - val_accuracy: 0.6322
Epoch 75/500
66/66 - 27s - loss: 0.0338 - accuracy: 0.9866 - val_loss: 2.3432 - val_accuracy: 0.6185
Epoch 76/500
66/66 - 27s - loss: 0.0339 - accuracy: 0.9883 - val_loss: 2.0658 - val_accuracy: 0.6267
Epoch 77/500
66/66 - 27s - loss: 0.0312 - accuracy: 0.9890 - val_loss: 2.3172 - val_accuracy: 0.6131
Epoch 78/500
66/66 - 27s - loss: 0.0319 - accuracy: 0.9883 - val_loss: 2.1129 - val_accuracy: 0.6294
Epoch 79/500
66/66 - 27s - loss: 0.0372 - accuracy: 0.9847 - val_loss: 2.1399 - val_accuracy: 0.6158
Epoch 80/500
66/66 - 27s - loss: 0.0421 - accuracy: 0.9840 - val_loss: 2.3662 - val_accuracy: 0.6403
Epoch 81/500
66/66 - 27s - loss: 0.0312 - accuracy: 0.9886 - val_loss: 2.2492 - val_accuracy: 0.6267
Epoch 82/500
66/66 - 27s - loss: 0.0336 - accuracy: 0.9874 - val_loss: 1.9521 - val_accuracy: 0.6376
Epoch 83/500
66/66 - 27s - loss: 0.0305 - accuracy: 0.9893 - val_loss: 2.1201 - val_accuracy: 0.6458
Epoch 84/500
66/66 - 27s - loss: 0.0319 - accuracy: 0.9874 - val_loss: 2.0386 - val_accuracy: 0.6431
Epoch 85/500
66/66 - 27s - loss: 0.0469 - accuracy: 0.9809 - val_loss: 2.0630 - val_accuracy: 0.6185
Epoch 86/500
66/66 - 27s - loss: 0.0297 - accuracy: 0.9866 - val_loss: 2.1456 - val_accuracy: 0.6431
Epoch 87/500
66/66 - 27s - loss: 0.0287 - accuracy: 0.9897 - val_loss: 2.3460 - val_accuracy: 0.6458
Epoch 88/500
66/66 - 27s - loss: 0.0332 - accuracy: 0.9857 - val_loss: 2.5652 - val_accuracy: 0.6158
Epoch 89/500
66/66 - 27s - loss: 0.0311 - accuracy: 0.9864 - val_loss: 2.1460 - val_accuracy: 0.6294
Epoch 90/500
66/66 - 27s - loss: 0.0283 - accuracy: 0.9878 - val_loss: 2.2471 - val_accuracy: 0.6403
Epoch 91/500
66/66 - 27s - loss: 0.0340 - accuracy: 0.9890 - val_loss: 2.0521 - val_accuracy: 0.6076
Epoch 92/500
66/66 - 27s - loss: 0.0416 - accuracy: 0.9855 - val_loss: 1.7505 - val_accuracy: 0.6431
Epoch 93/500
66/66 - 27s - loss: 0.0327 - accuracy: 0.9876 - val_loss: 2.1409 - val_accuracy: 0.6349
Epoch 94/500
66/66 - 27s - loss: 0.0292 - accuracy: 0.9893 - val_loss: 2.0420 - val_accuracy: 0.6458
Epoch 95/500
66/66 - 27s - loss: 0.0280 - accuracy: 0.9888 - val_loss: 2.1267 - val_accuracy: 0.6485
Epoch 96/500
66/66 - 27s - loss: 0.0311 - accuracy: 0.9886 - val_loss: 1.9006 - val_accuracy: 0.6322
Epoch 97/500
66/66 - 27s - loss: 0.0278 - accuracy: 0.9888 - val_loss: 2.0286 - val_accuracy: 0.6076
Epoch 98/500
66/66 - 27s - loss: 0.0252 - accuracy: 0.9876 - val_loss: 2.3163 - val_accuracy: 0.6403
Epoch 99/500
66/66 - 27s - loss: 0.0267 - accuracy: 0.9886 - val_loss: 1.9794 - val_accuracy: 0.6294
Epoch 100/500
66/66 - 27s - loss: 0.0277 - accuracy: 0.9881 - val_loss: 2.0009 - val_accuracy: 0.6213
Epoch 101/500
66/66 - 27s - loss: 0.0269 - accuracy: 0.9897 - val_loss: 2.1984 - val_accuracy: 0.6267
Epoch 102/500
66/66 - 27s - loss: 0.0269 - accuracy: 0.9881 - val_loss: 2.2251 - val_accuracy: 0.6322
Epoch 103/500
66/66 - 27s - loss: 0.0405 - accuracy: 0.9826 - val_loss: 2.0702 - val_accuracy: 0.6376
Epoch 104/500
66/66 - 27s - loss: 0.0304 - accuracy: 0.9883 - val_loss: 2.6852 - val_accuracy: 0.5940
Epoch 105/500
66/66 - 27s - loss: 0.0412 - accuracy: 0.9864 - val_loss: 2.1070 - val_accuracy: 0.6512
Epoch 106/500
66/66 - 27s - loss: 0.0364 - accuracy: 0.9859 - val_loss: 2.1811 - val_accuracy: 0.6376
Epoch 107/500
66/66 - 27s - loss: 0.0237 - accuracy: 0.9914 - val_loss: 2.3484 - val_accuracy: 0.6267
Epoch 108/500
66/66 - 27s - loss: 0.0231 - accuracy: 0.9907 - val_loss: 2.2590 - val_accuracy: 0.6349
Epoch 109/500
66/66 - 27s - loss: 0.0327 - accuracy: 0.9857 - val_loss: 2.2359 - val_accuracy: 0.6322
Epoch 110/500
66/66 - 27s - loss: 0.0376 - accuracy: 0.9847 - val_loss: 2.0090 - val_accuracy: 0.6376
Epoch 111/500
66/66 - 27s - loss: 0.0246 - accuracy: 0.9902 - val_loss: 2.1466 - val_accuracy: 0.6376
Epoch 112/500
66/66 - 27s - loss: 0.0210 - accuracy: 0.9905 - val_loss: 2.2642 - val_accuracy: 0.6267
Epoch 113/500
66/66 - 27s - loss: 0.0293 - accuracy: 0.9874 - val_loss: 2.1369 - val_accuracy: 0.6104
Epoch 114/500
66/66 - 27s - loss: 0.0280 - accuracy: 0.9902 - val_loss: 2.2588 - val_accuracy: 0.6294
Epoch 115/500
66/66 - 27s - loss: 0.0251 - accuracy: 0.9900 - val_loss: 2.2582 - val_accuracy: 0.6458
Epoch 116/500
66/66 - 27s - loss: 0.0260 - accuracy: 0.9902 - val_loss: 2.4439 - val_accuracy: 0.6376
Epoch 117/500
66/66 - 27s - loss: 0.0223 - accuracy: 0.9900 - val_loss: 2.2799 - val_accuracy: 0.6213
Epoch 118/500
66/66 - 27s - loss: 0.0194 - accuracy: 0.9905 - val_loss: 2.2188 - val_accuracy: 0.6213
Epoch 00118: early stopping
  0/256 [..............................] - ETA: 0s  5/256 [..............................] - ETA: 4:16 21/256 [=>............................] - ETA: 1:56 36/256 [===>..........................] - ETA: 1:34 51/256 [====>.........................] - ETA: 1:22 67/256 [======>.......................] - ETA: 1:12 82/256 [========>.....................] - ETA: 1:05 97/256 [==========>...................] - ETA: 59s 112/256 [============>.................] - ETA: 52s128/256 [==============>...............] - ETA: 46s144/256 [===============>..............] - ETA: 40s160/256 [=================>............] - ETA: 34s175/256 [===================>..........] - ETA: 28s190/256 [=====================>........] - ETA: 23s205/256 [=======================>......] - ETA: 17s221/256 [========================>.....] - ETA: 12s236/256 [==========================>...] - ETA: 6s 251/256 [============================>.] - ETA: 1sMCDO accuracy: 62.7%
MCDO-ensemble accuracy: 65.2%
tf.Tensor(
[[92  7  6  1  1]
 [12  1  5  0  0]
 [13  0  8  2  0]
 [ 3  0  2  2  0]
 [ 1  0  1  1  0]], shape=(5, 5), dtype=int32)
posterior mean: 2
true label: 2

class: 0; proba: 32.5%; var: 46.53% 
class: 1; proba: 11.9%; var: 32.20% 
class: 2; proba: 55.6%; var: 49.32% 
class: 3; proba: 0.0%; var: 0.00% 
class: 4; proba: 0.0%; var: 0.00% 


###############################################################################
Peregrine Cluster
Job 11450989 for user 's2934833'
Finished at: Thu May 14 12:40:59 CEST 2020

Job details:
============

Name                : MESDO
User                : s2934833
Partition           : gpu
Nodes               : pg-gpu14
Cores               : 12
State               : COMPLETED
Submit              : 2020-05-14T11:38:26
Start               : 2020-05-14T11:45:39
End                 : 2020-05-14T12:40:58
Reserved walltime   : 03:00:00
Used walltime       : 00:55:19
Used CPU time       : 00:44:51 (efficiency:  6.76%)
% User (Computation): 67.42%
% System (I/O)      : 32.58%
Mem reserved        : 62.50G/node
Max Mem used        : 7.95G (pg-gpu14)
Max Disk Write      : 153.60K (pg-gpu14)
Max Disk Read       : 5.83M (pg-gpu14)
Average GPU usage   : 92.9% (pg-gpu14)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/additional_information/scientific_output

################################################################################
