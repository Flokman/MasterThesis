
The following have been reloaded with a version change:
  1) FFTW/3.3.8-gompic-2019b => FFTW/3.3.8-gompi-2019b
  2) OpenMPI/3.1.4-gcccuda-2019b => OpenMPI/3.1.4-GCC-8.3.0
  3) ScaLAPACK/2.0.2-gompic-2019b => ScaLAPACK/2.0.2-gompi-2019b
  4) SciPy-bundle/2019.10-fosscuda-2019b-Python-3.7.4 => SciPy-bundle/2019.10-foss-2019b-Python-3.7.4

2020-03-16 12:16:05.078845: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-16 12:16:19.980310: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-16 12:16:19.989591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-16 12:16:19.990238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-03-16 12:16:19.990300: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-16 12:16:19.996963: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-16 12:16:20.001488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-16 12:16:20.003574: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-16 12:16:20.007732: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-16 12:16:20.010334: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-16 12:16:20.016164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-16 12:16:20.016416: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-16 12:16:20.017121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-16 12:16:20.017628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-16 12:16:20.021507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-16 12:16:20.021994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-03-16 12:16:20.022049: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-16 12:16:20.022104: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-16 12:16:20.022129: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-16 12:16:20.022150: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-16 12:16:20.022171: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-16 12:16:20.022192: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-16 12:16:20.022213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-16 12:16:20.022366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-16 12:16:20.022986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-16 12:16:20.023433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-16 12:16:20.023494: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-16 12:16:20.773140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-16 12:16:20.773271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-16 12:16:20.773288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-16 12:16:20.773718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-16 12:16:20.774522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-16 12:16:20.775061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-16 12:16:20.775621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28652 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2020-03-16 12:16:20.776082: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
2020-03-16 12:16:25.473412: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-16 12:16:25.761851: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-16 12:16:27.807584: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-03-16 12:16:27.807754: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1259] Profiler found 1 GPUs
2020-03-16 12:16:27.811279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1
2020-03-16 12:16:27.911964: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-03-16 12:16:27.912690: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-03-16 12:16:27.931220: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-03-16 12:16:27.931375: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
dataset_name = CIFAR10, batch_size = 32, num_classes = 10, epochs = 500,
        MCDO_amount_of_predictions = 50, MCDO_batch_size = 250, test_img_idx = 3612,
        train_test_split = 0.8, to_shuffle = True, augmentation = False,
        label_normalizer = True, save_augmentation_to_hdf5 = True, learn rate = 1e-05,
        add_dropout_inside = True, train_all_layers = True, weights_to_use = imagenet,
        mcdo = True, es_patience = 50, train_val_split = 0.9
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 test samples
Model: "model_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         
_________________________________________________________________
dropout (Dropout)            (None, 16, 16, 64)        0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 8, 8, 128)         0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 4, 4, 256)         0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 2, 2, 512)         0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 1, 1, 512)         0         
_________________________________________________________________
flatten (Flatten)            (None, 512)               0         
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              2101248   
_________________________________________________________________
dropout_5 (Dropout)          (None, 4096)              0         
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312  
_________________________________________________________________
dropout_6 (Dropout)          (None, 4096)              0         
_________________________________________________________________
predictions (Dense)          (None, 10)                40970     
=================================================================
Total params: 33,638,218
Trainable params: 33,638,218
Non-trainable params: 0
_________________________________________________________________
Start fitting monte carlo dropout model
Train for 1407 steps, validate for 157 steps
Epoch 1/500
1407/1407 - 26s - loss: 1.3632 - accuracy: 0.5120 - val_loss: 0.8889 - val_accuracy: 0.6948
Epoch 2/500
1407/1407 - 20s - loss: 0.8786 - accuracy: 0.6989 - val_loss: 0.6982 - val_accuracy: 0.7584
Epoch 3/500
1407/1407 - 20s - loss: 0.7389 - accuracy: 0.7489 - val_loss: 0.6245 - val_accuracy: 0.7842
Epoch 4/500
1407/1407 - 20s - loss: 0.6512 - accuracy: 0.7767 - val_loss: 0.5837 - val_accuracy: 0.8020
Epoch 5/500
1407/1407 - 20s - loss: 0.5834 - accuracy: 0.8012 - val_loss: 0.5485 - val_accuracy: 0.8128
Epoch 6/500
1407/1407 - 20s - loss: 0.5240 - accuracy: 0.8196 - val_loss: 0.5123 - val_accuracy: 0.8266
Epoch 7/500
1407/1407 - 20s - loss: 0.4787 - accuracy: 0.8361 - val_loss: 0.5080 - val_accuracy: 0.8278
Epoch 8/500
1407/1407 - 20s - loss: 0.4388 - accuracy: 0.8491 - val_loss: 0.4917 - val_accuracy: 0.8308
Epoch 9/500
1407/1407 - 20s - loss: 0.3977 - accuracy: 0.8635 - val_loss: 0.4715 - val_accuracy: 0.8410
Epoch 10/500
1407/1407 - 20s - loss: 0.3646 - accuracy: 0.8745 - val_loss: 0.4626 - val_accuracy: 0.8392
Epoch 11/500
1407/1407 - 20s - loss: 0.3302 - accuracy: 0.8870 - val_loss: 0.4598 - val_accuracy: 0.8512
Epoch 12/500
1407/1407 - 20s - loss: 0.2986 - accuracy: 0.8974 - val_loss: 0.4991 - val_accuracy: 0.8486
Epoch 13/500
1407/1407 - 20s - loss: 0.2713 - accuracy: 0.9076 - val_loss: 0.4806 - val_accuracy: 0.8502
Epoch 14/500
1407/1407 - 20s - loss: 0.2535 - accuracy: 0.9140 - val_loss: 0.4760 - val_accuracy: 0.8552
Epoch 15/500
1407/1407 - 20s - loss: 0.2219 - accuracy: 0.9226 - val_loss: 0.4864 - val_accuracy: 0.8586
Epoch 16/500
1407/1407 - 20s - loss: 0.2003 - accuracy: 0.9304 - val_loss: 0.4880 - val_accuracy: 0.8524
Epoch 17/500
1407/1407 - 20s - loss: 0.1855 - accuracy: 0.9356 - val_loss: 0.4972 - val_accuracy: 0.8568
Epoch 18/500
1407/1407 - 20s - loss: 0.1688 - accuracy: 0.9414 - val_loss: 0.4971 - val_accuracy: 0.8582
Epoch 19/500
1407/1407 - 20s - loss: 0.1516 - accuracy: 0.9487 - val_loss: 0.5025 - val_accuracy: 0.8600
Epoch 20/500
1407/1407 - 20s - loss: 0.1406 - accuracy: 0.9510 - val_loss: 0.5107 - val_accuracy: 0.8570
Epoch 21/500
1407/1407 - 20s - loss: 0.1282 - accuracy: 0.9562 - val_loss: 0.5205 - val_accuracy: 0.8630
Epoch 22/500
1407/1407 - 20s - loss: 0.1197 - accuracy: 0.9592 - val_loss: 0.5245 - val_accuracy: 0.8580
Epoch 23/500
1407/1407 - 20s - loss: 0.1025 - accuracy: 0.9654 - val_loss: 0.5401 - val_accuracy: 0.8632
Epoch 24/500
1407/1407 - 20s - loss: 0.0957 - accuracy: 0.9672 - val_loss: 0.6116 - val_accuracy: 0.8592
Epoch 25/500
1407/1407 - 20s - loss: 0.0872 - accuracy: 0.9703 - val_loss: 0.5781 - val_accuracy: 0.8578
Epoch 26/500
1407/1407 - 20s - loss: 0.0838 - accuracy: 0.9720 - val_loss: 0.5771 - val_accuracy: 0.8588
Epoch 27/500
1407/1407 - 20s - loss: 0.0804 - accuracy: 0.9727 - val_loss: 0.5608 - val_accuracy: 0.8644
Epoch 28/500
1407/1407 - 20s - loss: 0.0740 - accuracy: 0.9752 - val_loss: 0.6165 - val_accuracy: 0.8600
Epoch 29/500
1407/1407 - 20s - loss: 0.0687 - accuracy: 0.9763 - val_loss: 0.6346 - val_accuracy: 0.8556
Epoch 30/500
1407/1407 - 20s - loss: 0.0625 - accuracy: 0.9787 - val_loss: 0.6196 - val_accuracy: 0.8634
Epoch 31/500
1407/1407 - 20s - loss: 0.0603 - accuracy: 0.9792 - val_loss: 0.6134 - val_accuracy: 0.8628
Epoch 32/500
1407/1407 - 20s - loss: 0.0557 - accuracy: 0.9815 - val_loss: 0.6577 - val_accuracy: 0.8652
Epoch 33/500
1407/1407 - 20s - loss: 0.0532 - accuracy: 0.9820 - val_loss: 0.6715 - val_accuracy: 0.8560
Epoch 34/500
1407/1407 - 20s - loss: 0.0518 - accuracy: 0.9827 - val_loss: 0.6734 - val_accuracy: 0.8634
Epoch 35/500
1407/1407 - 20s - loss: 0.0487 - accuracy: 0.9832 - val_loss: 0.6843 - val_accuracy: 0.8602
Epoch 36/500
1407/1407 - 20s - loss: 0.0461 - accuracy: 0.9852 - val_loss: 0.6440 - val_accuracy: 0.8632
Epoch 37/500
1407/1407 - 20s - loss: 0.0452 - accuracy: 0.9841 - val_loss: 0.6586 - val_accuracy: 0.8664
Epoch 38/500
1407/1407 - 20s - loss: 0.0429 - accuracy: 0.9859 - val_loss: 0.6666 - val_accuracy: 0.8584
Epoch 39/500
1407/1407 - 20s - loss: 0.0433 - accuracy: 0.9859 - val_loss: 0.6674 - val_accuracy: 0.8618
Epoch 40/500
1407/1407 - 20s - loss: 0.0397 - accuracy: 0.9860 - val_loss: 0.6796 - val_accuracy: 0.8666
Epoch 41/500
1407/1407 - 20s - loss: 0.0397 - accuracy: 0.9862 - val_loss: 0.6343 - val_accuracy: 0.8678
Epoch 42/500
1407/1407 - 20s - loss: 0.0372 - accuracy: 0.9872 - val_loss: 0.6924 - val_accuracy: 0.8586
Epoch 43/500
1407/1407 - 20s - loss: 0.0332 - accuracy: 0.9888 - val_loss: 0.6789 - val_accuracy: 0.8718
Epoch 44/500
1407/1407 - 20s - loss: 0.0354 - accuracy: 0.9884 - val_loss: 0.6760 - val_accuracy: 0.8622
Epoch 45/500
1407/1407 - 20s - loss: 0.0350 - accuracy: 0.9886 - val_loss: 0.6860 - val_accuracy: 0.8694
Epoch 46/500
1407/1407 - 20s - loss: 0.0327 - accuracy: 0.9894 - val_loss: 0.7066 - val_accuracy: 0.8620
Epoch 47/500
1407/1407 - 20s - loss: 0.0301 - accuracy: 0.9901 - val_loss: 0.6995 - val_accuracy: 0.8662
Epoch 48/500
1407/1407 - 20s - loss: 0.0327 - accuracy: 0.9893 - val_loss: 0.6837 - val_accuracy: 0.8700
Epoch 49/500
1407/1407 - 20s - loss: 0.0274 - accuracy: 0.9906 - val_loss: 0.7349 - val_accuracy: 0.8674
Epoch 50/500
1407/1407 - 20s - loss: 0.0302 - accuracy: 0.9902 - val_loss: 0.6932 - val_accuracy: 0.8684
Epoch 51/500
1407/1407 - 20s - loss: 0.0259 - accuracy: 0.9917 - val_loss: 0.7278 - val_accuracy: 0.8640
Epoch 52/500
1407/1407 - 20s - loss: 0.0269 - accuracy: 0.9909 - val_loss: 0.7022 - val_accuracy: 0.8690
Epoch 53/500
1407/1407 - 20s - loss: 0.0290 - accuracy: 0.9905 - val_loss: 0.7170 - val_accuracy: 0.8696
Epoch 54/500
1407/1407 - 20s - loss: 0.0267 - accuracy: 0.9913 - val_loss: 0.6863 - val_accuracy: 0.8676
Epoch 55/500
1407/1407 - 20s - loss: 0.0245 - accuracy: 0.9923 - val_loss: 0.7390 - val_accuracy: 0.8642
Epoch 56/500
1407/1407 - 20s - loss: 0.0238 - accuracy: 0.9923 - val_loss: 0.7151 - val_accuracy: 0.8714
Epoch 57/500
1407/1407 - 20s - loss: 0.0233 - accuracy: 0.9924 - val_loss: 0.7665 - val_accuracy: 0.8604
Epoch 58/500
1407/1407 - 20s - loss: 0.0251 - accuracy: 0.9917 - val_loss: 0.7112 - val_accuracy: 0.8674
Epoch 59/500
1407/1407 - 20s - loss: 0.0241 - accuracy: 0.9920 - val_loss: 0.7889 - val_accuracy: 0.8630
Epoch 60/500
1407/1407 - 20s - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.7163 - val_accuracy: 0.8642
Epoch 61/500
1407/1407 - 20s - loss: 0.0208 - accuracy: 0.9926 - val_loss: 0.7585 - val_accuracy: 0.8646
Epoch 00061: early stopping
 0/50 [..............................] - ETA: 0sWARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
 9/50 [====>.........................] - ETA: 25s19/50 [==========>...................] - ETA: 17s29/50 [================>.............] - ETA: 11s39/50 [======================>.......] - ETA: 6s 49/50 [============================>.] - ETA: 0sMCDO accuracy: 70.6%
MCDO-ensemble accuracy: 70.9%
tf.Tensor(
[[966  13   3   0   0   0   0   5   9   4]
 [ 16 961   0   1   0   0   0   0   5  17]
 [153  29 710  35   0  47   2  20   4   0]
 [ 90  53  39 557   0 169  12  58   9  13]
 [207  86  82 126 115 161  15 196   6   6]
 [ 48  21  17 106   0 742   1  63   1   1]
 [ 45 142  54  48   0  86 592  12  15   6]
 [ 35  16  10  13   0  27   0 897   1   1]
 [166  61   5   0   0   1   0   3 747  17]
 [ 63 117   1   0   0   1   1  12   3 802]], shape=(10, 10), dtype=int32)
posterior mean: 1
true label: 1

class: 0; proba: 0.0%; var: 0.00% 
class: 1; proba: 100.0%; var: 0.00% 
class: 2; proba: 0.0%; var: 0.00% 
class: 3; proba: 0.0%; var: 0.00% 
class: 4; proba: 0.0%; var: 0.00% 
class: 5; proba: 0.0%; var: 0.00% 
class: 6; proba: 0.0%; var: 0.00% 
class: 7; proba: 0.0%; var: 0.00% 
class: 8; proba: 0.0%; var: 0.00% 
class: 9; proba: 0.0%; var: 0.00% 


###############################################################################
Peregrine Cluster
Job 10127913 for user 's2934833'
Finished at: Mon Mar 16 12:37:23 CET 2020

Job details:
============

Name                : CIFDO
User                : s2934833
Partition           : gpu
Nodes               : pg-gpu25
Cores               : 12
State               : COMPLETED
Submit              : 2020-03-16T10:38:39
Start               : 2020-03-16T12:15:56
End                 : 2020-03-16T12:37:23
Reserved walltime   : 03:00:00
Used walltime       : 00:21:27
Used CPU time       : 00:22:08 (efficiency:  8.60%)
% User (Computation): 79.33%
% System (I/O)      : 20.67%
Mem reserved        : 62.50G/node
Max Mem used        : 3.23G (pg-gpu25)
Max Disk Write      : 153.60K (pg-gpu25)
Max Disk Read       : 5.35M (pg-gpu25)
Average GPU usage   : 70.5% (pg-gpu25)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/additional_information/scientific_output

################################################################################
