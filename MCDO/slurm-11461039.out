
The following have been reloaded with a version change:
  1) FFTW/3.3.8-gompic-2019b => FFTW/3.3.8-gompi-2019b
  2) OpenMPI/3.1.4-gcccuda-2019b => OpenMPI/3.1.4-GCC-8.3.0
  3) ScaLAPACK/2.0.2-gompic-2019b => ScaLAPACK/2.0.2-gompi-2019b
  4) SciPy-bundle/2019.10-fosscuda-2019b-Python-3.7.4 => SciPy-bundle/2019.10-foss-2019b-Python-3.7.4

2020-05-14 15:55:59.165720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-14 15:56:14.340433: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-05-14 15:56:14.349656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 15:56:14.350233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-14 15:56:14.350318: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-14 15:56:14.357664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-14 15:56:14.362783: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-14 15:56:14.365159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-14 15:56:14.370519: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-14 15:56:14.374134: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-14 15:56:14.382656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-14 15:56:14.382872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 15:56:14.383506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 15:56:14.383946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-05-14 15:56:14.387518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 15:56:14.387979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.88GiB deviceMemoryBandwidth: 836.37GiB/s
2020-05-14 15:56:14.388048: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-14 15:56:14.388100: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-14 15:56:14.388131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-14 15:56:14.388159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-14 15:56:14.388187: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-14 15:56:14.388215: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-14 15:56:14.388242: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-14 15:56:14.388395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 15:56:14.388929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 15:56:14.389364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-05-14 15:56:14.389447: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-14 15:56:15.255907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-14 15:56:15.256034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-05-14 15:56:15.256054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-05-14 15:56:15.256428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 15:56:15.257190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 15:56:15.257826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-14 15:56:15.258332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28652 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2020-05-14 15:56:15.258753: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2020-05-14 15:56:21.012678: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-14 15:56:21.314284: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-14 15:56:27.260721: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-05-14 15:56:27.260864: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1259] Profiler found 1 GPUs
2020-05-14 15:56:27.270489: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1
2020-05-14 15:56:27.371227: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-05-14 15:56:27.371775: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_VIRTUALIZED_DEVICE_NOT_SUPPORTED
2020-05-14 15:56:27.766872: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER
2020-05-14 15:56:27.766995: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
main
loaded data
label count validation:  [112, 28, 30, 1, 2]
label count test:  [209, 52, 68, 16, 7]
dataset_name = /Messidor2_PNG_AUG_256.hdf5, batch_size = 64, num_classes = 5, epochs = 500,
        MCDO_amount_of_predictions = 256, MCDO_batch_size = 250, test_img_idx = 225,
        train_test_split = 0.7, to_shuffle = False, augmentation = False, label_count = [209, 52, 68, 16, 7],
        label_normalizer = False, save_augmentation_to_hdf5 = True, learn rate = 1e-05,
        add_dropout_inside = True, train_all_layers = True, weights_to_use = imagenet,
        mcdo = True, es_patience = 50, train_val_split = 0.33, Dropoutrates: [0.05, 0.1, 0.15, 0.2, 0.2, 0.2, 0.25, 0.25], MIN_DELTA = 0.005, Early_monitor = val_accuracy
x_train shape: (4193, 256, 256, 3)
4193 train samples
352 test samples
Model: "model_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 256, 256, 3)]     0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         
_________________________________________________________________
dropout (Dropout)            (None, 128, 128, 64)      0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 64, 64, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 32, 32, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 16, 16, 512)       0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 8, 8, 512)         0         
_________________________________________________________________
flatten (Flatten)            (None, 32768)             0         
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              134221824 
_________________________________________________________________
dropout_5 (Dropout)          (None, 4096)              0         
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312  
_________________________________________________________________
dropout_6 (Dropout)          (None, 4096)              0         
_________________________________________________________________
predictions (Dense)          (None, 5)                 20485     
=================================================================
Total params: 165,738,309
Trainable params: 165,738,309
Non-trainable params: 0
_________________________________________________________________
Start fitting monte carlo dropout model
Train for 66 steps, validate for 3 steps
Epoch 1/500
66/66 - 43s - loss: 1.6339 - accuracy: 0.2638 - val_loss: 1.1573 - val_accuracy: 0.6185
Epoch 2/500
66/66 - 31s - loss: 1.4474 - accuracy: 0.3723 - val_loss: 0.9189 - val_accuracy: 0.6705
Epoch 3/500
66/66 - 26s - loss: 1.3240 - accuracy: 0.4379 - val_loss: 0.9336 - val_accuracy: 0.6185
Epoch 4/500
66/66 - 31s - loss: 1.2007 - accuracy: 0.5047 - val_loss: 0.9103 - val_accuracy: 0.6590
Epoch 5/500
66/66 - 26s - loss: 1.0738 - accuracy: 0.5645 - val_loss: 0.9589 - val_accuracy: 0.6127
Epoch 6/500
66/66 - 27s - loss: 0.9850 - accuracy: 0.6072 - val_loss: 0.9646 - val_accuracy: 0.6474
Epoch 7/500
66/66 - 31s - loss: 0.8476 - accuracy: 0.6606 - val_loss: 0.9063 - val_accuracy: 0.6647
Epoch 8/500
66/66 - 30s - loss: 0.7277 - accuracy: 0.7098 - val_loss: 0.8637 - val_accuracy: 0.6705
Epoch 9/500
66/66 - 26s - loss: 0.6285 - accuracy: 0.7582 - val_loss: 0.9608 - val_accuracy: 0.6474
Epoch 10/500
66/66 - 26s - loss: 0.5951 - accuracy: 0.7734 - val_loss: 0.8992 - val_accuracy: 0.6590
Epoch 11/500
66/66 - 27s - loss: 0.5110 - accuracy: 0.8052 - val_loss: 0.9633 - val_accuracy: 0.6474
Epoch 12/500
66/66 - 27s - loss: 0.4603 - accuracy: 0.8207 - val_loss: 0.9977 - val_accuracy: 0.6705
Epoch 13/500
66/66 - 27s - loss: 0.4155 - accuracy: 0.8459 - val_loss: 0.9548 - val_accuracy: 0.6821
Epoch 14/500
66/66 - 27s - loss: 0.3685 - accuracy: 0.8638 - val_loss: 0.9667 - val_accuracy: 0.6474
Epoch 15/500
66/66 - 27s - loss: 0.3434 - accuracy: 0.8715 - val_loss: 1.0035 - val_accuracy: 0.6069
Epoch 16/500
66/66 - 27s - loss: 0.3132 - accuracy: 0.8810 - val_loss: 0.9617 - val_accuracy: 0.6358
Epoch 17/500
66/66 - 27s - loss: 0.3009 - accuracy: 0.8879 - val_loss: 1.0401 - val_accuracy: 0.6763
Epoch 18/500
66/66 - 27s - loss: 0.2496 - accuracy: 0.9048 - val_loss: 1.1596 - val_accuracy: 0.6532
Epoch 19/500
66/66 - 27s - loss: 0.2318 - accuracy: 0.9165 - val_loss: 1.0999 - val_accuracy: 0.6879
Epoch 20/500
66/66 - 27s - loss: 0.2183 - accuracy: 0.9175 - val_loss: 1.2171 - val_accuracy: 0.6532
Epoch 21/500
66/66 - 27s - loss: 0.1912 - accuracy: 0.9294 - val_loss: 1.3902 - val_accuracy: 0.6474
Epoch 22/500
66/66 - 27s - loss: 0.1787 - accuracy: 0.9344 - val_loss: 1.2233 - val_accuracy: 0.6301
Epoch 23/500
66/66 - 27s - loss: 0.1701 - accuracy: 0.9375 - val_loss: 1.3169 - val_accuracy: 0.6532
Epoch 24/500
66/66 - 27s - loss: 0.1570 - accuracy: 0.9466 - val_loss: 1.3092 - val_accuracy: 0.6590
Epoch 25/500
66/66 - 27s - loss: 0.1458 - accuracy: 0.9485 - val_loss: 1.2548 - val_accuracy: 0.6474
Epoch 26/500
66/66 - 27s - loss: 0.1538 - accuracy: 0.9480 - val_loss: 1.1500 - val_accuracy: 0.6647
Epoch 27/500
66/66 - 27s - loss: 0.1294 - accuracy: 0.9540 - val_loss: 1.3596 - val_accuracy: 0.6647
Epoch 28/500
66/66 - 27s - loss: 0.1301 - accuracy: 0.9554 - val_loss: 1.4191 - val_accuracy: 0.6474
Epoch 29/500
66/66 - 27s - loss: 0.1179 - accuracy: 0.9623 - val_loss: 1.3404 - val_accuracy: 0.6358
Epoch 30/500
66/66 - 27s - loss: 0.1039 - accuracy: 0.9642 - val_loss: 1.3678 - val_accuracy: 0.6590
Epoch 31/500
66/66 - 27s - loss: 0.1046 - accuracy: 0.9637 - val_loss: 1.4743 - val_accuracy: 0.6474
Epoch 32/500
66/66 - 27s - loss: 0.0928 - accuracy: 0.9690 - val_loss: 1.5171 - val_accuracy: 0.6590
Epoch 33/500
66/66 - 27s - loss: 0.0999 - accuracy: 0.9673 - val_loss: 1.5208 - val_accuracy: 0.6474
Epoch 34/500
66/66 - 27s - loss: 0.0812 - accuracy: 0.9735 - val_loss: 1.6820 - val_accuracy: 0.6532
Epoch 35/500
66/66 - 27s - loss: 0.0777 - accuracy: 0.9740 - val_loss: 1.6866 - val_accuracy: 0.6532
Epoch 36/500
66/66 - 27s - loss: 0.0686 - accuracy: 0.9771 - val_loss: 1.7024 - val_accuracy: 0.6705
Epoch 37/500
66/66 - 27s - loss: 0.0868 - accuracy: 0.9719 - val_loss: 1.4454 - val_accuracy: 0.6358
Epoch 38/500
66/66 - 27s - loss: 0.0744 - accuracy: 0.9728 - val_loss: 1.5132 - val_accuracy: 0.6532
Epoch 39/500
66/66 - 27s - loss: 0.0830 - accuracy: 0.9723 - val_loss: 1.7054 - val_accuracy: 0.6532
Epoch 40/500
66/66 - 27s - loss: 0.0667 - accuracy: 0.9754 - val_loss: 1.7575 - val_accuracy: 0.6474
Epoch 41/500
66/66 - 27s - loss: 0.0642 - accuracy: 0.9773 - val_loss: 1.6196 - val_accuracy: 0.6590
Epoch 42/500
66/66 - 27s - loss: 0.0721 - accuracy: 0.9750 - val_loss: 1.6940 - val_accuracy: 0.6127
Epoch 43/500
66/66 - 27s - loss: 0.0649 - accuracy: 0.9785 - val_loss: 1.6584 - val_accuracy: 0.6069
Epoch 44/500
66/66 - 27s - loss: 0.0552 - accuracy: 0.9812 - val_loss: 1.6684 - val_accuracy: 0.6705
Epoch 45/500
66/66 - 27s - loss: 0.0572 - accuracy: 0.9785 - val_loss: 1.5938 - val_accuracy: 0.6474
Epoch 46/500
66/66 - 27s - loss: 0.0584 - accuracy: 0.9785 - val_loss: 1.6190 - val_accuracy: 0.6532
Epoch 47/500
66/66 - 27s - loss: 0.0586 - accuracy: 0.9802 - val_loss: 1.5967 - val_accuracy: 0.6647
Epoch 48/500
66/66 - 27s - loss: 0.0595 - accuracy: 0.9783 - val_loss: 1.7044 - val_accuracy: 0.6590
Epoch 49/500
66/66 - 27s - loss: 0.0621 - accuracy: 0.9797 - val_loss: 1.6810 - val_accuracy: 0.6416
Epoch 50/500
66/66 - 27s - loss: 0.0497 - accuracy: 0.9824 - val_loss: 1.4753 - val_accuracy: 0.6243
Epoch 51/500
66/66 - 27s - loss: 0.0580 - accuracy: 0.9795 - val_loss: 1.8094 - val_accuracy: 0.6416
Epoch 52/500
66/66 - 27s - loss: 0.0522 - accuracy: 0.9826 - val_loss: 1.4799 - val_accuracy: 0.6416
Epoch 53/500
66/66 - 27s - loss: 0.0503 - accuracy: 0.9826 - val_loss: 1.7325 - val_accuracy: 0.6705
Epoch 54/500
66/66 - 27s - loss: 0.0481 - accuracy: 0.9838 - val_loss: 1.8835 - val_accuracy: 0.6532
Epoch 55/500
66/66 - 27s - loss: 0.0447 - accuracy: 0.9819 - val_loss: 1.7042 - val_accuracy: 0.6301
Epoch 56/500
66/66 - 27s - loss: 0.0449 - accuracy: 0.9852 - val_loss: 1.8219 - val_accuracy: 0.6301
Epoch 57/500
66/66 - 27s - loss: 0.0394 - accuracy: 0.9862 - val_loss: 1.8619 - val_accuracy: 0.6647
Epoch 58/500
66/66 - 27s - loss: 0.0411 - accuracy: 0.9843 - val_loss: 2.0490 - val_accuracy: 0.6416
Epoch 59/500
66/66 - 27s - loss: 0.0410 - accuracy: 0.9871 - val_loss: 1.8011 - val_accuracy: 0.6358
Epoch 60/500
66/66 - 27s - loss: 0.0498 - accuracy: 0.9831 - val_loss: 1.7044 - val_accuracy: 0.6301
Epoch 61/500
66/66 - 27s - loss: 0.0404 - accuracy: 0.9869 - val_loss: 1.9359 - val_accuracy: 0.6127
Epoch 62/500
66/66 - 27s - loss: 0.0484 - accuracy: 0.9843 - val_loss: 1.8862 - val_accuracy: 0.6532
Epoch 63/500
66/66 - 27s - loss: 0.0468 - accuracy: 0.9821 - val_loss: 1.6936 - val_accuracy: 0.6474
Epoch 64/500
66/66 - 27s - loss: 0.0537 - accuracy: 0.9819 - val_loss: 1.9591 - val_accuracy: 0.6358
Epoch 65/500
66/66 - 27s - loss: 0.0381 - accuracy: 0.9876 - val_loss: 1.7468 - val_accuracy: 0.6185
Epoch 66/500
66/66 - 27s - loss: 0.0334 - accuracy: 0.9893 - val_loss: 1.8708 - val_accuracy: 0.6763
Epoch 67/500
66/66 - 27s - loss: 0.0381 - accuracy: 0.9874 - val_loss: 1.9930 - val_accuracy: 0.6647
Epoch 68/500
66/66 - 27s - loss: 0.0378 - accuracy: 0.9864 - val_loss: 1.7542 - val_accuracy: 0.6532
Epoch 69/500
66/66 - 27s - loss: 0.0384 - accuracy: 0.9847 - val_loss: 1.6188 - val_accuracy: 0.6532
Epoch 00069: early stopping
  0/256 [..............................] - ETA: 0s  1/256 [..............................] - ETA: 33:39  8/256 [..............................] - ETA: 6:46  15/256 [>.............................] - ETA: 4:55 22/256 [=>............................] - ETA: 4:10 29/256 [==>...........................] - ETA: 3:45 36/256 [===>..........................] - ETA: 3:27 43/256 [====>.........................] - ETA: 3:14 50/256 [====>.........................] - ETA: 3:03 57/256 [=====>........................] - ETA: 2:53 64/256 [======>.......................] - ETA: 2:44 71/256 [=======>......................] - ETA: 2:36 78/256 [========>.....................] - ETA: 2:29 85/256 [========>.....................] - ETA: 2:22 92/256 [=========>....................] - ETA: 2:15 99/256 [==========>...................] - ETA: 2:08106/256 [===========>..................] - ETA: 2:02113/256 [============>.................] - ETA: 1:55120/256 [=============>................] - ETA: 1:49127/256 [=============>................] - ETA: 1:43134/256 [==============>...............] - ETA: 1:37141/256 [===============>..............] - ETA: 1:31148/256 [================>.............] - ETA: 1:25155/256 [=================>............] - ETA: 1:20162/256 [=================>............] - ETA: 1:14169/256 [==================>...........] - ETA: 1:08176/256 [===================>..........] - ETA: 1:02183/256 [====================>.........] - ETA: 57s 190/256 [=====================>........] - ETA: 51s197/256 [======================>.......] - ETA: 46s204/256 [======================>.......] - ETA: 40s211/256 [=======================>......] - ETA: 35s218/256 [========================>.....] - ETA: 29s225/256 [=========================>....] - ETA: 24s232/256 [==========================>...] - ETA: 18s239/256 [===========================>..] - ETA: 13s246/256 [===========================>..] - ETA: 7s 253/256 [============================>.] - ETA: 2sMCDO accuracy: 52.0%
MCDO-ensemble accuracy: 54.3%
tf.Tensor(
[[157  13  35   0   4]
 [ 35   4  12   1   0]
 [ 29   7  26   2   4]
 [  4   0   6   4   2]
 [  2   0   2   3   0]], shape=(5, 5), dtype=int32)
posterior mean: 2
true label: 0

class: 0; proba: 22.7%; var: 41.54% 
class: 1; proba: 0.0%; var: 0.00% 
class: 2; proba: 77.3%; var: 41.54% 
class: 3; proba: 0.0%; var: 0.00% 
class: 4; proba: 0.0%; var: 0.00% 


###############################################################################
Peregrine Cluster
Job 11461039 for user 's2934833'
Finished at: Thu May 14 16:30:53 CEST 2020

Job details:
============

Name                : MESDO
User                : s2934833
Partition           : gpu
Nodes               : pg-gpu13
Cores               : 12
State               : COMPLETED
Submit              : 2020-05-14T15:45:56
Start               : 2020-05-14T15:55:51
End                 : 2020-05-14T16:30:53
Reserved walltime   : 03:00:00
Used walltime       : 00:35:02
Used CPU time       : 00:29:15 (efficiency:  6.96%)
% User (Computation): 67.18%
% System (I/O)      : 32.82%
Mem reserved        : 62.50G/node
Max Mem used        : 10.12G (pg-gpu13)
Max Disk Write      : 153.60K (pg-gpu13)
Max Disk Read       : 5.83M (pg-gpu13)
Average GPU usage   : 93.2% (pg-gpu13)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/additional_information/scientific_output

################################################################################
